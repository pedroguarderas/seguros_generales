[["introducción.html", "Matemática Actuarial de los Seguros Generales Capítulo 1 Introducción 1.1 Materia 1.2 Resultados de aprendizaje 1.3 Contenidos propuestos 1.4 Referencias bibliográficas", " Matemática Actuarial de los Seguros Generales 2025-04-15 Capítulo 1 Introducción 1.1 Materia Las presentes notas de curso han sido creadas para el curso de Matemática Actuarial de los Seguros Generales el cual es dictado en la Maestría de Ciencias Actuariales que realizan de forma conjunta la “Escuela Politécnica Nacional” (EPN) y la “Pontificia Universidad Católica del Ecuador” (PUCE). La materia está a cargo del actuario Leonardo Vélez Aguirre. Las presentes notas han sido creadas con la motivación de facilitar el aprendizaje a los estudiantes, las mismas conjugan la parte teórica del curso con ejemplos prácticos implementados utilizando el lenguaje R. Estas notas han sido creadas en colaboración entre Leonardo Vélez y Pedro Guarderas. La motivación y objetivo para haber creado estas notas es llegar a generar un buen material de aprendizaje y referencia. En el estado actual, no son aún definitivas, están sujetas a mejoras y correcciones. Sin embargo, será un placer para nosotros que las lean, critiquen y en especial nos hagan llegar sus observaciones y posibles mejoras. 1.2 Resultados de aprendizaje Contrastar los criterios de valoración actuarial en los seguros generales, así como elaborar y aplicar las bases técnicas. Aprender a obtener la distribución y momentos correspondientes de la siniestralidad total pagada por el asegurador y por el reasegurador en presencia de franquicias y reaseguro. Identificar las modificaciones que pueden sufrir los contratos de seguros generales y valorar las consecuencias técnicas de dichas modificaciones. Calcular la función de distribución del coste total de una cartera de pólizas. 1.3 Contenidos propuestos Distribuciones compuestas Series de tiempo El Proceso de Riesgo: Distribución clase (a,b) y algoritmo de Panjer, Distribución de siniestralidad agregada Modelos Lineales Generalizados (GLMs): para datos binarios y recuentos Proceso de Tarificación Tarificación a priori: cálculo de la prima pura Tarificación a posteriori: sistemas Bonus-Malus Teoría de la Ruina 1.4 Referencias bibliográficas Principales libros guía [1], [2], [3], [4], [5], https://nonlifemaths.github.io/. Otras referencias de soporte De utilidad para quien desee profundizar con más detalle en algunos conceptos [6], [7], [8], [9], [10], [11]. GIL FANA: Elementos de Matemáticas para las Ciencias del Seguro. Fundación Mapfre Estudios. 1991 Requerimientos informáticos Lenguaje R Editor de código: RStudio, VScode, … Paquete R actuar [12]. "],["preliminares.html", "Capítulo 2 Preliminares 2.1 Notación matemática 2.2 Consideraciones de programación en R", " Capítulo 2 Preliminares 2.1 Notación matemática \\(\\mathbb{N}\\) el conjunto de los números naturales \\(\\mathbb{N}= \\{0,1,\\ldots,\\}\\) \\(\\mathbb{R}\\) el conjunto de los números reales \\(\\overline{\\mathbb{R}} = \\mathbb{R}\\cup \\{ +\\infty \\} \\cup \\{ -\\infty \\}\\) el conjunto de los reales extendido incluyendo los infinitos \\(x \\approx y\\) indica que el valor \\(y\\) es aproximado al valor \\(x\\) \\(f: X \\longrightarrow Y\\) la función que toma valores en \\(X\\) y entrega valores en \\(Y\\) \\(\\sum\\limits_{k=0}^n x_k\\) es la suma de los elementos \\(x_0,\\ldots,x_n\\) de una lista \\([ a, b ] = \\left\\{ x \\in \\mathbb{R}\\mid x \\geq a \\land x \\leq b \\right\\}\\) intervalo cerrado para cualquier \\(a,b \\in \\overline{\\mathbb{R}}\\) \\((a,b) = \\left\\{ x \\in \\mathbb{R}\\mid x &gt; a \\land x &lt; b \\right\\}\\) intervalo abierto para cualquier \\(a,b \\in \\overline{\\mathbb{R}}\\) \\(\\{x_n\\}_{n\\in\\mathbb{N}} = \\left\\{ x_n \\in X \\mid n \\in \\mathbb{N}\\right\\}\\) secuencia en el conjunto \\(X\\), no es más que una función de \\(\\mathbb{N}\\) con valores en \\(X\\) \\(\\underset{x \\rightarrow y}{\\lim} f(x) = a\\) límite de la función \\(f(x)\\) cuando \\(x\\) tiende a \\(y\\). \\(\\inf A\\) es la mayor de las cotas inferiores de \\(A\\). \\(\\sup A\\) es la menor de las cotas superiores de \\(A\\). 2.2 Consideraciones de programación en R Opciones usuales Code options( scipen = 9999 ) options( stringsAsFactors = FALSE ) Paquetes usuales Code library( actuar ) library( data.table ) library( fExtremes ) library( fitdistrplus ) library( ggplot2 ) library( googledrive ) library( kableExtra ) library( knitr ) library( latex2exp ) library( lubridate ) library( openxlsx ) library( readxl ) library( rmarkdown ) library( shiny ) library( wesanderson ) Estructuras básicas Para definir una variable utilizamos el operador de asignación &lt;-, también se puede utilizar =. Un vector se define con la función de concatenación c Code x &lt;- c( 1, 2, 3 ) print( x ) ## [1] 1 2 3 Una función se define con la sentencia function Code f &lt;- function( t ) { return( t^2 ) } Si buscamos aplicar una función sobre un vector, podemos utilizar sapply Code y &lt;- sapply( x, FUN = f ) print( y ) ## [1] 1 4 9 Code z &lt;- lapply( x, FUN = f ) print( z ) ## [[1]] ## [1] 1 ## ## [[2]] ## [1] 4 ## ## [[3]] ## [1] 9 Para muchas tareas que están relacionadas con el manejo de datos, podemos utilizar las funcionalidades del paquete de R, data.table. Para trabajar con fechas recomendamos utilizar el paquete lubridate. Para trabajar con distribuciones de probabilidad que se utilizan para modelar valores extremos utilizamos fExtremes. Para varias funcionalidades asociadas a la estimación de modelos de pérdida utilizamos actuar. "],["probabilidad-y-estadística.html", "Capítulo 3 Probabilidad y Estadística 3.1 Probabilidad y conceptos asociados 3.2 Resultados de convergencia 3.3 Desigualdades de concentración 3.4 Transformada de Fourier, contínua y discreta 3.5 Consideraciones financieras", " Capítulo 3 Probabilidad y Estadística Antes de introduccir algunos conceptos necesarios para nuestro estudio, necesitamos de algunos conceptos de base. 3.1 Probabilidad y conceptos asociados Definición 3.1 (Conceptos base) En breves términos, utilizaremos los siguientes conceptos Un fenómeno es un hecho que puede ser observado. Un fenómeno estocástico es un fenómeno sobre el que se realiza un experimento que puede arrojar más de un resultado posible. Un experimento es la observación de un fenómeno bajo condiciones específicas. Un resultado es la información obtenida de un experimento. En relación a lo anterior, también tenemos estas definiciones ya más formales. Definición 3.2 (Espacio muestral y eventos) El conjunto de todos los resultados lo denominamos espacio muestral y usualmente lo notamos por \\(\\Omega\\). Un evento es un conjunto de uno o más resultados posibles. En pocas palabras un evento \\(A\\) es un subcojunto de \\(\\Omega\\), i.e. \\(A \\subset \\Omega\\). En algunas ocasiones, para dar mayor precisión a la naturaleza de los eventos, si este está asociado a un fenómeno estocástico se denomina evento contingente. No todos los subconjuntos de \\(\\Omega\\) necesariamente son un evento, usualmente hay subconjuntos que no pueden resultar de un experimento. Así, si agrupamos todos los eventos usualmente tenemos un conjunto menor a las partes \\(\\mathcal{P}(\\Omega)\\) de \\(\\Omega\\). El conjunto de todos los eventos se conoce como una álgebra de eventos, \\(\\sigma\\)-álgebra o tribu. Usualmente se la nota por \\(\\mathcal{F}\\), es claro que \\(\\mathcal{F} \\subset \\mathcal{P}(\\Omega)\\). El álgebra de eventos, se denomina así, ya que usualmente es cerrada para algunas operaciones de conjuntos. Tiene las siguientes propiedades: Todos los resultados de espacio muestral están en \\(\\mathcal{F}\\), es decir \\(\\Omega \\in \\mathcal{F}\\) El complemento de un evento también es parte de \\(\\mathcal{F}\\), es decir si \\(A \\in \\mathcal{F}\\), entonces \\(A^c = \\Omega \\setminus A \\in \\mathcal{F}\\). La unión de eventos es un evento, si \\(A, B \\in \\mathcal{F}\\), entonces \\(A \\cup B \\in \\mathcal{F}\\), Aunque redunde, la intersección de eventos es un evento, si \\(A, B \\in \\mathcal{F}\\), entonces \\(A \\cap B \\in \\mathcal{F}\\). Definición 3.3 (Medida de probabilidad) La probabilidad es una medida de las posibilidades de que ocurra un evento contingente que toma valores en \\([0,1]\\). Formalmente, la probabilidad se la define como una medida, esto es una función de conjuntos \\[\\begin{equation} P: \\mathcal{F} \\longrightarrow [0,1] \\end{equation}\\] sobre los eventos \\(\\mathcal{F} \\subset \\mathcal{P}( \\Omega )\\) del espacio muestral \\(\\Omega\\). Si \\(A, B \\in \\mathcal{F}\\) son disjuntos \\(A \\cap B = \\emptyset\\), entonces \\(P( A \\cup B ) = P( A ) + P( B )\\) \\(P( \\Omega ) = 1\\) \\(P( \\emptyset ) = 0\\) Para cualquier par de eventos \\(A, B \\in \\mathcal{F}\\), la probabilidad condicional de \\(A\\) dado \\(B\\), está dada por: \\[\\begin{equation} P( A \\mid B ) = \\frac{P( A \\cap B)}{P(B)} \\end{equation}\\] Una propiedad sobre sobre \\(\\Omega\\) viene caracterizada por una función de verificación \\(V : \\Omega \\longrightarrow \\{0,1\\}\\) de tal forma, se dice que un evento \\(A \\in \\mathcal{F}\\) satisface la propiedad dada por \\(V\\) si \\(V(\\omega) = 1\\), para todo \\(\\omega \\in A\\). Entonces decimos que se satisface la propiedad en \\(V\\) en casi en todas partes o casi seguramente si para todo evento \\(N \\in \\mathcal{F}\\) que no satisfaga \\(V\\) mantiene una medida nula, es decir \\(P( N ) = 0\\) y para cualquier \\(\\omega \\in \\Omega \\setminus N\\) se satisface \\(V\\), \\(V( \\omega ) = 1\\). En otras palabras en ciertos experimentos hay resultados que se pueden presentar, están dentro de las opciones, sin embargo en caso de presentarse no hay forma que se pueda medirlos. En muchas ocasiones se observa los resultados a través de la realización de un experimento, y es usual que a cada experimente se le asocie un único resultado. Esta noción permite la definición de una variable aleatoria. Definición 3.4 (Variable aleatoria) Una variable aleatoria es una función que asigna un valor numérico a todo evento contingente. Una variable aleatoria \\(X: \\Omega \\longrightarrow D\\) que parte del espacio muestral \\(\\Omega\\) y toma valores en el conjunto de los números reales \\(\\mathbb{R}\\). Como la variable aleatoria es el resultado de un experimento, el cual debe ser medible, es natural esperar que todo intervalo observado sea el resultado de un evento en el espacio muestra \\(\\Omega\\). De forma más clara, la imagen recíproca de un cualquier intervalo \\(A \\subset \\mathbb{R}\\) es un evento en \\(\\mathcal{F}\\), i.e. \\(X^{-1}( A ) \\in \\mathcal{F}\\) esto precisamente se designa como una función medible. De \\(X\\) se puede construir o heredar otra medida a partir de \\(P\\), esta se representa \\(P_X\\) y tan solo mide los eventos que son imagen de \\(X\\). Es decir para cualquier intervalo \\(A \\in \\mathbb{R}\\) \\[\\begin{eqnarray*} P_X( A ) &amp; = &amp; P( X^{-1}( A ) )\\qquad \\text{definición de la notación} \\\\ &amp; = &amp; P(\\{ \\omega \\in \\Omega \\mid X( \\omega ) \\in A \\})\\qquad \\text{definición de imagen recíproca} \\\\ &amp; = &amp; \\int\\limits_{X^{-1}( A )} dP( \\omega )\\qquad \\text{representación en forma integral} \\end{eqnarray*}\\] a partir de la medida \\(P_X\\) precisamente se puede determinar algunas funciones que se conocen como distribuciones o densidades de probabilidad. De la idea de variable aleatoria a valores reales se puede extender fácilmente al caso de varias variables aleatorias, un vector aleatorio que toma valores en \\(\\mathbb{R}^n\\), i.e. una función medible \\(X : \\Omega \\longrightarrow \\mathbb{R}^n\\). Definición 3.5 (Variable aleatoria discreta) Una variable aleatoria \\(K: \\Omega \\longrightarrow D\\) que parte del espacio muestral \\(\\Omega\\) y toma valores en un conjunto discreto \\(D = \\left\\{k_i \\in \\mathbb{R}| i \\in \\mathbb{N} \\right\\}\\), sigue una probabilidad discreta dada por las probabilidades \\(p_i \\in [0,1]\\) , \\(i \\in \\mathbb{N}\\), si \\[\\begin{equation} P\\left( K = k_i \\right) = p_i,\\qquad \\forall i \\in \\mathbb{N} \\end{equation}\\] Además se cumple la condición de normalización que es muy importante. \\[\\begin{equation} \\sum\\limits_{i = 0}^{\\infty} p_i = 1 \\end{equation}\\] las probabilidades ¡Nunca son negativas! y !Suman siempre 1!. Definición 3.6 (Función de distribución acumulada) Consideramos una variable aleatoria a valores reales \\(X\\), la función de distribución acumulada \\(F\\) asociada a la variable aleatoria \\(X\\), está dada por la siguiente relación: \\[\\begin{equation} F( x ) = P( X \\leq x ) = P_X( (-\\infty, x] ) = P( X \\in (-\\infty, x] ) = P\\left( X^{-1}\\left( (-\\infty, x ] \\right) \\right) \\end{equation}\\] La función de distribución acumulada, tiene las siguientes propiedades: Para cualquier \\(x \\in \\mathbb{R}\\), \\(0 \\leq F( x ) \\leq 1\\), La función \\(F\\) es no decreciente, La función \\(F\\) es continua por derecha, Se satisfacen los siguientes límites: \\[\\begin{equation} \\underset{x \\rightarrow -\\infty}{\\lim} F( x ) = 0\\qquad \\underset{x \\rightarrow +\\infty}{\\lim} F( x ) = 1 \\end{equation}\\] Cuando se trata de un variable aleatoria con varias componentes reales \\(X = ( X_1, \\ldots, X_n )\\) toma valores en \\(\\mathbb{R}^n\\). Se extiende la definición de distribución acumulada por para valores reales \\(x = ( x_1, \\ldots, x_n ) \\in \\mathbb{R}^n\\) \\[\\begin{equation} F\\left( x_1, \\ldots, x_n \\right) = P\\left( X_1 \\leq x_1 \\land \\cdots \\land X_n \\leq x_n \\right) = P\\left( \\bigcap_{i=1}^n X_i^{-1}\\left( (-\\infty, x_i ] \\right) \\right) \\end{equation}\\] También se puede tener una interpretación de una función de distribución acumulada condicionada. Consideremos el caso más sencillo con dos variables aleatorias \\(X\\) y \\(Y\\) a valores reales, que tienen distribución conjunta acumulada \\(F_{X,Y}\\). Es de observar que para cualesquier \\(x,y \\in \\mathbb{R}\\) \\[\\begin{eqnarray*} F_{X,Y}( x, y ) &amp; = &amp; P( X \\leq x \\land Y \\leq y ) \\\\ &amp; = &amp; P( X \\leq x \\mid Y \\leq y ) P( Y \\leq y ) \\\\ &amp; = &amp; F_{X|Y}( x \\mid Y \\leq y ) F_Y( y ) \\end{eqnarray*}\\] de estas igualdades surge la distribución acumulada condicionada de \\(X\\) dado que \\(Y \\leq y\\), \\[\\begin{equation} F_{X|Y}( x \\mid Y \\leq y ) = \\frac{F_{X,Y}( x, y )}{F_Y( y )} \\end{equation}\\] está bien definida para \\(F_Y( y ) \\neq 0\\) Definición 3.7 (Función supervivencia) La función de supervivencia \\(S : \\mathbb{R}\\longrightarrow \\mathbb{R}\\) está asociada a una variable aleatoria \\(X\\), está dada por la siguiente: \\[\\begin{equation} S( x ) = 1 - F( x ) = 1 - P( X \\leq x ) = P( X &gt; x ) \\end{equation}\\] Definición 3.8 (Función de densidad de probabilidad) La densidad de probabilidad o también la ley de probabilidad de una variable aleatoria a valores reales \\(X\\), es una función \\(f: \\mathbb{R}\\longrightarrow \\mathbb{R}\\), tal que \\[\\begin{equation} P( a \\leq X \\leq b ) = F( b ) - F( a ) = \\int\\limits_a^b f( x )\\ dx \\end{equation}\\] Así se satisface la siguiente igualdad \\[\\begin{equation} F( x ) = \\int\\limits_{(-\\infty,x]} f( x )\\ dx = \\int\\limits_{-\\infty}^x f( x )\\ dx \\end{equation}\\] Esto implica que \\(f\\) es la derivada de \\(F\\), i.e. \\(\\frac{dF}{dx} = f\\), por tal razón \\(f\\) estará bien definida siempre y cuando la derivada de \\(F\\) esté bien definida. Definición 3.9 (Independencia de variables aleatorias) Dos variables aleatorias a valores reales \\(X\\) y \\(Y\\), se dicen independientes si para cualquier par de eventos \\(A\\) y \\(B\\), sucede la siguiente factorización de probabilidades \\[\\begin{equation} P( X \\in A \\land Y \\in B ) = P( X \\in A ) P( Y \\in B) \\end{equation}\\] La propiedad anterior, en particular para la función de distribución conjunta, toma la siguiente forma: \\[\\begin{equation} F_{X,Y}( x, y ) = P( X \\leq x \\land Y \\leq y ) = P( X \\leq x ) P( Y \\leq y ) = F_{X}( x ) F_{Y}( y ) \\end{equation}\\] Para cuando tratamos con dos variables aleatorias \\(X\\) y \\(Y\\), si en caso existe y está bien definida las derivadas hasta el segundo orden de la función de distribución acumulada conjunta \\(F_{X,Y}\\). En tal caso se puede definir la respectiva densidad de probabilidad \\[\\begin{equation} f_{X,Y}( x, y ) = \\frac{\\partial^2 F_{X,Y}}{\\partial x \\partial y}( x, y ) \\end{equation}\\] Así mismo, para la densidad de probabilidad conjunta, si en caso las variables aleatoria \\(X\\) y \\(Y\\) son independientes, también se puede factorar la densidad de probabilidad. \\[\\begin{equation} f_{X,Y}( x, y ) = f_X( x ) f_Y( y ) \\end{equation}\\] En el desarrollo a continuación haremos bastante uso de familias de variables aleatorias \\(X_1, \\ldots, X_n\\) las cuales muchas de las veces se consideraran que son independientes entre si e idénticamente distribuidas, es usual designarlas con las siglas i.i.d.. Esta situación si las \\(X_1, \\ldots, X_n\\) siguen la misma distribución, su distribución conjunta tiene la siguiente forma: \\[\\begin{equation} F( x_1, \\ldots, x_n ) P( X_1 \\leq x_1 \\land \\cdots \\land X_n \\leq x_n ) = \\prod\\limits_{i=1}^n P( X_i \\leq x_i ) = \\prod\\limits_{i=1}^n F( x_i ) \\end{equation}\\] La siguiente función es utilidad para comprender algunos resultados en teoría de probabilidades. También, es bastante útil para realizar de forma más clara y rápida algunos cálculos. Definición 3.10 (Función indicatriz) La función indicatriz de un conjunto \\(A \\subset \\Omega\\), es la función \\(\\mathbf{1}_A : \\Omega \\longrightarrow \\{0,1\\}\\), que toma los valores \\(\\mathbf{1}_A( \\omega ) = 0\\), si \\(\\omega \\notin A\\) y \\(\\mathbf{1}_A( \\omega ) = 1\\), si \\(\\omega \\in A\\). Hay un caso atípico que suele ser útil, esto sucede cuando la variable aleatoria \\(X : \\Omega \\longrightarrow \\mathbb{R}\\), es constante, quiere decir que tenemos un \\(a \\in \\mathbb{R}\\), tal que \\(X( \\omega ) = a\\) para todo \\(\\omega \\in \\mathbb{R}\\). En este caso la distribución de probabilidad acumulada \\(F\\) de \\(X\\), tiene la siguiente forma particular. \\[\\begin{equation} F( x ) = P( X \\leq x ) = \\mathbf{1}_{[a, +\\infty)}( x ) \\end{equation}\\] Proposición 3.1 Las constantes o variables aleatorias constantes son independientes de cualquier otra variable aleatoria. Demostración. Consideremos \\(X\\) una constante o variable aleatoria constante, tal que existe un \\(a \\in \\mathbb{R}\\), tal que \\(X( \\omega ) = a\\) para cualquier \\(\\omega \\in Omega\\) y \\(Y\\) una variable aleatoria cualquiera a valores reales. Para cualesquier intervalos \\(A, B \\subset \\mathbb{R}\\). Entonces tenemos dos casos, primero \\(X \\notin A\\), entonces \\(\\emptyset = \\{ \\omega \\in \\Omega \\mid X( \\omega ) \\in A \\}\\), por otra parte si \\(y \\in A\\), entonces \\(\\Omega = \\{ \\omega \\in \\Omega \\mid X( \\omega ) \\in A \\}\\), como consecuencia \\[\\begin{equation} P( X \\in A ) = P\\left( X^{-1}(A) \\right) = P\\left( \\{ \\omega \\in \\Omega \\mid X( \\omega ) \\in A \\} \\right) = \\mathbf{1}_{A}( a ) \\end{equation}\\] Ahora consideramos los casos anteriores para la probabilidad conjunta, primero el caso \\(X \\notin A\\) \\[\\begin{eqnarray*} P\\left( X \\in A \\land Y \\in B \\right) &amp; = &amp; P\\left( X^{-1}(A) \\cap Y^{-1}(B) \\right) \\\\ &amp; = &amp; P\\left( \\{ \\omega \\in \\Omega \\mid X( \\omega ) \\in A \\} \\cap \\{ \\omega \\in \\Omega \\mid Y( \\omega ) \\in B \\} \\right) \\\\ &amp; = &amp; P\\left( \\emptyset \\cap \\{ \\omega \\in \\Omega \\mid Y( \\omega ) \\in B \\} \\right) \\\\ &amp; = &amp; P( \\emptyset ) \\\\ &amp; = &amp; 0 \\end{eqnarray*}\\] El segundo caso \\(X \\in A\\) \\[\\begin{eqnarray*} P\\left( X \\in A \\land Y \\in B \\right) &amp; = &amp; P\\left( X^{-1}(A) \\cap Y^{-1}(B) \\right) \\\\ &amp; = &amp; P\\left( \\{ \\omega \\in \\Omega \\mid X( \\omega ) \\in A \\} \\cap \\{ \\omega \\in \\Omega \\mid Y( \\omega ) \\in B \\} \\right) \\\\ &amp; = &amp; P\\left( \\Omega \\cap \\{ \\omega \\in \\Omega \\mid Y( \\omega ) \\in B \\} \\right) \\\\ &amp; = &amp; P( Y \\in B ) \\end{eqnarray*}\\] Esto quiere decir en conclusión que \\[\\begin{equation} P( X \\in A \\land Y \\in B ) = \\mathbf{1}_{A}( a ) P( Y \\in B ) = P( X \\in A ) P( Y \\in B ) \\end{equation}\\] por tanto \\(X\\) y \\(Y\\) son independientes Definición 3.11 (Medida de probabilidad empírica) A partir de una muestra de \\(X_1, \\ldots, X_n\\) de una variable aleatoria \\(X\\), podemos definir también la medida de probabilidad empírica asociada a la muestra \\(X_1, \\ldots, X_n\\). Así para cualquier evento del espacio muestral \\(\\Omega\\), \\(A \\subset \\Omega\\) \\[\\begin{equation} P_n( B ) = \\frac{1}{n} \\sum\\limits_{i=1}^n \\mathbf{1}_{B}\\left( X_i \\right) \\end{equation}\\] A partir de la medida empírica de probabilidad, podemos extraer la de para la distribución acumulada empírica \\(F_n\\), la cual la hemos definido con anterioridad, para ello consideremos \\(P_n( (-\\infty,x])\\) para cualquier \\(x \\in \\mathbb{R}\\) \\[\\begin{equation} P_n( (-\\infty,x]) = \\frac{1}{n} \\sum\\limits_{i=1}^n \\mathbf{1}_{(-\\infty,x]}\\left( X_i \\right) = F_n( x ) \\end{equation}\\] Para muchos resultados asociados a la estimación de estadística la variantes empíricas \\(P_n\\) y \\(F_n\\) son de utilidad. Definición 3.12 (Esperanza matemática) Considerando una variable aleatoria discreta \\(K : \\Omega \\longrightarrow D \\subset \\mathbb{R}\\), donde \\(D\\) es un conjunto discreto, es decir sus elementos se pueden contar y poner en correspondencia con \\(\\mathbb{N}\\). Entonces, la esperanza matemática se define como: \\[\\begin{equation} \\mathbb{E}[ K ] = \\mathbb{E}_P[ K ] = \\sum\\limits_{i=0}^{\\infty} k_i P\\left( K = k_i \\right) = \\sum\\limits_{i=0}^{\\infty} k_i p_i \\end{equation}\\] Para el caso de una variable aleatoria continua \\(X : \\Omega \\longrightarrow \\mathbb{R}\\) a valores reales, la esperanza matemática está dada por \\[\\begin{equation} \\mathbb{E}[ X ] = \\mathbb{E}_P[ K ] = \\int\\limits_{\\mathbb{\\Omega}} X( \\omega )\\ dP( \\omega ) = \\int\\limits_{\\mathbb{R}} x\\ dF( x ) \\end{equation}\\] Cuando la función de densidad de probabilidad está bien definida es posible expresar y calcular la esperanza matemática como la siguiente expresión: \\[\\begin{equation} \\mathbb{E}[ X ] = \\int\\limits_{\\mathbb{R}} x f( x )\\ dx \\end{equation}\\] La esperanza matemática goza de las siguientes propiedades: Linealidad, \\(a \\in \\mathbb{R}\\) \\[\\begin{equation} \\mathbb{E}[ aX + Y ] = a \\mathbb{E}[ X ] + \\mathbb{E}[ Y ] \\end{equation}\\] Monotonía, si \\(X \\leq Y\\), entonces \\[\\begin{equation} \\mathbb{E}[X] \\leq \\mathbb{E}[Y] \\end{equation}\\] La esperanza de una constante \\(a \\in \\mathbb{R}\\) es la misma constante. \\[\\begin{equation} \\mathbb{E}[a] = \\int\\limits_{\\mathbb{R}} a\\ dF_X( x ) = a\\int\\limits_{\\mathbb{R}} dF_X( x ) = a \\end{equation}\\] De esto resulta que la esperanza jamás puede ser mayor que cualquiera de los valores que toma la variable aleatoria \\(X\\). La función indicatriz \\(\\mathbf{1}_A\\) sobre un evento \\(A\\) del espacio muestral \\(\\Omega\\), también se puede interpretar como una variable aleatoria, que tan solo tomo los valores \\(0\\) o \\(1\\). Es más, su esperanza es precisamente la probabilidad del evento \\(A\\). \\[\\begin{equation} \\mathbb{E}\\left[ \\mathbf{1}_A \\right] = \\int\\limits_\\Omega \\mathbf{1}_A( \\omega )\\ dP( \\omega ) = \\int\\limits_A dP( \\omega ) = P( A ) \\end{equation}\\] Definición 3.13 (Función generadora de momentos) La función generadora de momentos de la variable aleatoria a valores reales \\(X\\), es la función: \\[\\begin{equation} M_X( t ) = \\mathbb{E}\\left[ \\exp( t X ) \\right] \\end{equation}\\] Si \\(X_1, \\ldots, X_n\\) son variables aleatorias y \\(Y = X_1 + \\cdots + X_n\\), entonces \\[\\begin{eqnarray*} M_Y( t ) &amp; = &amp; \\mathbb{E}\\left[ \\exp\\left( t Y \\right) \\right] \\\\ &amp; = &amp; \\mathbb{E}\\left[ \\exp\\left( t \\sum\\limits_{i=1}^n X_i \\right) \\right] \\\\ &amp; = &amp; \\prod\\limits_{i=1}^n \\mathbb{E}\\left[ \\exp\\left( t X_i \\right) \\right],\\qquad \\text{si las variables $X_i$ son independientes} \\\\ &amp; = &amp; \\left( \\mathbb{E}\\left[ \\exp\\left( t X \\right) \\right] \\right)^n,\\qquad \\text{si las variables $X_i$ son identicamente distribuidas} \\\\ &amp; = &amp; \\left( M_X( t ) \\right)^n \\end{eqnarray*}\\] Definición 3.12 (Varianza) Así mismo su varianza es la dada por: \\[\\begin{equation} \\mathbb{V}[ X ] = \\mathbb{E}\\left[ \\left( X - \\mathbb{E}[ X ] \\right)^2 \\right] = \\mathbb{E}\\left[ X^2 \\right] - \\mathbb{E}\\left[ X \\right]^2 \\end{equation}\\] Definición 3.14 (Mixtura de distribuciones) Un caso de especial interés para estudiar algunos problemas actuariales se da cuando se dispone de dos variables aleatorias, \\(N\\) que toma solo valores discretos (numerables) los cuales pueden ser finitos como infinitos, por ejemplo: \\(N\\) toma valores \\(\\mathbb{N}\\) y otra variable aleatoria \\(X\\) que toma valores continuos reales en \\(\\mathbb{R}\\). La distribución conjunta puede generarse de la siguiente forma \\[\\begin{eqnarray*} F( n, x ) &amp; = &amp; P( N = n \\land X \\leq x ) \\\\ &amp; = &amp; P( X \\leq x \\mid N = n ) P( N = n )\\qquad \\text{propiedades de la probabilidad condicional} \\\\ &amp; = &amp; F_n( x ) p_n\\qquad \\text{simplificando notación} \\\\ \\end{eqnarray*}\\] \\(F_n( x )\\) es la ley condicionada de \\(X\\) dado que \\(N = n\\) y \\(p_n = P( N = n )\\) Además, es de notar que: \\[\\begin{eqnarray*} F_X( x ) &amp; = &amp; P( X \\leq x ) \\\\ &amp; = &amp; P( X \\leq x \\land N \\in \\mathbb{N} ) \\\\ &amp; = &amp; P\\left( X \\leq x \\land N \\in \\bigcup_{n \\in \\mathbb{N}} \\{n\\} \\right) \\\\ &amp; = &amp; P\\left( \\bigcup_{n \\in \\mathbb{N}} \\left\\{ X \\leq x \\land N \\in \\{n\\} \\right\\} \\right) \\\\ &amp; = &amp; \\sum\\limits_{n \\in \\mathbb{N}} P\\left( X \\leq x \\land N \\in \\{n\\} \\right) \\\\ &amp; = &amp; \\sum\\limits_{n \\in \\mathbb{N}} P\\left( X \\leq x \\land N = n \\right) \\\\ &amp; = &amp; \\sum\\limits_{n \\in \\mathbb{N}} P\\left( X \\leq x\\ \\middle|\\ N = n \\right) P( N = n ) \\\\ &amp; = &amp; \\sum\\limits_{n \\in \\mathbb{N}} F_n( x ) p_n \\end{eqnarray*}\\] la distribución de \\(F_X\\) de \\(X\\) no es más que una mixtura de las distribuciones condicionales de \\(X\\) para cada \\(n \\in \\mathbb{N}\\). Definición 3.15 (Covarianza) La covarianza de dos variables aleatorias, está dada por la siguiente expresión: \\[\\begin{equation} \\mathbb{C}[ X, Y ] = \\mathbb{E}\\left[ \\left( X - \\mathbb{E}[ X ] \\right)\\left( Y - \\mathbb{E}[ Y ] \\right) \\right] = \\mathbb{E}\\left[ X Y \\right] - \\mathbb{E}\\left[ X \\right]\\mathbb{E}\\left[ Y \\right] \\end{equation}\\] De forma integral esta se la puede expresar como: \\[\\begin{eqnarray*} \\mathbb{C}[ X, Y ] &amp; = &amp; \\int\\limits_{\\mathbb{R}^2} xy\\ dP( x, y ) - \\int\\limits_{\\mathbb{R}^2} x\\ dP( x, y )\\int\\limits_{\\mathbb{R}^2} y\\ dP( x, y ) \\\\ &amp; = &amp; \\int\\limits_{\\mathbb{R}^2} xy f_{X,Y}( x, y )\\ dx dy - \\int\\limits_{\\mathbb{R}^2} x f_{X,Y}( x, y )\\ dx dy\\int\\limits_{\\mathbb{R}^2} y f_{X,Y}( x, y )\\ dx dy \\end{eqnarray*}\\] No está por demás notar que \\(\\mathbb{C}[ X, X ] = \\mathbb{V}[ X ]\\) Definición 3.16 (Distribución de la suma de variables aleatorias) Dadas dos variables aleatorias a valores reales \\(X\\) y \\(Y\\), con funciones de distribución acumulada \\(F_X\\) y \\(F_Y\\) respectivamente, la distribución acumulada \\(F_Z\\) de la variable aleatoria \\(Z = X + Y\\) está dada por la siguiente expresión: \\[\\begin{equation} F_Z( z ) = P( Z \\leq z ) = F_X \\star F_Y ( z ) = \\int\\limits_{\\mathbb{R}} F_X( x - y )dF_Y( y ) \\end{equation}\\] si en caso se puede definir las densidades de probabilidad \\(f_X\\) y \\(f_Y\\) para las variables aleatorias \\(X\\) y \\(Y\\), entonces: \\[\\begin{equation} f_Z( z ) = f_X \\star f_Y ( z ) = \\int\\limits_{\\mathbb{R}} f_X( x - y ) f_Y( y )\\ dy \\end{equation}\\] El producto \\(\\star\\) se conoce como convolución de funciones, el mismo es simétrico. Para cuando se realiza la convolución de varias veces la misma función, se opta por una notación más compacta \\(f^{\\star k}\\), para el producto de convolución \\(k\\)-veces la misma función \\(f \\star f \\star \\cdots \\star f\\). Cuando se tiene dos variables aleatorias independientes \\(X\\) y \\(Y\\), muchas de las veces nos interesamos a trabajar con la variable aleatoria dada por el mínimo entre estas variables, i.e. \\(Z = \\min( X, Y )\\). De ello surge la necesidad de determinar la distribución de probabilidad acumulada \\(F_Z\\) de \\(Z\\), a partir de las distribuciones de \\(F_X\\) de \\(X\\) y \\(F_Y\\) de \\(Y\\). \\[\\begin{eqnarray*} F_Z( z ) &amp; = &amp; P( Z \\leq z ) \\\\ &amp; = &amp; 1 - P( Z &gt; z ) \\\\ &amp; = &amp; 1 - P( \\min(X,Y) &gt; z ) \\\\ &amp; = &amp; 1 - P( X &gt; z \\land Y &gt; z ) \\\\ &amp; = &amp; 1 - P( X &gt; z ) P( Y &gt; z ) \\\\ &amp; = &amp; 1 - \\left( 1 - F_X( z ) \\right) \\left( 1 - F_Y( z ) \\right) \\\\ &amp; = &amp; F_X( z ) + F_Y( z ) - F_X( z ) F_Y( z ) \\end{eqnarray*}\\] En particular cuando \\(Y = a\\) es constante tenemos la siguiente distribución de probabilidad para \\(Z = \\min( X, Y ) = \\min( X, a )\\) \\[\\begin{equation} F_Z( z ) = F_X( z ) + \\mathbf{1}_{[a,+\\infty)}( z ) - \\mathbf{1}_{[a,+\\infty)}( z ) F_X( z ) = \\mathbf{1}_{(-\\infty,a)}( z ) F_X( z ) + \\mathbf{1}_{[a,+\\infty)}( z ) \\end{equation}\\] De forma similar nos podemos también interesar a la variable aleatoria que expresa el máximo entre otras dos variables, i.e. \\(Z = \\max( X, Y )\\), por un razonamiento similar podemos obtener la distribución de probabilidad \\(F_Z\\) de \\(Z\\). \\[\\begin{eqnarray*} F_Z( z ) &amp; = &amp; P( Z \\leq z ) \\\\ &amp; = &amp; P( \\max(X,Y) \\leq z ) \\\\ &amp; = &amp; P( X \\leq z \\land Y \\leq z ) \\\\ &amp; = &amp; P( X \\leq z ) P( Y \\leq z ) \\\\ &amp; = &amp; F_X( z ) F_Y( z ) \\end{eqnarray*}\\] De forma análoga el caso cuando \\(Y = a\\) es una constante se reduce a la siguiente distribución de probabilidad para \\(Z\\). \\[\\begin{equation} F_Z( z ) = \\mathbf{1}_{[a,+\\infty)}( z ) F_X( z ) \\end{equation}\\] La siguiente definición de distribución de exceso condicionada es útil para el estudio de los valores extremos que se pueden presentar en el estudio de los valores de siniestros que se presentan en un seguro. Definición 3.17 (Distribución de exceso condicionada) La distribución de exceso condicionada asociada a una variable aleatoria \\(X\\) con distribución de probabilidad acumulada \\(F\\) y a un umbral de condicionamiento \\(u &gt; 0\\), está dada por: \\[\\begin{equation} F_u( y ) = P\\left( X - u \\leq y \\mid X &gt; u \\right) = \\frac{P\\left( u &lt; X \\leq y + u\\right)}{P(X &gt; u)} = \\frac{F( u + y ) - F( u )}{ 1 - F( u )} \\end{equation}\\] 3.2 Resultados de convergencia De las ramas de las Matemáticas la Estadística ciertamente es la más subestimada, en muchos casos menospreciada. Sin embargo, no sin mucha pretención, sino más bien honestidad, se puede decir que la Estadística es una de las ramas más complicadas de las Ciencias en general, ya que busca en muchos casos comprender, explicar y predecir fenómenos reales. En su fundamentación, al profundizar en ella, uno encontrará un sin número de conceptos, métodos y teorías con un amplio espectro de complejidad, que incluso se sustentan en ideas filosóficas bastante elaboradas y poco comprendidas. No olvidar, la Estadística busca de frente y sin rodeos extraer conocimiento de la realidad y no hay algo más complejo y duro que la realidad misma. Muchos de las herramientas de las estadística se resumen en algunas recetas o aplicaciones de software, sin embargo, no se debe olvidar que en muchos casos estas herramientas hacen uso de muchos métodos bastante avanzados y complejos en lo que respecta al conocimiento Matemático. Teorema 3.1 (Ley débil de los grandes números) Consideramos la secuencia de variables aleatorias \\(\\{X_i\\}_{i\\in \\mathbb{N}}\\) las cuales consideraremos que son i.i.d. y con media común finita \\(\\mathbb{E}[X_i] = \\mu &lt; +\\infty\\). Entonces, se satisface el siguiente límite en probabilidad \\[\\begin{equation} \\frac{1}{n} \\sum\\limits_{i=1}^n X_i \\rightarrow \\mu \\end{equation}\\] esto quiere decir que para cualquier \\(\\varepsilon &gt; 0\\) se satisface el siguiente límite \\[\\begin{equation} \\underset{n \\rightarrow +\\infty}{\\lim} P\\left( \\left| \\sum\\limits_{i=1}^n X_i - \\mu \\right|\\right) = 0 \\end{equation}\\] Teorema 3.2 (Teorema del límite central) Consideramos las variables aleatorias \\(X_1,\\ldots,X_n\\) i.i.d. con media común finita \\(\\mathbb{E}[X_i] = \\mu &lt; +\\infty\\) y varianza común finita \\(\\mathbb{V}[ X_i ] = \\sigma^2 &lt; +\\infty\\), para todo \\(i \\in \\{1, \\ldots, n \\}\\). Si consideramos la variable aleatoria de la suma total \\(S_n = \\sum\\limits_{i=1}^n X_i\\), entonces \\[\\begin{equation} \\frac{S_n - \\mathbb{E}[S_n]}{\\mathbb{V}[ S_n ]} \\overset{d}{\\longrightarrow} Z \\end{equation}\\] cuando \\(n \\rightarrow +\\infty\\), donde \\(Z \\rightsquigarrow N( 0, 1 )\\). Más aún \\[\\begin{equation} \\underset{n \\rightarrow +\\infty}{\\lim} P\\left( \\frac{S_n - \\mathbb{E}[S_n]}{\\mathbb{V}[ S_n ]} \\leq z \\right) = \\Phi( z ) \\end{equation}\\] El teorema del límite central en su forma usual no proporciona una tasa de convergencia es decir, la variable aleatoria \\(\\frac{S_n - \\mathbb{E}[S_n]}{\\mathbb{V}[ S_n ]}\\) tiende a tener un comportamiento de una variable aleatoria normal estándar conforme aumenta \\(n\\), pero no estamos seguros que tamaño debe tomar \\(n\\) para que esto se cumpla con una alta certeza. Para ello adicional al 3.2 se debe considerar otros resultados asociados a desigualdades de concentración. El siguiente teorema es de gran ayuda para estimar la tasa de convergencia del resultado anterior 3.2. 3.3 Desigualdades de concentración Para muchos fines prácticos es importante encontrar una buena estimación de donde se encuentran concentrados los valores de una distribución de probabilidad, para ello existen varios resultados que caracterizan precisamente ello, estos se conocen como desigualdades de concentración. Proposición 3.2 (Desigualdad de Chebyshev (Чебышёв)) Dada una variable aleatoria \\(X\\) con esperanza y varianza finitas \\(\\mathbb{E}[X] &lt;+ \\infty\\) y \\(\\mathbb{V}[X] &lt; +\\infty\\), tenemos que se satisface la siguiente desigualdad para cualquier \\(varepsilon &gt; 0\\) \\[\\begin{equation} P\\left( \\left| X - \\mathbb{E}[X] \\right| &gt; \\varepsilon \\right) &lt; \\frac{1}{\\varepsilon^2} \\mathbb{V}[ X ] \\end{equation}\\] Teorema 3.3 (Desigualdad de Berry-Esséen) Sean \\(X_1, \\ldots X_n\\) variables aleatorias i.i.d., con media y varianza finitas, i.e \\(\\mathbb{E}[X] &lt; +\\infty\\) y \\(\\mathbb{V}[X] &lt; +\\infty\\) y además con tercer momento absoluto finito \\(\\mathbb{E}\\left[\\left|X - \\mathbb{E}[X]\\right|^3\\right] &lt; +\\infty\\). Entonces, la distribución acumulada \\(F_{U_n}\\) de la variable aleatoria \\[\\begin{equation} U_n = \\frac{S_n - \\mathbb{E}[ S_n ]}{\\mathbb{V}[ S_n ]} \\end{equation}\\] con \\(S_n = \\sum\\limits_{i=1}^n X_i\\). Satisface la siguiente desigualdad respecto de la distribución acumulada de la ley normal \\(\\Phi\\). \\[\\begin{equation} \\underset{u}{\\sup}\\left| F_{U_n}( u ) - \\Phi( u ) \\right| \\leq \\frac{A}{\\sqrt{n}} \\frac{\\mathbb{E}\\left[\\left|X - \\mathbb{E}[X]\\right|^3\\right]}{\\sqrt{\\mathbb{V}[X]}^3} \\end{equation}\\] Teorema 3.4 (Desigualdad Dvoretzky–Kiefer–Wolfowitz) Dada una serie de variables aleatorias a valores reales \\(X_1, \\ldots, X_n\\), i.i.d., con distribución acumulada \\(F\\), tenemos la siguiente desigualdad asociada a la distribución acumulada empírica \\[\\begin{equation} F_n( x ) = \\frac{1}{n}\\sum\\limits_{i=1}^n \\mathbf{1}_{(-\\infty,x]}( X_i ) \\end{equation}\\] y su aproximación a \\(F\\). \\[\\begin{equation} P\\left( \\underset{x \\in \\mathbb{R}}{\\sup} \\left| F_n( x ) - F( x ) \\right| &gt; \\varepsilon \\right) \\leq 2 e^{-2n \\varepsilon^2 }\\qquad \\forall \\varepsilon &gt; 0 \\end{equation}\\] Como podemos notar el orden de convergencia del teorema es \\(\\sqrt{n}\\) en el tamaño de observaciones, esto quiere decir que la convergencia es menos que el orden lineal. Acorde a la desigualdad 3.4, para tener un probabilidad baja de aproximación \\(\\delta &gt; 0\\) en un error de discrepancia \\(\\varepsilon &gt;0\\), necesitamos satisfacer la desigualdad. \\[\\begin{eqnarray*} 2 e^{-2n \\varepsilon^2 } &amp; \\leq &amp; \\delta \\\\ 2n \\varepsilon^2 &amp; \\geq &amp; -\\ln\\left( \\frac{\\delta}{2} \\right) \\\\ n &amp; \\geq &amp; \\left\\lceil -\\frac{1}{2\\varepsilon^2} \\ln\\left( \\frac{\\delta}{2} \\right) \\right\\rceil \\end{eqnarray*}\\] así se observa que para tener una aproximación de orden \\(\\delta\\) y con un error de discrepancia \\(\\varepsilon\\), se requiere como mínimo realizar un número de simulaciones \\(n\\) de orden logarítmico en \\(\\delta\\) y cuadrático en \\(\\varepsilon\\). Code delta &lt;- 0.01 e &lt;- unlist( lapply( seq( 1, 9, 1 ), FUN = function( n ) seq( 9, 1, -1 ) * 10^{-n} ) ) n &lt;- ceiling( -log( delta / 2 ) / ( 2 * e^2 ) ) Code dt &lt;- data.table( delta = delta, e, n, d = 8 * n / 1024^3 ) dt %&gt;% kable( caption = &#39;Error versus número de simulaciones&#39;, row.names = FALSE, col.names = c( &quot;$\\\\delta$&quot;, &quot;$\\\\varepsilon$&quot;, &quot;$n$&quot;, &quot;GB&quot; ), align = &#39;llrr&#39;, digits = c( 10, 20, 0, 10 ), format.args = list( big.mark = &#39;,&#39;, decimal.mark = &#39;.&#39;, scientific = FALSE ), escape = FALSE ) %&gt;% kable_classic( font_size = 14, full_width = FALSE, html_font = &quot;Cambria&quot; ) %&gt;% scroll_box( width = &quot;1050px&quot;, height = &quot;500px&quot; ) Tabla 3.1: Tabla 3.2: Error versus número de simulaciones \\(\\delta\\) \\(\\varepsilon\\) \\(n\\) GB 0.01 0.900000000 4 0.0000000298 0.01 0.800000000 5 0.0000000373 0.01 0.700000000 6 0.0000000447 0.01 0.600000000 8 0.0000000596 0.01 0.500000000 11 0.0000000820 0.01 0.400000000 17 0.0000001267 0.01 0.300000000 30 0.0000002235 0.01 0.200000000 67 0.0000004992 0.01 0.100000000 265 0.0000019744 0.01 0.090000000 328 0.0000024438 0.01 0.080000000 414 0.0000030845 0.01 0.070000000 541 0.0000040308 0.01 0.060000000 736 0.0000054836 0.01 0.050000000 1,060 0.0000078976 0.01 0.040000000 1,656 0.0000123382 0.01 0.030000000 2,944 0.0000219345 0.01 0.020000000 6,623 0.0000493452 0.01 0.010000000 26,492 0.0001973808 0.01 0.009000000 32,706 0.0002436787 0.01 0.008000000 41,394 0.0003084093 0.01 0.007000000 54,065 0.0004028156 0.01 0.006000000 73,588 0.0005482733 0.01 0.005000000 105,967 0.0007895157 0.01 0.004000000 165,573 0.0012336150 0.01 0.003000000 294,351 0.0021930858 0.01 0.002000000 662,290 0.0049344450 0.01 0.001000000 2,649,159 0.0197377726 0.01 0.000900000 3,270,567 0.0243676230 0.01 0.000800000 4,139,311 0.0308402702 0.01 0.000700000 5,406,447 0.0402811691 0.01 0.000600000 7,358,775 0.0548271462 0.01 0.000500000 10,596,635 0.0789510831 0.01 0.000400000 16,557,242 0.1233610660 0.01 0.000300000 29,435,097 0.2193085626 0.01 0.000200000 66,228,968 0.4934442639 0.01 0.000100000 264,915,869 1.9737770334 0.01 0.000090000 327,056,628 2.4367617667 0.01 0.000080000 413,931,045 3.0840266123 0.01 0.000070000 540,644,630 4.0281163901 0.01 0.000060000 735,877,413 5.4827139750 0.01 0.000050000 1,059,663,474 7.8951081187 0.01 0.000040000 1,655,724,178 12.3361064345 0.01 0.000030000 2,943,509,649 21.9308558777 0.01 0.000020000 6,622,896,709 49.3444257155 0.01 0.000010000 26,491,586,833 197.3777028397 0.01 0.000009000 32,705,662,757 243.6761763468 0.01 0.000008000 41,393,104,427 308.4026606902 0.01 0.000007000 54,064,462,924 402.8116384447 0.01 0.000006000 73,587,741,203 548.2713967785 0.01 0.000005000 105,966,347,331 789.5108113512 0.01 0.000004000 165,572,417,705 1,233.6106427386 0.01 0.000003000 294,350,964,809 2,193.0855870917 0.01 0.000002000 662,289,670,819 4,934.4425709471 0.01 0.000001000 2,649,158,683,275 19,737.7702837810 0.01 0.000000900 3,270,566,275,647 24,367.6176342890 0.01 0.000000800 4,139,310,442,616 30,840.2660683990 0.01 0.000000700 5,406,446,292,396 40,281.1638444364 0.01 0.000000600 7,358,774,120,206 54,827.1396771520 0.01 0.000000500 10,596,634,733,097 78,951.0811351016 0.01 0.000000400 16,557,241,770,463 123,361.0642735884 0.01 0.000000300 29,435,096,480,823 219,308.5587086007 0.01 0.000000200 66,228,967,081,851 493,444.2570943460 0.01 0.000000100 264,915,868,327,402 1,973,777.0283773690 0.01 0.000000090 327,056,627,564,694 2,436,761.7634288520 0.01 0.000000080 413,931,044,261,566 3,084,026.6068396419 0.01 0.000000070 540,644,629,239,596 4,028,116.3844436109 0.01 0.000000060 735,877,412,020,561 5,482,713.9677149132 0.01 0.000000050 1,059,663,473,309,608 7,895,108.1135094762 0.01 0.000000040 1,655,724,177,046,262 12,336,106.4273585528 0.01 0.000000030 2,943,509,648,082,242 21,930,855.8708596379 0.01 0.000000020 6,622,896,708,185,045 49,344,425.7094341889 0.01 0.000000010 26,491,586,832,740,180 197,377,702.8377367556 0.01 0.000000009 32,705,662,756,469,352 243,676,176.3428848386 0.01 0.000000008 41,393,104,426,156,528 308,402,660.6839636564 0.01 0.000000007 54,064,462,923,959,544 402,811,638.4443606734 0.01 0.000000006 73,587,741,202,056,032 548,271,396.7714908123 0.01 0.000000005 105,966,347,330,960,720 789,510,811.3509470224 0.01 0.000000004 165,572,417,704,626,112 1,233,610,642.7358546257 0.01 0.000000003 294,350,964,808,224,128 2,193,085,587.0859632492 0.01 0.000000002 662,289,670,818,504,448 4,934,442,570.9434185028 0.01 0.000000001 2,649,158,683,274,017,792 19,737,770,283.7736740112 Teorema 3.5 (Desigualdad de Chernoff) Dada una variable aleatoria \\(X\\) a valores reales, para la cual si existe y está bien definida su función generadora de momentos \\(M\\), entonces se satisface la siguientes desigualdades para cualquier \\(\\varepsilon \\in \\mathbb{R}\\). \\[\\begin{equation} P( X \\geq \\varepsilon ) \\leq \\underset{t &gt; 0}{\\inf} \\exp( -t \\varepsilon ) M( t ) \\end{equation}\\] así mismo \\[\\begin{equation} P( X \\leq \\varepsilon ) \\leq \\underset{t &lt; 0}{\\inf} \\exp( -t \\varepsilon ) M( t ) \\end{equation}\\] Teorema 3.6 (Desigualdad de Paley-Zygmund) Dada una variable aleatoria \\(X\\) a valores reales, que solo toma valores no negativos \\(X \\geq 0\\) y que además tiene varianza finita \\(\\mathbb{V}[X] &lt; +\\infty\\), entonces si tomamos un valor \\(\\rho \\in [0,1]\\), se satisface la siguiente desigualdad: \\[\\begin{equation} P( X \\geq \\rho \\mathbb{E}[ X ] ) \\geq ( 1 - \\rho )^2 \\frac{\\mathbb{E}[ X ]^2}{\\mathbb{E}[ X^2 ]} \\end{equation}\\] 3.4 Transformada de Fourier, contínua y discreta Definición 3.18 (Tansformada de Fourier) La transformada de Fourier para una función integrable \\(f : \\mathbb{R}^n \\longrightarrow \\mathbb{R}\\), está definida como un funcional que toma funciones acotadas y general una función usualmente integrable a valores complejos en general. De forma más formal, se puede definir la transformada de Fourier como una función \\(\\mathscr{F}: L^1( \\mathbb{R}^n ) \\longrightarrow L^{\\infty} \\left( \\mathbb{R}^n, \\mathbb{C} \\right)\\) \\[\\begin{equation} \\mathscr{F}( f )( \\omega ) = \\int\\limits_{\\mathbb{R}^n} f( x ) \\exp( -2 \\pi i \\omega \\cdot x )\\ dx \\end{equation}\\] donde \\(i\\) es la cantidad compleja \\(i = \\sqrt{-1}\\). la inversa de la transformada de Fourier, para una función \\(g : \\mathbb{R}^n \\longrightarrow \\mathbb{R}\\), está dada por: \\[\\begin{equation} \\mathscr{F}^{-1}( g ) = \\int\\limits_{\\mathbb{R}^n} g( x ) \\exp( 2 \\pi i \\omega \\cdot x )\\ dx \\end{equation}\\] se satisface la siguiente igualdad \\[\\begin{equation} \\mathscr{F}^{-1}\\left( \\mathscr{F}( f ) \\right) = f \\end{equation}\\] Además, la transformada de Fourier satisface las siguientes propiedades: La transformada de Fourier es lineal, si \\(a,b \\in \\mathbb{R}\\) y \\(f :\\mathbb{R}^n \\longrightarrow \\mathbb{R}\\) y \\(g :\\mathbb{R}^n \\longrightarrow \\mathbb{R}\\), funciones integrables. \\[\\begin{equation} \\mathscr{F}\\left( a f + b g \\right) = a \\mathscr{F}( f ) + b \\mathscr{F}( g ) \\end{equation}\\] La transformada de Fourier de la convolución de funciones es el producto de las transformadas de Fourier. \\[\\begin{equation} \\mathscr{F}\\left( f \\star g \\right) = \\mathscr{F}( f ) \\mathscr{F}( g ) \\end{equation}\\] Definición 3.19 (Tansformada de Fourier discreta) Dada una secuencia finita de números \\(x_0, \\ldots, x_{N-1}\\), también notada por \\(\\{x_k\\}_{k \\in \\{0,\\ldots,N-1\\}}\\) o simplemente \\(\\{x_k\\}\\) cuando quede entendida su dimensión, claramente \\(\\{x_k\\}\\) puede ser interpretada como un vector en \\(\\mathbb{R}^n\\), indexado desde \\(0\\). Entonces, la transformada de Fourier discreta de la secuencia \\(\\{x_k\\}\\) es la función \\(\\operatorname{DFT}: \\mathbb{R}^n \\longrightarrow \\mathbb{R}^n\\), definida por: \\[\\begin{equation} \\operatorname{DFT}\\left[ \\{x_k\\} \\right] = \\left\\{ \\sum\\limits_{k=0}^{N-1} x_k \\exp\\left( -2\\pi i \\frac{jk}{N} \\right) \\right\\}_j \\end{equation}\\] con \\(j \\in \\{0, \\ldots, N-1 \\}\\). la inversa de la transformada de Fourier discreta, está simplemente dada por: \\[\\begin{equation} \\operatorname{DFT}^{-1}\\left[ \\{x_k\\} \\right] = \\left\\{ \\frac{1}{N} \\sum\\limits_{k=0}^{N-1} x_k \\exp\\left( 2\\pi i \\frac{jk}{N} \\right) \\right\\}_j \\end{equation}\\] 3.4.1 Aproximación numérica en una dimensión Para el caso de 1-dimensional podemos tener la siguiente aproximación a la transformada de Fourier. Consideramos el caso donde la función \\(f\\) está concentrada en su mayoría en un intervalo \\([a,b]\\), la mayor parte de su integral está ahí. Luego para aproximar la integral consideramos una discretización uniforme del intervalo \\([a,b]\\), seleccionando un tamaño \\(N \\in \\mathbb{N}\\) y tomando una secuencia de valores discretos \\(x_k = a + k h\\), con \\(h = \\frac{b-a}{N}\\) y \\(k \\in \\{0, \\ldots, N\\}\\). Así, tenemos la siguiente aproximación a la transformada de Fourier. \\[\\begin{eqnarray*} \\mathscr{F}( f )( \\omega ) &amp; = &amp; \\int\\limits_{\\mathbb{R}} f( x ) \\exp( -2\\pi i \\omega x )\\ dx \\\\ &amp; \\approx &amp; \\int\\limits_{a}^b f( x ) \\exp( -2\\pi i \\omega x )\\ dx \\quad \\text{dominio finito $[ a, b ]$ que concentra la integral} \\\\ &amp; \\approx &amp; \\sum\\limits_{k=0}^{N-1} f( x_k ) \\exp( -2 \\pi i \\omega x_k ) h \\quad \\text{discretización de la integral} \\\\ &amp; = &amp; h \\sum\\limits_{k=0}^{N-1} f( x_k ) \\exp( -2\\pi i \\omega ( a + k h ) ) \\\\ &amp; = &amp; h \\exp( -i 2\\pi \\omega a ) \\sum\\limits_{k=0}^{N-1} f( x_k ) \\exp\\left( -2\\pi i \\omega k \\frac{b - a}{N} \\right) \\end{eqnarray*}\\] donde \\(\\{f_k\\}\\) es la secuencia finita de números \\(f_k = f( x_k )\\) y \\(\\operatorname{DFT}\\) es la transformada de Fourier Discreta. La anterior relación es una aproximación para todo \\(\\omega\\). En particular se puede considerar \\(\\omega_j = \\frac{j}{b-a}\\), para \\(j \\in \\{0,\\ldots,N-1\\}\\) \\[\\begin{eqnarray*} \\mathscr{F}( f )\\left( \\omega_j \\right) &amp; = &amp; h \\exp\\left( -2\\pi i \\frac{j}{b-a} a \\right) \\sum\\limits_{k=0}^{N-1} f( x_k ) \\exp\\left( -2\\pi i \\frac{jk}{N} \\right) \\\\ \\hat{f}_j &amp; = &amp; h \\exp\\left( -2\\pi i \\frac{j}{b-a} a \\right) \\left( \\operatorname{DFT}\\left[ \\{f_k\\} \\right] \\right)_j \\quad \\text{por definición de la $\\operatorname{DFT}$} \\end{eqnarray*}\\] entonces, lo anterior implica que podemos recuperar los valores aproximados a \\(f(x_k)\\) utilizando la transformada de Fourier discreta y su inversión. \\[\\begin{equation} \\{f( x_k )\\} \\approx \\operatorname{DFT}^{-1}\\left[ \\operatorname{DFT}\\left[ \\{f_k\\} \\right] \\right] = \\operatorname{DFT}^{-1}\\left[ \\left\\{ \\frac{1}{h} \\exp\\left( 2\\pi i \\frac{j}{b-a} a \\right) \\hat{f}_j \\right\\} \\right] \\end{equation}\\] es de notar que numérica por la aritmética en coma flotante la expresión \\(\\operatorname{DFT}^{-1}\\left[ \\left\\{ \\frac{1}{h} \\exp\\left( 2\\pi i \\frac{j}{b-a} a \\right) \\hat{f}_j \\right\\} \\right]\\) puede tener parte compleja muy pequeña, cercana a \\(0\\). Para superar este posible problema numérico tomamos solo la parte real. \\[\\begin{equation} \\{f( x_k )\\} \\approx \\operatorname{Re}\\left( \\operatorname{DFT}^{-1}\\left[ \\left\\{ \\frac{1}{h} \\exp\\left( 2\\pi i \\frac{j}{b-a} a \\right) \\hat{f}_j \\right\\} \\right] \\right) \\end{equation}\\] Code N &lt;- 3000 alpha &lt;- 2 theta &lt;- 3 b &lt;- qgamma( 0.9999, shape = alpha, scale = theta ) a &lt;- 0 h &lt;- ( b - a ) / N n &lt;- 0:N x &lt;- a + n * h w &lt;- n / ( b - a ) eta &lt;- h * exp( -2 * pi * 1i * w * a ) f &lt;- sapply( x, FUN = function( x ) dgamma( x, shape = alpha, scale = theta ) ) Ff &lt;- eta * fft( f ) IFf &lt;- fft( eta^(-1) * Ff, inverse = TRUE ) / ( N + 1 ) IFf &lt;- Re( IFf ) err &lt;- norm( f - IFf, type = &#39;2&#39; ) El error cuadrático de esta aproximación para el caso de la distribución \\(Gamma( \\alpha, \\theta )\\), como es de esperar es bastante pequeño. \\[\\begin{equation} \\left\\| \\{f( x_k ) \\} - \\operatorname{DFT}^{-1}\\left[ \\left\\{ \\frac{1}{h} \\exp\\left( 2\\pi i \\frac{j}{b-a} a \\right) \\hat{f}_j \\right\\} \\right] \\right\\|_2 = 0.00000000000035173800 \\end{equation}\\] Como se puede observar se superponen cada una de las distribuciones la discretización \\(f_k\\) y la calculada con inversión de la transformada de Fourier discreta. Code plot( x, f, type = &#39;l&#39; ) points( x, Re( IFf ), col = &#39;green&#39;, pch = 16, cex = 0.5 ) Code e &lt;- f - IFf eb &lt;- max( abs( e ) ) hist( e, breaks = 40, xlim = c( -eb, eb ), probability = TRUE ) 3.4.2 Uso de la transformada de Fourier Esta aproximación es realmente de utilidad cuando se tiene que determinar la densidad de la suma \\(S_n = \\sum\\limits_{i=1}^n X_i\\) de varias variables aleatorias \\(X_1 \\rightsquigarrow f_{X_1}, \\ldots, X_n \\rightsquigarrow f_{X_n}\\) que son independientes, pero que podrían ser o no idénticamente distribuidas. Claramente la densidad de probabilidad de \\(S\\) está dada por la convolución de las densidades de probabilidad de cada una de las variables aleatorias \\(X_1, \\ldots, X_n\\). \\[\\begin{equation} f_S = f_{X_1} \\star \\cdots \\star f_{X_n} \\end{equation}\\] sin embargo esta convolución implica el realizar una interacción en \\(n\\)-dimensiones. Si las las variables aleatorias \\(\\{X_i\\}\\) son independientes sabemos además que \\[\\begin{equation} \\mathscr{F}\\left( f_S \\right) = \\prod\\limits_{i=1}^n \\mathscr{F}\\left( f_{X_i} \\right) \\end{equation}\\] Por otra parte, con lo anterior sabemos que es posible aproximar numéricamente cada \\(\\mathscr{F}\\left( f_{X_i} \\right)\\) con una serie \\(\\{\\hat{f}_{i,j}\\}\\) dada por la discretización de la transformada de Fourier y su aplicación sobre la discretización de la densidad de probabilidad \\(f_{i,k} = f_{X_i}( s_k )\\). Por tanto, para cada de las densidades con \\(i \\in \\{1, \\ldots, n\\}\\) y \\(\\omega_j = \\frac{b-a}{N}\\), se puede calcular de forma separada las aproximaciones a cada una de las transformadas \\[\\begin{equation} \\mathscr{F}( f_{X_i} )\\left( \\omega_j \\right) \\approx \\hat{f}_{i,j} = h \\exp\\left( -2\\pi i \\omega_j a \\right) \\left( \\operatorname{DFT}\\left[ \\{f_{i,k}\\} \\right] \\right)_j \\end{equation}\\] con lo anterior, también, se puede realizar una aproximación a la trasformada de Fourier \\(\\mathscr{F}\\left( f_S \\right)\\) de la densidad de probabilidad que buscamos \\(f_S\\), como el producto de sus transformadas de Fourier. \\[\\begin{equation} \\mathscr{F}( f_{S} )\\left( \\omega_j \\right) = \\prod\\limits_{i=1}^n \\mathscr{F}\\left( f_{X_i} \\right)\\left( \\omega_j \\right) \\approx \\prod\\limits_{i=1}^n \\hat{f}_{i,j} \\end{equation}\\] utilizando la inversión de la transformada de Fourier discreta podemos calcular una serie que precisamente aproxima a la densidad \\(f_S\\) \\[\\begin{equation} \\{ f_{S}( s_k ) \\} \\approx \\operatorname{Re}\\left( \\operatorname{DFT}^{-1}\\left[ \\left\\{ \\frac{1}{h} \\exp\\left( 2\\pi i \\omega_j a \\right) \\prod\\limits_{i=1}^n \\hat{f}_{i,j} \\right\\} \\right] \\right) \\end{equation}\\] Code N &lt;- 10000 alpha &lt;- sample( x = seq( 1, 20, length = 40 ), size = 50, replace = TRUE ) theta &lt;- 3 b &lt;- sum( sapply( alpha, FUN = function( a ) qgamma( 0.9999, shape = a, scale = theta ) ) ) a &lt;- 0 h &lt;- ( b - a ) / N n &lt;- 0:N s &lt;- a + n * h w &lt;- n / ( b - a ) eta &lt;- h * exp( -2 * pi * 1i * w * a ) f &lt;- lapply( alpha, function( a ) sapply( s, FUN = function( sk ) dgamma( sk, shape = a, scale = theta ) ) ) Ff &lt;- lapply( f, FUN = function( fi ) eta * fft( fi ) ) FS &lt;- rep( 1, N + 1 ) for ( i in 1:length( f ) ) { FS &lt;- FS * Ff[[ i ]] } IFfS &lt;- fft( eta^(-1) * FS, inverse = TRUE ) / ( N + 1 ) fS &lt;- Re( IFfS ) fSx &lt;- sapply( s, FUN = function( sk ) dgamma( sk, shape = sum( alpha ), scale = theta ) ) Code plot( s, fSx, type = &#39;l&#39; ) points( s, fS, col = &#39;green&#39;, pch = 16, cex = 0.5 ) Code e &lt;- fS - fSx eb &lt;- max( abs( e ) ) hist( e, breaks = 40, xlim = c( -eb, eb ), probability = TRUE ) 3.5 Consideraciones financieras Antes de desarrollar el contenido propio del curso, debemos tener en cuenta algunas consideraciones financieras como las siguientes: 3.5.1 Función de actualización o descuento Definición 3.20 (Funciones de atualización y capitalización) La función de actualización de flujos \\(v: \\mathbb{R}\\times \\mathbb{R}\\longrightarrow [0,1]\\), al evaluar en \\(s, t \\in \\mathbb{R}, s\\leq t, v(s,t)\\), diremos que actualizamos los flujos que se producen en el tiempo \\(t\\), valorados desde el tiempo \\(s\\). Además la función de actualización tiene las siguientes propiedades: Si \\(s = t, v(s,t) = 1\\), Si \\(s \\leq t, v(s,t) \\leq 1\\), Si \\(r \\leq s \\leq t, v( r, s ) v( s, t ) = v( r, t )\\). La función de capitalización, es la función \\(u: \\mathbb{R}\\times \\mathbb{R}\\longrightarrow [0,1]\\), tal que \\(u( s, t ) v( s, t ) = 1\\). El caso más particular y sencillo se presenta cuando la función de actualización es generada por una tasa constante \\(i \\in \\mathbb{R}\\) en el tiempo, es decir, la función de actualización toma la forma \\[\\begin{equation} v(s,t) = ( 1 + i )^{-(t-s)} \\end{equation}\\] 3.5.2 Flujos financieros Un flujo financiero discreto \\(c\\) es una serie de valores reales \\(c(t_1), c(t_2), \\cdots, c(t_n)\\) que se producen en un número discreto de tiempos \\(t_0 &lt; t_1 &lt; \\cdots &lt; t_n\\). El valor presente de estos flujos, en un tiempo \\(t \\leq t_0\\), se lo puede calcular utilizando precisamente la función de actualización \\(v\\) \\[\\begin{equation} VP_t( c ) = \\sum\\limits_{k = 1}^n v( t, t_k ) c( t_k ) \\end{equation}\\] cuando \\(t=0\\), se suele solo expresar \\(VP( c ) = VP_0( c )\\). 3.5.3 Flujos financieros probables Un flujo financiero discreto \\(c\\) es una serie de valores reales \\(c(t_1), c(t_2), \\cdots, c(t_n)\\) que se producen en un número discreto de tiempos \\(t_0 &lt; t_1 &lt; \\cdots &lt; t_n\\). El valor actuarial presente de estos flujos, en un tiempo \\(t \\leq t_0\\), se lo puede calcular utilizando precisamente la función de actualización \\(v\\) \\[\\begin{equation} VAP_t( c ) = \\mathbb{E}\\left[ \\sum\\limits_{k = 1}^n v( t, t_k ) c( t_k ) \\right] = \\sum\\limits_{k = 1}^n v( t, t_k ) \\mathbb{E}\\left[ c( t_k ) \\right] \\end{equation}\\] cuando \\(t=0\\), se suele solo expresar \\(VAP( c ) = VAP_0( c )\\). Si cada \\(c(t_k)\\) es una variable aleatoria discreta \\[\\begin{equation} VAP_t( c ) = \\sum\\limits_{k = 1}^n v( t, t_k ) \\mathbb{E}\\left[ c( t_k ) \\right] = \\sum\\limits_{k = 1}^n \\sum\\limits_{i=1}^{\\infty} v( t, t_k ) c_i( t_k ) p_i( t_k ) \\end{equation}\\] 3.5.4 Equilibrio financiero Se dice que un flujo financiero \\(c(t_1), c(t_2), \\cdots, c(t_n)\\) como el anterior, está en equilibrio financiero si: \\[\\begin{equation} VP_0( c ) = \\sum\\limits_{k=0}^{n} v( 0, t_k ) c( t_k ) = 0 \\end{equation}\\] El equilibrio financiero se mantiene en el tiempo, basta observar que para cualquier instante \\(t \\geq 0\\) \\[\\begin{eqnarray*} 0 &amp; = &amp; u( 0, t ) VP_0( c ) \\\\ &amp; = &amp; u( 0, t ) \\sum\\limits_{k=0}^{n} v( 0, t_k ) c( t_k ) \\\\ &amp; = &amp; \\sum\\limits_{t_k \\leq t} u( 0, t ) v( 0, t_k ) c( t_k ) + \\sum\\limits_{t_k &gt; t} u( 0, t ) v( 0, t_k ) c( t_k ) \\\\ &amp; = &amp; \\sum\\limits_{t_k \\leq t} u( 0, t_k ) u( t_k, t ) v( 0, t_k ) c( t_k ) + \\sum\\limits_{t_k &gt; t} u( 0, t ) v( 0, t ) v( t, t_k ) c( t_k ) \\\\ &amp; = &amp; \\sum\\limits_{t_k \\leq t} u( t_k, t ) c( t_k ) + \\sum\\limits_{t_k &gt; t} v( t, t_k ) c( t_k ) \\\\ \\end{eqnarray*}\\] Esto implica que el valor actualizado a cualquier instante \\(t\\) de un flujo financiero \\(c\\) que está en equilibrio en un inicio, se mantiene también en equilibrio; siempre y cuando se preserve los flujos y tasas de actualización. A pesar de ser un resultado evidente, en la izquierda tenemos los flujos capitalizados hasta el tiempo \\(t\\) y en la derecha tenemos los flujos actualizados al tiempo \\(t\\). La expresión de la izquierda se conoce como la parte retrospectiva y la expresión de la derecha como la parte prospectiva. En condiciones de equilibrio financiero la parte retrospectiva es igual a menos la parte prospectiva. \\[\\begin{equation} \\sum\\limits_{t_k \\leq t} u( t_k, t ) c( t_k ) = -\\sum\\limits_{t_k &gt; t} v( t, t_k ) c( t_k ) \\end{equation}\\] algunas veces se considera la parte prospectiva con el signo menos. "],["distribuciones.html", "Capítulo 4 Distribuciones 4.1 Distribuciones discretas 4.2 Familia de Panjer 4.3 Distribuciones continuas 4.4 Estimación", " Capítulo 4 Distribuciones 4.1 Distribuciones discretas Definición 4.1 (Distribución binomial) Una variable aleatoria \\(N\\) que toma valores en \\(\\mathbb{N}\\) se dice que sigue una distribución o ley de binomial \\(N \\rightsquigarrow Bin( n, p )\\), con parámetros \\(n \\in \\mathbb{N}\\) y \\(p \\in [0, 1]\\), si: \\[\\begin{equation} P( N = k ) = \\binom{n}{k} p^k ( 1 - p )^{n-k}, \\qquad \\forall k \\in \\{0,\\ldots, n\\} \\end{equation}\\] esta distribución discreta se caracteriza por presentar el valor \\(k \\frac{p_k}{p_{k-1}}\\) decreciente conforme cambia \\(k \\in \\mathbb{N}\\) Code n &lt;- 50 p &lt;- 0.3 k &lt;- 2 m &lt;- 100 N &lt;- rbinom( n = m, size = n, prob = p ) # simular una muestra de tamaño m pk &lt;- dbinom( x = k, size = n, prob = p ) # cálculo de probabilidad P( N = k ) Pk &lt;- pbinom( q = k, size = n, prob = p ) # cálculo de probabilidad P( N &lt;= k ) p &lt;- dbinom( x = 0:n, size = n, prob = p ) v &lt;- 1:n * p[ 2:(n + 1) ] / p[ 1:n ] plt &lt;- ggplot() + geom_point( aes( x = 1:n, y = v ), colour = &#39;darkred&#39; ) + xlab( TeX( &quot;$k$&quot; ) ) + ylab( TeX( &quot;$k \\\\frac{p_k}{p_{k-1}}$&quot; ) ) + theme_bw() plot( plt ) Definición 4.2 (Distribución de Poisson) Una variable aleatoria \\(N\\) que toma valores en \\(\\mathbb{N}\\) se dice que sigue una distribución o ley de Poisson \\(N \\rightsquigarrow Pois( n, p )\\), con parámetro \\(\\lambda \\in \\mathbb{R}\\), si: \\[\\begin{equation} P( N = k ) = \\exp\\left( -\\lambda \\right) \\frac{\\lambda^k}{k!}, \\qquad \\forall k \\in \\mathbb{N} \\end{equation}\\] esta distribución discreta se caracteriza por presentar el valor \\(k \\frac{p_k}{p_{k-1}}\\) constante conforme cambia \\(k \\in \\mathbb{N}\\) Code lambda &lt;- 2 k &lt;- 2 m &lt;- 100 N &lt;- rpois( n = m, lambda = lambda ) # simular una muestra de tamaño m pk &lt;- dpois( x = k, lambda = lambda ) # cálculo de probabilidad P( N = k ) Pk &lt;- ppois( q = k, lambda = lambda ) # cálculo de probabilidad P( N &lt;= k ) n &lt;- 50 p &lt;- dpois( x = 0:n, lambda = lambda ) v &lt;- 1:n * p[ 2:(n + 1) ] / p[ 1:n ] plt &lt;- ggplot() + geom_point( aes( x = 1:n, y = v ), colour = &#39;darkred&#39; ) + xlab( TeX( &quot;$k$&quot; ) ) + ylab( TeX( &quot;$k \\\\frac{p_k}{p_{k-1}}$&quot; ) ) + theme_bw() plot( plt ) Definición 4.3 (Distribución binomial negativa) Una variable aleatoria \\(N\\) que toma valores en \\(\\mathbb{N}\\) se dice que sigue una distribución o ley de binomial negativa \\(N \\rightsquigarrow NBin( \\alpha, p )\\), con parámetro \\(\\alpha &gt; 0\\) y \\(p \\in (0,1)\\), si: \\[\\begin{equation} P( N = k ) = \\binom{\\alpha + k - 1}{k} p^\\alpha ( 1 - p )^k = \\frac{\\Gamma( \\alpha + k )}{\\Gamma(k+1) \\Gamma(\\alpha)}p^\\alpha ( 1 - p )^k, \\qquad \\forall k \\in \\mathbb{N} \\end{equation}\\] donde \\(\\Gamma( \\alpha ) = \\int\\limits_0^{+\\infty} x^{\\alpha - 1} \\exp(-x)\\ dx\\), \\(\\forall \\alpha \\geq 0\\). Esta distribución discreta se caracteriza por presentar el valor \\(k \\frac{p_k}{p_{k-1}}\\) creciente conforme cambia \\(k \\in \\mathbb{N}\\) Code alpha &lt;- 2.5 p &lt;- 0.3 k &lt;- 2 m &lt;- 100 N &lt;- rnbinom( n = m, size = alpha, prob = p ) # simular una muestra de tamaño m pk &lt;- dnbinom( x = k, size = alpha, prob = p ) # cálculo de probabilidad P( N = k ) Pk &lt;- pnbinom( q = k, size = alpha, prob = p ) # cálculo de probabilidad P( N &lt;= k ) n &lt;- 50 p &lt;- dnbinom( x = 0:n, size = alpha, prob = p ) v &lt;- 1:n * p[ 2:(n + 1) ] / p[ 1:n ] plt &lt;- ggplot() + geom_point( aes( x = 1:n, y = v ), colour = &#39;darkred&#39; ) + xlab( TeX( &quot;$k$&quot; ) ) + ylab( TeX( &quot;$k \\\\frac{p_k}{p_{k-1}}$&quot; ) ) + theme_bw() plot( plt ) Definición 4.4 (Distribución geométrica) Una variable aleatoria \\(N\\) que toma valores en \\(\\mathbb{N}\\) se dice que sigue una distribución o ley geométrica \\(N \\rightsquigarrow Geo( p )\\), con parámetro \\(p \\in (0,1]\\), si: \\[\\begin{equation} P( N = k ) = ( 1 - p )^k p, \\qquad \\forall k \\in \\mathbb{N} \\end{equation}\\] Code p &lt;- 0.3 k &lt;- 2 m &lt;- 100 N &lt;- rgeom( n = m, prob = p ) # simular una muestra de tamaño m pk &lt;- dgeom( x = k, prob = p ) # cálculo de probabilidad P( N = k ) Pk &lt;- pgeom( q = k, prob = p ) # cálculo de probabilidad P( N &lt;= k ) Es fácil darse cuenta que la distribución geométrica \\(Geo( p )\\) es una binomial negativa \\(BN( 1, p )\\), con \\(\\alpha = 1\\). Asociado a estas distribuciones discretas existe un resultado de caracterización, el cual permite seleccionar la distribución de conteo. 4.2 Familia de Panjer El criterio anterior para identificar el tipo de distribución, mediante la observación del comportamiento de la variable \\(k \\frac{p_k}{p_{k-1}}\\), se formaliza precisamente en la definición de la familia de Panjer. Definición 4.5 (Familia de Panjer) Una variable aleatoria discreta \\(N\\), que toma valores enteros positivos \\(N \\in \\mathbb{N}\\), se dice que pertenece a la familia de Panjer, si sus probabilidades \\(p_k = P( N = k )\\) para cada \\(k \\in \\mathbb{N}\\), satisfacen la siguiente relación de recurrencia. \\[\\begin{equation} p_k = \\left( a + \\frac{b}{k} \\right)p_{k-1},\\qquad \\forall k \\in \\mathbb{N}\\setminus \\{0\\} \\end{equation}\\] Además tenemos la siguiente proposición que caracteriza a la distribución de las variables aleatorias en la familia de Panjer. Proposición 4.1 (Caracterización familia de Panjer) Las únicas leyes de probabilidad que satisfacen la relación de recurrencia anterior son: La ley de Poisson, la cual se obtiene para \\(a = 0\\) y \\(b &gt; 0\\) \\[\\begin{equation} k \\frac{p_k}{p_{k-1}} = b &gt; 0,\\quad \\text{constante en $k$} \\end{equation}\\] La ley binomial negativa, la cual se obtiene para \\(0 &lt; a &lt; 1\\) y \\(a + b &gt; 0\\) \\[\\begin{equation} k \\frac{p_k}{p_{k-1}} = a k + b &gt; 0,\\quad \\text{creciente en $k$} \\end{equation}\\] La ley binomial, la cual se obtenida para \\(a &lt; 0\\) y \\(b = -a(m + 1)\\), para cierto \\(m\\) entero y positivo. \\[\\begin{equation} k \\frac{p_k}{p_{k-1}} = a( k - m - 1 ) &lt; 0, \\quad \\text{decreciente en $k$} \\end{equation}\\] Para una demostración detallada de la proposición anterior se puede consultar [4] o en https://nonlifemaths.github.io/. Code # la librería CASdatasets fue previamente cargada data( beMTPL97 ) beMTPL97 &lt;- as.data.table( beMTPL97 ) conteo &lt;- beMTPL97[ , list( fn = .N ), by = list( sex, fuel, N = nclaims ) ] conteo[ , pn := fn / sum( fn ), by = list( sex, fuel ) ] setorder( conteo, sex, fuel, N ) conteo[ , pns := shift( pn, type = &#39;lag&#39;, fill = 0 ) ] conteo[ , jn := N * pns / pn ] conteo %&gt;% kable( caption = &#39;Estimación conteos por sexo&#39;, row.names = FALSE, col.names = c( &quot;sexo&quot;, &quot;fuel&quot;, &quot;$N$&quot;, &quot;$f_k$&quot;, &quot;$p_k$&quot;, &quot;$p_{k+1}$&quot;, &quot;$k \\\\frac{p_{k+1}}{p_k}$&quot; ), align = &#39;llrrrrr&#39;, digits = c( 0, 0, 0, 0, 5, 5, 5 ), format.args = list( big.mark = &#39;,&#39;, decimal.mark = &#39;.&#39;, scientific = FALSE ), escape = FALSE ) %&gt;% kable_classic( font_size = 14, full_width = FALSE, html_font = &quot;Cambria&quot; ) %&gt;% scroll_box( width = &quot;750px&quot;, height = &quot;500px&quot; ) Tabla 4.1: Tabla 4.2: Estimación conteos por sexo sexo fuel \\(N\\) \\(f_k\\) \\(p_k\\) \\(p_{k+1}\\) \\(k \\frac{p_{k+1}}{p_k}\\) female gasoline 0 29,533 0.88741 0.00000 0.00000 female gasoline 1 3,384 0.10168 0.88741 8.72725 female gasoline 2 326 0.00980 0.10168 20.76074 female gasoline 3 33 0.00099 0.00980 29.63636 female gasoline 4 3 0.00009 0.00099 44.00000 female gasoline 5 1 0.00003 0.00009 15.00000 female diesel 0 8,557 0.86539 0.00003 0.00000 female diesel 1 1,206 0.12197 0.86539 7.09536 female diesel 2 109 0.01102 0.12197 22.12844 female diesel 3 14 0.00142 0.01102 23.35714 female diesel 4 2 0.00020 0.00142 28.00000 male gasoline 0 71,357 0.89714 0.00020 0.00000 male gasoline 1 7,417 0.09325 0.89714 9.62074 male gasoline 2 682 0.00857 0.09325 21.75073 male gasoline 3 74 0.00093 0.00857 27.64865 male gasoline 4 7 0.00009 0.00093 42.28571 male gasoline 5 1 0.00001 0.00009 35.00000 male diesel 0 35,489 0.87614 0.00001 0.00000 male diesel 1 4,532 0.11188 0.87614 7.83076 male diesel 2 439 0.01084 0.11188 20.64692 male diesel 3 41 0.00101 0.01084 32.12195 male diesel 4 5 0.00012 0.00101 32.80000 Code plot( conteo$N, conteo$jn ) 4.3 Distribuciones continuas Definición 4.6 (Distribución uniforme) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución uniforme \\(X \\rightsquigarrow Unif( a, b )\\) de parámetros \\(a, b \\in \\mathbb{R}\\), si su función de distribución acumulada es de la siguiente forma: \\[\\begin{equation} F_X( x ) = \\frac{x-a}{b-a} \\mathbf{1}_{[a,b)}( x ) + \\mathbf{1}_{[b,+\\infty)}( x ) \\end{equation}\\] sin mucho esfuerzo se puede verificar que su densidad de probabilidad está dada por la función \\[\\begin{equation} f_X( x ) = \\frac{1}{b-a}\\mathbf{1}_{[a,b]}( x ) \\end{equation}\\] \\[\\begin{equation} M_X( t ) = \\frac{\\exp(bt)-\\exp(at)}{t(b-a)} \\end{equation}\\] \\[\\begin{equation} \\mathbb{E}[X] = \\frac{a + b}{2},\\qquad \\mathbb{V}[X] = \\frac{(b - a)^2}{12} \\end{equation}\\] Code a &lt;- 1 b &lt;- 2 x &lt;- 1.5 m &lt;- 100 X &lt;- runif( n = m, min = a, max = b ) # simular una muestra de tamaño m fx &lt;- dunif( x = x, min = a, max = b ) # cálculo de la densidad f(x) Fk &lt;- punif( q = x, min = a, max = b ) # cálculo de probabilidad F(x) Definición 4.7 (Distribución exponencial) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución exponencial \\(X \\rightsquigarrow Exp( \\lambda )\\) de parámetros \\(\\lambda &gt; 0\\), si su función de distribución acumulada es de la siguiente forma: \\[\\begin{equation} F_X( x ) = \\mathbf{1}_{(0,+\\infty)}( x ) \\left( 1 - \\exp\\left( -\\lambda x \\right) \\right) \\end{equation}\\] sin mucho esfuerzo se puede verificar que su densidad de probabilidad está dada por la función \\[\\begin{equation} f_X( x ) = \\mathbf{1}_{(0,+\\infty)}( x ) \\lambda \\exp\\left( -\\lambda x \\right) \\end{equation}\\] \\[\\begin{equation} M_X( t ) = \\frac{\\lambda}{\\lambda - t} \\end{equation}\\] \\[\\begin{equation} \\mathbb{E}[X] = \\frac{1}{\\lambda},\\qquad \\mathbb{V}[X] = \\frac{1}{\\lambda^2} \\end{equation}\\] Code lambda &lt;- 2 x &lt;- 1.5 m &lt;- 100 X &lt;- rexp( n = m, rate = lambda ) # simular una muestra de tamaño m fx &lt;- dexp( x = x, rate = lambda ) # cálculo de la densidad f(x) Fk &lt;- pexp( q = x, rate = lambda ) # cálculo de probabilidad F(x) Definición 4.8 (Distribución gamma) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución gamma \\(X \\rightsquigarrow Gamma( \\alpha, \\beta )\\) de parámetros \\(\\alpha &gt; 0\\), \\(\\beta &gt; 0\\), si su función de distribución acumulada es de la siguiente forma: \\[\\begin{equation} F_X( x ) = \\frac{\\beta^\\alpha}{\\Gamma( \\alpha )} \\int\\limits_{0}^{x} u^{\\alpha-1} \\exp(-\\beta u)\\ du \\end{equation}\\] la densidad de probabilidad automáticamente está dada por la función: \\[\\begin{equation} f_X( x ) = \\mathbf{1}_{[0,+\\infty}( x ) \\frac{\\beta^\\alpha}{\\Gamma( \\alpha )} x^{\\alpha-1} \\exp(-\\beta x) \\end{equation}\\] \\[\\begin{equation} M_X( t ) = \\left( \\frac{\\beta}{\\beta - t} \\right)^\\alpha,\\qquad \\text{si}\\ t &lt; \\beta \\end{equation}\\] \\[\\begin{equation} \\mathbb{E}[X] = \\frac{\\alpha}{\\beta},\\qquad \\mathbb{V}[X] = \\frac{\\alpha}{\\beta^2} \\end{equation}\\] Code alpha &lt;- 2 beta &lt;- 1 x &lt;- 3 m &lt;- 100 X &lt;- rgamma( n = m, shape = alpha, scale = beta ) # simular una muestra de tamaño m fx &lt;- dgamma( x = x, shape = alpha, scale = beta ) # cálculo de la densidad f(x) Fk &lt;- pgamma( q = x, shape = alpha, scale = beta ) # cálculo de probabilidad F(x) Definición 4.8 (Distribución normal) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución normal \\(X \\rightsquigarrow N( \\mu, \\sigma )\\) de parámetros \\(\\mu \\in \\mathbb{R}\\), \\(\\sigma &gt; 0\\), si su función de distribución acumulada es de la siguiente forma: \\[\\begin{equation} F_X( x ) = \\frac{1}{\\sqrt{2\\pi} \\sigma} \\int\\limits_{-\\infty}^x \\exp\\left( -\\frac{(y - \\mu)^2}{\\sigma^2} \\right)\\ dy \\end{equation}\\] la densidad de probabilidad automáticamente está dada por la función: \\[\\begin{equation} f_X( x ) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left( -\\frac{(x - \\mu)^2}{\\sigma^2} \\right) \\end{equation}\\] \\[\\begin{equation} M_X( t ) = \\exp\\left( t \\mu + \\frac{1}{2} t^2 \\sigma^2 \\right) \\end{equation}\\] \\[\\begin{equation} \\mathbb{E}[X] = \\mu,\\qquad \\mathbb{V}[X] = \\sigma^2 \\end{equation}\\] Code mu &lt;- 2 sigma &lt;- 1 x &lt;- 3 m &lt;- 100 X &lt;- rnorm( n = m, mean = mu, sd = sigma ) # simular una muestra de tamaño m fx &lt;- dnorm( x = x, mean = mu, sd = sigma ) # cálculo de la densidad f(x) Fk &lt;- pnorm( q = x, mean = mu, sd = sigma ) # cálculo de probabilidad F(x) Definición 4.9 (Distribución log-normal) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución log-normal \\(X \\rightsquigarrow LN( \\mu, \\sigma )\\) de parámetros \\(\\mu &gt; 0\\), \\(\\sigma &gt; 0\\), si su función de distribución acumulada es de la siguiente forma: \\[\\begin{equation} F_X( x ) = \\frac{1}{\\sqrt{2\\pi} \\sigma} \\int\\limits_{0}^{x} \\frac{1}{y} \\exp\\left( -\\frac{(\\ln(y) - \\mu)^2}{\\sigma^2} \\right)\\ dy \\end{equation}\\] la densidad de probabilidad automáticamente está dada por la función: \\[\\begin{equation} f_X( x ) = \\frac{1}{x\\sqrt{2\\pi} \\sigma} \\exp\\left( -\\frac{(\\ln(x) - \\mu)^2}{\\sigma^2} \\right) \\end{equation}\\] No hay forma analítica para \\(M_X\\) \\[\\begin{equation} \\mathbb{E}[X] = \\exp\\left( \\mu + \\frac{1}{2}\\sigma^2 \\right),\\qquad \\mathbb{V}[X] = \\exp\\left( 2 \\mu + \\sigma^2 \\right) \\left( \\exp( \\sigma^2 ) - 1 \\right) \\end{equation}\\] Code mu &lt;- 2 sigma &lt;- 1 x &lt;- 3 m &lt;- 100 X &lt;- rlnorm( n = m, meanlog = mu, sdlog = sigma ) # simular una muestra de tamaño m fx &lt;- dlnorm( x = x, meanlog = mu, sdlog = sigma ) # cálculo de la densidad f(x) Fk &lt;- plnorm( q = x, meanlog = mu, sdlog = sigma ) # cálculo de probabilidad F(x) En pocas, una variable aleatoria \\(X \\rightsquigarrow LN( \\mu, \\sigma )\\) sigue una distribución log-normal si y solamente si la variable aleatoria dada por su logaritmo \\(\\ln( X ) \\rightsquigarrow N( \\mu, \\sigma )\\) sigue una distribución normal. Definición 4.10 (Distribución de Pareto generalizada) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución de Pareto generalizada \\(X \\rightsquigarrow GPD( \\mu, \\sigma, \\xi )\\) de parámetros \\(\\mu \\in \\mathbb{R}, \\sigma &gt; 0, \\xi \\in \\mathbb{R}\\), si su función de distribución acumulada es de la siguiente forma: \\[\\begin{equation} F_X( x ) = \\left \\{ \\begin{array}{ll} 1 - \\left( 1 + \\xi \\frac{x-\\mu}{\\sigma} \\right)^{-\\frac{1}{\\xi}} &amp; \\text{si}\\ \\xi \\neq 0 \\\\ 1 - \\exp\\left( -\\frac{x-\\mu}{\\sigma} \\right) &amp; \\text{si}\\ \\xi = 0 \\end{array} \\right. \\end{equation}\\] y su densidad de probabilidad está dada por la función \\[\\begin{equation} f_X( x ) = \\left \\{ \\begin{array}{ll} \\frac{1}{\\sigma} \\left( 1 + \\xi \\frac{x-\\mu}{\\sigma} \\right)^{-1-\\frac{1}{\\xi}} &amp; \\text{si}\\ \\xi \\neq 0 \\\\ \\frac{1}{\\sigma} \\exp\\left( -\\frac{x-\\mu}{\\sigma} \\right) &amp; \\text{si}\\ \\xi = 0 \\end{array} \\right. \\end{equation}\\] \\[\\begin{equation} M_X( t ) = \\exp(\\theta \\mu) \\sum\\limits_{j=0}^{+\\infty} \\frac{\\theta^j \\sigma^j} {\\prod\\limits_{k=0}^j ( 1 - k \\xi )} \\end{equation}\\] Code xi &lt;- 1 mu &lt;- 2 sigma &lt;- 1 x &lt;- 3 m &lt;- 100 X &lt;- rgpd( n = m, xi = xi, mu = mu, beta = sigma ) # simular una muestra de tamaño m fx &lt;- dgpd( x = x, xi = xi, mu = mu, beta = sigma ) # cálculo de la densidad f(x) Fk &lt;- pgpd( q = x, xi = xi, mu = mu, beta = sigma ) # cálculo de probabilidad F(x) Definición 4.11 (Distribución de valores extremos generalizada) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución generalizada de valores extremos \\(X \\rightsquigarrow GEV( \\mu, \\sigma, \\xi )\\) de parámetros \\(\\mu \\in \\mathbb{R}, \\sigma &gt; 0, \\xi \\in \\mathbb{R}\\), si su función de distribución acumulada es de la siguiente forma: \\[\\begin{equation} F_X( x ) = \\left\\{ \\begin{array}{ll} \\exp\\left( -\\exp\\left( -\\frac{x-\\mu}{\\sigma} \\right) \\right) &amp; \\text{si}\\ \\xi = 0 \\\\ \\exp\\left( -\\left( 1 + \\xi \\frac{x-\\mu}{\\sigma} \\right)^{-\\frac{1}{\\xi}} \\right) &amp; \\text{si}\\ \\xi \\neq 0, 1 + \\xi\\frac{x - \\mu}{\\sigma} &gt; 0 \\end{array} \\right. \\end{equation}\\] además se puede verificar que su densidad de probabilidad está dada por la función \\[\\begin{equation} f_X( x ) = \\left\\{ \\begin{array}{ll} \\exp\\left(-\\frac{x-\\mu}{\\sigma}\\right) \\exp\\left(-\\exp\\left(-\\frac{x-\\mu}{\\sigma}\\right)\\right) &amp; \\text{si}\\ \\xi = 0 \\\\ \\left( 1 + \\xi \\frac{x - \\mu}{\\sigma}\\right)^{-1-\\frac{1}{\\xi}} \\exp\\left( -\\left( 1 + \\xi \\frac{x-\\mu}{\\sigma} \\right)^{-\\frac{1}{\\xi}} \\right) &amp; \\text{si}\\ \\xi \\neq 0, 1 + \\xi\\frac{x - \\mu}{\\sigma} &gt; 0 \\end{array} \\right. \\end{equation}\\] Code xi &lt;- -1 mu &lt;- 2 sigma &lt;- 1 x &lt;- 3 m &lt;- 100 X &lt;- rgev( n = m, xi = xi, mu = mu, beta = sigma ) # simular una muestra de tamaño m fx &lt;- dgev( x = x, xi = xi, mu = mu, beta = sigma ) # cálculo de la densidad f(x) Fk &lt;- pgev( q = x, xi = xi, mu = mu, beta = sigma ) # cálculo de probabilidad F(x) Definición 4.12 (Distribución t de Student) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución t de Student \\(X \\rightsquigarrow t( \\nu )\\) de parámetros \\(\\nu &gt; 0\\), si su función de distribución acumulada es de la siguiente forma: \\[\\begin{equation} F_X( x ) = \\frac{1}{2} + \\frac{x}{\\sqrt{\\pi \\nu}} \\frac{\\Gamma\\left( \\frac{\\nu + 1}{2} \\right)}{\\Gamma\\left( \\frac{\\nu}{2} \\right)} F\\left( \\frac{1}{2}, \\frac{\\nu+1}{2}, \\frac{3}{2}, -\\frac{x^2}{\\nu} \\right) \\end{equation}\\] donde \\(F\\) es la función hipergeométrica. \\[\\begin{equation} F( a, b, c, z ) = \\sum\\limits_{n=0}^{+\\infty} \\frac{(a)_n (b)_n}{(c)_n} \\frac{z^n}{n!} \\end{equation}\\] con \\[\\begin{equation} (a)_n = \\left\\{ \\begin{array}{ll} 1 &amp; n = 0 \\\\ a( a + 1 ) \\cdots (a + n - 1) &amp; n &gt; 0 \\end{array} \\right. \\end{equation}\\] Además, se puede verificar que su densidad de probabilidad está dada por la función \\[\\begin{equation} f_X( x ) = \\frac{x}{\\sqrt{\\pi \\nu}} \\frac{\\Gamma\\left(\\frac{\\nu+1}{2}\\right)}{\\Gamma\\left( \\frac{\\nu}{2} \\right)} \\left( 1 + \\frac{x^2}{\\nu} \\right)^{-\\frac{\\nu+1}{2}} \\end{equation}\\] La función generadora de momentos \\(M_X( t )\\) no está definida \\[\\begin{equation} \\mathbb{E}[X] = \\left\\{ \\begin{array}{ll} 0 &amp; \\text{si}\\ \\nu &gt; 0 \\\\ \\text{no definida} &amp; \\text{si}\\ \\nu \\leq 0 \\end{array} \\right. \\end{equation}\\] \\[\\begin{equation} \\mathbb{V}[X] = \\left\\{ \\begin{array}{ll} \\frac{\\nu}{\\nu-2} &amp; \\text{si}\\ \\nu &gt; 2 \\\\ +\\infty &amp; \\text{si}\\ 1 &lt; \\nu \\leq 2 \\\\ \\text{no definida} &amp; \\text{si}\\ \\nu \\leq 1 \\end{array} \\right. \\end{equation}\\] Code nu &lt;- 3 x &lt;- 4 m &lt;- 100 X &lt;- rt( n = m, df = nu ) # simular una muestra de tamaño m fx &lt;- dt( x = x, df = nu ) # cálculo de la densidad f(x) Fk &lt;- pt( q = x, df = nu ) # cálculo de probabilidad F(x) Definición 4.13 (Distribución gamma transformada) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución gamma transformada \\(X \\rightsquigarrow GT( \\alpha, \\tau, \\theta )\\) de parámetros \\(\\alpha &gt; 0, \\tau &gt; 0, \\theta &gt; 0\\), si su función de distribución acumulada es de la siguiente forma: \\[\\begin{equation} F_X( x ) = \\frac{\\tau}{\\Gamma( \\alpha )} \\int\\limits_{0}^x \\frac{1}{u} \\left( \\frac{u}{\\theta} \\right)^{\\alpha} \\exp\\left(-\\left( \\frac{u}{\\theta} \\right)^{\\tau}\\right)\\ du \\end{equation}\\] además se puede verificar que su densidad de probabilidad está dada por la función: \\[\\begin{equation} f_X( x ) = \\left\\{ \\begin{array}{ll} 0 &amp; \\text{si}\\ x \\leq 0 \\\\ \\frac{\\tau}{x \\Gamma( \\alpha )} \\left( \\frac{x}{\\theta} \\right)^{\\alpha} \\exp\\left(-\\left( \\frac{x}{\\theta} \\right)^{\\tau}\\right) &amp; \\text{si}\\ x &gt; 0 \\end{array} \\right. \\end{equation}\\] \\[\\begin{eqnarray*} \\mathbb{E}[X^k] &amp; = &amp; \\frac{\\theta^k \\Gamma\\left( \\alpha + \\frac{k}{\\tau}\\right)}{\\Gamma( \\alpha )}, \\quad \\text{si}\\ k &gt; -\\alpha \\tau \\\\ \\mathbb{E}[X] &amp; = &amp; \\frac{\\theta \\Gamma\\left( \\alpha + \\frac{1}{\\tau}\\right)}{\\Gamma( \\alpha )}, \\quad \\text{si}\\ 1 &gt; -\\alpha \\tau \\\\ \\mathbb{V}[X] &amp; = &amp; \\frac{\\theta^2 \\Gamma\\left( \\alpha + \\frac{2}{\\tau}\\right)}{\\Gamma( \\alpha )} - \\frac{\\theta^2 \\Gamma\\left( \\alpha + \\frac{1}{\\tau}\\right)^2}{\\Gamma( \\alpha )^2} \\end{eqnarray*}\\] Code alpha &lt;- 1 tau &lt;- 1 theta &lt;- 1 x &lt;- 3 m &lt;- 100 X &lt;- rtrgamma( n = m, shape1 = alpha, shape2 = tau, scale = theta ) # simular una muestra de tamaño m fx &lt;- dtrgamma( x = x, shape1 = alpha, shape2 = tau, scale = theta ) # cálculo de la densidad f(x) Fk &lt;- ptrgamma( q = x, shape1 = alpha, shape2 = tau, scale = theta ) # cálculo de probabilidad F(x) En la familia gamma se incluyen las siguientes distribuciones: La distribución inversa gamma transformada, es decir es una familia estable por inversión La distribución gamma para \\(\\alpha = n/2\\) y \\(\\theta = 2\\) La distribución inversa gamma La distribución de Weibull La distribución inversa de Weibull La distribución exponencial La distribución inversa exponencial Definición 4.14 (Distribución beta transformada) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución beta transformada \\(X \\rightsquigarrow BT( \\alpha, \\gamma, \\tau, \\theta )\\) de parámetros \\(\\alpha &gt; 0, \\gamma &gt; 0, \\tau &gt; 0, \\theta &gt; 0\\), si su función de distribución acumulada es de la siguiente forma: \\[\\begin{equation} F_X( x ) = \\frac{\\Gamma(\\alpha + \\tau)}{\\Gamma( \\alpha ) \\Gamma( \\tau )} \\int\\limits_0^x \\frac{\\gamma \\left( \\frac{u}{\\theta} \\right)^{\\gamma \\tau}}{u\\left( 1 + \\left( \\frac{u}{\\theta} \\right)^{\\gamma}\\right)^{\\alpha + \\tau}}\\ du \\end{equation}\\] además se puede verificar que su densidad de probabilidad está dada por la función: \\[\\begin{equation} f_X( x ) = \\mathbf{1}_{[0,+\\infty)}( x ) \\frac{\\Gamma(\\alpha + \\tau)}{\\Gamma( \\alpha ) \\Gamma( \\tau )} \\frac{ \\gamma \\left( \\frac{x}{\\theta} \\right)^{\\gamma \\tau}}{x\\left( 1 + \\left( \\frac{x}{\\theta} \\right)^{\\gamma}\\right)^{\\alpha + \\tau}} \\end{equation}\\] \\[\\begin{eqnarray*} \\mathbb{E}[X^k] &amp; = &amp; \\frac{\\theta^k \\Gamma\\left( \\tau + \\frac{k}{\\gamma}\\right) \\Gamma\\left( \\tau - \\frac{k}{\\gamma}\\right)}{\\Gamma( \\alpha ) \\Gamma( \\tau )}, \\quad \\text{si}\\ -\\tau \\gamma &lt; k &lt; \\tau \\gamma \\\\ \\mathbb{E}[X] &amp; = &amp; \\frac{\\theta \\Gamma\\left( \\tau + \\frac{1}{\\gamma}\\right) \\Gamma\\left( \\tau - \\frac{1}{\\gamma}\\right)}{\\Gamma( \\alpha ) \\Gamma( \\tau )} \\\\ \\mathbb{V}[X] &amp; = &amp; \\frac{\\theta^2 \\Gamma\\left( \\tau + \\frac{2}{\\gamma}\\right) \\Gamma\\left( \\tau - \\frac{2}{\\gamma}\\right)}{\\Gamma( \\alpha ) \\Gamma( \\tau )} - \\frac{\\theta^2 \\Gamma\\left( \\tau + \\frac{1}{\\gamma}\\right)^2 \\Gamma\\left( \\tau - \\frac{1}{\\gamma}\\right)^2}{\\Gamma( \\alpha )^2 \\Gamma( \\tau )^2} \\end{eqnarray*}\\] Code alpha &lt;- 1 gamma &lt;- 1 tau &lt;- 1 theta &lt;- 1 x &lt;- 3 m &lt;- 100 X &lt;- rtrbeta( n = m, shape1 = alpha, shape2 = gamma, shape3 = tau, scale = theta ) # simular una muestra de tamaño m fx &lt;- dtrbeta( x = x, shape1 = alpha, shape2 = gamma, shape3 = tau, scale = theta ) # cálculo de la densidad f(x) Fk &lt;- ptrbeta( q = x, shape1 = alpha, shape2 = gamma, shape3 = tau, scale = theta ) # cálculo de probabilidad F(x) Dentro de la familia beta transformada se cuenta algunas distribuciones de probabilidad: La distribución de Burr para \\(\\tau = 1\\) La distribución de log-logística para \\(\\alpha = \\tau = 1\\) La distribución de paralogística para \\(\\alpha = \\gamma, \\tau = 1\\) La distribución de generalizada de Pareto para \\(\\gamma = 1\\) La distribución de Pareto para \\(\\gamma = \\tau = 1\\) La distribución de inversa de Burr para \\(\\alpha = 1\\) La distribución de inversa de Pareto para \\(\\alpha = \\gamma = 1\\) La distribución de inversa paralogística para \\(\\alpha = 1, \\gamma = \\tau\\) La distribución transformada gamma es un caso límite de la distribución transformada beta, cuando \\(\\theta \\rightarrow +\\infty, \\alpha \\rightarrow +\\infty\\) y \\(\\theta \\alpha^{-\\frac{1}{\\gamma}} \\rightarrow \\xi\\) 4.4 Estimación En la práctica se observa la realización de una variable aleatoria \\(X\\), es decir se tiene una muestra de la misma \\(X_1, \\ldots, X_n\\). Pero, no se dispone de la distribución \\(F\\) o de la densidad \\(f\\) que la describe. Como ya hemos mencionado, conociendo la distribución se puede inferir algunas propiedades sobre la variable. De ahí surge la necesidad de buscar la mejor distribución \\(F\\) posible a partir de la muestra. Para ello se ha formulado diferentes aproximaciones, entre las cuales citamos las siguientes: Método de sustitución Método de los momentos Método de la distancia mínima Método de maximización de la verosimilitud 4.4.1 Método de sustitución Se considera que para la medida de de probabilidad \\(P_X\\) que caracteriza a la variable aleatoria \\(X\\) está dentro de una familia de funciones que dependen de un parámetro \\(\\theta \\in \\Theta\\), es decir para cada \\(\\theta\\), \\(P_{\\theta}\\) es una medida de probabilidad y para algún \\(\\theta \\in \\Theta, P_X = P_{\\theta}\\). Entonces, se parte de suponer que existe funcional \\(G\\) actuando sobre el conjunto de medidas de probabilidad \\(\\mathcal{P}\\) que contiene al conjunto \\(P( \\Theta ) = \\{ P_{\\theta} \\mid \\theta \\in \\Theta\\} \\subset \\mathcal{P}\\) y que toma valores en \\(\\Theta\\), i.e. \\(G: \\mathcal{P} \\longrightarrow \\Theta\\). De tal forma que \\(P_{\\theta}\\) es invariante, es decir: \\[\\begin{equation} G( P_{\\theta} ) = \\theta,\\quad \\forall \\theta \\in \\Theta \\end{equation}\\] Así se construye un estimador por el método de sustitución si a partir de la medida de probabilidad empírica \\(P_n\\) construida con una muestra \\(X_1, \\ldots, X_n\\) de la variable aleatoria \\(X\\), se toma como parámetro el dado por: \\[\\begin{equation} \\widehat{\\theta} = G\\left( P_n \\right) \\end{equation}\\] En otras palabras se sustituye el parámetro \\(\\theta\\) por \\(\\widehat{\\theta}\\). Esto implica que se aproxima la medida \\(P_X\\) que caracteriza a \\(X\\), con la aproximación \\(P_X \\approx P_{\\widehat{\\theta}}\\). Es de notar que a priori no se hace establece ninguna medida de la calidad de la aproximación, para ello hay que adjuntar algunos otros criterios que caracterizan un buen tipo de estimador. En otras ocasiones a partir de la muestra se define un estimador del parámetro \\(\\theta \\in \\Theta\\) a partir de una familia de funciones medibles que dependen directamente de la muestra \\(X_1, \\ldots, X_n\\) y su tamaño \\(n\\), i.e. una función \\(\\theta_n( X_1, \\ldots, X_n )\\). Se puede considerar el caso anterior como un caso en particular de este tipo de funciones, ya que se puede definir \\(\\theta_n( X_1, \\ldots, X_n ) = G( P_n )\\), pero hay que tener cuidado que \\(G\\) es un funcional y como tal puede resultar una función que no es medible. Definición 4.15 (Estimadores convergentes) En el mismo contexto anterior. Si la variable aleatoria \\(X\\) está caracterizada por la medida \\(P_X = P_{\\theta}\\), para algún \\(\\theta \\in \\Theta\\). Decimos que una familia de estimadores \\(\\{\\theta_n\\}\\) es convergente si al generar cada vez una muestra más grande el estimador \\(\\theta_n( X_1, \\ldots, X_n )\\) converge en probabilidad a \\(\\theta\\). Esto quiere decir que para cualquier \\(\\varepsilon &gt; 0\\) \\[\\begin{equation} \\underset{n \\rightarrow +\\infty}{\\lim} P_{\\theta}\\left( \\left| \\theta_n( X_1, \\ldots, X_n ) - \\theta \\right| \\geq \\varepsilon \\right) = 0 \\end{equation}\\] Decimos que converge fuertemente si la convergencia de la familia de estimadores \\(\\theta_n( X_1, \\ldots, X_n )\\) a \\(\\theta\\) se da casi seguramente o casi todas partes. Esto en término de límites implica que: \\[\\begin{equation} P_{\\theta}\\left( \\underset{n \\rightarrow +\\infty}{\\lim} \\theta_n( X_1, \\ldots, X_n ) = \\theta \\right) = 1 \\end{equation}\\] En otras palabras, la probabilidad de que el límite del estimador \\(\\theta_n( X_1, \\ldots, X_n )\\) sea igual a \\(\\theta\\) es \\(1\\), salvo un conjunto de medida nula para \\(P_{\\theta}\\). De ahí resulta la terminología de convergencia casi segura o convergencia en casi todas partes. 4.4.2 Método de momentos Un estimador de momento se contruye a partir de una relación función entre la media de una función medible \\(g\\) y el parámetro \\(\\theta \\in \\Theta\\) que caracteriza a la distribución o medida de probabilidad de la variable aleatoria \\(X\\). Es decir, existen funciones \\(g\\) y \\(m\\) a valores reales de tal forma que \\[\\begin{equation} m( \\theta ) = \\mathbb{E}_{P_X} \\left[ g( X ) \\right] = \\int\\limits_{\\mathbb{R}} g( x ) dP_X( x ) = \\int\\limits_{\\mathbb{R}} g( x ) dP_{\\theta}( x ) \\end{equation}\\] Si de alguna forma se puede invertir \\(m\\), de tal forma que se pueda determinar \\(\\theta\\), en tal caso se pude utilizar un estimador por momentos a partir de una muestra de la variable aleatoria \\(X_1, \\ldots, X_n\\) \\[\\begin{equation} \\widehat{\\theta} = \\theta_n\\left( X_1, \\ldots, X_n \\right) = m^{-1}\\left( \\overline{g} \\right) \\end{equation}\\] donde \\[\\begin{equation} \\overline{g} = \\int\\limits_{\\mathbb{R}} g( x ) dP_n( x ) = \\frac{1}{n}\\sum\\limits_{i=1}^n g\\left( X_i \\right) \\end{equation}\\] Si en caso \\(\\overline{g}\\) está fuera de la imagen de \\(m\\), \\(\\overline{g} \\notin m( \\Theta )\\), la inversión no sería posible. Para resolver este problema se puede recurrir a una distancia \\(d\\) y buscar \\(\\hat{g}\\) tal que minimize la distancia a \\(m( \\Theta )\\), i.e.  \\(\\hat{g} = \\underset{h \\in m( \\Theta )}{\\operatorname{arginf}}\\ d( \\overline{g}, h)\\). Una vez determinado \\(\\hat{g}\\) se toma como estimador de momentos su inversa con \\(m\\), i.e.  \\(\\widehat{\\theta} = m^{-1}( \\hat{g} )\\). Es de notar que en el caso anterior, la selección de la mejor distancia \\(d\\) no es para nada evidente y puede ser un problema tanto o más difícil que la misma estimación del parámetro \\(\\theta\\) o la inversión de \\(m\\). La estimación por momentos en los casos más elaborados lleva a buscar la solución de problemas no lineales, que no suelen ser estables y que deben estar bien definidos para proveer una solución única. 4.4.3 Método de la distancia mínima Este método requiere de la definición de una distancia sobre el espacio de distribuciones de probabilidad \\(\\mathcal{P}\\), i.e. una función \\(d : \\mathcal{P} \\times \\mathcal{P} \\longrightarrow \\mathbb{R}_+\\) que satisface las siguientes propiedades: Propiedad de simetría, para cualquier \\(P, Q \\in \\mathcal{P}\\), \\(d( P, Q ) = d( Q, P )\\), Para cualquier \\(P \\in \\mathcal{P}\\), \\(d( P, P ) = 0\\). Desigualdad triangular, para cualquier \\(P,Q,R \\in \\mathcal{P}\\) \\[\\begin{equation} d( P, Q ) \\leq d( P, R ) + d( R, Q ) \\end{equation}\\] A partir de la medida empírica de probabilidad \\(P_n\\), se busca una probabilidad \\(P_{\\theta}\\) que minimize la distancia medida con \\(d\\). Así resulta el estimador con el método de distancia mínima \\[\\begin{equation} \\widehat{\\theta} = \\underset{\\theta \\in \\Theta}{\\operatorname{arginf}} d\\left( P_{\\theta}, P_n \\right) \\end{equation}\\] Entra las distancias que se puede considerar tenemos las siguientes Distancia del supremo entre las distribuciones acumuladas correspondientes \\[\\begin{equation} d(P,Q) = \\underset{x}{\\sup} \\left| F_P( x ) - F_Q( x ) \\right| \\end{equation}\\] Distancia cuadrática entre las distribuciones acumuladas correspondientes \\[\\begin{equation} d( P, Q ) = \\int\\limits_{\\mathbb{R}} \\left( F_P( x ) - F_Q( x ) \\right)^2\\ dF_Q( x ) \\end{equation}\\] Distancia de Wasserstein, para \\(p &gt; 1\\) \\[\\begin{equation} d( P, Q ) = W_p( P, Q ) = \\underset{(X,Y) \\rightsquigarrow \\mu \\in \\Gamma( P, Q )}{\\inf} \\mathbb{E}_{\\mu}\\left[ |X - Y|^p \\right]^{\\frac{1}{p}} \\end{equation}\\] donde \\[\\begin{equation} \\Gamma( P, Q ) = \\left\\{ \\mu \\middle| \\text{$\\mu$ es medida de probabilidad sobre $\\Omega \\times \\Omega$, cuyas distribuciones marginales son $P$ y $Q$}\\right\\} \\end{equation}\\] 4.4.4 Método de maximización de la verosimilitud La estimación de verosimilitud parte de asumir que se observan una cierta cantidad de eventos independientes \\(B_1, \\ldots, B_n\\), relacionados precisamente a la variable aleatoria en estudio \\(X\\). Se postula precisamente que la mejor medida de probabilidad es aquella que maximiza la probabilidad de observar estos eventos independientes. En el caso en particular de la estimación de una medida de probabilidad en una familia \\(\\{P_{\\theta}\\}\\) con \\(\\theta \\in \\Theta\\), se busca maximizar la probabilidad: \\[\\begin{equation} \\underset{\\theta \\in \\Theta}{\\sup} \\prod\\limits_{i=1}^n P_{\\theta}\\left( B_i \\right) \\end{equation}\\] o de forma equivalente, si se toma logaritmos: \\[\\begin{equation} \\underset{\\theta \\in \\Theta}{\\sup} \\sum\\limits_{i=1}^n \\log P_{\\theta} \\left( B_i \\right) \\end{equation}\\] Así, el estimador por verosimilitud, es el dado por: \\[\\begin{equation} \\widehat{\\theta} = \\underset{\\theta \\in \\Theta}{\\operatorname{argsup}} \\sum\\limits_{i=1}^n \\log P_{\\theta} \\left( B_i \\right) \\end{equation}\\] En la práctica los eventos que se observa \\(B_i\\) son puntuales y son precisamente los valores que toma la variable aleatoria \\(X\\). Es decir, se observa una muestra \\(X_1, \\ldots, X_n\\). Podemos tener una variable aleatoria discreta \\(N\\), de la cual hemos observado una muestra de \\(N_1, \\ldots, N_m\\) asumiendo independencia entre cada una de las observaciones. Podemos ademas suponer que \\(N\\) pertenece a la familia de distribuciones discretas en la clase \\((0,a,b)\\) y por tanto \\(P( N = 0 ) = p_0\\) es un parámetro inicial \\(p_n = ( a + b/n) p_{n-1}\\), para cualquier \\(n &gt; 1\\). \\[\\begin{equation} P\\left( N_1 = n_1 \\land \\cdots \\land N_m = n_m \\right) = \\prod\\limits_{i=1}^m p_i^{n_i} \\end{equation}\\] 4.4.5 Calidad de estimadores Definición 4.16 (Estimador insesgado) Se dice que un estimador \\(\\theta_1\\) se dice insesgado para estimar el parámetro \\(\\theta\\), si se cumple que: \\[\\begin{equation} \\mathbb{E}\\left[ \\theta_1 \\right] = \\theta \\end{equation}\\] caso contrario se dirá que el estimador es sesgado o que presenta un error sistemático. Definición 4.17 (Mejor estimador en media cuadrática) Se dice que un estimador \\(\\theta_1\\) es mejor estimador en media cuadrática que el estimador \\(\\theta_2\\), respecto del parámetro \\(\\theta\\), si se cumple la siguiente desigualdad \\[\\begin{equation} \\mathbb{E}\\left[ \\left( \\theta_1 - \\theta \\right)^2 \\right] &lt; \\mathbb{E}\\left[ \\left( \\theta_2 - \\theta \\right)^2 \\right] \\end{equation}\\] "],["modelos-de-pérdida-agregada.html", "Capítulo 5 Modelos de pérdida agregada 5.1 Mutualización del riesgo 5.2 Modelo individual 5.3 Modelo colectivo 5.4 Modelos mixtos 5.5 Modelos con variables explicativas 5.6 Proceso estocástico de reclamos totales 5.7 Aplicación del deducible 5.8 Algoritmo de Panjer 5.9 Estimación usando la transformada de Fourier", " Capítulo 5 Modelos de pérdida agregada 5.1 Mutualización del riesgo La idea de mantener un seguro está basada en la mutualización de los riesgos. La mutualización como tal nace del mismo mecanismo bajo el cual funciona un seguro, cada asegurado transfiera su riesgo individual a la compañia de seguros por su parte, la suma total de estos riesgos \\(S\\) es el riesgo total que asume el asegurador. Los riesgos de cada uno de los \\(n \\in \\mathbb{N}\\) asegurados, pueden ser representados por variables aleatorias \\(X_1,\\ldots X_n\\), las mismas pueden ser independientes o dependientes entre ellas. El costo total del portafolio está dado por la suma de todos estos riesgos. \\[\\begin{equation} S = \\sum\\limits_{i=1}^n X_i \\end{equation}\\] El conocer la distribución del costo total \\(S\\) es una tarea crucial para el asegurador. El valore esperado de de los reclamos totales, puede ser calculado fácilmente utilizando las propiedades de linealidad de la esperanza matemática \\(\\mathbb{E}\\) \\[\\begin{equation} \\mathbb{E}[ S ] = \\mathbb{E}\\left[ \\sum\\limits_{i=1}^n X_i \\right] = \\sum\\limits_{i=1}^n \\mathbb{E}\\left[ X_i \\right] \\end{equation}\\] por su parte, la varianza de la variable aleatoria del costo total \\(S\\), está dada por: \\[\\begin{eqnarray*} \\mathbb{V}\\left[ S \\right] &amp; = &amp; \\mathbb{V}\\left[ \\sum\\limits_{i=1}^n X_i \\right] \\\\ &amp; = &amp; \\sum\\limits_{i=1}^n \\mathbb{V}\\left[ X_i \\right] + \\sum\\limits_{i=1}^n \\sum\\limits_{j=1,j\\neq i}^n \\mathbb{C}\\left[ X_i, X_j \\right] \\\\ &amp; = &amp; \\sum\\limits_{i=1}^n \\mathbb{V}\\left[ X_i \\right] + 2\\sum\\limits_{i=1}^{n-1} \\sum\\limits_{j=i+1}^n \\mathbb{C}\\left[ X_i, X_j \\right] \\end{eqnarray*}\\] Muchas de las veces el número total de reclamos \\(n\\) es incierto y por tal razón es mejor considerar que el número de siniestros vendrá dado por otra variable aleatoria discreta \\(N\\) que solo tomará valores en \\(\\mathbb{N}\\) \\[\\begin{equation} S = \\sum\\limits_{i=1}^N X_i \\end{equation}\\] Esto nos lleva a considerar diferentes modelos de agregación de reclamos o pérdidas como se suele decir en inglés “loss models” [1], [2]. De forma preliminar estudiemos la forma general que podría tener la distribución de \\(S\\), sin realizar alguna hipótesis previa sobre el comportamiento de las variables aleatorias \\(X_1, \\ldots, X_n\\) y \\(N\\). \\[\\begin{eqnarray*} F( S \\leq s ) &amp; = &amp; P\\left( \\sum\\limits_{i=1}^N X_i \\leq s \\right) \\\\ &amp; = &amp; P\\left( \\sum\\limits_{i=1}^N X_i \\leq s \\land N \\in \\mathbb{N}\\right) \\\\ &amp; = &amp; P\\left( \\bigcup\\limits_{n\\in \\mathbb{N}} \\left\\{ \\sum\\limits_{i=1}^N X_i \\leq s \\land N \\in \\{n\\} \\right\\}\\right) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} P\\left( \\sum\\limits_{i=1}^n X_i \\leq s \\land N = n \\right) \\qquad \\text{probabilidad de eventos disjuntos} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} P\\left( \\sum\\limits_{i=1}^n X_i \\leq s\\ \\middle|\\ N = n \\right) P( N = n ) \\qquad \\text{propiedades de la probabilidad condicional} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} \\int\\limits_{\\left\\{\\sum\\limits_{i=1}^n x_i \\leq s\\right\\}} dF_n( x_1, \\ldots, x_n )\\ p_n \\qquad \\text{$F_n$ es la distribución conjunta de $X_1, \\ldots, X_n$} \\end{eqnarray*}\\] la última expresión es importante de retener, nos dice que para comprender el comportamiento de los reclamos totales \\(S\\), debemos estudiar y estimar la frecuencia de los reclamos \\(N\\), y también debemos comprender y estimar cada uno de los reclamos \\(X_i\\) y también su interacción, siendo al menos estos una infinidad si \\(N\\) puede tomar valores tendiendo al infinito. En términos resumidos, hay que comprender y estimar la frecuencia y severidad de los reclamos que están asociados al riesgo cubierto. Los términos integrales \\(\\int\\limits_{\\left\\{\\sum\\limits_{i=1}^n x_i \\leq s\\right\\}} dF_n( x_1, \\ldots, x_n )\\) asociados a la severidad presentan un verdadero reto estadístico y computacional; hace unos años atrás se desarrolló unos nuevos algoritmos para calcular estos términos [13], [14]. 5.2 Modelo individual En el modelo de riesgos individuales consideramos que el número de siniestros que se producirán es conocido, por ejemplo puede ser a lo sumo el tamaño de la población asegurada, en tal caso la variable aleatoria \\(N\\) pasa a ser una constante, que representaremos por \\(n\\). De esta forma, la severidad total puede ser fácilmente representada por: \\[\\begin{equation} S = \\sum\\limits_{i=1}^n X_i \\end{equation}\\] La hipótesis más usual que sostiene a este modelo es la indenpendencia entre cada uno de los reclamos \\(X_i\\) y \\(X_j\\) son independientes para cualquier \\(1 \\leq i \\neq j \\leq n\\). El valor esperado de la severidad total \\(S\\) es: \\[\\begin{eqnarray*} \\mathbb{E}[S] &amp; = &amp; \\mathbb{E}\\left[ \\sum\\limits_{i=1}^n X_i \\right] \\\\ &amp; = &amp; \\sum\\limits_{i=1}^n \\mathbb{E}\\left[ X_i \\right] \\\\ &amp; = &amp; n \\mathbb{E}[X] \\quad \\text{si $\\{X_i\\}$ son idénticamente distribuidas} \\end{eqnarray*}\\] Así mismo con la varianza de \\(S\\). \\[\\begin{eqnarray*} \\mathbb{V}\\left[ S \\right] &amp; = &amp; \\mathbb{V}\\left[ \\sum\\limits_{i=1}^n X_i \\right] \\\\ &amp; = &amp; \\sum\\limits_{i=1}^n \\mathbb{V}\\left[ X_i \\right] + \\sum\\limits_{i=1}^n \\sum\\limits_{j=1,j\\neq i}^n \\mathbb{C}\\left[ X_i, X_j \\right] \\\\ &amp; = &amp; \\sum\\limits_{i=1}^n \\mathbb{V}\\left[ X_i \\right]\\quad \\text{si $\\{X_i\\}$ sin son independientes entre si} \\\\ &amp; = &amp; n \\mathbb{V}\\left[ X \\right]\\quad \\text{si $\\{X_i\\}$ sin son idénticamente distribuidas} \\end{eqnarray*}\\] Al tener un número determinado de reclamos \\(n \\in \\mathbb{N}\\), la distribución de probabilidad del total de reclamos \\(S\\) puede ser calculada de una forma maś sencilla. \\[\\begin{eqnarray*} F_S( x ) &amp; = &amp; F_{X_1} \\star \\cdots \\star F_{X_n} ( s )\\quad \\text{sin $\\{X_i\\}$ son independientes} \\\\ &amp; = &amp; F_{X}^{\\star n}( s )\\quad \\text{si $\\{X_i\\}$ son idénticamente distribuidas} \\end{eqnarray*}\\] así mismo, si las densidades de probabilidad están bien definidas, entonces \\[\\begin{eqnarray*} f_S( s ) &amp; = &amp; f_{X_1} \\star \\cdots \\star f_{X_n} ( s )\\quad \\text{sin $\\{X_i\\}$ son independientes} \\\\ &amp; = &amp; f_{X}^{\\star n}( s )\\quad \\text{si $\\{X_i\\}$ son idénticamente distribuidas} \\end{eqnarray*}\\] Una posible estrategias para estimar \\(F_S\\) o \\(f_S\\) es utilizar la transformada de Fourier \\(\\mathscr{F}\\), la cual convierte las convoluciones en productos y luego invertir de nuevo la transformada de Fourier. \\[\\begin{eqnarray*} F_S &amp; = &amp; \\mathscr{F}^{-1}\\left( \\mathscr{F}\\left( F_S \\right) \\right) \\\\ &amp; = &amp; \\mathscr{F}^{-1}\\left( \\mathscr{F}\\left( F_{X_1} \\star \\cdots \\star F_{X_n} \\right) \\right) \\quad \\text{sin $\\{X_i\\}$ son independientes} \\\\ &amp; = &amp; \\mathscr{F}^{-1}\\left( \\prod\\limits_{i=1}^n \\mathscr{F}\\left( F_{X_i} \\right) \\right) \\\\ &amp; = &amp; \\mathscr{F}^{-1}\\left( \\mathscr{F}\\left( F_{X} \\right)^n \\right) \\quad \\text{si $\\{X_i\\}$ sin son idénticamente distribuidas } \\\\ \\end{eqnarray*}\\] o de forma equivalente para la densidad \\(f_S\\) \\[\\begin{eqnarray*} f_S &amp; = &amp; \\mathscr{F}^{-1}\\left( \\mathscr{F}\\left( f_S \\right) \\right) \\\\ &amp; = &amp; \\mathscr{F}^{-1}\\left( \\mathscr{F}\\left( f_{X_1} \\star \\cdots \\star f_{X_n} \\right) \\right) \\quad \\text{sin $\\{X_i\\}$ son independientes} \\\\ &amp; = &amp; \\mathscr{F}^{-1}\\left( \\prod\\limits_{i=1}^n \\mathscr{F}\\left( f_{X_i} \\right) \\right) \\\\ &amp; = &amp; \\mathscr{F}^{-1}\\left( \\mathscr{F}\\left( f_{X} \\right)^n \\right) \\quad \\text{si $\\{X_i\\}$ sin son idénticamente distribuidas } \\\\ \\end{eqnarray*}\\] 5.2.1 Algoritmo de simulación Se puede simular la severidad total \\(S\\) para el caso donde se asume independencia entre cada una de las severidades \\(X_1, \\ldots, X_n\\) y se conoce cada una de sus densidades de probabilidad \\(f_{X_1}, \\ldots, f_{X_n}\\) o distribuciones de probabilidad \\(F_{X_1}, \\ldots, F_{X_n}\\). Se tiene fijo \\(n \\in \\mathbb{N}\\), Se fija el número de simulaciones \\(m \\in \\mathbb{N}\\) Para cada \\(i \\in \\{1, \\ldots, m\\}\\) se extrae una muestra \\(X_{i,1} \\rightsquigarrow f_{X_1},\\ldots,X_{i,n} \\rightsquigarrow f_{X_n}\\), Para cada \\(i \\in \\{1, \\ldots, m\\}\\) se calcula la severidad total para la muestra \\(i\\), \\(S_i = \\sum\\limits_{j=1}^n X_{i,j}\\) Ejemplo 5.1 El siguiente código ejemplifica el algoritmo anterior, donde se asume que cada variable aleatoria de severidad \\(X_i\\) sigue una ley log-normal \\(LN( \\mu_i, \\sigma_i )\\), de parámetros \\(\\mu_i, \\sigma_i\\), para \\(i \\in \\{1,\\ldots, n\\}\\). Code # 1. número de distribuciones n &lt;- 200 # parámetros para las n distribuciones mu &lt;- seq( 1, 2, length.out = n ) sigma &lt;- seq( 2, 3, length.out = n ) # 2. número de simulaciones m &lt;- 1e4 # 3. simulación de severidades X &lt;- lapply( 1:m, FUN = function( i ) sapply( 1:n, FUN = function( j ) rlnorm( 1, meanlog = mu[ j ], sdlog = sigma[ j ] ) ) ) # 4. simulación de severidad total S &lt;- sapply( X, FUN = function( x ) sum( x ) ) En el ejemplo anterior es de notar que la densidad de probabilidad de la severidad \\(S\\) resulta de la convolución de las \\(n\\) densidades individuales \\(f_S = f_{X_1} \\star \\cdots \\star f_{X_n}\\), la cual no presenta una forma analítica conocida. De la imposibilidad anterior se se puede ver la utilidad de trabajar con la simulación aleatoria de la variable \\(S\\). Se puede estimar la distribución acumulada de probabilidad \\(F_S\\) a partir de la distribución empírica \\(F_m\\) de la muestra, con: \\[\\begin{equation} F_S( s ) \\approx F_m( s ) = \\frac{1}{m} \\sum\\limits_{i=1}^m \\mathbf {1}_{(-\\infty,s]}( S_i ) \\end{equation}\\] el resultado de acotación de 3.4 nos da un criterio de convergencia de \\(F_m\\) a \\(F_S\\) Para construir \\(F_m\\) en R, se puede utilizar la función ya empaquetada ecdf (empirical cumulative distribution function). Code # estimación distribución acumulada empírica de S Fm &lt;- ecdf( S ) # esperanza empírica EeS &lt;- mean( S ) # esperanza teórica ES &lt;- sum( sapply( 1:n, FUN = function( i ) exp( mu[i] + 0.5 * sigma[i]^2 ) ) ) s &lt;- seq( quantile( S, probs = 0.01 ), quantile( S, probs = 0.99 ), length.out = 1e3 ) Fms &lt;- sapply( s, FUN = Fm ) plot( s, Fms, type = &#39;s&#39; ) abline( v = EeS, col = &#39;red&#39; ) abline( v = ES, col = &#39;orange&#39; ) Para calcular la esperanza de la severidad total \\(S\\), también se puede utilizar una aproximación a la integral de Riemann-Stieltjes utilizando la distribución acumulada empírica \\(F_m\\). \\[\\begin{equation} \\mathbb{E}[ S ] = \\int\\limits_{\\mathbb{R}} s dF_S( s ) \\approx \\int\\limits_{\\mathbb{R}} s dF_m( s ) \\approx \\sum\\limits_{i=1}^N s_{i} \\left( F_m( s_{i+1} ) - F_m( s_{i} ) \\right) \\end{equation}\\] Esta aproximación en R puede ser implementada de la siguiente forma: Code N &lt;- 1e5 s &lt;- seq( min( S ), max( S ), length.out = N ) EmS &lt;- sum( s[-N] * diff( sapply( s, FUN = Fm ) ) ) De ello tenemos los siguientes resultados de cálculo para el valor esperado de la severidad total \\[\\begin{eqnarray*} \\mathbb{E}[S] = \\sum\\limits_{i=1}^n e^{ \\mu_i + \\frac{1}{2} \\sigma_i^2 } &amp; = &amp; 34562.7208, \\\\ \\overline{S} = \\frac{1}{m} \\sum\\limits_{i=1}^m S_i &amp; = &amp; 35805.0631, \\\\ \\sum\\limits_{i=1}^N s_{i} \\left( F_m( s_{i+1} ) - F_m( s_{i} ) \\right) &amp; = &amp; 35677.4091 \\end{eqnarray*}\\] Lo bueno de poseer una buena aproximación a la distribución acumulada de una variable aleatoria, es que podemos calcular algunos otros valores de importancia relacionados a la variable aleatoria y no tan solo utilizar medidas de tendencia central. Sin embargo, para que esta aproximación sea útil se requiere reducir el error de probabilidad 3.4. Ejemplo 5.2 Podemos considerar el caso sencillo donde el valor posible de severidad es determinista, es decir para cada póliza \\(i\\in \\{1,\\ldots,n\\}\\), el valor de severidad probable es único \\(M &gt; 0\\) si en caso se da un evento \\(A_i\\), esto lo podemos expresar como \\(X_i = M \\mathbf{1}_{A_i}\\) es constante. Así, pérdida total está dada por: \\[\\begin{equation} S = \\sum\\limits_{i=1}^n X_i = \\sum\\limits_{i=1}^n M \\mathbf{1}_{A_i} \\end{equation}\\] El valor total esperado de reclamos está dado por: \\[\\begin{equation} \\mathbb{E}[ S ] = \\sum\\limits_{i=1}^n \\mathbb{E}\\left[ M \\mathbf{1}_{A_i} \\right] = M \\sum\\limits_{i=1}^n P( A_i ) \\end{equation}\\] la última igualdad resulta de las propiedades de la función indicatriz 3.10. Si en caso todos los \\(P(A_i) = p\\) tienen la misma probabilidad, el valor total esperado de reclamos toma la siguiente forma: \\[\\begin{equation} \\mathbb{E}[S] = n M p \\end{equation}\\] 5.3 Modelo colectivo El modelo colectivo de riesgo considera un número de reclamos descritos por una variable aleatoria discreta \\(N\\). Los reclamos corresponden a un número de pólizas en un periodo específico, el valor de cada reclamo \\(i \\in \\{1,\\ldots,N\\}\\) está representado por las variables aleatorias \\(X_i\\). Usualmente, se considera que cada uno de los reclamos \\(X_i\\) están idénticamente distribuidos. \\[\\begin{equation} S = \\left\\{ \\begin{array}{ll} \\sum\\limits_{i=1}^N X_i &amp; \\text{si}\\ N &gt; 0 \\\\ 0 &amp; \\text{si}\\ N = 0 \\end{array} \\right. \\end{equation}\\] o de forma más compacta se tan solo utilizar la igualdad \\(S = \\sum\\limits_{i=1}^N X_i\\), donde se asume que la suma da \\(0\\) si \\(N = 0\\). El valor esperado del total de reclamos \\(S\\), está dado por: \\[\\begin{eqnarray*} \\mathbb{E}[S] &amp; = &amp; \\mathbb{E}\\left[ \\sum\\limits_{i=1}^N X_i \\right] \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} \\mathbb{E}\\left[ \\sum\\limits_{i=1}^n X_i\\ \\middle|\\ N = n \\right]P( N = n ) \\quad \\text{utilizando la esperanza condicional} \\\\ &amp; = &amp; 0 P( N = 0 ) + \\sum\\limits_{n=1}^{+\\infty} \\mathbb{E}\\left[ \\sum\\limits_{i=1}^n X_i\\ \\middle|\\ N = n \\right]P( N = n ) \\\\ &amp; = &amp; \\sum\\limits_{n=1}^{+\\infty} \\sum\\limits_{i=1}^n \\mathbb{E}\\left[ X_i \\mid N = n \\right]P( N = n ) \\quad \\text{linealidad de la esperanza} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} n \\mathbb{E}\\left[ X \\mid N = n \\right]P( N = n ) \\quad \\text{si $\\{X_i\\}$ son idénticamente distribuidas} \\\\ &amp; = &amp; \\mathbb{E}\\left[ X \\right] \\sum\\limits_{n=0}^{+\\infty} n P( N = n ) \\quad \\text{si $X$ y $N$ son independientes} \\\\ &amp; = &amp; \\mathbb{E}[ N ] \\mathbb{E}[ X ] \\end{eqnarray*}\\] También podemos calcular la varianza de los reclamos totales \\(S\\), para ello necesitamos primeramente calcular su segundo momento. \\[\\begin{eqnarray*} \\mathbb{E}[S^2] &amp; = &amp; \\mathbb{E}\\left[ \\left( \\sum\\limits_{i=1}^N X_i \\right)^2 \\right] \\\\ &amp; = &amp; \\sum\\limits_{n=0}^\\infty \\mathbb{E}\\left[ \\sum\\limits_{i, j=1}^n X_i X_j \\middle| N = n \\right] P( N = n ) \\quad \\text{propiedades de la esperanza condicional} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^\\infty \\sum\\limits_{i, j=1}^n \\mathbb{E}\\left[ X_i X_j \\right] P( N = n ) \\quad \\text{si $\\{X_i\\}$ y $N$ son independientes} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^\\infty \\left( \\sum\\limits_{i=1}^n \\mathbb{E}\\left[ X_i^2 \\right] + \\sum\\limits_{i,j=1,i\\neq j}^n \\mathbb{E}\\left[ X_i X_j \\right] \\right) P( N = n ) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^\\infty \\left( n \\mathbb{E}\\left[ X^2 \\right] + n(n-1) \\mathbb{E}\\left[ X \\right]^2 \\right) P( N = n ) \\quad \\text{si $\\{X_i\\}$ son i.i.d} \\\\ &amp; = &amp; \\mathbb{E}\\left[N\\right] \\mathbb{E}\\left[X^2\\right] + \\mathbb{E}\\left[N^2\\right] \\mathbb{E}\\left[X\\right]^2 - \\mathbb{E}\\left[N\\right] \\mathbb{E}\\left[X\\right]^2 \\\\ &amp; = &amp; \\mathbb{E}\\left[N\\right] \\mathbb{V}\\left[X\\right] + \\mathbb{E}\\left[N^2\\right] \\mathbb{E}\\left[X\\right]^2 \\end{eqnarray*}\\] finalmente la varianza de \\(S\\) tiene la siguiente expresión \\[\\begin{eqnarray*} \\mathbb{V}\\left[S\\right] &amp; = &amp; \\mathbb{E}\\left[S^2\\right] - \\mathbb{E}\\left[S\\right]^2 \\\\ &amp; = &amp; \\mathbb{E}\\left[N\\right] \\mathbb{V}\\left[X\\right] + \\mathbb{E}\\left[N^2\\right] \\mathbb{E}\\left[X\\right]^2 - \\mathbb{E}\\left[N\\right]^2 \\mathbb{E}\\left[X\\right]^2 \\\\ &amp; = &amp; \\mathbb{E}\\left[N\\right] \\mathbb{V}\\left[X\\right] + \\mathbb{V}\\left[N\\right] \\mathbb{E}\\left[X\\right]^2 \\end{eqnarray*}\\] La distribución acumulada del reclamo total \\(S\\) tiene la forma: \\[\\begin{eqnarray*} F_S( s ) &amp; = &amp; P( S \\leq s ) \\\\ &amp; = &amp; P\\left( \\sum\\limits_{i=1}^N X_i \\leq s \\right) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} P\\left( \\sum\\limits_{i=1}^n X_i \\leq s \\middle| N = n \\right) P( N = n )\\quad \\text{utilizando la probabilidad condicional} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} P\\left( \\sum\\limits_{i=1}^n X_i \\leq s \\right) p_n\\quad \\text{si $X_i$ y $N$ son independientes} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} F_{X_1} \\star \\cdots \\star F_{X_n}( s ) p_n\\quad \\text{distribución de la suma de variables aleatorias} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} F^{\\star n}_{X}( s ) p_n\\quad \\text{si $\\{X_i\\}$ son idénticamente distribuidas} \\end{eqnarray*}\\] tomando \\(F^{\\star 0}_{X}( s ) = 1\\). Este último resultado muestra que la distribución de probabilidad de \\(S\\) no es más que una mixtura de las distribuciones para los modelos individuales \\(F^{\\star n}_{X}\\) tomando para mezclarlas las probabilidades \\(p_n = P( N = n )\\) de la variable aleatoria discreta \\(N\\) que describe la frecuencia de los reclamos. 5.3.1 Algoritmo de simulación La variable del reclamo total \\(S\\) puede ser simulada mediante el siguiente método montecarlo. Si \\(N\\) sigue una ley discreta \\(f_N\\) y cada valor severidad \\(X\\) son idénticamente distribuidos con ley \\(f_X\\). Seleccionar el número de simulaciones \\(m\\), Se genera una muestra de tamaño \\(m\\) de variables \\(N_1, \\ldots, N_m\\) con ley \\(f_N\\), Se genera para cada \\(i \\in \\{1,\\ldots,m\\}\\) una muestra de tamaño \\(N_i\\) de variables aleatorias \\(X_{i,1}, \\ldots X_{i,N_i}\\) con ley \\(f_X\\), Se calcula los reclamos totales \\(S_1, \\ldots, S_m\\) para cada simulación \\(i = \\{1, \\ldots, m\\}\\), mediante la siguiente suma \\(S_i = \\sum\\limits_{j=1}^{N_i} X_{i,j}\\). En el lenguaje de programación R, este método de simulación puede ser fácilmente implementado, como ya lo hemos realizado, utilizando las funciones de aplicación vectorial sapply y lapply. Ejemplo 5.3 Consideramos el caso de un modelo colectivo para el cuál el conteo de siniestros \\(N \\rightsquigarrow Pois( \\lambda )\\) y la distribución de cada uno de los reclamos \\(\\{X_i\\}_{i\\in \\mathbb{N}}\\), está dada por la misma distribución de probabilidad \\(X \\rightsquigarrow LN( \\mu, \\sigma )\\), siendo además cada uno de los reclamos indepencientes entre si. Code # 1. selección de simulaciones m &lt;- 1e4 # 2. especificación de los parámetros para las distribuciones u &lt;- 5 s &lt;- 2 l &lt;- 3 # 3. simulación del conteo de siniestros N &lt;- rpois( n = m, lambda = l ) # 4. simulación de la severidad de los reclamos X &lt;- lapply( N, FUN = function( n ) rlnorm( n, meanlog = u, sdlog = s ) ) # 5. reclamo total, agregación por cada simulación S &lt;- sapply( X, FUN = function( x ) sum( x, na.rm = TRUE ) ) Es de notar que una algoritmo como el descrito tiene una falencia cuando la frecuencia de siniestros es poco observada, esto sucede cuando la probabilidad \\(P( N = 0 )\\) es alta y por tal razón para generar suficientes reclamos y así poder tener cálculos con una buena aproximación numérica, con el uso de simulaciones se necesitará muchas simulaciones. Es interesante observar que el modelo colectivo puede ser muchas veces calculado de forma similar a un modelo individual, para ciertos casos particulares. Por ejemplo, si consideramos el caso cuando la variable aleatoria del conteo de siniestros \\(N \\rightsquigarrow Bin( n, p )\\) sigue una distribución binomial con parámetros \\(n\\) y \\(p\\) y los reclamos individuales \\(\\{ X_i \\}\\) son i.i.d. A partir de esto, el reclamo total \\(S\\) puede ser expresado de dos formas \\[\\begin{equation} S = \\sum\\limits_{k=0}^{N} X_k = \\sum\\limits_{k=0}^n B_k X_k \\end{equation}\\] donde \\(B_k \\rightsquigarrow Ber( p )\\) y es independientes de \\(X_k\\). Así el modelo colectivo se transforma en un modelo individual con \\(n\\) constante y valores de reclamos individuales dados por la variable aleatoria \\(Y_k = B_k X_k\\). Para este caso en particular \\[\\begin{eqnarray*} \\mathbb{E}[ S ] &amp; = &amp; \\mathbb{E}\\left[ \\sum\\limits_{k=0}^{n} B_k X_k \\right] \\\\ &amp; = &amp; \\sum\\limits_{k=0}^{n} \\mathbb{E}\\left[ B_k X_k \\right] \\\\ &amp; = &amp; n \\mathbb{E}[ B X ] \\\\ &amp; = &amp; n \\mathbb{E}[ B ] \\mathbb{E}[ X ] \\\\ &amp; = &amp; n p \\mathbb{E}[ X ] \\end{eqnarray*}\\] así mismo, \\[\\begin{eqnarray*} \\mathbb{V}[ S ] &amp; = &amp; n \\mathbb{V}[ B X ] \\\\ &amp; = &amp; n \\left( \\mathbb{E}[ B^2 X^2 ] - \\mathbb{E}[ B X ]^2 \\right) \\\\ &amp; = &amp; n \\left( \\mathbb{E}[ B^2 ] \\mathbb{E}[ X^2 ] - \\mathbb{E}[ B ]^2 \\mathbb{E}[ X ]^2 \\right) \\\\ &amp; = &amp; n \\left( p \\mathbb{E}[ X^2 ] - p^2 \\mathbb{E}[ X ]^2 \\right) \\\\ &amp; = &amp; n \\left( p \\mathbb{E}[ X^2 ] - p \\mathbb{E}[ X ]^2 + p \\mathbb{E}[ X ]^2 - p^2 \\mathbb{E}[ X ]^2 \\right) \\\\ &amp; = &amp; n \\left( p \\mathbb{V}[ X ] + p ( 1 - p ) \\mathbb{E}[ X ]^2 \\right) \\\\ &amp; = &amp; n \\left( \\mathbb{E}[B] \\mathbb{V}[ X ] + \\mathbb{V}[B] \\mathbb{E}[ X ]^2 \\right) \\end{eqnarray*}\\] Ejemplo 5.3 Hacemos uso del algoritmo de simulación, pero bajo la consideración anterior donde el conteo de siniestros \\(N \\rightsquigarrow Bin( n, p )\\), en algunos casos se puede considerar \\(n\\) como el número de pólizas vendidas, esto supone que solo se presenta un reclamo por póliza. Por su parte los reclamos consideraremos \\(X_i \\rightsquigarrow LN( \\mu, \\sigma )\\), para todo \\(i \\in \\{1,\\ldots,n\\}\\). Si consideramos generar la simulación como un modelo individual, generamos variables aleatorias \\(B_i \\rightsquigarrow Ber(p)\\), para todo \\(i \\in \\{1,\\ldots,n\\}\\). Code m &lt;- 1e4 n &lt;- 1000 p &lt;- 0.2 mu &lt;- 5 sigma &lt;- 2 B &lt;- lapply( 1:m, FUN = function( i ) rbinom( n, size = 1, prob = p ) ) X &lt;- lapply( 1:m, FUN = function( i ) rlnorm( n, meanlog = mu, sdlog = sigma ) ) S &lt;- sapply( 1:m, FUN = function( i ) sum( B[[ i ]] * X[[ i ]], na.rm = TRUE ) ) EeS &lt;- mean( S ) ES &lt;- n * p * exp( mu + 0.5 * sigma^2 ) \\[\\begin{eqnarray*} \\mathbb{E}[S] = n p e^{ \\mu + \\frac{1}{2} \\sigma^2 } &amp; = &amp; 219326.6317, \\\\ \\overline{S} = \\frac{1}{m} \\sum\\limits_{i=1}^m S_i &amp; = &amp; 220338.7282, \\end{eqnarray*}\\] Es importante observar que si la frecuencia de reclamos es superior a \\(1\\), sea este por póliza, individuo o en general por unidad asegurada, la aproximación anterior no es la correcta si no se realiza un ajuste al valor \\(n\\) que es el número máximo de siniestros. Sino también, se puede considera que las variables de los reclamos es la suma total de reclamos por póliza. Por otra parte, es de notar que en el cálculo hay un gasto innecesario de valores simulados de reclamos \\(X_i\\) ya que algunos se multiplicaran por \\(B_i\\), la cual solo toma valores \\(\\{0,1\\}\\). 5.4 Modelos mixtos En algunos casos en particular se considera un modelo de agregación que es una mixtura entre el modelo individual y el modelo colectivo. Se parte de considerar un número \\(n\\) de unidades aseguradas donde para cada unidad \\(i \\in \\{1, \\ldots, n\\}\\), se considera que puede presentar una cantidad de reclamos dados por una variable aleatoria discreta \\(N_i\\), y así para cada presentar un número de reclamos \\(X_{i,1}, \\ldots, X_{i,N_i}\\). Así el reclamo total viene dado por la expresión \\[\\begin{equation} S = \\sum\\limits_{i=1}^n X_i = \\sum\\limits_{i=1}^n \\sum\\limits_{j=1}^{N_i} X_{i,j} \\end{equation}\\] 5.5 Modelos con variables explicativas En algunos casos más generales, donde la población presenta heterogeneidad respecto del riesgo al cual están expuestos, como también de las dimensiones de sus reclamos, se considera que existen variables aleatorias adicionales \\(Y_1, \\ldots, Y_n\\) que determinan el número de reclamos \\(N\\) y el valor de los siniestros \\(\\{X_i\\}\\). Es decir no hay independencia entre \\(\\{Y_j\\}\\) y \\(N\\) así como tampoco entre \\(\\{Y_j\\}\\) y \\(\\{X_i\\}\\). Es así que un modelo colectivo \\(S = \\sum\\limits_{i=1}^N X_i\\) su estudio, estimación y tarificación debe ser realizada de forma condicional respecto de las variables aleatorias explicativas \\(\\{Y_j\\}\\), \\[\\begin{equation} \\mathbb{E}[ S ] = \\mathbb{E}\\left[ \\mathbb{E}\\left[ S \\middle| Y_1, \\ldots, Y_n \\right] \\right] \\end{equation}\\] de donde es necesario estimar cada una de las esperanzas condicionadas \\(\\mathbb{E}\\left[ S \\middle| Y_1, \\ldots, Y_n \\right]\\). En la práctica las variables explicativas \\(\\{ Y_j \\}\\) suelen ser seleccionadas para caracterizar el perfil de riesgo de cada cliente. Para su selección se suele utilizar algunos criterios de tipo económico, financiero, legal y estadístico. 5.6 Proceso estocástico de reclamos totales Hasta el momento no hemos considerado que los reclamos se producen en el tiempo, que cada reclamo está bien vinculado al tiempo; es más podemos identificar algunos instantes en el tiempo que le corresponde, tenemos así el tiempo cuando se suscita el siniestro o tiempo de ocurrencia, el tiempo de aviso cuando se comunica al asegurador el siniestro y un tiempo de pago. Los dos últimos no son directos asociados al evento del siniestro sino están asociados a otras variables que pueden afectar la demora para comunicar un siniestro por parte del asegurado y la demora para cancelarlo por parte del asegurador. Así por tanto si tenemos una secuencia de siniestros \\(\\{X_n\\}_{n\\in\\mathbb{N}^*}\\), estos los podemos considerar ordenados en el tiempo conforme han venido presentándose en instantes \\(T_1 \\leq \\cdots \\leq T_n \\leq \\cdots\\), es decir se le asocia a los reclamos \\(\\{X_n\\}\\) la secuencia de los tiempos de arribo \\(\\{T_n\\}_{n\\in\\mathbb{N}^*}\\), donde \\(T_1 &gt; 0\\) y \\(T_{n+1} \\geq T_n\\), para cualquier \\(n \\in \\mathbb{N}\\). Ciertamente, es de esperar que los tiempos de arribo sean variables aleatorias y están asociados a la frecuencia \\(N\\) en un periodo dado, ya que \\(N\\) cuenta los tiempos de arribo hasta un tiempo dado, transformamos así a \\(N\\) en una variable aleatoria dependiente del tiempo, en lo que se conoce como un proceso estocástico. \\[\\begin{equation} N( t ) = \\#\\left\\{ k \\in \\mathbb{N}\\ \\middle|\\ T_k \\leq t \\right\\} = \\sum\\limits_{k=0}^{+\\infty} \\mathbf{1}_{(-\\infty,t]}\\left( T_k \\right) \\end{equation}\\] Inmediatamente de este razonamiento, resulta que los reclamos totales también se transforman en proceso estocástico. \\[\\begin{equation} S( t ) = \\sum\\limits_{i=1}^{N( t )} X_i \\end{equation}\\] Además, se pueden identificar las variables aleatorias de tiempos entre arribos \\[\\begin{equation} W_n = T_n - T_{n-1},\\quad \\forall n \\in \\mathbb{N} \\end{equation}\\] tomando \\(T_0 = 0\\). 5.7 Aplicación del deducible En muchas ocasiones según las condiciones de los contratos de seguro y el apetito de riesgo del asegurador, se configura funciones deducibles sobre los reclamos. Code # 1. selección de simulaciones m &lt;- 1e4 # 2. especificación de los parámetros para las distribuciones u &lt;- 5 s &lt;- 2 l &lt;- 3 # 3. se especifica la función deducible D &lt;- function( x, d, M ) { return( min( max( x - d, 0 ), M ) ) } # 4. simulación del conteo de siniestros N &lt;- rpois( n = m, lambda = l ) # 5. simulación de la severidad de los reclamos X &lt;- lapply( N, FUN = function( n ) rlnorm( n, meanlog = u, sdlog = s ) ) # 6. se aplica el deducible a los reclamos DX &lt;- lapply( X, FUN = function( x ) sapply( x, FUN = function( y ) D( y, 10, 1000 ) ) ) # 7. reclamo total, agregación por cada simulación S &lt;- sapply( DX, FUN = function( x ) ifelse( length( x ) == 0, 0, sum( x, na.rm = TRUE ) ) ) \\(S_1, \\ldots, S_m \\rightsquigarrow F_S\\) Code FS &lt;- seq( 0, 1, 0.01 ) Sq &lt;- quantile( S, probs = FS ) ES &lt;- mean( S ) plot( Sq, FS, type = &#39;s&#39;, col = &#39;darkgreen&#39; ) abline( v = ES, col = &#39;red&#39; ) Ejemplo 5.4 En este caso en particular estudiaremos la velocidad de convergencia del método resultante del teorema del límite central 3.2. Generaremos una simulación aleatoria de la suma agregada \\(S_n\\) y mostraresmo s Code m &lt;- 500 n &lt;- 1000 u &lt;- 4 s &lt;- 2 X &lt;- lapply( 1:m, FUN = function( j ) rlnorm( n, meanlog = u, sdlog = s ) ) EX &lt;- exp( u + 0.5 * s^2 ) SDX &lt;- sqrt( ( exp( s^2 ) - 1 ) * exp( 2 * u + s^2 ) ) S &lt;- lapply( X, FUN = function( x ) cumsum( x ) ) ES &lt;- sapply( 1:n, FUN = function( i ) mean( sapply( 1:m, FUN = function( j ) S[[ j ]][ i ] ) ) ) VS &lt;- sapply( 1:n, FUN = function( i ) var( sapply( 1:m, FUN = function( j ) S[[ j ]][ i ] ) ) ) NS &lt;- lapply( S, FUN = function( s ) ( s - ES ) / sqrt( abs( VS ) ) ) z &lt;- seq( -4, 4, length.out = 100 ) FSn &lt;- lapply( 1:n, FUN = function( i ) ecdf( sapply( 1:m, FUN = function( j ) NS[[ j ]][ i ] ) )( z ) ) D &lt;- sapply( FSn, FUN = function( Fn ) max( abs( Fn - pnorm( z ) ) ) ) C &lt;- 0.015 # C &lt;- 1 / sqrt( 2 * pi ) rho &lt;- exp( 3 * u + 3^2 * s^2 / 2 ) Bn &lt;- C * rho / ( SDX^3 * sqrt( 1:n ) ) plot( 1:n, D, pch = 16, cex = 0.5, type = &#39;l&#39;, lwd = 2, lty = 1, ylim = c( 0, 0.5 ), col = &#39;royalblue4&#39; ) points( 1:n, Bn, type = &#39;l&#39;, lty = 1, col = &#39;red&#39; ) Code l &lt;- 3 n &lt;- 300 dt &lt;- rexp( n = n, rate = 1 / l ) t &lt;- c( 0, cumsum( dt ) ) dN &lt;- sapply( dt, FUN = function( w ) rpois( 1, lambda = l * w ) ) N &lt;- c( 0, cumsum( dN ) ) sh &lt;- 3 rt &lt;- 2 X &lt;- lapply( dN, FUN = function( n ) rgamma( n, shape = sh, rate = rt ) ) dS &lt;- sapply( X, FUN = function( x ) sum( x ) ) S &lt;- c( 0, cumsum( dS ) ) plot( t, N, type = &#39;s&#39; ) Code plot( t, S, type = &#39;s&#39; ) 5.8 Algoritmo de Panjer 5.9 Estimación usando la transformada de Fourier Para el caso del modelo individual de riesgos podemos hacer uso de la siguiente estimación de la densidad de probabilidad de los reclamos totales \\(S\\), utilizando la transformada de Fourier. En la implementación numérica se utiliza la transformada de Fourier rápida (FFT). \\[\\begin{equation} \\mathscr{F}\\left( f_S \\right) = \\mathscr{F}\\left( f^{\\star n}_X \\right) = \\mathscr{F}\\left( f_X \\right)^{n} \\end{equation}\\] Por tanto de esta relación como la transformada de Fourier es invertible, existe \\(\\mathscr{F}^{-1}\\). Resulta el siguiente método para calcular la densidad de \\(S\\) \\[\\begin{equation} f_S = \\mathscr{F}^{-1}\\left( \\mathscr{F}\\left( f_S \\right) \\right) = \\mathscr{F}^{-1}\\left(\\mathscr{F}\\left( f_X \\right)^{n} \\right) \\end{equation}\\] En conclusión para determinar la densidad de probabilidad de \\(S\\) basta conocer la transformada de Fourier de la distribución de los reclamos individuales, multiplicarla por si misma \\(n\\) veces y tomar la transformada de Fourier inversa. \\[\\begin{eqnarray*} \\mathscr{F}\\left( f_S \\right) &amp; = &amp; \\mathscr{F}\\left( \\sum\\limits_{n=0}^{+\\infty} p_n f_X^{\\star n} \\right) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} p_n \\mathscr{F}\\left( f_X^{\\star n} \\right) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} p_n \\mathscr{F}\\left( f_X \\right)^{n} \\end{eqnarray*}\\] como consecuencia \\[\\begin{eqnarray*} f_S &amp; = &amp; \\mathscr{F}^{-1}\\left( \\mathscr{F}\\left( f_S \\right) \\right)\\\\ &amp; = &amp; \\mathscr{F}^{-1}\\left( \\sum\\limits_{n=0}^{+\\infty} p_n \\mathscr{F}\\left( f_X \\right)^{n} \\right)\\quad \\text{Una sola inversión} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} p_n \\mathscr{F}^{-1}\\left( \\mathscr{F}\\left( f_X \\right)^{n} \\right)\\quad \\text{Una inversión por cada término en la suma} \\end{eqnarray*}\\] \\[\\begin{equation} W_n = \\frac{S_n}{n} \\end{equation}\\] \\[\\begin{equation} \\mathbb{E}\\left[ W_n \\right] = \\mathbb{E}\\left[ \\frac{S_n}{n} \\right] = \\frac{1}{n} \\mathbb{E}\\left[ S_n \\right] \\end{equation}\\] \\[\\begin{equation} \\mathbb{V}\\left[ W_n \\right] = \\mathbb{V}\\left[ \\frac{S_n}{n} \\right] = \\frac{1}{n^2} \\mathbb{V}\\left[ S_n \\right] \\end{equation}\\] "],["tarificación.html", "Capítulo 6 Tarificación 6.1 Tarificación en grandes términos 6.2 Medidas de riesgo 6.3 Prima 6.4 Segmentación 6.5 Deducibles", " Capítulo 6 Tarificación Para realizar la tarificación de un producto de seguro, además de estudiar y estimar el comportamiento futuro de los reclamos totales \\(S\\), es necesario también tomar en cuenta el capital \\(K\\) destinado para hacer frente al riesgo subscrito y los costos generales \\(G\\) 6.1 Tarificación en grandes términos La tarificación que conlleva a la selección de la prima \\(\\Pi\\) debe tomar en cuenta como se manejan y equilibran los activos y pasivos en el negocio asegurador. Pasivos Capitales propios Reservas técnicas Reservas para otros riesgos Deudas o depósitos en dinero recibidos por cesiones Otras deudas por pagar Activos Capital suscrito no desembolsado Activos no materiales Inversiones Parte de reaseguros en reservas técnicas Deudas por cobrar Otros activos En el proceso de tarificación no es pertinente incluir todos los activos de la empresa, ya que muchos de estos no tienen la liquidez necesaria como para ser considerados un tipo de activo viable para la tarificación. Tampoco se toma en cuenta el dinero recibido por la cesión de primas en un ramo en particular, ya que esto constituye un nivel más arriba propio del negocio reasegurador. En términos generales se busca equilibrar el resultado operativo del ramo de negocio \\(R\\) a lo largo de la vida del ramo. El resultado \\(R\\) a su vez está dado por la siguiente relación: \\[\\begin{equation} R = \\Pi + I - S - G - K \\end{equation}\\] donde las variables a considerarse en principio son: \\(\\Pi\\) Ingreso por primas \\(I\\) Ingreso por inversiones \\(S\\) Pago de siniestros \\(G\\) Gastos de subscripción \\(K\\) Coste de capital En varias ocasiones el ciclo del negocio puede ser corto y no permite considerar un ingreso por inversiones \\(I = 0\\). \\[\\begin{equation} R = \\Pi - S - G - K \\end{equation}\\] Sería ideal que a lo largo de la vida del ramo el resultado mantenga \\(R &gt; 0\\), pero al tratarse de un negocio que depende de la aleatoriedad de los reclamos, es bastante complicado encontrar un costo de capital \\(K\\) y una prima \\(\\Pi\\) que siempre asegure ante todo escenario que se mantenga la positividad. Ante este riesgo continuo se busca minimizar la probabilidad de ruina \\(R &lt; 0\\) a un nivel \\(\\alpha &gt; 0\\) adecuado \\[\\begin{equation} P( R &lt; 0 ) &lt; \\alpha \\end{equation}\\] Muchas de las veces se parte del principio de equilibrio financiero 3.5.4, donde se busca la igualdad \\(\\mathbb{E}[R] = 0\\), la misma implica la siguiente relación: \\[\\begin{eqnarray*} 0 &amp; = &amp; \\mathbb{E}[R] \\\\ 0 &amp; = &amp; \\mathbb{E}[R\\mid R \\geq 0]P( R \\geq 0 ) + \\mathbb{E}[R\\mid R &lt; 0]P( R &lt; 0 ) \\\\ \\mathbb{E}[R\\mid R \\geq 0]P( R \\geq 0 ) &amp; = &amp; -\\mathbb{E}[R\\mid R &lt; 0]P( R &lt; 0 ) \\\\ \\frac{P( R &lt; 0 )}{P( R \\geq 0 ) } &amp; = &amp; -\\frac{\\mathbb{E}[R\\mid R \\geq 0]}{\\mathbb{E}[R\\mid R &lt; 0]} \\end{eqnarray*}\\] en el equilibrio financiero, la proporción de la probabilidad de ruina respecto de la probabilidad de no estar en ruina es igual a la proporción entre la esperanza condicional del resultado cuando no se produce la ruina respecto de la esperanza condicional cuando si se produce la ruina. Un modelo puede estar equilibrado financieramente \\(\\mathbb{E}[R] = 0\\), pero se desconoce la probabilidad de ruina \\(P( R &lt; 0)\\), esta podría ser muy grande. La razón anterior permite estimar la relevancia de la probabilidad de ruina en un modelo equilibrado, con el uso de las esperanzas condicionales. Es usual asumir que la única parte aleatoria de \\(R\\) viene dada por el valor de los reclamos totales, en razón de esto se tiene: \\[\\begin{equation} \\mathbb{E}[ R ] = \\Pi - \\mathbb{E}[S] - G - K \\end{equation}\\] El coste de capital \\(K\\) es el dinero que se requiere adicional para estar cubiertos a un nivel de solvencia adecuado en caso se presenten mayores variaciones en el valor observado del reclamo total \\(S\\) y el esperado \\(\\mathbb{E}[S]\\). Para ello se suele utilizar una medida de riesgo \\(\\zeta\\) que permita controlar la probabilidad de ruina \\(P( R &lt; 0)\\) al nivel de \\(\\alpha &gt; 0\\), así se suele tomar \\[\\begin{equation} K = \\zeta( S ) - \\mathbb{E}[S] \\end{equation}\\] de tal forma que \\[\\begin{equation} P( \\Pi - S - G - K &lt; 0 ) = P( \\Pi - G - \\zeta(S) - ( S - \\mathbb{E}[S] ) &lt; 0 ) &lt; \\alpha. \\end{equation}\\] De la relación anterior se observa que una vez seleccionado el nivel de cobertura \\(\\alpha\\) y la medida de riesgo \\(\\zeta\\), las variables correspondientes a la prima \\(\\Pi\\) y a los gastos \\(G\\) quedan libres, de ahí resulta un margen que permite seleccionar la prima más óptima para un producto de seguro, así como también optimizar los gastos \\(G\\). Este proceso de selección es precisamente lo que llamamos tarificación (pricing). 6.2 Medidas de riesgo Definición 3.7 (Medida de riesgo coherente) Una medida de riesgo coeherente es una función \\(\\zeta: \\mathbb{R}\\longrightarrow \\mathbb{R}\\), que satisface la siguientes propiedades: Homogenidad positiva, para cualquier \\(a &gt; 0\\) \\[\\begin{equation} \\zeta( a X ) = a \\zeta( X ) \\end{equation}\\] Invarianza ante las traslaciones, para cualquier \\(a &gt; 0\\) \\[\\begin{equation} \\zeta( \\alpha X + a ) = \\zeta( \\alpha X ) + a \\end{equation}\\] Monotonicidad, Si \\(X \\leq Y\\) \\[\\begin{equation} \\zeta( X ) \\leq \\zeta( Y ) \\end{equation}\\] Sub-aditividad \\[\\begin{equation} \\zeta( X + Y ) \\leq \\zeta( X ) + \\zeta( Y ) \\end{equation}\\] En lo que continúa citamos algunas de las medidas de riesgo usualmente utilizadas. Definición 6.1 (Valor en riesgo) Dada una variable aleatoria a valores reales \\(X\\), el valor en riesgo (value at risk) de \\(X\\) al nivel de probabilidad \\(\\alpha \\in (0,1)\\) está dado por \\[\\begin{equation} \\operatorname{VaR}_{\\alpha}( X ) = \\inf\\left\\{ x \\in \\mathbb{R}\\middle| F_X( x ) &gt; \\alpha \\right\\} \\end{equation}\\] Proposición 6.1 Si la función de distribución acumulada \\(F_X\\) es continua, entonces \\(\\operatorname{VaR}_{\\alpha}( X ) = F_X^{-1}( \\alpha )\\). Por otra parte, \\(\\operatorname{VaR}_{\\alpha}\\) para cualquier \\(\\alpha\\) no es una medida de riesgo sub-aditiva. Definición 6.2 (Valor en riesgo en la cola) Dada una variable aleatoria a valores reales \\(X\\), el valor en riesgo en la colas (tail value at risk) de \\(X\\) al nivel de probabilidad \\(\\alpha \\in (0,1)\\) está dado por \\[\\begin{equation} \\operatorname{TVaR}_{\\alpha}( X ) = \\frac{1}{1-\\alpha} \\int\\limits_{\\alpha}^1 \\operatorname{VaR}_u( X )\\ du \\end{equation}\\] Proposición 6.2 (Coherencia de la medida TVaR) La medida de riesgo \\(\\operatorname{TVaR}_{\\alpha}\\) es una medida de riesgo coherente si la variable aleatoria sobre la cual se mide es una variable aleatoria continua. Definición 6.3 (Esperanza condicional en la cola) Dada una variable aleatoria a valores reales \\(X\\), la esperanza condicional en la cola (conditional tail expectation) de \\(X\\) al nivel de probabilidad \\(\\alpha \\in (0,1)\\) está dado por \\[\\begin{equation} \\operatorname{CTE}_{\\alpha}( X ) = \\mathbb{E}\\left[ X \\middle| X &gt; \\operatorname{VaR}_{\\alpha}( X ) \\right] \\end{equation}\\] Proposición 6.3 Si la función de distribución acumulada \\(F_X\\) de la variable aleatoria \\(X\\) es continua, entonces se tiene la siguiente igualdad \\[\\begin{equation} \\operatorname{CTE}_{\\alpha}( X ) = \\operatorname{TVaR}_{\\alpha}( X ) \\end{equation}\\] Definición 6.4 (Valor en riesgo condicionado) Dada una variable aleatoria a valores reales \\(X\\), el valor en riesgo condicionado (conditional value at risk) de \\(X\\) al nivel de probabilidad \\(\\alpha \\in (0,1)\\) está dado por \\[\\begin{equation} \\operatorname{CVaR}_{\\alpha}( X ) = \\mathbb{E}\\left[ X - \\operatorname{VaR}_{\\alpha}( X ) \\middle| X &gt; \\operatorname{VaR}_{\\alpha}( X ) \\right] = \\operatorname{CTE}_{\\alpha}( X ) - \\operatorname{VaR}_{\\alpha}( X ) \\end{equation}\\] Definición 6.5 (Déficit esperado) Dada una variable aleatoria a valores reales \\(X\\), el déficit esperado (expected shortfall) de \\(X\\) al nivel de probabilidad \\(\\alpha \\in (0,1)\\) está dado por \\[\\begin{equation} \\operatorname{ES}_{\\alpha}( X ) = \\mathbb{E}\\left[ \\max\\left( X - \\operatorname{VaR}_{\\alpha}( X ), 0 \\right) \\right] \\end{equation}\\] Definición 6.6 (Valor en riesgo entrópico) Dada una variable aleatoria a valores reales \\(X\\), el valor en riesgo entrópico (entropic value at risk) de \\(X\\) al nivel de probabilidad \\(\\alpha \\in (0,1)\\) está dado por \\[\\begin{equation} \\operatorname{EVaR}_{\\alpha}( X ) = \\inf\\left\\{ \\frac{1}{t} \\ln\\left( \\frac{M_X( t )}{1 - \\alpha} \\right) \\middle| t &gt; 0 \\right\\} \\end{equation}\\] Proposición 6.4 (Coherencia de la medida EVaR) La medida de riesgo \\(\\operatorname{EVaR}_{\\alpha}\\) es una medida de riesgo coherente. Ejemplo 6.1 Podemos considerar el caso particular donde todos los reclamos se suponen independientes e idénticamente distribuidos (i.i.d), en este caso con distribución \\(X_i \\rightsquigarrow LN(\\mu,\\sigma)\\) Code u &lt;- 4 s &lt;- 0.5 n &lt;- 1e4 X &lt;- rlnorm( n, meanlog = u, sdlog = s ) k &lt;- seq( 0, 1, 0.2 ) VaRX &lt;- quantile( X, probs = k, names = FALSE ) TVaRX &lt;- sapply( 1:length( VaRX ), FUN = function( i ) ifelse( k[ i ] &lt; 1, ( 1 / ( 1 - k[ i ] ) ) * mean( X * ( X &gt; VaRX[ i ] ) ), max( X ) ) ) Code plot( k, VaRX, ylim = c( 0, 1e3 ) ) points( k, TVaRX, col = &#39;red&#39; ) 6.3 Prima La prima es la cantidad de dinero que un individuo o entidad pagan por una póliza de seguro, la cual está diseñada para cubrir ciertos riesgos personales o comerciales. La determinación de las primas por parte del asegurador hace uso de la mutualización del riesgo y diversificación, para así poder asumir la transferencia del riesgo por parte de sus asegurados. Así por tanto, es deseable que cualquier método que se utilice para la estimación de primas, se satisfaga, algunas propiedades importantes. Sin consideramos dos riesgos a cubrir \\(S_1\\) y \\(S_2\\), entonces la función que estima \\(\\rho\\) las primas sería aconsejable satisfaga las siguientes propiedades. Si se decide cobrir por compleo dos riesgos \\(S_1\\) y \\(S_2\\) en un mismo producto, el valor de la prima deberá ser menor o igual al valor que se resultaría de cubrir cada uno de los riesgos con productos separados. \\[\\begin{equation} \\rho( S_1 + S_2 ) \\leq \\rho( S_1 ) + \\rho( S_2 ) \\end{equation}\\] El asumir mayor riesgo debe tener como consecuencia el aumento de la prima \\[\\begin{equation} \\rho( S_1 ) \\leq \\rho( S_1 + S_2 ) \\end{equation}\\] Esta propiedad implica que al configurar un producto de seguro con mejor cobertura, se espera una prima de mayor costo. Si el riesgo a cubrir está limitado, es decir \\(P( S \\leq M ) = 1\\), para un valor \\(M &gt; 0\\), entonces jamás la prima será superior a \\(M\\) \\[\\begin{equation} \\rho( S ) \\leq M \\end{equation}\\] Esto se traduce a que ningún asegurado estará interesado en adquirir una póliza para cubrir un riesgo por encima del valor total asegurado. Es así que hay algunos principios para la estimación de primas, aquí citamos algunos de los más conocidos: Prima neta, o prima pura de riesgo \\[\\begin{equation} \\rho( S ) = \\mathbb{E}[S] \\approx \\overline{S} \\end{equation}\\] Prima de riesgo con recargo sobre la esperanza matemática \\[\\begin{equation} P = \\rho( S ) = (1 + \\rho) \\mathbb{E}[S] \\approx (1 + \\rho) \\overline{S} \\end{equation}\\] Prima de riesgo con recargo sobre la varianza \\[\\begin{equation} P = \\rho( S ) = \\mathbb{E}[S] + \\rho \\mathbb{V}[S] \\approx \\overline{S} + \\rho \\sigma_S^2 \\end{equation}\\] Prima de riesgo con recargo sobre la desviación \\[\\begin{equation} P = \\rho( S ) = \\mathbb{E}[S] + \\rho \\sqrt{\\mathbb{V}[S]} \\approx \\overline{S} + \\rho \\sigma_S \\end{equation}\\] Prima de riesgo con principio exponencial para \\(t &gt; 0\\) \\[\\begin{equation} P = \\rho( S ) = \\frac{1}{2} \\mathbb{E}\\left[\\exp(tS)\\right] = \\frac{1}{2} M_N\\big( \\ln M_X( t ) \\big) \\approx \\frac{1}{m} \\sum\\limits_{i=1}^m \\exp\\left(t S_i\\right) \\end{equation}\\] Prima de percentiles para un valor de confianza \\(\\alpha \\in [0,1]\\) o prima de valor en riesgo \\(VaR_\\alpha\\) \\[\\begin{equation} P = \\rho( S ) = \\operatorname{VaR}_\\alpha( S ) = F_S^{-1}( \\alpha ) \\end{equation}\\] Prima de valor en riesgo en la cola (Tail Value at Risk) \\(TVaR_\\alpha\\). Es el promedio uniforme de todos los valores en riesgo \\(VaR_u\\), con \\(u \\geq \\alpha\\). \\[\\begin{equation} P = \\rho( S ) = \\operatorname{TVaR}_\\alpha( S ) = \\frac{1}{1-\\alpha} \\int\\limits_{\\alpha}^1 \\operatorname{VaR}_u( S )\\ du \\end{equation}\\] Ejemplo 6.1 Consideremos el caso donde todos los siniestros son igualmente distribuidos e independientes (i.i.d) \\(X_i \\rightsquigarrow Gamma( \\alpha_i, \\theta )\\), para \\(i \\in \\{1,\\ldots,n\\}\\), el número de unidades aseguradas está dado por \\(n \\in \\mathbb{N}\\). Utilizaremos el modelo individual para la agregación de los reclamos y obtener el reclamo total \\(S = \\sum\\limits_{i=1}^n X_i\\). Como todas las variables \\(X_i\\) siguen una ley \\(Gamma( \\alpha_i, \\theta )\\), sabemos que la familia \\(Gamma\\) es cerrada por adición, es decir, a suma de variables aleatorias con ley \\(Gamma\\) también sigue una ley \\(Gamma\\). En este caso en particular para el reclamo total tenemos que \\(S \\rightsquigarrow Gamma\\left( \\sum\\limits_{i=1}^n \\alpha_i, \\theta \\right)\\). Es de notar que para cada \\(i\\in \\{1,\\ldots,n\\}\\), la variable aleatoria \\(X_i\\) correspondiente al \\(i\\)-ésimo reclamo tiene como parámetro un diferente factor \\(\\alpha_i\\), pero el mismo factor \\(\\theta\\). Ya que cada \\(X_i \\rightsquigarrow Gamma( \\alpha_i, \\theta )\\), podemos calcular de forma determinista las experanzas de \\(\\mathbb{E}[X_i]\\), para cada \\(i \\in \\{1,\\ldots,n\\}\\) y de igual forma podemos calcular la esperanza del reclamo total \\(\\mathbb{E}[S] = \\sum\\limits_{i=1}^n \\mathbb{E}[X_i]\\). Además como asumimos independencia entre los \\(X_i\\), la varianza de \\(S\\) también puede ser calculada fácilmente como \\(\\mathbb{V}[S] = \\sum\\limits_{i=1}^n \\mathbb{V}[X_i]\\). También estamos en la capacidad de simular la variable \\(S\\) utilizando un algoritmo de aleatorio, para así aproximar los cálculos de sus momentos y otros estadísticos. Primeramente definamos los parámetros. Code # número de unidades aseguradas n &lt;- 1000 # parámetros para cada X_i a &lt;- runif( n, 5, 10 ) # parámetro theta, común a todas las X_i theta &lt;- 4 # parámetro para S A &lt;- sum( a ) Code EX &lt;- a * theta VX &lt;- a * theta^2 ES &lt;- sum( EX ) VS &lt;- sum( VX ) SDS &lt;- sqrt( VS ) La variable aleatoria del reclamo total \\(S\\) la podemos simular tomando una muestra i.i.d de tamaño \\(m\\), i.e. \\(S_1,\\ldots,S_m\\) de la distribución \\(Gamma\\left( \\sum\\limits_{i=1}^n \\alpha_i, \\theta \\right)\\). Code m &lt;- 1e5 S &lt;- rgamma( m, shape = A, scale = theta ) Prima pura: Code P &lt;- ES P &lt;- mean( S ) alpha &lt;- 0.95 P_avg &lt;- ( 1 + alpha ) * ES P_avg &lt;- ( 1 + alpha ) * mean( S ) P_var &lt;- ES + alpha * VS P_var &lt;- mean( S ) + alpha * var( S ) P_sde &lt;- ES + alpha * SDS P_sde &lt;- mean( S ) + alpha * sd( S ) VaRS &lt;- qgamma( alpha, shape = A, scale = theta ) P_VaR &lt;- VaRS P_VaR &lt;- quantile( S, probs = alpha ) P_TVaR &lt;- ( 1 / ( 1 - alpha ) ) * ( A * theta ) * ( 1 - pgamma( VaRS, shape = A + 1, scale = theta ) ) P_TVaR &lt;- ( 1 / ( 1 - alpha ) ) * integrate( f = function( u ) qgamma( u, shape = A, scale = theta ), alpha, 1 )$value P_TVaR &lt;- mean( sapply( runif( m, alpha, 1 ), FUN = function( k ) qgamma( k, shape = A, scale = theta ) ) ) I &lt;- as.numeric( S &gt; VaRS ) P_TVaR &lt;- mean( S * I ) / mean( I ) Code n &lt;- 1e3 S &lt;- rgamma( n, shape = A, scale = theta ) smin &lt;- qgamma( 0.001, shape = A, scale = theta ) smax &lt;- qgamma( 0.999, shape = A, scale = theta ) s &lt;- seq( smin, smax, length.out = 1000 ) Fns &lt;- ecdf( S )( s ) Fs &lt;- pgamma( s, shape = A, scale = theta ) alph &lt;- 0.02 er &lt;- sqrt( log( 2 / alph ) / ( 2 * n ) ) mean( abs( Fs - Fns ) &gt; er ) ## [1] 0 Code plot( s, Fs, type = &#39;l&#39;, ylim = c( -er, 1 + er ) ) points( s, Fns - er, col = &#39;red&#39;, type = &#39;l&#39; ) points( s, Fns + er, col = &#39;red&#39;, type = &#39;l&#39; ) Code hist( pgamma( S, shape = A, scale = theta ), breaks = 5 ) 6.4 Segmentación En muchas ocasiones es necesario tener en cuenta algunas características asociadas al riesgo de asegurado, de tal forma que la prima sea lo más eficiente y adecuado según el riesgo cubierto y las características del mismo. La idea de segmentar la población es obtener grupos homogéneos con riesgos similares. 6.5 Deducibles El principal objetivo de los deducibles, es el reducir los costos de atención de los reclamos usualmente mediante la exclusión de siniestros usualmente numerosos debidos a reclamos pequeños. En otras ocasiones, los deducibles están diseñados para incentivar al asegurado para evitar y prevenir siniestros por cierto monto límite. Prevención de la pérdida - as the compensation is reduced by a deductible the retention of the insured is positive; This makes out a good case for avoiding the loss; Reducción de la pérdida - the fact a deductible puts the policyholder at risk of obtaining only partial compensation provides an economic incentive to reduce the extend of the damage; Evitar pequeñas pérdidas - where administration costs are dominant for small losses, the administration costs will often exceed the loss itself, and hence the insurance company would want the policyholder to pay it himself; Reducción de la prima - premium reduction can be an important aspect for the policyholders, they may prefer to take a higher deductible to get a lower premium. Code n &lt;- 1e5 l &lt;- 3 dat &lt;- data.table( id = 1:n, k = rpois( n, lambda = l ) ) datf &lt;- dat[ , list( fk = .N ), by = k ] setorder( datf, k ) datf[ , fks := shift( fk, n = 1 ) ] datf[ , gk := k * fk / fks ] datf &lt;- datf[ !is.na( gk ) ] plot( datf$k, datf$gk ) Code dflm &lt;- lm( formula = gk ~ k, data = datf, method = &#39;qr&#39; ) a &lt;- coef( dflm )[ 2 ] b &lt;- coef( dflm )[ 1 ] p0 &lt;- exp( -b ) k &lt;- seq( 1, 100, 1 ) p &lt;- p0 * cumprod( c( 1, a + b / k ) ) sum( p ) ## [1] 1.138913 Code k &lt;- seq( 0, 100, 1 ) sum( dpois( k, lambda = l ) ) ## [1] 1 Code EN &lt;- sum( k * p ) Code D &lt;- function( x, d ) return( max( x - d, 0 ) ) d &lt;- 100 u &lt;- 6 s &lt;- 0.3 n &lt;- 1e3 X &lt;- rlnorm( n, meanlog = u, sdlog = s ) DX &lt;- sapply( X, FUN = D, d ) x &lt;- seq( 0, 1e3, length.out = 500 ) FXe &lt;- ecdf( X ) FDXe &lt;- ecdf( DX ) Fx &lt;- sapply( x, FUN = function( x ) FXe( x ) ) FDx &lt;- sapply( x, FUN = function( x ) FDXe( x ) ) plot( x, Fx, type = &#39;s&#39; ) points( x, FDx, type = &#39;s&#39;, col = &#39;blue&#39; ) Code D &lt;- function( x, M ) return( min( x, M ) ) M &lt;- 600 u &lt;- 6 s &lt;- 0.3 n &lt;- 1e4 X &lt;- rlnorm( n, meanlog = u, sdlog = s ) DX &lt;- sapply( X, FUN = D, M ) x &lt;- seq( 0, 1e3, length.out = 500 ) FXe &lt;- ecdf( X ) FDXe &lt;- ecdf( DX ) Fx &lt;- sapply( x, FUN = function( x ) FXe( x ) ) FDx &lt;- sapply( x, FUN = function( x ) FDXe( x ) ) plot( x, Fx, type = &#39;s&#39; ) points( x, FDx, type = &#39;s&#39;, col = &#39;blue&#39; ) "],["reservas-técnicas.html", "Capítulo 7 Reservas técnicas 7.1 Reservas para primas no adquiridas 7.2 Reservas de riesgos en curso 7.3 Reservas de siniestros a pagar", " Capítulo 7 Reservas técnicas 7.1 Reservas para primas no adquiridas 7.2 Reservas de riesgos en curso 7.3 Reservas de siniestros a pagar 7.3.1 Siniestros sucedidos, reportados, resueltos, no pagados 7.3.2 Siniestros sucedidos, reportados, no resueltos, no pagados 7.3.3 Siniestros sucedidos, no reportados, no resueltos, no pagados "],["modelos-lineales-generalizados-glm.html", "Capítulo 8 Modelos lineales generalizados (GLM) 8.1 Familia exponencial 8.2 Modelo lineal generalizado (GLM)", " Capítulo 8 Modelos lineales generalizados (GLM) 8.1 Familia exponencial De forma amplia, un modelo lineal generalizado aprovecha algunas propiedades de la distribución de probabilidad \\(f_X\\) de la variable (vector) aleatoria \\(X : \\Omega \\longrightarrow \\mathbb{R}^n\\) en estudio. Se parte de asumir que \\(X\\) tiene una distribución dentro de la familia exponencial, es decir, existen: Un conjunto admisible de parámetros \\(\\Theta \\subset \\mathbb{R}^m\\), así cada parámetro \\(\\theta = ( \\theta_1, \\ldots, \\theta_m )^T \\in \\Theta\\), Una función \\(T: \\mathbb{R}^n \\longrightarrow \\mathbb{R}^p\\) Una función \\(A: \\mathbb{R}^m \\longrightarrow \\mathbb{R}\\) Una función \\(\\eta: \\mathbb{R}^m \\longrightarrow \\mathbb{R}^p\\) de tal forma que: \\[\\begin{equation} f_X( x \\mid \\theta ) = h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right) \\end{equation}\\] Al tener varias observaciones independientes de la misma variable aleatoria \\(x_1, \\ldots, x_N\\), su distribución conjunta se puede expresar como: \\[\\begin{equation} f_{X_1,\\ldots,X_N}( x_1, \\ldots, x_N \\mid \\theta ) = \\prod\\limits_{i=1}^N f_{X_i}( x_i \\mid \\theta ) \\end{equation}\\] La función de verosimilitud logarítmica, “log-likelihood”, toma una forma específica, la cual puede ser trabajada con comodidad para la maximización de verosimilitud. \\[\\begin{eqnarray*} \\ell( \\theta ) &amp; = &amp; \\log f_{X_1,\\ldots,X_N}( x_1, \\ldots, x_N \\mid \\theta ) \\\\ &amp; = &amp; \\sum\\limits_{i=1}^N \\log f_{X_i}( x_i \\mid \\theta ) \\\\ &amp; = &amp; \\sum\\limits_{i=1}^N \\left( \\log h( x_i ) + \\eta( \\theta ) \\cdot T( x_i ) - A( \\theta ) \\right) \\end{eqnarray*}\\] lo que podemos observar es que existe una casi linealidad respecto de la variable \\(\\theta\\). Esta propiedad permite obtener un problema de maximización de verosimilitud que puede ser atacado con varios paquetes de optimización numérica de una forma eficiente. \\[\\begin{equation} \\underset{\\theta \\in \\Theta}{\\sup} \\ell( \\theta ) = \\underset{\\theta \\in \\Theta}{\\sup} \\sum\\limits_{i=1}^N \\left( \\eta( \\theta ) \\cdot T( x_i ) - A( \\theta ) \\right) \\end{equation}\\] Usualmente, este problema se suele atacar mediante la anulación del gradiente de la función objetivo, esto lo realiza la mayor parte de paquetes de software. El sistema a resolver es el siguiente sistema, usualmente no lineal, de dimensión \\(m\\): \\[\\begin{equation} \\frac{\\partial\\ell}{\\partial\\theta_i}( \\theta ) = \\sum\\limits_{i=1}^N \\left( \\frac{\\partial\\eta}{\\partial\\theta_i}( \\theta ) \\cdot T( x_i ) - \\frac{\\partial A}{\\partial\\theta_i}( \\theta ) \\right) = 0,\\qquad \\forall i \\in \\{1,\\ldots, m\\} \\end{equation}\\] En la familia exponential tenemos las siguientes distribuciones: normal, exponencial, log-normal, gamma, chi-cuadrado, beta, Dirichlet, Bernoulli, Poisson, binomial, geométrica, binomial negativa, von Mises-Fisher, Pareto con valor mínimo conocido, Gaussiana inversa, gamma inversa, multinomial con número \\(n\\) conocido, Wishart, categórica. Por la condición de normalización de la densidad de probabilidad \\(f_X\\), se satisface la igualdad: \\[\\begin{eqnarray*} 1 &amp; = &amp; \\int\\limits f_X( x \\mid \\theta )\\ dx \\\\ 1 &amp; = &amp; \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right)\\ dx \\\\ 1 &amp; = &amp; \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) \\right) \\exp\\left( - A( \\theta ) \\right)\\ dx \\\\ 1 &amp; = &amp; \\exp\\left( - A( \\theta ) \\right) \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) \\right)\\ dx \\\\ \\exp\\left( A( \\theta ) \\right) &amp; = &amp; \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) \\right)\\ dx \\\\ A( \\theta ) &amp; = &amp; \\log\\left( \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) \\right)\\ dx \\right) \\end{eqnarray*}\\] de donde se determina precisamente la forma que tiene la función \\(A\\) y su el papel como factor de normalización para la distribución de la variable aleatoria \\(X\\). Así mismo, podemos establecer una cierta relación para la espera de los valores observados de \\(T(X)\\) en función de \\(A\\) \\[\\begin{eqnarray*} 0 &amp; = &amp; \\frac{\\partial}{\\partial\\theta_i} 1 \\\\ 0 &amp; = &amp; \\frac{\\partial}{\\partial\\theta_i} \\int\\limits f_X( x \\mid \\theta )\\ dx \\\\ 0 &amp; = &amp; \\int\\limits h( x ) \\frac{\\partial}{\\partial\\theta_i} \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right)\\ dx \\\\ 0 &amp; = &amp; \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right) \\left( \\frac{\\partial\\eta}{\\partial\\theta_i}( \\theta ) \\cdot T( x ) - \\frac{\\partial A}{\\partial\\theta_i}( \\theta ) \\right)\\ dx \\\\ 0 &amp; = &amp; \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right) \\frac{\\partial\\eta}{\\partial\\theta_i}( \\theta ) \\cdot T( x )\\ dx \\\\ &amp; &amp; - \\frac{\\partial A}{\\partial\\theta_i} ( \\theta ) \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right)\\ dx \\\\ 0 &amp; = &amp; \\int \\limits \\frac{\\partial\\eta}{\\partial\\theta_i}( \\theta ) \\cdot T( x ) f_X( x \\mid \\theta )\\ dx - \\frac{\\partial A}{\\partial\\theta_i}( \\theta ) \\int \\limits f_X( x \\mid \\theta )\\ dx \\end{eqnarray*}\\] estamos en la capacidad de concluir que: \\[\\begin{equation} \\mathbb{E}\\left[ \\frac{\\partial\\eta}{\\partial\\theta_i}( \\theta ) \\cdot T( X ) \\right] = \\frac{\\partial A}{\\partial\\theta_i}( \\theta ) \\end{equation}\\] Cuando se da el caso que \\(\\eta\\) y \\(T\\) son las funciones identidad, la relación anterior se reduce a la siguiente igualdad: \\[\\begin{equation} \\mathbb{E}\\left[ X_i \\right] = \\frac{\\partial A}{\\partial\\theta_i}( \\theta ) \\end{equation}\\] 8.2 Modelo lineal generalizado (GLM) Precisamente, un modelo lineal generalizado (GLM por sus siglas en inglés) busca explotar las propiedades de las variables aleatorias que poseen una densidad de probabilidad dada por alguna de la funciones de la familia exponencial. Para más detalles se puede consultar [10]. La idea general es poder describir el comportamiento de una variable aleatoria \\(Y\\) que se presume puede ser descrita por alguna función de la familia exponencial, a partir de otras variables aleatorias \\(X : \\Omega \\longrightarrow \\mathbb{R}^n\\) mediante una función de vínculo \\(g: \\mathbb{R}^q \\longrightarrow \\mathbb{R}^m\\) entre \\(\\theta\\) y \\(X\\), a través del paso por una composición con una función lineal \\(\\beta : \\mathbb{R}^n \\longrightarrow \\mathbb{R}^q\\), de tal forma que: \\[\\begin{equation} \\theta = g( \\beta( X ) ) = g( \\beta X ) \\end{equation}\\] Así, un GLM prescribe una distribución de probabilidad para \\(Y\\) que tendrá la siguiente forma y será dependiente de los parámetros \\(\\beta\\) y las variables explicativas \\(X\\) \\[\\begin{equation} f_Y( y \\mid \\theta ) = f_Y( y \\mid g( \\beta x ) ) = h( y ) \\exp\\left( \\eta( g( \\beta x ) ) \\cdot T( y ) - A( g( \\beta x ) ) \\right) \\end{equation}\\] En la aplicación, el ajuste de un modelo GLM a \\(N \\in \\mathbb{N}\\) observaciones \\(y_1, \\ldots, y_N\\) de la variable aleatoria \\(Y\\) y sus respectivas variables explicativas \\(x_1, \\ldots, x_N\\). Se asume independencias entre las observaciones y se busca maximizar la verosimilitud de los valores observados, pero en función del nuevo parámetro \\(\\beta\\), de ahí la parte lineal del modelo. \\[\\begin{equation} \\ell( \\beta ) = \\sum\\limits_{i=1}^N \\left( \\log h( y_i ) + \\eta( g( \\beta x_i ) ) \\cdot T( y_i ) - A( g( \\beta x_i ) \\right) \\end{equation}\\] De ello resulta el problema de maximización de verosimilitud que se busca resolver para ajustar un modelo GLM. \\[\\begin{equation} \\underset{\\beta \\in \\mathbb{R}^{q \\times n}}{\\sup} \\ell( \\beta ) = \\underset{\\beta \\in \\mathbb{R}^{q \\times n}}{\\sup} \\sum\\limits_{i=1}^N \\left( \\log h( y_i ) + \\eta( g( \\beta x_i ) ) \\cdot T( y_i ) - A( g( \\beta x_i ) \\right) \\end{equation}\\] es de notar que el término \\(\\sum\\limits_{i=1}^N \\log h( y_i )\\) no depende de \\(\\beta\\) y por tal razón puede ser omitido al momento de maximizar la verosimilitud. En varias ocasiones no todos los parámetros \\(\\theta\\) de la densidad de probabilidad son considerados, sino tan solo una parte de los mismos, los otros parámetros se consideran como un valor constante ya dado o también como un parámetro a determinar. Así, se divide \\(\\theta = ( \\theta_1, \\theta_2 ), \\theta_1 \\in \\mathbb{R}^{m_1}, \\theta_2 \\in \\mathbb{R}^{m_2}, m = m_1 + m_2\\), donde solo se establece una función de vínculo para la primera parte \\(\\theta_1 = g( \\beta X )\\). Esta consideración en muchos casos ayuda a simplificar la formulación del modelo y el costo computacional de estimación. En este contexto la función de verosimilitud tomaría la forma: \\[\\begin{equation} \\ell( \\beta, \\theta_2 ) = \\sum\\limits_{i=1}^N \\left( \\log h( y_i ) + \\eta( g( \\beta x_i ), \\theta_2 ) \\cdot T( y_i ) - A( g( \\beta x_i ), \\theta_2 ) \\right) \\end{equation}\\] Ejemplo 8.1 (Regresión de Poisson) En este caso presentamos el modelo bastante utilizado conocido como regresión de Poisson. En donde suponemos que \\(N \\rightsquigarrow Pois( \\lambda( x ) ER( x ) ) = Pois( g( \\beta x ) ER( x ) )\\) donde \\(\\lambda\\) es el parámetro a estimar en función de las variables explicativas \\(x\\). \\[\\begin{equation} \\mathbb{E}[ N ] = \\lambda( x ) ER( x ) = g( \\beta x ) ER( x ) \\end{equation}\\] \\[\\begin{equation} P( N = n ) = \\exp(-g( \\beta x ) ER( x )) \\frac{g( \\beta x )^n ER( x )^n}{n!} \\end{equation}\\] Code # la librería CASdatasets fue previamente cargada data( beMTPL97 ) beMTPL97 &lt;- as.data.table( beMTPL97 ) # Impresión de las primeras filas de la tabla beMTPL97[ 1:100 ] %&gt;% kable( caption = &quot;Pólizas y reclamos de automóviles en Bélgica&quot;, row.names = FALSE, col.names = names( beMTPL97 ), align = paste0( rep( &quot;r&quot;, ncol( beMTPL97 ) ), collapse = &quot;&quot; ), digits = c( 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4 ), format.args = list( big.mark = &#39;,&#39;, decimal.mark = &#39;.&#39;, scientific = FALSE ), escape = FALSE ) %&gt;% kable_classic( font_size = 14, full_width = FALSE, html_font = &quot;Cambria&quot; ) %&gt;% scroll_box( width = &quot;750px&quot;, height = &quot;500px&quot; ) Tabla 8.1: Tabla 8.2: Pólizas y reclamos de automóviles en Bélgica id expo claim nclaims amount average coverage ageph sex bm power agec fuel use fleet postcode long lat 1 1.00 1 1 1,618.00 1,618.00 TPL 50 male 5 77 12 gasoline private 0 1,000 4.3552 50.8454 2 1.00 0 0 0.00 NaN TPL+ 64 female 5 66 3 gasoline private 0 1,000 4.3552 50.8454 3 1.00 0 0 0.00 NaN TPL 60 male 0 70 10 diesel private 0 1,000 4.3552 50.8454 4 1.00 0 0 0.00 NaN TPL 77 male 0 57 15 gasoline private 0 1,000 4.3552 50.8454 5 0.05 1 1 155.97 155.97 TPL 28 female 9 70 7 gasoline private 0 1,000 4.3552 50.8454 6 1.00 0 0 0.00 NaN TPL 26 male 11 70 12 gasoline private 0 1,000 4.3552 50.8454 7 1.00 1 1 155.97 155.97 TPL++ 26 male 11 55 8 gasoline private 0 1,000 4.3552 50.8454 8 0.40 0 0 0.00 NaN TPL 58 female 11 47 14 gasoline private 0 1,000 4.3552 50.8454 9 1.00 0 0 0.00 NaN TPL++ 59 male 0 98 3 gasoline private 0 1,000 4.3552 50.8454 10 1.00 0 0 0.00 NaN TPL+ 34 male 7 74 6 gasoline private 0 1,000 4.3552 50.8454 11 1.00 1 1 544.87 544.87 TPL++ 39 male 1 85 2 diesel private 0 1,000 4.3552 50.8454 12 0.98 0 0 0.00 NaN TPL 55 male 11 87 6 diesel private 0 1,000 4.3552 50.8454 13 1.00 0 0 0.00 NaN TPL+ 77 male 9 104 6 gasoline private 0 1,000 4.3552 50.8454 14 0.97 0 0 0.00 NaN TPL 49 male 8 71 19 gasoline private 0 1,000 4.3552 50.8454 15 0.58 0 0 0.00 NaN TPL 63 male 0 104 7 gasoline private 0 1,000 4.3552 50.8454 16 1.00 0 0 0.00 NaN TPL++ 43 male 1 85 2 diesel private 1 1,000 4.3552 50.8454 17 1.00 0 0 0.00 NaN TPL+ 51 male 0 113 7 gasoline private 1 1,000 4.3552 50.8454 18 0.21 0 0 0.00 NaN TPL 67 male 10 130 6 gasoline private 0 1,000 4.3552 50.8454 19 0.18 0 0 0.00 NaN TPL 52 male 0 125 16 gasoline private 0 1,000 4.3552 50.8454 20 0.89 0 0 0.00 NaN TPL++ 40 male 0 66 1 diesel private 0 1,000 4.3552 50.8454 21 1.00 0 0 0.00 NaN TPL+ 45 male 2 128 6 gasoline private 0 1,000 4.3552 50.8454 22 1.00 1 1 252.03 252.03 TPL 34 male 6 119 9 gasoline private 0 1,000 4.3552 50.8454 23 0.85 0 0 0.00 NaN TPL+ 47 male 0 85 4 gasoline private 0 1,000 4.3552 50.8454 24 1.00 0 0 0.00 NaN TPL+ 51 male 1 98 8 gasoline private 0 1,000 4.3552 50.8454 25 1.00 0 0 0.00 NaN TPL 61 male 3 98 8 gasoline private 0 1,000 4.3552 50.8454 26 0.90 0 0 0.00 NaN TPL 65 male 7 51 11 diesel private 0 1,000 4.3552 50.8454 27 1.00 0 0 0.00 NaN TPL 57 male 0 98 7 gasoline private 0 1,000 4.3552 50.8454 28 1.00 0 0 0.00 NaN TPL 38 male 11 74 15 gasoline private 0 1,000 4.3552 50.8454 29 1.00 0 0 0.00 NaN TPL+ 59 male 1 85 4 gasoline private 1 1,000 4.3552 50.8454 30 1.00 0 0 0.00 NaN TPL 31 male 9 98 7 gasoline private 0 1,000 4.3552 50.8454 31 1.00 1 2 232.60 116.30 TPL 33 male 4 101 9 gasoline private 0 1,000 4.3552 50.8454 32 1.00 0 0 0.00 NaN TPL 53 male 10 55 6 diesel private 0 1,000 4.3552 50.8454 33 1.00 0 0 0.00 NaN TPL+ 47 male 1 55 7 diesel work 0 1,000 4.3552 50.8454 34 1.00 0 0 0.00 NaN TPL+ 65 male 0 110 5 gasoline private 0 1,000 4.3552 50.8454 35 1.00 0 0 0.00 NaN TPL+ 62 female 1 55 11 gasoline private 0 1,000 4.3552 50.8454 36 1.00 0 0 0.00 NaN TPL++ 39 male 4 66 5 diesel work 0 1,000 4.3552 50.8454 37 0.68 0 0 0.00 NaN TPL++ 64 male 0 66 5 diesel private 0 1,000 4.3552 50.8454 38 0.84 0 0 0.00 NaN TPL+ 28 male 5 59 8 diesel private 0 1,000 4.3552 50.8454 39 0.98 0 0 0.00 NaN TPL 56 male 1 98 6 gasoline private 0 1,000 4.3552 50.8454 40 1.00 1 1 62.42 62.42 TPL 41 female 11 66 10 gasoline private 0 1,000 4.3552 50.8454 41 1.00 0 0 0.00 NaN TPL++ 28 male 0 85 4 gasoline private 0 1,000 4.3552 50.8454 42 0.17 0 0 0.00 NaN TPL+ 58 male 10 50 7 diesel private 0 1,000 4.3552 50.8454 43 0.48 0 0 0.00 NaN TPL 31 male 11 50 8 diesel private 0 1,000 4.3552 50.8454 44 0.20 0 0 0.00 NaN TPL 40 male 0 66 14 gasoline private 0 1,000 4.3552 50.8454 45 1.00 0 0 0.00 NaN TPL+ 70 female 0 55 4 diesel private 0 1,000 4.3552 50.8454 46 1.00 0 0 0.00 NaN TPL+ 51 male 3 55 10 gasoline private 0 1,000 4.3552 50.8454 47 1.00 0 0 0.00 NaN TPL++ 57 male 3 110 2 gasoline work 1 1,000 4.3552 50.8454 48 1.00 1 1 164.65 164.65 TPL 47 male 11 55 16 gasoline private 0 1,000 4.3552 50.8454 49 1.00 0 0 0.00 NaN TPL+ 46 male 0 44 16 gasoline private 0 1,000 4.3552 50.8454 50 1.00 0 0 0.00 NaN TPL++ 31 male 10 110 3 gasoline private 0 1,000 4.3552 50.8454 51 0.59 0 0 0.00 NaN TPL+ 66 male 0 50 9 diesel private 0 1,000 4.3552 50.8454 52 1.00 1 1 562.72 562.72 TPL++ 36 male 0 98 4 gasoline private 0 1,000 4.3552 50.8454 53 1.00 1 1 461.75 461.75 TPL++ 37 male 5 94 7 gasoline private 0 1,000 4.3552 50.8454 54 1.00 0 0 0.00 NaN TPL+ 36 male 0 55 2 gasoline private 0 1,000 4.3552 50.8454 55 1.00 0 0 0.00 NaN TPL 78 male 1 87 8 gasoline private 0 1,000 4.3552 50.8454 56 1.00 0 0 0.00 NaN TPL 58 male 0 151 23 gasoline private 0 1,000 4.3552 50.8454 57 1.00 0 0 0.00 NaN TPL+ 31 male 12 66 2 gasoline work 0 1,000 4.3552 50.8454 58 1.00 1 2 2,852.76 1,426.38 TPL++ 24 male 11 70 2 gasoline private 0 1,000 4.3552 50.8454 59 1.00 0 0 0.00 NaN TPL 74 female 5 29 14 gasoline private 0 1,000 4.3552 50.8454 60 1.00 0 0 0.00 NaN TPL 26 female 11 29 5 gasoline private 0 1,000 4.3552 50.8454 61 1.00 0 0 0.00 NaN TPL++ 46 male 0 75 2 gasoline work 0 1,000 4.3552 50.8454 62 0.13 0 0 0.00 NaN TPL 34 male 4 100 16 gasoline private 0 1,000 4.3552 50.8454 63 0.29 0 0 0.00 NaN TPL 51 male 0 85 5 gasoline private 0 1,000 4.3552 50.8454 64 1.00 1 1 16.86 16.86 TPL++ 54 male 0 103 3 gasoline work 0 1,000 4.3552 50.8454 65 1.00 0 0 0.00 NaN TPL++ 43 male 0 85 7 diesel private 0 1,000 4.3552 50.8454 66 1.00 0 0 0.00 NaN TPL+ 35 male 1 105 5 diesel private 0 1,000 4.3552 50.8454 67 1.00 0 0 0.00 NaN TPL 37 male 10 95 8 gasoline work 0 1,000 4.3552 50.8454 68 1.00 1 2 99.23 49.62 TPL+ 56 male 13 103 3 gasoline work 0 1,000 4.3552 50.8454 69 1.00 0 0 0.00 NaN TPL+ 39 male 0 75 4 gasoline work 0 1,000 4.3552 50.8454 70 1.00 0 0 0.00 NaN TPL 62 female 0 65 12 gasoline private 0 1,000 4.3552 50.8454 71 1.00 0 0 0.00 NaN TPL++ 33 male 5 110 6 gasoline private 0 1,000 4.3552 50.8454 72 0.13 0 0 0.00 NaN TPL 24 male 9 83 10 gasoline private 0 1,000 4.3552 50.8454 73 1.00 0 0 0.00 NaN TPL++ 39 male 4 110 4 gasoline private 0 1,000 4.3552 50.8454 74 1.00 0 0 0.00 NaN TPL 36 male 11 72 8 gasoline private 0 1,000 4.3552 50.8454 75 1.00 0 0 0.00 NaN TPL 37 male 11 77 16 gasoline private 0 1,000 4.3552 50.8454 76 0.45 0 0 0.00 NaN TPL 52 male 6 63 12 diesel private 0 1,000 4.3552 50.8454 77 0.47 0 0 0.00 NaN TPL 27 male 11 92 14 gasoline private 0 1,000 4.3552 50.8454 78 0.64 0 0 0.00 NaN TPL++ 33 male 12 75 3 gasoline work 0 1,000 4.3552 50.8454 79 0.34 0 0 0.00 NaN TPL++ 43 male 0 85 1 diesel private 0 1,000 4.3552 50.8454 80 1.00 0 0 0.00 NaN TPL++ 68 male 0 110 7 gasoline work 1 1,000 4.3552 50.8454 81 1.00 0 0 0.00 NaN TPL+ 55 female 0 92 14 gasoline private 0 1,000 4.3552 50.8454 82 0.38 0 0 0.00 NaN TPL+ 41 male 5 124 8 gasoline work 0 1,000 4.3552 50.8454 83 0.55 0 0 0.00 NaN TPL 55 male 1 90 16 gasoline private 0 1,000 4.3552 50.8454 84 1.00 0 0 0.00 NaN TPL 43 female 0 85 3 gasoline private 0 1,000 4.3552 50.8454 85 1.00 1 1 1,837.16 1,837.16 TPL+ 35 male 8 85 5 diesel private 0 1,000 4.3552 50.8454 86 1.00 0 0 0.00 NaN TPL++ 29 male 14 66 2 diesel work 0 1,000 4.3552 50.8454 87 1.00 1 1 158.38 158.38 TPL 45 female 11 83 9 gasoline private 0 1,000 4.3552 50.8454 88 0.46 0 0 0.00 NaN TPL++ 51 male 0 83 5 gasoline private 0 1,000 4.3552 50.8454 89 1.00 0 0 0.00 NaN TPL++ 51 male 0 110 1 gasoline private 1 1,000 4.3552 50.8454 90 1.00 1 1 1,306.10 1,306.10 TPL 23 male 8 90 6 gasoline private 0 1,000 4.3552 50.8454 91 1.00 0 0 0.00 NaN TPL++ 36 female 0 74 8 gasoline private 0 1,000 4.3552 50.8454 92 1.00 1 1 1,363.41 1,363.41 TPL 27 male 11 66 3 diesel private 0 1,000 4.3552 50.8454 93 0.07 0 0 0.00 NaN TPL 29 male 13 75 4 gasoline work 0 1,000 4.3552 50.8454 94 1.00 1 1 70.80 70.80 TPL++ 54 male 4 110 4 gasoline private 0 1,000 4.3552 50.8454 95 1.00 0 0 0.00 NaN TPL++ 68 male 0 85 4 diesel private 0 1,000 4.3552 50.8454 96 1.00 0 0 0.00 NaN TPL+ 58 female 4 110 10 gasoline work 0 1,000 4.3552 50.8454 97 1.00 0 0 0.00 NaN TPL+ 69 male 1 85 11 diesel work 1 1,000 4.3552 50.8454 98 1.00 0 0 0.00 NaN TPL+ 52 female 0 68 2 diesel private 0 1,000 4.3552 50.8454 99 1.00 0 0 0.00 NaN TPL 34 male 3 19 8 gasoline private 0 1,000 4.3552 50.8454 100 1.00 0 0 0.00 NaN TPL++ 34 male 12 51 1 diesel private 0 1,000 4.3552 50.8454 Code model_N &lt;- glm( formula = nclaims ~ ageph + sex + power + fuel + offset( log( expo ) ) + 0, family = poisson( link = &#39;log&#39; ), data = beMTPL97 ) Code dat &lt;- tidy( model_N ) dat %&gt;% kable( caption = &quot;Resultados del modelo GLM&quot;, row.names = FALSE, col.names = names( dat ), align = &#39;lrrrr&#39;, digits = c( 0, 6, 6, 6, 6 ), format.args = list( big.mark = &#39;,&#39;, decimal.mark = &#39;.&#39;, scientific = FALSE ), escape = FALSE ) %&gt;% kable_classic( font_size = 14, full_width = FALSE, html_font = &quot;Cambria&quot; ) %&gt;% scroll_box( width = &quot;750px&quot;, height = &quot;300px&quot; ) Tabla 8.3: Tabla 8.4: Resultados del modelo GLM term estimate std.error statistic p.value ageph -0.015627 0.000508 -30.790409 0 sexfemale -1.409836 0.032166 -43.830099 0 sexmale -1.458010 0.034274 -42.539517 0 power 0.002499 0.000372 6.714624 0 fueldiesel 0.140048 0.015098 9.275900 0 Code dat &lt;- glance( model_N ) dat %&gt;% kable( caption = &quot;Resultados del modelo GLM&quot;, row.names = FALSE, col.names = names( dat ), align = paste0( rep( &quot;r&quot;, ncol( dat ) ), collapse = &quot;&quot; ), digits = c( 4, 0, 2, 2, 2, 2, 0, 0 ), format.args = list( big.mark = &#39;,&#39;, decimal.mark = &#39;.&#39;, scientific = FALSE ), escape = FALSE ) %&gt;% kable_classic( font_size = 14, full_width = FALSE, html_font = &quot;Cambria&quot; ) %&gt;% scroll_box( width = &quot;750px&quot;, height = &quot;200px&quot; ) Tabla 8.5: Tabla 8.6: Resultados del modelo GLM null.deviance df.null logLik AIC BIC deviance df.residual nobs 260,163.9 163,212 -63,171.99 126,354 126,404 88,651.89 163,207 163,212 Code pob &lt;- expand.grid( ageph = seq( 18, 90, 1 ), sex = c( &#39;male&#39;, &#39;female&#39; ), power = seq( 10, 250 ), fuel = c( &#39;gasoline&#39;, &#39;diesel&#39; ), expo = 1 ) pob &lt;- as.data.table( pob ) pob[ , EN := predict( model_N, newdata = pob, type = &#39;response&#39; ) ] "],["estimación-de-valores-extremos.html", "Capítulo 9 Estimación de valores extremos 9.1 Estimación con valores extremos 9.2 Simulación con valores extremos", " Capítulo 9 Estimación de valores extremos Definición 9.1 (Distribución con cola pesada) Una variable aleatoria a valores reales \\(X\\) se dice que tiene su distribución \\(F\\) es de cola pesada hacia la derecha si el siguiente límite no es finito. \\[\\begin{equation} \\underset{x \\rightarrow +\\infty}{\\lim} \\exp( t x ) P( X &gt; x ) = \\underset{x \\rightarrow +\\infty}{\\lim} \\exp( t x ) ( 1 - F( x ) ) = + \\infty, \\qquad \\forall t &gt; 0 \\end{equation}\\] de forma muy similar diremos que la distribución tiene cola pesada hacia la izquierda si \\[\\begin{equation} \\underset{x \\rightarrow -\\infty}{\\lim} \\exp( -t x ) P( X \\leq x ) = \\underset{x \\rightarrow -\\infty}{\\lim} \\exp( -t x ) F( x ) = + \\infty, \\qquad \\forall t &gt; 0 \\end{equation}\\] Como consecuencia de la definición anterior, las variables aleatoria a valores reales que tiene cola pesada no poseen función generadora de momentos ya que la integral a continuación diverge para cualquier valor \\(t &gt; 0\\) \\[\\begin{equation} \\int\\limits_{\\mathbb{R}} \\exp( t x ) dF( x ) = + \\infty \\end{equation}\\] Teorema 9.1 (Fisher-Tippett-Gnedenko) Si consideramos una secuencia de variables aleatorias \\(\\{X_i\\}_{i\\in \\mathbb{N}}\\) las mismas son i.i.d, con distribución acumulada \\(F\\). Entonces, si existen dos sucesiones de valores reales \\(\\{a_n\\}_{n \\in \\mathbb{N}}\\) y \\(\\{b_n\\}_{n \\in \\mathbb{N}}\\), con \\(a_n &gt; 0\\) para cualquier \\(n \\in \\mathbb{N}\\) y una distribución acumulada no degenerada \\(G\\), de tal forma que para la variable aleatoria del máximo \\(M_n = \\max\\{ X_1, \\ldots, X_n \\}\\) se satisfaga el siguiente límite \\[\\begin{equation} \\underset{n \\rightarrow +\\infty}{\\lim} P\\left( \\frac{M_n - b_n}{a_n} &lt; x\\right) = \\underset{n \\rightarrow +\\infty}{\\lim} ( F\\left( a_n x + b_n \\right) )^n = G( x ), \\forall x \\in \\mathbb{R} \\end{equation}\\] decimos por tanto que la distribución \\(F\\) pertenece al máximo dominio de atracción de \\(G\\) y lo representamos por \\(F \\in MDA( G )\\). Además, las distribuciones \\(G\\) vienen caracterizadas por ser alguna de las distribuciones valores extremos generalizadas \\(GEV( \\mu, \\sigma, \\xi )\\). Las cuales engloban tres tipos relevantes: Tipo I, una distribución de Gumbel \\(G(x) = \\exp\\left( -\\exp\\left( -\\frac{x-\\mu}{\\sigma} \\right) \\right)\\), para \\(x \\in \\mathbb{R}, \\xi = 0\\) Tipo II, una distribución de Fréchet \\(G( x ) = \\exp\\left( -\\left(1 + \\xi\\frac{x-\\mu}{\\sigma}\\right)^{-\\frac{1}{\\xi}} \\right)\\), para \\(x &gt; \\mu - \\frac{\\sigma}{\\xi}\\) y \\(\\frac{1}{\\xi} &gt; 0\\), Tipo III, una distribución de Weibull inversa \\(G( x ) = \\exp\\left( -\\left(1 - |\\xi|\\frac{x-\\mu}{\\sigma}\\right)^{\\frac{1}{\\xi}} \\right)\\), para \\(x &lt; \\mu + \\frac{\\sigma}{|\\xi|}\\) y \\(\\frac{1}{\\xi} &lt; 0\\), Teorema 9.2 (Pickands-Balkema-De Haan) Sea \\(F_u\\) la distribución de exceso asociada a la variable aleatoria \\(X\\) y con umbral de condicionamiento \\(u &gt; 0\\). Entonces, para cualquier \\(\\varepsilon \\in \\mathbb{R}\\) tenemos que \\(F \\in MDA( H )\\) para alguna distribución \\(H = GEV( \\mu, \\sigma, \\varepsilon )\\) si y solamente si existe una distribución \\(G = GPD( \\nu, \\beta, \\varepsilon )\\), de tal forma que el siguiente límite se satisface por la distribución de exceso \\(F_u\\). \\[\\begin{equation} \\underset{u \\longrightarrow x_F}{\\lim} \\underset{0 &lt; x &lt; x_F - u}{\\sup} \\left| F_u( x ) - G( x ) \\right| = 0 \\end{equation}\\] donde \\(x_F = \\sup\\{ x\\in \\mathbb{R}\\mid F(x) &lt; 1 \\}\\) y \\(\\nu, \\beta\\) dependen de los parámetros \\(\\mu\\), \\(\\sigma\\) y \\(u\\). El teorema anterior 9.2 en cierta forma sugiere que si en el límite la distribución de exceso a partir de un valor de condicionamiento \\(u\\) cada vez se comporta más como una distribución de generalizada de Pareto. Entonces, la distribución de los máximos que se observen de una muestra de la variable aleatoria \\(X\\) tienen un comportamiento que puede ser descrito por una distribución de valores extremos generalizada. Un forma de estimar si hay la posibilidad de presentar valores extremos es tomando un corte a un nivel \\(u\\) de los valores observados de reclamos \\(X_1, \\ldots, X_n\\), es decir tomar de la muestra todos los valores \\(\\{ X_i \\mid X_i \\geq u \\}\\), a estos valores realizarles un test de ajuste a una distribución de Pareto generalizada \\(GPD( \\nu, \\beta, \\varepsilon )\\), si el test es aceptable y no se rechaza la hipótesis nula, entonces tenemos el resultado de aproximación anterior 9.2. Luego se puede simular los reclamos de forma condiciona. Es importante observar antes de continuar que para estudiar los valores extremos de reclamos estos no deben haber pasado por alguna deducción, después de aplicar alguna función deducible \\(D\\), sino posiblemente estaremos en el caso inútil de tener valores truncados, con una cola limitada, para los cuales es imposible estimar de forma adecuada alguna distribución de valores extremos. 9.1 Estimación con valores extremos Para generar un modelo utilizando valores extremos se puede tomar la siguiente aproximación haciendo uso 9.2 Seleccionar un valor de corte \\(u &gt; 0\\). A partir de la muestra de valores de reclamos observados, tomar aquellos valores observados tales que \\(X_i \\geq u\\). Al conjunto \\(\\{ X_i \\mid X_i \\geq u \\}\\) aplicarle un test de ajuste a una distribución de Pareto generalizada \\(GPD( u, \\beta, \\varepsilon )\\), donde \\(u\\) está fijo como parámetro. Si el test es satisfactorio, buscar un nuevo \\(u\\), realizar nuevamente los pasos 2 y 3. Comparar el resultado de ajuste con el anterior y decidir cuál \\(u\\) mantener según algún criterio de selección estadística. Usualmente un criterio de información o la significancia de los valores \\(p\\) Si llegamos a obtener un resultado satisfactorio para algún \\(u &gt; 0\\), podemos concluir con cierto nivel de certeza, que los valores extremos de los reclamos si pueden ser descritos con una distribución de valores extremos generalizada \\(GEV( \\mu, \\sigma, \\varepsilon )\\) o de forma equivalente que los reclamos en la cola \\(X \\geq u\\) pueden ser descritos con una distribución de Pareto generalizada \\(GPD( u, \\beta, \\varepsilon )\\). Se ajusta una distribución de severidad \\(F\\) a todos los reclamos en la muestra \\(X\\). La distribución que se ajusta, debe estar precisamente dentro de la familia de funciones que están el dominio máximo de atracción de la familia de distribuciones de valores extremos generalizadas, i.e. \\(F \\in MDA( GEV( \\mu, \\sigma, \\varepsilon ) )\\). Si la prueba anterior fue satisfactoria para algún \\(u &gt; 0\\). Se determina a que percentil \\(p_u\\) pertenece, esto se lo puede realizar a partir de la muestra mismo \\(F_n( X \\leq u ) = p_u\\) o con la distribución ajustada para los reclamos \\(F( X \\leq u ) = p_u\\). 9.2 Simulación con valores extremos Si en caso se desea simular los reclamos, se toma con probabilidad \\(p_u\\) un muestra con la distribución truncada \\(X \\rightsquigarrow F_{(u)}( x ) = F( x \\mid X \\leq u ) = \\frac{F(\\min(u,x))}{F(u)}\\) y con probabilidad \\(1 - p_u\\) una muestra con la distribución de Pareto generalizada estimada \\(X \\rightsquigarrow G = GPD( u, \\beta, \\varepsilon )\\). Así, en particular al esperanza de \\(X\\) tiene al forma \\[\\begin{equation} \\mathbb{E}[ X ] = \\mathbb{E}[ X \\mid X \\leq u ] P( X \\leq u ) + \\mathbb{E}[ X \\mid X &gt; u ] P( X &gt; u ) = p_u \\mathbb{E}_{F_{(u)}}[ X ] + \\left( 1 - p_u \\right) \\mathbb{E}_{G}[ X ] \\end{equation}\\] Si la muestra inicial es lo suficientemente representable y por tanto tiene un buen tamaño, el valor \\(p_u\\) puede ser realmente cercano a \\(1\\), por tal razón si se decide realizar una simulación de valores extremos de tamaño \\(m\\), se tiene que tomar en cuenta que en promedio \\(m ( 1 - p_u )\\) de esos valores serán valores extremos, si \\(m\\) no es lo suficientemente grande puede que los valores extremos simulados sean cero en cantidad y habrá sido inútil el haber realizado una estimación más compleja con valores extremos, ya que no se la está utilizando en las simulaciones. En tales circunstancias es mucho mejor utilizar algún algoritmo determinista que supere este problema. "],["bibliografía.html", "Capítulo 10 Bibliografía", " Capítulo 10 Bibliografía "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
