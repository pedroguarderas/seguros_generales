[["introducción.html", "Matemática Actuarial de los Seguros Generales Capítulo 1 Introducción 1.1 Materia 1.2 Resultados de aprendizaje 1.3 Contenidos propuestos", " Matemática Actuarial de los Seguros Generales 2025-03-25 Capítulo 1 Introducción 1.1 Materia Matemática Actuarial de los Seguros Generales 1.2 Resultados de aprendizaje Contrastar los criterios de valoración actuarial en los seguros generales, así como elaborar y aplicar las bases técnicas. Aprender a obtener la distribución y momentos correspondientes de la siniestralidad total pagada por el asegurador y por el reasegurador en presencia de franquicias y reaseguro. Identificar las modificaciones que pueden sufrir los contratos de seguros generales y valorar las consecuencias técnicas de dichas modificaciones. Calcular la función de distribución del coste total de una cartera de pólizas. 1.3 Contenidos propuestos Distribuciones compuestas Series de tiempo El Proceso de Riesgo: Distribución clase (a,b) y algoritmo de Panjer, Distribución de siniestralidad agregada Modelos Lineales Generalizados (GLMs): para datos binarios y recuentos Proceso de Tarificación Tarificación a priori: cálculo de la prima pura Tarificación a posteriori: sistemas Bonus-Malus Teoría de la Ruina En cuanto a las referencias utilizaremos los siguientes libros guía, [1], [2], [3], [4], [5]. Utilizaremos algunos otras referencias de soporte, que serán de utilidad para quien desee profundizar con más detalle en algunos conceptos [6], [7], [8], [9], [10]. En cuanto a la parte computacional, haremos uso del paquete para R, [11]. GIL FANA: Elementos de Matemáticas para las Ciencias del Seguro. Fundación Mapfre Estudios. 1991 Bibliografía "],["consideraciones-preliminares.html", "Capítulo 2 Consideraciones preliminares 2.1 Consideraciones de probabilidades 2.2 Desigualdades de concentración 2.3 Consideraciones estadísticas 2.4 Consideraciones financieras 2.5 Consideraciones de programación en R", " Capítulo 2 Consideraciones preliminares 2.1 Consideraciones de probabilidades Definition 2.1 (Variable aleatoria) Una variable aleatoria \\(X: \\Omega \\longrightarrow D\\) que parte del espacio muestral \\(\\Omega\\) y toma valores en el conjunto de los números reales \\(\\mathbb{R}\\), decimos que sigue la ley \\(f : \\mathbb{R} \\longrightarrow \\mathbb{R}\\), si para cualquier evento \\(A \\subset \\Omega\\) \\[\\begin{equation} P( X \\in A ) = \\int\\limits_{A} dP_X( x ) = \\int\\limits_{A} d(P \\circ X^{-1})( x ) = \\int\\limits_{X^{-1}( A )} dP( \\omega ) \\end{equation}\\] Definition 2.2 (Variable aleatoria discreta) Una variable aleatoria \\(K: \\Omega \\longrightarrow D\\) que parte del espacio muestral \\(\\Omega\\) y toma valores en un conjunto discreto \\(D = \\left\\{k_i \\in \\mathbb{R} | i \\in \\mathbb{N} \\right\\}\\), sigue una probabilidad discreta dada por las probabilidades \\(p_i \\in [0,1]\\) , \\(i \\in \\mathbb{N}\\), si \\[\\begin{equation} P\\left( K = k_i \\right) = p_i,\\qquad \\forall i \\in \\mathbb{N} \\end{equation}\\] Además se cumple la condición de normalización que es muy importante. \\[\\begin{equation} \\sum\\limits_{i = 0}^{\\infty} p_i = 1 \\end{equation}\\] las probabilidades ¡Nunca son negativas! y !Suman siempre 1!. Definition 2.3 (Función de distribución acumulada) Consideramos una variable aleatoria a valores reales \\(X\\), la función de distribución acumulada \\(F\\) asociada a la variable aleatoria \\(X\\), está dada por la siguiente relación: \\[\\begin{equation} F( x ) = P( X \\leq x ) \\end{equation}\\] La función de distribución acumulada, tiene las siguientes propiedades: Para cualquier \\(x \\in \\mathbb{R}\\), \\(0 \\leq F( x ) \\leq 1\\), La función \\(F\\) es no decreciente, La función \\(F\\) es continua por derecha, Se satisfacen los siguientes límites: \\[\\begin{equation} \\underset{x \\rightarrow -\\infty}{\\lim} F( x ) = 0\\qquad \\underset{x \\rightarrow +\\infty}{\\lim} F( x ) = 1 \\end{equation}\\] Definition 2.4 (Función supervivencia) La función de supervivencia \\(S : \\mathbb{R} \\longrightarrow \\mathbb{R}\\) está asociada a una variable aleatoria \\(X\\), está dada por la siguiente: \\[\\begin{equation} S( x ) = 1 - F( x ) = 1 - P( X \\leq x ) = P( X &gt; x ) \\end{equation}\\] Definition 2.5 (Función de densidad de probabilidad) La densidad de probabilidad o también la ley de probabilidad de una variable aleatoria a valores reales \\(X\\), es una función \\(f: \\mathbb{R} \\longrightarrow \\mathbb{R}\\), tal que \\[\\begin{equation} P( a \\leq X \\leq b ) = F( b ) - F( a ) = \\int\\limits_a^b f( x )\\ dx \\end{equation}\\] Así se satisface la siguiente igualdad \\[\\begin{equation} F( x ) = \\int\\limits_{-\\infty}^x f( x )\\ dx \\end{equation}\\] Definition 2.6 (Esperanza matemática) Considerando una variable aleatoria discreta \\(K : \\Omega \\longrightarrow D = \\{k_1, \\ldots, k_n\\} \\subset \\mathbb{R}\\), la esperanza matemática está dada por: \\[\\begin{equation} \\mathbb{E}[ K ] = \\sum\\limits_{i=0}^{\\infty} k_i P\\left( K = k_i \\right) = \\sum\\limits_{i=0}^{\\infty} k_i p_i \\end{equation}\\] Para el caso de una variable aleatoria continua \\(X : \\Omega \\longrightarrow \\mathbb{R}\\) a valores reales, la esperanza matemática está dada por \\[\\begin{equation} \\mathbb{E}[ X ] = \\int\\limits_{\\mathbb{\\Omega}} X( \\omega )\\ dP( \\omega ) = \\int\\limits_{\\mathbb{R}} x\\ dF( x ) \\end{equation}\\] Cuando la función de densidad de probabilidad está bien definida es posible expresar y calcular la esperanza matemática como la siguiente expresión: \\[\\begin{equation} \\mathbb{E}[ X ] = \\int\\limits_{\\mathbb{R}} x f( x )\\ dx \\end{equation}\\] La esperanza matemática goza de las siguientes propiedades: Linealidad, \\(a \\in \\mathbb{R}\\) \\[\\begin{equation} \\mathbb{E}[ aX + Y ] = a \\mathbb{E}[ X ] + \\mathbb{E}[ Y ] \\end{equation}\\] Monotonía, si \\(X \\leq Y\\), entonces \\[\\begin{equation} \\mathbb{E}[X] \\leq \\mathbb{E}[Y] \\end{equation}\\] Definition 2.6 (Varianza) Así mismo su varianza es la dada por: \\[\\begin{equation} \\mathbb{V}[ X ] = \\mathbb{E}\\left[ \\left( X - \\mathbb{E}[ X ] \\right)^2 \\right] = \\mathbb{E}\\left[ X^2 \\right] - \\mathbb{E}\\left[ X \\right]^2 \\end{equation}\\] Definition 2.7 (Independencia de variables aleatorias) Dos variables aleatorias a valores reales \\(X\\) y \\(Y\\), se dicen independientes si para cualquier par de eventos \\(A\\) y \\(B\\), sucede la siguiente factorización de probabilidades \\[\\begin{equation} P( X \\in A \\wedge Y \\in B ) = P( X \\in A ) P( Y \\in B) \\end{equation}\\] La propiedad anterior, en particular para la función de distribución conjunta, toma la siguiente forma: \\[\\begin{equation} F_{X,Y}( x, y ) = P( X \\leq x \\wedge Y \\leq y ) = P( X \\leq x ) P( Y \\leq y ) = F_{X}( x ) F_{Y}( y ) \\end{equation}\\] Así mismo, para la densidad de probabilidad conjunto, sucede la siguiente factorización \\[\\begin{equation} f_{X,Y}( x, y ) = f_X( x ) f_Y( y ) \\end{equation}\\] La siguiente función es utilidad para comprender algunos resultados en teoría de probabilidades. También, es bastante útil para realizar de forma más clara y rápida algunos cálculos. Definition 2.8 (Función indicatriz) La función indicatriz de un conjunto \\(A \\subset \\Omega\\), es la función \\(\\mathbf{1}_A : \\Omega \\longrightarrow \\{0,1\\}\\), que toma los valores \\(\\mathbf{1}_A( \\omega ) = 0\\), si \\(\\omega \\notin A\\) y \\(\\mathbf{1}_A( \\omega ) = 1\\), si \\(\\omega \\in A\\). La función indicatriz \\(\\mathbf{1}_A\\) sobre un evento \\(A\\) del espacio muestral \\(\\Omega\\), también se puede interpretar como una variable aleatoria, que tan solo tomo los valores \\(0\\) o \\(1\\). Es más, su esperanza es precisamente la probabilidad del evento \\(A\\). \\[\\begin{equation} \\mathbb{E}\\left[ \\mathbf{1}_A \\right] = \\int\\limits_\\Omega \\mathbf{1}_A( \\omega )\\ dP( \\omega ) = \\int\\limits_A dP( \\omega ) = P( A ) \\end{equation}\\] Definition 2.9 (Distribución de la suma de variables aleatorias) Dadas dos variables aleatorias a valores reales \\(X\\) y \\(Y\\), con funciones de distribución acumulada \\(F_X\\) y \\(F_Y\\) respectivamente, la distribución acumulada \\(F_Z\\) de la variable aleatoria \\(Z = X + Y\\) está dada por la siguiente expresión: \\[\\begin{equation} F_Z( z ) = P( Z \\leq z ) = F_X \\star F_Y ( z ) = \\int\\limits_{\\mathbb{R}} F_X( x - y )dF_Y( y ) \\end{equation}\\] si en caso se puede definir las densidades de probabilidad \\(f_X\\) y \\(f_Y\\) para las variables aleatorias \\(X\\) y \\(Y\\), entonces: \\[\\begin{equation} f_Z( z ) = f_X \\star f_Y ( z ) = \\int\\limits_{\\mathbb{R}} f_X( x - y ) f_Y( y )\\ dy \\end{equation}\\] El producto \\(\\star\\) se conoce como convolución de funciones, el mismo es simétrico. Para cuando se realiza la convolución de varias veces la misma función, se opta por una notación más compacta \\(f^{\\star k}\\), para el producto de convolución \\(k\\)-veces la misma función \\(f \\star f \\star \\cdots \\star f\\). La siguiente definición de distribución de exceso condicionada es útil para el estudio de los valores extremos que se pueden presentar en el estudio de los valores de siniestros que se presentan en un seguro. Definition 2.10 (Distribución de exceso condicionada) La distribución de exceso condicionada asociada a una variable aleatoria \\(X\\) con distribución de probabilidad acumulada \\(F\\) y a un umbral de condicionamiento \\(u &gt; 0\\), está dada por: \\[\\begin{equation} F_u( y ) = P\\left( X - u \\leq y \\mid X &gt; u \\right) = \\frac{P\\left( u &lt; X \\leq y + u\\right)}{P(X &gt; u)} = \\frac{F( u + y ) - F( u )}{ 1 - F( u )} \\end{equation}\\] 2.2 Desigualdades de concentración Para muchos fines prácticos es importante encontrar una buena estimación de donde se encuentran concentrados los valores de una distribución de probabilidad, para ello existen varios resultados que caracterizan precisamente ello, estos se conocen como desigualdades de concentración. Proposition 2.1 (Desigualdad de Chebyshev (Чебышёв)) Dada una variable aleatoria \\(X\\) con esperanza y varianza finitas \\(\\mathbb{E}[X] &lt;+ \\infty\\) y \\(\\mathbb{V}[X] &lt; +\\infty\\), tenemos que se satisface la siguiente desigualdad para cualquier \\(varepsilon &gt; 0\\) \\[\\begin{equation} P\\left( \\left| X - \\mathbb{E}[X] \\right| &gt; \\varepsilon \\right) &lt; \\frac{1}{\\varepsilon^2} \\mathbb{V}[ X ] \\end{equation}\\] Theorem 2.1 (Desigualdad de Berry-Esséen) Sean \\(X_1, \\ldots X_n\\) variables aleatoria i.i.d, con media y varianza finitas, i.e \\(\\mathbb{E}[X] &lt; +\\infty\\) y \\(\\mathbb{V}[X] &lt; +\\infty\\) y además con tercer momento absoluto finito \\(\\mathbb{E}\\left[\\left|X - \\mathbb{E}[X]\\right|^3\\right] &lt; +\\infty\\). Entonces, la distribución acumulada \\(F_n\\) de la variable aleatoria \\[\\begin{equation} U_n = \\frac{S_n - \\mathbb{E}[ S_n ]}{\\mathbb{V}[ S_n ]} \\end{equation}\\] con \\(S_n = \\sum\\limits_{i=1}^n X_i\\). Satisface la siguiente desigualdad respecto de la distribución acumulada de la ley normal \\(\\Phi\\). \\[\\begin{equation} \\underset{u}{\\sup}\\left| F_n( u ) - \\Phi( u ) \\right| \\leq \\frac{A}{\\sqrt{n}} \\frac{\\mathbb{E}\\left[\\left|X - \\mathbb{E}[X]\\right|^3\\right]}{\\sqrt{\\mathbb{V}[X]}^3} \\end{equation}\\] 2.3 Consideraciones estadísticas De las ramas de las Matemáticas la Estadística ciertamente es la más subestimada, en muchos casos menospreciada. Sin embargo, no sin mucha pretención, sino más bien honestidad, se puede decir que la Estadística es una de las ramas más complicadas de las Ciencias en general, ya que busca en muchos casos comprender, explicar y predecir fenómenos reales. En su fundamentación, al profundizar en ella, uno encontrará un sin número de conceptos, métodos y teorías con un amplio espectro de complejidad, que incluso se sustentan en ideas filosóficas bastante elaboradas y poco comprendidas. No olvidar, la Estadística busca de frente y sin rodeos extraer conocimiento de la realidad y no hay algo más complejo y duro que la realidad misma. Muchos de las herramientas de las estadística se resumen en algunas recetas o aplicaciones de software, sin embargo, no se debe olvidar que en muchos casos estas herramientas hacen uso de muchos métodos bastante avanzados y complejos en lo que respecta al conocimiento Matemático. Theorem 2.2 (Teorema del límite central) Consideramos las variables aleatorias \\(X_1,\\ldots,X_n\\), independientes e idénticamente distribuidas (i.i.d) con media común finita \\(\\mathbb{E}[X_i] = \\mu &lt; +\\infty\\) y varianza común finita \\(\\mathbb{V}[ X_i ] = \\sigma^2 &lt; +\\infty\\), para todo \\(i \\in \\{1, \\ldots, n \\}\\). Si consideramos la variable aleatoria de la suma total \\(S_n = \\sum\\limits_{i=1}^n X_i\\), entonces \\[\\begin{equation} \\frac{S_n - \\mathbb{E}[S_n]}{\\mathbb{V}[ S_n ]} \\overset{d}{\\longrightarrow} Z \\end{equation}\\] cuando \\(n \\rightarrow +\\infty\\), donde \\(Z \\rightsquigarrow N( 0, 1 )\\). Más aún \\[\\begin{equation} \\underset{n \\rightarrow +\\infty}{\\lim} P\\left( \\frac{S_n - \\mathbb{E}[S_n]}{\\mathbb{V}[ S_n ]} \\leq z \\right) = \\Phi( z ) \\end{equation}\\] El teorema del límite central en su forma usual no proporciona una tasa de convergencia es decir, la variable aleatoria \\(\\frac{S_n - \\mathbb{E}[S_n]}{\\mathbb{V}[ S_n ]}\\) tiende a tener un comportamiento de una variable aleatoria normal estándar conforme aumenta \\(n\\), pero no estamos seguros que tamaño debe tomar \\(n\\) para que esto se cumpla con una alta certeza. Para ello adicional al 2.2 se debe considerar otros resultados asociados a desigualdades de concentración. El siguiente teorema es de gran ayuda para estimar la tasa de convergencia del resultado anterior 2.2. Theorem 2.3 (Desigualdad Dvoretzky–Kiefer–Wolfowitz) Dada una serie de variables aleatorias a valores reales \\(X_1, \\ldots, X_n\\), independientes entre si e idénticamente distribuidas (i.i.d), con distribución acumulada \\(F\\), tenemos la siguiente desigualdad asociada a la distribución acumulada empírica \\[\\begin{equation} F_n( x ) = \\frac{1}{n}\\sum\\limits_{i=1}^n \\mathbf{1}_{(-\\infty,x]}( X_i ) \\end{equation}\\] y su aproximación a \\(F\\). \\[\\begin{equation} P\\left( \\underset{x \\in \\mathbb{R}}{\\sup} \\left| F_n( x ) - F( x ) \\right| &gt; \\varepsilon \\right) \\leq 2 e^{-2n \\varepsilon^2 }\\qquad \\forall \\varepsilon &gt; 0 \\end{equation}\\] Como podemos notar el orden de convergencia del teorema es \\(\\sqrt{n}\\) en el tamaño de observaciones, esto quiere decir que la convergencia es menos que el orden lineal. Definition 2.11 (Distribución de Pareto generalizada) \\[\\begin{equation} G_{\\varepsilon,\\beta}( x ) = \\left \\{ \\begin{array}{ll} 1 - \\left( 1 + \\varepsilon \\frac{x}{\\beta} \\right)^{-\\frac{1}{\\varepsilon}}, \\text{si}\\ \\varepsilon \\neq 0 \\\\ 1 - e^{-\\frac{x}{\\beta}}, \\text{si}\\ \\varepsilon = 0 \\end{array} \\right. \\end{equation}\\] Theorem 2.4 (Pickands-Balkema-De Haan) Sea \\(F_u\\) la distribución de exceso asociada a la variable aleatoria \\(X\\) y con umbral de condicionamiento \\(u &gt; 0\\). Entonces, para cualquier \\(\\varepsilon \\in \\mathbb{R}\\). \\[\\begin{equation} \\underset{u \\longrightarrow x}{\\lim} \\underset{x &gt; 0}{\\sup} \\left| F_u( x ) - G_{\\varepsilon,\\beta(u)( x )} \\right| = 0 \\end{equation}\\] 2.4 Consideraciones financieras Antes de desarrollar el contenido propio del curso, debemos tener en cuenta algunas consideraciones financieras como las siguientes: 2.4.1 Función de actualización o descuento La función de actualización de flujos \\(v: \\mathbb{R} \\times \\mathbb{R} \\longrightarrow [0,1]\\), al evaluar en \\(s, t \\in \\mathbb{R}, s\\leq t, v(s,t)\\), diremos que actualizamos los flujos que se producen en el tiempo \\(t\\), valorados desde el tiempo \\(s\\). Además la función de actualización tiene las siguientes propiedades: Si \\(s = t, v(s,t) = 1\\), Si \\(s \\leq t, v(s,t) \\leq 1\\), Si \\(r \\leq s \\leq t, v( r, s ) v( s, t ) = v( r, t )\\). El caso más particular y sencillo se presenta cuando la función de actualización es generada por una tasa constante \\(i \\in [0,1]\\), es decir, \\(v(s,t) = ( 1 + i )^{t-s}\\). La función de capitalización, es la función \\(u: \\mathbb{R} \\times \\mathbb{R} \\longrightarrow [0,1]\\), tal que \\(u( s, t ) v( s, t ) = 1\\). 2.4.2 Flujos financieros Un flujo financiero discreto \\(c\\) es una serie de valores reales \\(c(t_1), c(t_2), \\cdots, c(t_n)\\) que se producen en un número discreto de tiempos \\(t_0 &lt; t_1 &lt; \\cdots &lt; t_n\\). El valor presente de estos flujos, en un tiempo \\(t \\leq t_0\\), se lo puede calcular utilizando precisamente la función de actualización \\(v\\) \\[\\begin{equation} VP_t( c ) = \\sum\\limits_{k = 1}^n v( t, t_k ) c( t_k ) \\end{equation}\\] cuando \\(t=0\\), se suele solo expresar \\(VP( c ) = VP_0( c )\\). 2.4.3 Flujos financieros probables Un flujo financiero discreto \\(c\\) es una serie de valores reales \\(c(t_1), c(t_2), \\cdots, c(t_n)\\) que se producen en un número discreto de tiempos \\(t_0 &lt; t_1 &lt; \\cdots &lt; t_n\\). El valor actuarial presente de estos flujos, en un tiempo \\(t \\leq t_0\\), se lo puede calcular utilizando precisamente la función de actualización \\(v\\) \\[\\begin{equation} VAP_t( c ) = \\mathbb{E}\\left[ \\sum\\limits_{k = 1}^n v( t, t_k ) c( t_k ) \\right] = \\sum\\limits_{k = 1}^n v( t, t_k ) \\mathbb{E}\\left[ c( t_k ) \\right] \\end{equation}\\] cuando \\(t=0\\), se suele solo expresar \\(VAP( c ) = VAP_0( c )\\). Si cada \\(c(t_k)\\) es una variable aleatoria discreta \\[\\begin{equation} VAP_t( c ) = \\sum\\limits_{k = 1}^n v( t, t_k ) \\mathbb{E}\\left[ c( t_k ) \\right] = \\sum\\limits_{k = 1}^n \\sum\\limits_{i=1}^{\\infty} v( t, t_k ) c_i( t_k ) p_i( t_k ) \\end{equation}\\] 2.4.4 Equilibrio financiero Se dice que un flujo financiero \\(c(t_1), c(t_2), \\cdots, c(t_n)\\) como el anterior, está en equilibrio financiero si: \\[\\begin{equation} VP_0( c ) = \\sum\\limits_{k=0}^{n} v( 0, t_k ) c( t_k ) = 0 \\end{equation}\\] El equilibrio financiero se mantiene en el tiempo, basta observar que para cualquier instante \\(t \\geq 0\\) \\[\\begin{eqnarray*} 0 &amp; = &amp; u( 0, t ) VP_0( c ) \\\\ &amp; = &amp; u( 0, t ) \\sum\\limits_{k=0}^{n} v( 0, t_k ) c( t_k ) \\\\ &amp; = &amp; \\sum\\limits_{t_k \\leq t} u( 0, t ) v( 0, t_k ) c( t_k ) + \\sum\\limits_{t_k &gt; t} u( 0, t ) v( 0, t_k ) c( t_k ) \\\\ &amp; = &amp; \\sum\\limits_{t_k \\leq t} u( 0, t_k ) u( t_k, t ) v( 0, t_k ) c( t_k ) + \\sum\\limits_{t_k &gt; t} u( 0, t ) v( 0, t ) v( t, t_k ) c( t_k ) \\\\ &amp; = &amp; \\sum\\limits_{t_k \\leq t} u( t_k, t ) c( t_k ) + \\sum\\limits_{t_k &gt; t} v( t, t_k ) c( t_k ) \\\\ \\end{eqnarray*}\\] Esto implica que el valor actualizado a cualquier instante \\(t\\) de un flujo financiero \\(c\\) que está en equilibrio en un inicio, se mantiene también en equilibrio; siempre y cuando se preserve los flujos y tasas de actualización. A pesar de ser un resultado evidente, en la izquierda tenemos los flujos capitalizados hasta el tiempo \\(t\\) y en la derecha tenemos los flujos actualizados al tiempo \\(t\\). La expresión de la izquierda se conoce como la parte retrospectiva y la expresión de la derecha como la parte prospectiva. En condiciones de equilibrio financiero la parte retrospectiva se igual con menos la parte prospectiva. \\[\\begin{equation} \\sum\\limits_{t_k \\leq t} u( t_k, t ) c( t_k ) = -\\sum\\limits_{t_k &gt; t} v( t, t_k ) c( t_k ) \\end{equation}\\] algunas veces se considera la parte prospectiva con el signo menos. 2.5 Consideraciones de programación en R En el transcurso del presente curso utilizaremos algunos paquetes de R, acá la lista de carga de los mismos library( actuar ) library( data.table ) library( ggplot2 ) library( googledrive ) library( kableExtra ) library( knitr ) library( latex2exp ) library( lubridate ) library( openxlsx ) library( readxl ) library( rmarkdown ) library( shiny ) library( wesanderson ) options( scipen = 9999 ) options( stringsAsFactors = FALSE ) Para definir una variable utilizamos el operador de asignación &lt;-, también se puede utilizar =. Un vector se define con la función de concatenación c x &lt;- c( 1, 2, 3 ) print( x ) ## [1] 1 2 3 Un función se define con la sentencia function f &lt;- function( t ) { return( t^2 ) } Si buscamos aplicar una función sobre un vector, podemos utilizar sapply y &lt;- sapply( x, FUN = f ) print( y ) ## [1] 1 4 9 z &lt;- lapply( x, FUN = f ) print( z ) ## [[1]] ## [1] 1 ## ## [[2]] ## [1] 4 ## ## [[3]] ## [1] 9 Para muchas tareas que están relacionadas con el manejo de datos, podemos utilizar las funcionalidades del paquete de R, data.table. Para trabajar con fechas recomendamos utilizar el paquete lubridate. "],["modelos-de-pérdida-agregada.html", "Capítulo 3 Modelos de pérdida agregada 3.1 Mutualización del riesgo 3.2 Modelo individual 3.3 Modelo colectivo 3.4 Medidas de riesgo", " Capítulo 3 Modelos de pérdida agregada \\(R\\) Ganancia \\(P\\) Ingreso por primas \\(I\\) Ingreso por inversiones \\(S\\) Pago de siniestros \\(G\\) Gastos de subscripción \\[\\begin{equation} R = P + I - S - G \\end{equation}\\] 3.1 Mutualización del riesgo La idea de mantener un seguro está basada en la mutualización de los riesgos. La mutualización como tal nace del mismo mecanismo bajo el cual funciona un seguro, cada asegurado transfiera su riesgo individual a la compañia de seguros por su parte, la suma total de estos riesgos \\(S\\) es el riesgo total que asume el asegurador. Los riesgos de cada uno de los \\(n \\in \\mathbb{N}\\) asegurados, pueden ser representados por variables aleatorias \\(X_1,\\ldots X_n\\), las mismas pueden ser independientes o dependientes entre ellas. El costo total del portafolio está dado por la suma de todos estos riesgos. \\[\\begin{equation} S = \\sum\\limits_{i=1}^n X_i \\end{equation}\\] El conocer la distribución del costo total \\(S\\) es una tarea crucial para el asegurador. El costo total esperado esta dado claramente por la siguiente expresión. \\[\\begin{equation} \\mathbb{E}[ S ] = \\mathbb{E}\\left[ \\sum\\limits_{i=1}^n X_i \\right] = \\sum\\limits_{i=1}^n \\mathbb{E}\\left[ X_i \\right] \\end{equation}\\] la varianza de la variable aleatoria del costo total \\(S\\), está dada por: \\[\\begin{eqnarray*} \\mathbb{V}\\left[ S \\right] &amp; = &amp; \\mathbb{V}\\left[ \\sum\\limits_{i=1}^n X_i \\right] \\\\ &amp; = &amp; \\sum\\limits_{i=1}^n \\mathbb{V}\\left[ X_i \\right] + \\sum\\limits_{i=1}^n \\sum\\limits_{j=1,j\\neq i}^n \\mathbb{C}\\left[ X_i, X_j \\right] \\\\ &amp; = &amp; \\sum\\limits_{i=1}^n \\mathbb{V}\\left[ X_i \\right] + 2\\sum\\limits_{i=1}^{n-1} \\sum\\limits_{j=i+1}^n \\mathbb{C}\\left[ X_i, X_j \\right] \\end{eqnarray*}\\] \\(S_n = \\sum\\limits_{i=1}^n X_i\\) \\[\\begin{equation} W_n = \\frac{S_n}{n} \\end{equation}\\] \\[\\begin{equation} \\mathbb{E}\\left[ W_n \\right] = \\mathbb{E}\\left[ \\frac{S_n}{n} \\right] = \\frac{1}{n} \\mathbb{E}\\left[ S_n \\right] \\end{equation}\\] \\[\\begin{equation} \\mathbb{V}\\left[ W_n \\right] = \\mathbb{V}\\left[ \\frac{S_n}{n} \\right] = \\frac{1}{n^2} \\mathbb{V}\\left[ S_n \\right] \\end{equation}\\] 3.2 Modelo individual En el modelo de riesgos individuales consideramos que el número de siniestros que se producirán es conocido, por ejemplo puede ser a lo sumo el tamaño de la población asegurada, en tal caso la variable aleatoria \\(N\\) pasa a ser una constante, que representaremos por \\(n\\). De esta forma, la severidad total puede ser fácilmente representada por: \\[\\begin{equation} S = \\sum\\limits_{i=1}^n X_i \\end{equation}\\] La hipótesis más usual que sostiene a este modelo es la indenpendencia entre cada uno de los reclamos \\(X_i\\) y \\(X_j\\) son independientes para cualquier \\(1 \\leq i \\neq j \\leq n\\). El valor esperado de la severidad total \\(S\\) es: \\[\\begin{eqnarray*} \\mathbb{E}[S] &amp; = &amp; \\mathbb{E}\\left[ \\sum\\limits_{i=1}^n X_i \\right] \\\\ &amp; = &amp; \\sum\\limits_{i=1}^n \\mathbb{E}\\left[ X_i \\right] \\end{eqnarray*}\\] m &lt;- 100 n &lt;- 200 u &lt;- sample( c( 1, 2, 3, 4 ), size = n, replace = TRUE ) s &lt;- sample( c( 1, 2, 3, 4 ), size = n, replace = TRUE ) X &lt;- sapply( 1:n, FUN = function( i ) rlnorm( m, meanlog = u[ i ], sdlog = s[ i ] ) ) S &lt;- sapply( 1:m, FUN = function( i ) sum( X[i,] ) ) FS &lt;- seq( 0, 1, 0.01 ) Sq &lt;- quantile( S, probs = FS ) EeS &lt;- mean( S ) ES &lt;- sum( sapply( 1:n, FUN = function( i ) exp( u[i] + 0.5 * s[i]^2 ) ) ) plot( Sq, FS, type = &#39;s&#39;, col = &#39;dodgerblue4&#39; ) abline( v = EeS, col = &#39;red&#39; ) abline( v = ES, col = &#39;orange&#39; ) 3.3 Modelo colectivo El modelo colectivo de riesgo considera un número de reclamos descritos por una variable aleatoria discreta \\(N\\). Los reclamos corresponden a un número de pólizas en un periodo específico, el valor de cada reclamo \\(i \\in \\{1,\\ldots,N\\}\\) está representado por las variables aleatorias \\(X_i\\). Usualmente, se considera que cada uno de los reclamos \\(X_i\\) están idénticamente distribuidos. \\[\\begin{equation} S = \\left\\{ \\begin{array}{ll} \\sum\\limits_{i=1}^N X_i &amp; \\text{si}\\ N &gt; 0 \\\\ 0 &amp; \\text{si}\\ N = 0 \\end{array} \\right. \\end{equation}\\] o de forma más compacta y equivalente \\(S = \\mathbf{1}_{\\mathbb{N}^*}( N ) \\sum\\limits_{i=1}^N X_i\\) El valor esperado del total de reclamos \\(S\\), está dado por: \\[\\begin{eqnarray*} \\mathbb{E}[S] &amp; = &amp; \\mathbb{E}\\left[ \\mathbf{1}_{\\mathbb{N}^*}( N ) \\sum\\limits_{i=1}^N X_i \\right] \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} \\mathbb{E}\\left[ \\mathbf{1}_{\\mathbb{N}^*}( N ) \\sum\\limits_{i=1}^n X_i\\ \\middle|\\ N = n \\right]P( N = n )\\quad \\text{utilizando la esperanza condicional} \\\\ &amp; = &amp; 0 P( N = 0 ) + \\sum\\limits_{n=1}^{+\\infty} \\mathbb{E}\\left[ \\sum\\limits_{i=1}^n X_i\\ \\middle|\\ N = n \\right]P( N = n ) \\\\ &amp; = &amp; \\sum\\limits_{n=1}^{+\\infty} \\sum\\limits_{i=1}^n \\mathbb{E}\\left[ X_i \\mid N = n \\right]P( N = n )\\quad \\text{linealidad de la esperanza} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} n \\mathbb{E}\\left[ X \\mid N = n \\right]P( N = n )\\quad \\text{si $\\{X_i\\}$ son identicamente distribuidas} \\\\ &amp; = &amp; \\mathbb{E}\\left[ X \\right] \\sum\\limits_{n=0}^{+\\infty} n P( N = n )\\quad \\text{si $X$ y $N$ son independientes} \\\\ &amp; = &amp; \\mathbb{E}[ X ] \\mathbb{E}[ N ] \\end{eqnarray*}\\] La variable del reclamo total \\(S\\) puede ser simulada mediante el siguiente método montecarlo. Si \\(N\\) sigue una ley discreta \\(f_N\\) y cada valor severidad \\(X\\) son idénticamente distribuidos con ley \\(f_X\\). Seleccionar el número de simulaciones \\(m\\), Se genera una muestra de tamaño \\(m\\) de variables \\(N_1, \\ldots, N_m\\) con ley \\(f_N\\), Se genera para cada \\(i \\in \\{1,\\ldots,m\\}\\) una muestra de tamaño \\(N_i\\) de variables aleatorias \\(X_{i,1}, \\ldots X_{i,N_i}\\) con ley \\(f_X\\), Se calcula los reclamos totales \\(S_1, \\ldots, S_m\\) para cada simulación \\(i = \\{1, \\ldots, m\\}\\), mediante la siguiente suma \\(S_i = \\sum\\limits_{j=1}^{N_i} X_{i,j}\\). En el lenguaje de programación R, este método de simulación puede ser fácilmente implementado utilizando las funciones de aplicación vectorial sapply y lapply. Example 3.1 Para este ejemplo práctico en particular consideramos \\(N \\rightsquigarrow Pois( \\lambda )\\) y \\(X \\rightsquigarrow LN( \\mu, \\sigma )\\). m &lt;- 1e4 u &lt;- 5 s &lt;- 2 l &lt;- 3 N &lt;- rpois( n = m, lambda = l ) X &lt;- lapply( N, FUN = function( n ) rlnorm( n, meanlog = u, sdlog = s ) ) S &lt;- sapply( X, FUN = function( x ) sum( x, na.rm = TRUE ) ) plot( sort( S ) ) D &lt;- function( x, m, M ) { return( min( max( x - m, 0 ), M ) ) } m &lt;- 1000 n &lt;- 100 u &lt;- 5 s &lt;- 2 l &lt;- 5 N &lt;- rpois( n = m, lambda = l ) X &lt;- lapply( 1:m, FUN = function( i ) rlnorm( N[i], meanlog = u, sdlog = s ) ) DX &lt;- lapply( X, FUN = function( x ) sapply( x, FUN = function( y ) D( y, 10, 1000 ) ) ) S &lt;- sapply( X, FUN = function( x ) sum( x ) ) plot( sort( S ) ) \\(S_1, \\ldots, S_m \\rightsquigarrow F_S\\) FS &lt;- seq( 0, 1, 0.01 ) Sq &lt;- quantile( S, probs = FS ) ES &lt;- mean( S ) plot( Sq, FS, type = &#39;s&#39;, col = &#39;darkgreen&#39; ) abline( v = ES, col = &#39;red&#39; ) \\[\\begin{equation} \\mathbb{E}[ S ] = \\int_{\\mathbb{R}_+} f_S( x )\\ dx \\approx \\frac{1}{m} \\sum\\limits_{i=1}^m S_i \\end{equation}\\] Example 3.2 En este caso en particular estudiaremos la velocidad de convergencia del método resultante del teorema del límite central 2.2. Generaremos una simulación aleatoria de la suma agregada \\(S_n\\) y mostraresmo s m &lt;- 500 n &lt;- 5000 u &lt;- 4 s &lt;- 2 X &lt;- lapply( 1:m, FUN = function( j ) rlnorm( n, meanlog = u, sdlog = s ) ) EX &lt;- exp( u + 0.5 * s^2 ) SDX &lt;- sqrt( ( exp( s^2 ) - 1 ) * exp( 2 * u + s^2 ) ) S &lt;- lapply( X, FUN = function( x ) cumsum( x ) ) ES &lt;- sapply( 1:n, FUN = function( i ) mean( sapply( 1:m, FUN = function( j ) S[[ j ]][ i ] ) ) ) VS &lt;- sapply( 1:n, FUN = function( i ) var( sapply( 1:m, FUN = function( j ) S[[ j ]][ i ] ) ) ) NS &lt;- lapply( S, FUN = function( s ) ( s - ES ) / sqrt( abs( VS ) ) ) z &lt;- seq( -4, 4, length.out = 100 ) FSn &lt;- lapply( 1:n, FUN = function( i ) ecdf( sapply( 1:m, FUN = function( j ) NS[[ j ]][ i ] ) )( z ) ) D &lt;- sapply( FSn, FUN = function( Fn ) max( abs( Fn - pnorm( z ) ) ) ) C &lt;- 0.015 # C &lt;- 1 / sqrt( 2 * pi ) rho &lt;- exp( 3 * u + 3^2 * s^2 / 2 ) Bn &lt;- C * rho / ( SDX^3 * sqrt( 1:n ) ) plot( 1:n, D, pch = 16, cex = 0.5, type = &#39;l&#39;, lwd = 2, lty = 1, ylim = c( 0, 0.5 ), col = &#39;royalblue4&#39; ) points( 1:n, Bn, type = &#39;l&#39;, lty = 1, col = &#39;red&#39; ) l &lt;- 3 n &lt;- 300 dt &lt;- rexp( n = n, rate = 1 / l ) t &lt;- c( 0, cumsum( dt ) ) dN &lt;- sapply( dt, FUN = function( w ) rpois( 1, lambda = l * w ) ) N &lt;- c( 0, cumsum( dN ) ) sh &lt;- 3 rt &lt;- 2 X &lt;- lapply( dN, FUN = function( n ) rgamma( n, shape = sh, rate = rt ) ) dS &lt;- sapply( X, FUN = function( x ) sum( x ) ) S &lt;- c( 0, cumsum( dS ) ) plot( t, N, type = &#39;s&#39; ) plot( t, S, type = &#39;s&#39; ) 3.4 Medidas de riesgo Definition 2.4 (Medida de riesgo coherente) Una medida de riesgo coeherente es una función \\(\\zeta: \\mathbb{R} \\longrightarrow \\mathbb{R}\\), que satisface la siguientes propiedades: Homogenidad positiva, para cualquier \\(a &gt; 0\\) \\[\\begin{equation} \\zeta( a X ) = a \\zeta( X ) \\end{equation}\\] Invarianza ante las traslaciones, para cualquier \\(a &gt; 0\\) \\[\\begin{equation} \\zeta( \\alpha X + a ) = \\zeta( \\alpha X ) + a \\end{equation}\\] Monotonicidad, Si \\(X \\leq Y\\) \\[\\begin{equation} \\zeta( X ) \\leq \\zeta( Y ) \\end{equation}\\] Sub-aditividad \\[\\begin{equation} \\zeta( X + Y ) \\leq \\zeta( X ) + \\zeta( Y ) \\end{equation}\\] \\[\\begin{equation} VaR_{\\alpha}( X ) = F_X^{-1}( \\alpha ) \\end{equation}\\] \\[\\begin{equation} TVaR_{\\alpha}( X ) = \\frac{1}{1-\\alpha} \\int\\limits_{\\alpha}^1 VaR_u( X )\\ du \\end{equation}\\] u &lt;- 4 s &lt;- 0.5 n &lt;- 1e4 X &lt;- rlnorm( n, meanlog = u, sdlog = s ) k &lt;- seq( 0, 1, 0.2 ) VaRX &lt;- quantile( X, probs = k, names = FALSE ) TVaRX &lt;- sapply( 1:length( VaRX ), FUN = function( i ) ifelse( k[ i ] &lt; 1, ( 1 / ( 1 - k[ i ] ) ) * mean( X * ( X &gt; VaRX[ i ] ) ), max( X ) ) ) hist( X, breaks = 100, xlim = c( 0, 1.1 * max( X ) ) ) abline( v = VaRX, col = &#39;red&#39; ) hist( X, breaks = 100, xlim = c( 0, 1.1 * max( X ) ) ) abline( v = TVaRX, col = &#39;blue&#39; ) plot( k, VaRX, ylim = c( 0, 1e3 ) ) points( k, TVaRX, col = &#39;red&#39; ) "],["series-de-tiempo.html", "Capítulo 4 Series de tiempo 4.1 Familia de Panjer", " Capítulo 4 Series de tiempo 4.1 Familia de Panjer Definition 4.1 (Familia de Panjer) Una variable aleatoria discreta \\(N\\), que toma valores enteros positivos \\(N \\in \\mathbb{N}\\), se dice que pertenece a la familia de Panjer, si sus probabilidades \\(p_k = P( N = k )\\) para cada \\(k \\in \\mathbb{N}\\), satisfacen la siguiente relación de recurrencia. \\[\\begin{equation} p_k = \\left( a + \\frac{b}{k} \\right)p_{k-1},\\qquad \\forall k \\in \\mathbb{N} \\setminus \\{0\\} \\end{equation}\\] Además tenemos la siguiente proposición que caracteriza a la distribución de las variables aleatorias en la familia de Panjer. Proposition 4.1 (Caracterización familia de Panjer) Las únicas leyes de probabilidad que satisfacen la relación de recurrencia anterior son: La ley de Poisson, la cual se obtiene para \\(a = 0\\) y \\(b &gt; 0\\) La ley binomial negativa, la cual se obtiene para \\(0 &lt; a &lt; 1\\) y \\(a + b &gt; 0\\) La ley binomial, la cual se obtenida para \\(a &lt; 0\\) y \\(b = -a(m + 1)\\), para cierto \\(m\\) entero y positivo. Para una demostración detallada de la proposición anterior se puede consultar [4]. Bibliografía "],["tarificación.html", "Capítulo 5 Tarificación 5.1 Prima 5.2 Deducibles", " Capítulo 5 Tarificación 5.1 Prima La prima es la cantidad de dinero que un individuo o entidad pagan por una póliza de seguro, la cual está diseñada para cubrir ciertos riesgos personales o comerciales. \\[\\begin{equation} P = \\frac{S}{n} \\end{equation}\\] Prima neta, o prima pura de riesgo \\[\\begin{equation} P = \\mathbb{E}[S] \\end{equation}\\] Prima de riesgo con recargo sobre la esperanza \\[\\begin{equation} P = (1 + \\rho) \\mathbb{E}[S] \\end{equation}\\] Prima de riesgo con recargo sobre la varianza \\[\\begin{equation} P = \\mathbb{E}[S] + \\rho \\mathbb{V}[S] \\end{equation}\\] Prima de riesgo con recargo sobre la desviación \\[\\begin{equation} P = \\mathbb{E}[S] + \\rho \\sqrt{\\mathbb{V}[S]} \\end{equation}\\] Prima de riesgo con principio exponencial para \\(t &gt; 0\\) \\[\\begin{equation} P = \\frac{1}{2} \\mathbb{E}\\left[e^{tS}\\right] = \\frac{1}{2} M_N\\big( \\ln M_X( t ) \\big) \\end{equation}\\] Prima de percentiles para un valor de confianza \\(\\alpha \\in [0,1]\\) o prima de valor en riesgo \\(VaR_\\alpha\\) \\[\\begin{equation} P = VaR_\\alpha( S ) = F_S^{-1}( \\alpha ) \\end{equation}\\] Prima de valor en riesgo en la cola (Tail Value at Risk) \\(TVaR_\\alpha\\). Es el promedio uniforme de todos los valores en riesgo \\(VaR_u\\), con \\(u \\geq \\alpha\\). \\[\\begin{equation} P = TVaR_\\alpha( S ) = \\frac{1}{1-\\alpha} \\int\\limits_{\\alpha}^1 VaR_u( S )\\ du \\end{equation}\\] \\(X_i \\rightsquigarrow Gamma( \\alpha_i, \\theta )\\), para \\(i \\in \\{1,\\ldots,n\\}\\), \\(S \\rightsquigarrow Gamma\\left( \\sum\\limits_{i=1}^n \\alpha_i \\right)\\) n &lt;- 1000 a &lt;- runif( n, 5, 10 ) A &lt;- sum( a ) theta &lt;- 4 EX &lt;- a * theta VX &lt;- a * theta^2 ES &lt;- sum( EX ) VS &lt;- sum( VX ) SDS &lt;- sqrt( VS ) m &lt;- 1e5 S &lt;- rgamma( m, shape = A, scale = theta ) alpha &lt;- 0.95 P &lt;- ES P &lt;- mean( S ) P_avg &lt;- ( 1 + alpha ) * ES P_avg &lt;- ( 1 + alpha ) * mean( S ) P_var &lt;- ES + alpha * VS P_var &lt;- mean( S ) + alpha * var( S ) P_sde &lt;- ES + alpha * SDS P_sde &lt;- mean( S ) + alpha * sd( S ) VaRS &lt;- qgamma( alpha, shape = A, scale = theta ) P_VaR &lt;- VaRS P_VaR &lt;- quantile( S, probs = alpha ) P_TVaR &lt;- ( 1 / ( 1 - alpha ) ) * ( A * theta ) * ( 1 - pgamma( VaRS, shape = A + 1, scale = theta ) ) P_TVaR &lt;- ( 1 / ( 1 - alpha ) ) * integrate( f = function( u ) qgamma( u, shape = A, scale = theta ), alpha, 1 )$value P_TVaR &lt;- mean( sapply( runif( m, alpha, 1 ), FUN = function( k ) qgamma( k, shape = A, scale = theta ) ) ) I &lt;- as.numeric( S &gt; VaRS ) P_TVaR &lt;- mean( S * I ) / mean( I ) alph &lt;- 0.01 e &lt;- unlist( lapply( seq( 1, 6, 1 ), FUN = function( n ) seq( 9, 1, -0.2 ) * 10^{-n} ) ) n &lt;- log( 2 / alph ) / e^2 plot( e, n, type = &#39;l&#39;, xlim = c( 0, 0.00001 ) ) dt &lt;- data.table( e, n ) cat( paste( paste0( formatC( e, digits = 10, format = &#39;f&#39; ), &#39;, &#39;, formatC( n, digits = 30, format = &#39;f&#39; ) ), collapse = &#39;\\n&#39; ) ) ## 0.9000000000, 6.541132551293871166819826612482 ## 0.8800000000, 6.841835442339920803078712197021 ## 0.8600000000, 7.163760636219627997434145072475 ## 0.8400000000, 7.508953183883270376952623337274 ## 0.8200000000, 7.879710539185063922218432708178 ## 0.8000000000, 8.278620885231305237539345398545 ## 0.7800000000, 8.708608426278823699817621672992 ## 0.7600000000, 9.172987130450200865539045480546 ## 0.7400000000, 9.675524774558134311064350185916 ## 0.7200000000, 10.220519611396673198555618000682 ## 0.7000000000, 10.812892584791908845431862573605 ## 0.6800000000, 11.458298803088311501596763264388 ## 0.6600000000, 12.163263008604305426274549972732 ## 0.6400000000, 12.935345133173910880941548384726 ## 0.6200000000, 13.783343825567211382576715550385 ## 0.6000000000, 14.717548240411208126943165552802 ## 0.5800000000, 15.750051624696897789590366301127 ## 0.5600000000, 16.895144663737365675615365034901 ## 0.5400000000, 18.169812642482977338431737734936 ## 0.5200000000, 19.594368959127358209570957114920 ## 0.5000000000, 21.193269466192145245031497324817 ## 0.4800000000, 22.996169125642520469909868552350 ## 0.4600000000, 25.039307025274279538962218794040 ## 0.4400000000, 27.367341769359697423169563990086 ## 0.4200000000, 30.035812735533095718665208551101 ## 0.4000000000, 33.114483540925220950157381594181 ## 0.3800000000, 36.691948521800803462156181922182 ## 0.3600000000, 40.882078445586699899649829603732 ## 0.3400000000, 45.833195212353260217241768259555 ## 0.3200000000, 51.741380532695686156330339144915 ## 0.3000000000, 58.870192961644832507772662211210 ## 0.2800000000, 67.580578654949462702461460139602 ## 0.2600000000, 78.377475836509432838283828459680 ## 0.2400000000, 91.984676502570096090494189411402 ## 0.2200000000, 109.469367077438818114387686364353 ## 0.2000000000, 132.457934163700883800629526376724 ## 0.1800000000, 163.528313782346799598599318414927 ## 0.1600000000, 206.965522130782744625321356579661 ## 0.1400000000, 270.322314619797907653264701366425 ## 0.1200000000, 367.938706010280668579071061685681 ## 0.1000000000, 529.831736654803535202518105506897 ## 0.0900000000, 654.113255129387198394397273659706 ## 0.0880000000, 684.183544233992165572999510914087 ## 0.0860000000, 716.376063621962885008542798459530 ## 0.0840000000, 750.895318388327041247976012527943 ## 0.0820000000, 787.971053918506527224963065236807 ## 0.0800000000, 827.862088523130637440772261470556 ## 0.0780000000, 870.860842627882334454625379294157 ## 0.0760000000, 917.298713045020122081041336059570 ## 0.0740000000, 967.552477455813459528144448995590 ## 0.0720000000, 1022.051961139667241695860866457224 ## 0.0700000000, 1081.289258479190948492032475769520 ## 0.0680000000, 1145.829880308831207003095187246799 ## 0.0660000000, 1216.326300860430592365446500480175 ## 0.0640000000, 1293.534513317391656528343446552753 ## 0.0620000000, 1378.334382556721493529039435088634 ## 0.0600000000, 1471.754824041121310074231587350368 ## 0.0580000000, 1575.005162469690048965276218950748 ## 0.0560000000, 1689.514466373736468085553497076035 ## 0.0540000000, 1816.981264248297293306677602231503 ## 0.0520000000, 1959.436895912736190439318306744099 ## 0.0500000000, 2119.326946619214140810072422027588 ## 0.0480000000, 2299.616912564251833828166127204895 ## 0.0460000000, 2503.930702527427456516306847333908 ## 0.0440000000, 2736.734176935969571786699816584587 ## 0.0420000000, 3003.581273553309074486605823040009 ## 0.0400000000, 3311.448354092522549763089045882225 ## 0.0380000000, 3669.194852180080488324165344238281 ## 0.0360000000, 4088.207844558670331025496125221252 ## 0.0340000000, 4583.319521235326647001784294843674 ## 0.0320000000, 5174.138053269569354597479104995728 ## 0.0300000000, 5887.019296164485240296926349401474 ## 0.0280000000, 6758.057865494945872342213988304138 ## 0.0260000000, 7837.747583650944761757273226976395 ## 0.0240000000, 9198.467650257012792280875146389008 ## 0.0220000000, 10946.936707743885563104413449764252 ## 0.0200000000, 13245.793416370090199052356183528900 ## 0.0180000000, 16352.831378234681324101984500885010 ## 0.0160000000, 20696.552213078277418389916419982910 ## 0.0140000000, 27032.231461979798041284084320068359 ## 0.0120000000, 36793.870601028072996996343135833740 ## 0.0100000000, 52983.173665480360796209424734115601 ## 0.0090000000, 65411.325512938703468535095453262329 ## 0.0088000000, 68418.354423399228835478425025939941 ## 0.0086000000, 71637.606362196267582476139068603516 ## 0.0084000000, 75089.531838832699577324092388153076 ## 0.0082000000, 78797.105391850651358254253864288330 ## 0.0080000000, 82786.208852313066017813980579376221 ## 0.0078000000, 87086.084262788252090103924274444580 ## 0.0076000000, 91729.871304502012208104133605957031 ## 0.0074000000, 96755.247745581378694623708724975586 ## 0.0072000000, 102205.196113966725533828139305114746 ## 0.0070000000, 108128.925847919090301729738712310791 ## 0.0068000000, 114582.988030883148894645273685455322 ## 0.0066000000, 121632.630086043078335933387279510498 ## 0.0064000000, 129353.451331739168381318449974060059 ## 0.0062000000, 137833.438255672139348462224006652832 ## 0.0060000000, 147175.482404112117365002632141113281 ## 0.0058000000, 157500.516246968996711075305938720703 ## 0.0056000000, 168951.446637373621342703700065612793 ## 0.0054000000, 181698.126424829766619950532913208008 ## 0.0052000000, 195943.689591273549012839794158935547 ## 0.0050000000, 211932.694661921443184837698936462402 ## 0.0048000000, 229961.691256425227038562297821044922 ## 0.0046000000, 250393.070252742734737694263458251953 ## 0.0044000000, 273673.417693596973549574613571166992 ## 0.0042000000, 300358.127355330914724618196487426758 ## 0.0040000000, 331144.835409252264071255922317504883 ## 0.0038000000, 366919.485218008048832416534423828125 ## 0.0036000000, 408820.784455867018550634384155273438 ## 0.0034000000, 458331.952123532711993902921676635742 ## 0.0032000000, 517413.805326956906355917453765869141 ## 0.0030000000, 588701.929616448469460010528564453125 ## 0.0028000000, 675805.786549494485370814800262451172 ## 0.0026000000, 783774.758365094196051359176635742188 ## 0.0024000000, 919846.765025701257400214672088623047 ## 0.0022000000, 1094693.670774388359859585762023925781 ## 0.0020000000, 1324579.341637009056285023689270019531 ## 0.0018000000, 1635283.137823468074202537536621093750 ## 0.0016000000, 2069655.221307827625423669815063476562 ## 0.0014000000, 2703223.146197979804128408432006835938 ## 0.0012000000, 3679387.060102807357907295227050781250 ## 0.0010000000, 5298317.366548036225140094757080078125 ## 0.0009000000, 6541132.551293870434165000915527343750 ## 0.0008800000, 6841835.442339920438826084136962890625 ## 0.0008600000, 7163760.636219627223908901214599609375 ## 0.0008400000, 7508953.183883270248770713806152343750 ## 0.0008200000, 7879710.539185062982141971588134765625 ## 0.0008000000, 8278620.885231306776404380798339843750 ## 0.0007800000, 8708608.426278823986649513244628906250 ## 0.0007600000, 9172987.130450200289487838745117187500 ## 0.0007400000, 9675524.774558134377002716064453125000 ## 0.0007200000, 10220519.611396674066781997680664062500 ## 0.0007000000, 10812892.584791911765933036804199218750 ## 0.0006800000, 11458298.803088312968611717224121093750 ## 0.0006600000, 12163263.008604306727647781372070312500 ## 0.0006400000, 12935345.133173914626240730285644531250 ## 0.0006200000, 13783343.825567213818430900573730468750 ## 0.0006000000, 14717548.240411210805177688598632812500 ## 0.0005800000, 15750051.624696897342801094055175781250 ## 0.0005600000, 16895144.663737364113330841064453125000 ## 0.0005400000, 18169812.642482969909906387329101562500 ## 0.0005200000, 19594368.959127359092235565185546875000 ## 0.0005000000, 21193269.466192144900560379028320312500 ## 0.0004800000, 22996169.125642519444227218627929687500 ## 0.0004600000, 25039307.025274276733398437500000000000 ## 0.0004400000, 27367341.769359696656465530395507812500 ## 0.0004200000, 30035812.735533092170953750610351562500 ## 0.0004000000, 33114483.540925227105617523193359375000 ## 0.0003800000, 36691948.521800801157951354980468750000 ## 0.0003600000, 40882078.445586711168289184570312500000 ## 0.0003400000, 45833195.212353266775608062744140625000 ## 0.0003200000, 51741380.532695688307285308837890625000 ## 0.0003000000, 58870192.961644843220710754394531250000 ## 0.0002800000, 67580578.654949456453323364257812500000 ## 0.0002600000, 78377475.836509436368942260742187500000 ## 0.0002400000, 91984676.502570107579231262207031250000 ## 0.0002200000, 109469367.077438831329345703125000000000 ## 0.0002000000, 132457934.163700908422470092773437500000 ## 0.0001800000, 163528313.782346844673156738281250000000 ## 0.0001600000, 206965522.130782753229141235351562500000 ## 0.0001400000, 270322314.619797885417938232421875000000 ## 0.0001200000, 367938706.010280668735504150390625000000 ## 0.0001000000, 529831736.654803633689880371093750000000 ## 0.0000900000, 654113255.129387140274047851562500000000 ## 0.0000880000, 684183544.233992218971252441406250000000 ## 0.0000860000, 716376063.621962666511535644531250000000 ## 0.0000840000, 750895318.388327002525329589843750000000 ## 0.0000820000, 787971053.918506264686584472656250000000 ## 0.0000800000, 827862088.523130536079406738281250000000 ## 0.0000780000, 870860842.627882361412048339843750000000 ## 0.0000760000, 917298713.045019984245300292968750000000 ## 0.0000740000, 967552477.455813527107238769531250000000 ## 0.0000720000, 1022051961.139667391777038574218750000000 ## 0.0000700000, 1081289258.479190826416015625000000000000 ## 0.0000680000, 1145829880.308831453323364257812500000000 ## 0.0000660000, 1216326300.860430717468261718750000000000 ## 0.0000640000, 1293534513.317391157150268554687500000000 ## 0.0000620000, 1378334382.556720972061157226562500000000 ## 0.0000600000, 1471754824.041120767593383789062500000000 ## 0.0000580000, 1575005162.469689846038818359375000000000 ## 0.0000560000, 1689514466.373736143112182617187500000000 ## 0.0000540000, 1816981264.248297452926635742187500000000 ## 0.0000520000, 1959436895.912735462188720703125000000000 ## 0.0000500000, 2119326946.619214534759521484375000000000 ## 0.0000480000, 2299616912.564251422882080078125000000000 ## 0.0000460000, 2503930702.527427196502685546875000000000 ## 0.0000440000, 2736734176.935969352722167968750000000000 ## 0.0000420000, 3003581273.553308963775634765625000000000 ## 0.0000400000, 3311448354.092522144317626953125000000000 ## 0.0000380000, 3669194852.180079936981201171875000000000 ## 0.0000360000, 4088207844.558669567108154296875000000000 ## 0.0000340000, 4583319521.235325813293457031250000000000 ## 0.0000320000, 5174138053.269566535949707031250000000000 ## 0.0000300000, 5887019296.164483070373535156250000000000 ## 0.0000280000, 6758057865.494944572448730468750000000000 ## 0.0000260000, 7837747583.650941848754882812500000000000 ## 0.0000240000, 9198467650.257009506225585937500000000000 ## 0.0000220000, 10946936707.743881225585937500000000000000 ## 0.0000200000, 13245793416.370088577270507812500000000000 ## 0.0000180000, 16352831378.234678268432617187500000000000 ## 0.0000160000, 20696552213.078266143798828125000000000000 ## 0.0000140000, 27032231461.979793548583984375000000000000 ## 0.0000120000, 36793870601.028068542480468750000000000000 ## 0.0000100000, 52983173665.480354309082031250000000000000 ## 0.0000090000, 65411325512.938713073730468750000000000000 ## 0.0000088000, 68418354423.399223327636718750000000000000 ## 0.0000086000, 71637606362.196289062500000000000000000000 ## 0.0000084000, 75089531838.832733154296875000000000000000 ## 0.0000082000, 78797105391.850631713867187500000000000000 ## 0.0000080000, 82786208852.313064575195312500000000000000 ## 0.0000078000, 87086084262.788238525390625000000000000000 ## 0.0000076000, 91729871304.502029418945312500000000000000 ## 0.0000074000, 96755247745.581359863281250000000000000000 ## 0.0000072000, 102205196113.966766357421875000000000000000 ## 0.0000070000, 108128925847.919113159179687500000000000000 ## 0.0000068000, 114582988030.883163452148437500000000000000 ## 0.0000066000, 121632630086.043090820312500000000000000000 ## 0.0000064000, 129353451331.739181518554687500000000000000 ## 0.0000062000, 137833438255.672180175781250000000000000000 ## 0.0000060000, 147175482404.112091064453125000000000000000 ## 0.0000058000, 157500516246.968994140625000000000000000000 ## 0.0000056000, 168951446637.373626708984375000000000000000 ## 0.0000054000, 181698126424.829772949218750000000000000000 ## 0.0000052000, 195943689591.273559570312500000000000000000 ## 0.0000050000, 211932694661.921508789062500000000000000000 ## 0.0000048000, 229961691256.425201416015625000000000000000 ## 0.0000046000, 250393070252.742828369140625000000000000000 ## 0.0000044000, 273673417693.596984863281250000000000000000 ## 0.0000042000, 300358127355.330993652343750000000000000000 ## 0.0000040000, 331144835409.252258300781250000000000000000 ## 0.0000038000, 366919485218.008117675781250000000000000000 ## 0.0000036000, 408820784455.867126464843750000000000000000 ## 0.0000034000, 458331952123.532714843750000000000000000000 ## 0.0000032000, 517413805326.956970214843750000000000000000 ## 0.0000030000, 588701929616.448364257812500000000000000000 ## 0.0000028000, 675805786549.494506835937500000000000000000 ## 0.0000026000, 783774758365.094238281250000000000000000000 ## 0.0000024000, 919846765025.701171875000000000000000000000 ## 0.0000022000, 1094693670774.388305664062500000000000000000 ## 0.0000020000, 1324579341637.009033203125000000000000000000 ## 0.0000018000, 1635283137823.468505859375000000000000000000 ## 0.0000016000, 2069655221307.827880859375000000000000000000 ## 0.0000014000, 2703223146197.980468750000000000000000000000 ## 0.0000012000, 3679387060102.807128906250000000000000000000 ## 0.0000010000, 5298317366548.036132812500000000000000000000 d &lt;- n * 8 / 1024^2 n &lt;- 1e3 S &lt;- rgamma( n, shape = A, scale = theta ) smin &lt;- qgamma( 0.001, shape = A, scale = theta ) smax &lt;- qgamma( 0.999, shape = A, scale = theta ) s &lt;- seq( smin, smax, length.out = 1000 ) Fns &lt;- ecdf( S )( s ) Fs &lt;- pgamma( s, shape = A, scale = theta ) alph &lt;- 0.02 er &lt;- sqrt( log( 2 / alph ) / ( 2 * n ) ) abs( Fs - Fns ) &gt; er ## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [20] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [39] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [58] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [77] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [96] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [115] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [134] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [153] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [172] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [191] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [210] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [229] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [248] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [267] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [286] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [305] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [324] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [343] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [362] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [381] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [400] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [419] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [438] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [457] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [476] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [495] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [514] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [533] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [552] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [571] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [590] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [609] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [628] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [647] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [666] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [685] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [704] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [723] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [742] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [761] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [780] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [799] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [818] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [837] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [856] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [875] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [894] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [913] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [932] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [951] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [970] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [989] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE plot( s, Fs, type = &#39;l&#39;, ylim = c( -er, 1 + er ) ) points( s, Fns - er, col = &#39;red&#39;, type = &#39;l&#39; ) points( s, Fns + er, col = &#39;red&#39;, type = &#39;l&#39; ) hist( pgamma( S, shape = A, scale = theta ), breaks = 5 ) 5.2 Deducibles El principal objetivo de los deducibles, es el reducir los costos de atención de los reclamos usualmente mediante la exclusión de siniestros usualmente numerosos debidos a reclamos pequeños. En otras ocasiones, los deducibles están diseñados para incentivar al asegurado para evitar y prevenir siniestros por cierto monto límite. Prevención de la pérdida - as the compensation is reduced by a deductible the retention of the insured is positive; This makes out a good case for avoiding the loss; Reducción de la pérdida - the fact a deductible puts the policyholder at risk of obtaining only partial compensation provides an economic incentive to reduce the extend of the damage; Evitar pequeñas pérdidas - where administration costs are dominant for small losses, the administration costs will often exceed the loss itself, and hence the insurance company would want the policyholder to pay it himself; Reducción de la prima - premium reduction can be an important aspect for the policyholders, they may prefer to take a higher deductible to get a lower premium. n &lt;- 1e5 l &lt;- 3 dat &lt;- data.table( id = 1:n, k = rpois( n, lambda = l ) ) datf &lt;- dat[ , list( fk = .N ), by = k ] setorder( datf, k ) datf[ , fks := shift( fk, n = 1 ) ] datf[ , gk := k * fk / fks ] datf &lt;- datf[ !is.na( gk ) ] plot( datf$k, datf$gk ) dflm &lt;- lm( formula = gk ~ k, data = datf, method = &#39;qr&#39; ) a &lt;- coef( dflm )[ 2 ] b &lt;- coef( dflm )[ 1 ] p0 &lt;- exp( -b ) k &lt;- seq( 1, 100, 1 ) p &lt;- p0 * cumprod( c( 1, a + b / k ) ) sum( p ) ## [1] 1.106565 k &lt;- seq( 0, 100, 1 ) sum( dpois( k, lambda = l ) ) ## [1] 1 EN &lt;- sum( k * p ) D &lt;- function( x, d ) return( max( x - d, 0 ) ) d &lt;- 100 u &lt;- 6 s &lt;- 0.3 n &lt;- 1e3 X &lt;- rlnorm( n, meanlog = u, sdlog = s ) DX &lt;- sapply( X, FUN = D, d ) x &lt;- seq( 0, 1e3, length.out = 500 ) FXe &lt;- ecdf( X ) FDXe &lt;- ecdf( DX ) Fx &lt;- sapply( x, FUN = function( x ) FXe( x ) ) FDx &lt;- sapply( x, FUN = function( x ) FDXe( x ) ) plot( x, Fx, type = &#39;s&#39; ) points( x, FDx, type = &#39;s&#39;, col = &#39;blue&#39; ) D &lt;- function( x, M ) return( min( x, M ) ) M &lt;- 600 u &lt;- 6 s &lt;- 0.3 n &lt;- 1e4 X &lt;- rlnorm( n, meanlog = u, sdlog = s ) DX &lt;- sapply( X, FUN = D, M ) x &lt;- seq( 0, 1e3, length.out = 500 ) FXe &lt;- ecdf( X ) FDXe &lt;- ecdf( DX ) Fx &lt;- sapply( x, FUN = function( x ) FXe( x ) ) FDx &lt;- sapply( x, FUN = function( x ) FDXe( x ) ) plot( x, Fx, type = &#39;s&#39; ) points( x, FDx, type = &#39;s&#39;, col = &#39;blue&#39; ) "],["modelos-lineales-generalizados-glm.html", "Capítulo 6 Modelos lineales generalizados (GLM) 6.1 Familia exponencial 6.2 Modelo lineal generalizado (GLM)", " Capítulo 6 Modelos lineales generalizados (GLM) 6.1 Familia exponencial De forma amplia, un modelo lineal generalizado aprovecha algunas propiedades de la distribución de probabilidad \\(f_X\\) de la variable (vector) aleatoria \\(X : \\Omega \\longrightarrow \\mathbb{R}^n\\) en estudio. Se parte de asumir que \\(X\\) tiene una distribución dentro de la familia exponencial, es decir, existen: Un conjunto admisible de parámetros \\(\\Theta \\subset \\mathbb{R}^m\\), así cada parámetro \\(\\theta = ( \\theta_1, \\ldots, \\theta_m )^T \\in \\Theta\\), Una función \\(T: \\mathbb{R}^n \\longrightarrow \\mathbb{R}^p\\) Una función \\(A: \\mathbb{R}^m \\longrightarrow \\mathbb{R}\\) Una función \\(\\eta: \\mathbb{R}^m \\longrightarrow \\mathbb{R}^p\\) de tal forma que: \\[\\begin{equation} f_X( x \\mid \\theta ) = h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right) \\end{equation}\\] Al tener varias observaciones independientes de la misma variable aleatoria \\(x_1, \\ldots, x_N\\), su distribución conjunta se puede expresar como: \\[\\begin{equation} f_{X_1,\\ldots,X_N}( x_1, \\ldots, x_N \\mid \\theta ) = \\prod\\limits_{i=1}^N f_{X_i}( x_i \\mid \\theta ) \\end{equation}\\] La función de verosimilitud logarítmica, “log-likelihood”, toma una forma específica, la cual puede ser trabajada con comodidad para la maximización de verosimilitud. \\[\\begin{eqnarray*} \\ell( \\theta ) &amp; = &amp; \\log f_{X_1,\\ldots,X_N}( x_1, \\ldots, x_N \\mid \\theta ) \\\\ &amp; = &amp; \\sum\\limits_{i=1}^N \\log f_{X_i}( x_i \\mid \\theta ) \\\\ &amp; = &amp; \\sum\\limits_{i=1}^N \\left( \\log h( x_i ) + \\eta( \\theta ) \\cdot T( x_i ) - A( \\theta ) \\right) \\end{eqnarray*}\\] lo que podemos observar es que existe una casi linealidad respecto de la variable \\(\\theta\\). Esta propiedad permite obtener un problema de maximización de verosimilitud que puede ser atacado con varios paquetes de optimización numérica de una forma eficiente. \\[\\begin{equation} \\underset{\\theta \\in \\Theta}{\\sup} \\ell( \\theta ) = \\underset{\\theta \\in \\Theta}{\\sup} \\sum\\limits_{i=1}^N \\left( \\eta( \\theta ) \\cdot T( x_i ) - A( \\theta ) \\right) \\end{equation}\\] Usualmente, este problema se suele atacar mediante la anulación del gradiente de la función objetivo, esto lo realiza la mayor parte de paquetes de software. El sistema a resolver es el siguiente sistema, usualmente no lineal, de dimensión \\(m\\): \\[\\begin{equation} \\frac{\\partial \\ell}{\\partial \\theta_i}( \\theta ) = \\sum\\limits_{i=1}^N \\left( \\frac{\\partial \\eta}{\\partial \\theta_i}( \\theta ) \\cdot T( x_i ) - \\frac{\\partial A}{\\partial \\theta_i}( \\theta ) \\right) = 0,\\qquad \\forall i \\in \\{1,\\ldots, m\\} \\end{equation}\\] En la familia exponential tenemos las siguientes distribuciones: normal, exponencial, log-normal, gamma, chi-cuadrado, beta, Dirichlet, Bernoulli, Poisson, binomial, geométrica, binomial negativa, von Mises-Fisher, Pareto con valor mínimo conocido, Gaussiana inversa, gamma inversa, multinomial con número \\(n\\) conocido, Wishart, categórica. Por la condición de normalización de la densidad de probabilidad \\(f_X\\), se satisface la igualdad: \\[\\begin{eqnarray*} 1 &amp; = &amp; \\int\\limits f_X( x \\mid \\theta )\\ dx \\\\ 1 &amp; = &amp; \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right)\\ dx \\\\ 1 &amp; = &amp; \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) \\right) \\exp\\left( - A( \\theta ) \\right)\\ dx \\\\ 1 &amp; = &amp; \\exp\\left( - A( \\theta ) \\right) \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) \\right)\\ dx \\\\ \\exp\\left( A( \\theta ) \\right) &amp; = &amp; \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) \\right)\\ dx \\\\ A( \\theta ) &amp; = &amp; \\log\\left( \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) \\right)\\ dx \\right) \\end{eqnarray*}\\] de donde se determina precisamente la forma que tiene la función \\(A\\) y su el papel como factor de normalización para la distribución de la variable aleatoria \\(X\\). Así mismo, podemos establecer una cierta relación para la espera de los valores observados de \\(T(X)\\) en función de \\(A\\) \\[\\begin{eqnarray*} 0 &amp; = &amp; \\frac{\\partial}{\\partial \\theta_i} 1 \\\\ 0 &amp; = &amp; \\frac{\\partial}{\\partial \\theta_i} \\int\\limits f_X( x \\mid \\theta )\\ dx \\\\ 0 &amp; = &amp; \\int\\limits h( x ) \\frac{\\partial}{\\partial \\theta_i} \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right)\\ dx \\\\ 0 &amp; = &amp; \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right) \\left( \\frac{\\partial \\eta}{\\partial \\theta_i}( \\theta ) \\cdot T( x ) - \\frac{\\partial A}{\\partial \\theta_i}( \\theta ) \\right)\\ dx \\\\ 0 &amp; = &amp; \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right) \\frac{\\partial \\eta}{\\partial \\theta_i}( \\theta ) \\cdot T( x )\\ dx \\\\ &amp; &amp; - \\frac{\\partial A}{\\partial \\theta_i} ( \\theta ) \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right)\\ dx \\\\ 0 &amp; = &amp; \\int \\limits \\frac{\\partial \\eta}{\\partial \\theta_i}( \\theta ) \\cdot T( x ) f_X( x \\mid \\theta )\\ dx - \\frac{\\partial A}{\\partial \\theta_i}( \\theta ) \\int \\limits f_X( x \\mid \\theta )\\ dx \\end{eqnarray*}\\] estamos en la capacidad de concluir que: \\[\\begin{equation} \\mathbb{E}\\left[ \\frac{\\partial \\eta}{\\partial \\theta_i}( \\theta ) \\cdot T( X ) \\right] = \\frac{\\partial A}{\\partial \\theta_i}( \\theta ) \\end{equation}\\] Cuando se da el caso que \\(\\eta\\) y \\(T\\) son las funciones identidad, la relación anterior se reduce a la siguiente igualdad: \\[\\begin{equation} \\mathbb{E}\\left[ X_i \\right] = \\frac{\\partial A}{\\partial \\theta_i}( \\theta ) \\end{equation}\\] 6.2 Modelo lineal generalizado (GLM) Precisamente, un modelo lineal generalizado (GLM por sus siglas en inglés) busca explotar las propiedades de las variables aleatorias que poseen una densidad de probabilidad dada por alguna de la funciones de la familia exponencial. Para más detalles se puede consultar [9]. La idea general es poder describir el comportamiento de una variable aleatoria \\(Y\\) que se presume puede ser descrita por alguna función de la familia exponencial, a partir de otras variables aleatorias \\(X : \\Omega \\longrightarrow \\mathbb{R}^n\\) mediante una función de vínculo \\(g: \\mathbb{R}^q \\longrightarrow \\mathbb{R}^m\\) entre \\(\\theta\\) y \\(X\\), a través del paso por una composición con una función lineal \\(\\beta : \\mathbb{R}^n \\longrightarrow \\mathbb{R}^q\\), de tal forma que: \\[\\begin{equation} \\theta = g( \\beta( X ) ) = g( \\beta X ) \\end{equation}\\] Así, un GLM prescribe una distribución de probabilidad para \\(Y\\) que tendrá la siguiente forma y será dependiente de los parámetros \\(\\beta\\) y las variables explicativas \\(X\\) \\[\\begin{equation} f_Y( y \\mid \\theta ) = f_Y( y \\mid g( \\beta x ) ) = h( y ) \\exp\\left( \\eta( g( \\beta x ) ) \\cdot T( y ) - A( g( \\beta x ) ) \\right) \\end{equation}\\] En la aplicación, el ajuste de un modelo GLM a \\(N \\in \\mathbb{N}\\) observaciones \\(y_1, \\ldots, y_N\\) de la variable aleatoria \\(Y\\) y sus respectivas variables explicativas \\(x_1, \\ldots, x_N\\). Se asume independencias entre las observaciones y se busca maximizar la verosimilitud de los valores observados, pero en función del nuevo parámetro \\(\\beta\\), de ahí la parte lineal del modelo. \\[\\begin{equation} \\ell( \\beta ) = \\sum\\limits_{i=1}^N \\left( \\log h( y_i ) + \\eta( g( \\beta x_i ) ) \\cdot T( y_i ) - A( g( \\beta x_i ) \\right) \\end{equation}\\] En varias ocasiones no todos los parámetros \\(\\theta\\) de la densidad de probabilidad son considerados, sino tan solo una parte de los mismos, los otros parámetros se consideran como un valor constante ya dado o también como un parámetro a determinar. Así, se divide \\(\\theta = ( \\theta_1, \\theta_2 ), \\theta_1 \\in \\mathbb{R}^{m_1}, \\theta_2 \\in \\mathbb{R}^{m_2}, m = m_1 + m_2\\), donde solo se establece una función de vínculo para la primera parte \\(\\theta_1 = g( \\beta X )\\). Esta consideración en muchos casos ayuda a simplificar la formulación del modelo y el costo computacional de estimación. En este contexto la función de verosimilitud tomaría la forma: \\[\\begin{equation} \\ell( \\beta, \\theta_2 ) = \\sum\\limits_{i=1}^N \\left( \\log h( y_i ) + \\eta( g( \\beta x_i ), \\theta_2 ) \\cdot T( y_i ) - A( g( \\beta x_i ), \\theta_2 ) \\right) \\end{equation}\\] Bibliografía "],["estimación-de-valores-extremos.html", "Capítulo 7 Estimación de valores extremos", " Capítulo 7 Estimación de valores extremos "],["teoría-de-la-ruina.html", "Capítulo 8 Teoría de la Ruina", " Capítulo 8 Teoría de la Ruina "],["bibliografía.html", "Capítulo 9 Bibliografía", " Capítulo 9 Bibliografía "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
