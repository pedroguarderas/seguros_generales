[["introducción.html", "Matemática Actuarial de los Seguros Generales Capítulo 1 Introducción 1.1 Materia 1.2 Resultados de aprendizaje 1.3 Contenidos propuestos", " Matemática Actuarial de los Seguros Generales 2025-04-03 Capítulo 1 Introducción 1.1 Materia Matemática Actuarial de los Seguros Generales 1.2 Resultados de aprendizaje Contrastar los criterios de valoración actuarial en los seguros generales, así como elaborar y aplicar las bases técnicas. Aprender a obtener la distribución y momentos correspondientes de la siniestralidad total pagada por el asegurador y por el reasegurador en presencia de franquicias y reaseguro. Identificar las modificaciones que pueden sufrir los contratos de seguros generales y valorar las consecuencias técnicas de dichas modificaciones. Calcular la función de distribución del coste total de una cartera de pólizas. 1.3 Contenidos propuestos Distribuciones compuestas Series de tiempo El Proceso de Riesgo: Distribución clase (a,b) y algoritmo de Panjer, Distribución de siniestralidad agregada Modelos Lineales Generalizados (GLMs): para datos binarios y recuentos Proceso de Tarificación Tarificación a priori: cálculo de la prima pura Tarificación a posteriori: sistemas Bonus-Malus Teoría de la Ruina En cuanto a las referencias utilizaremos los siguientes libros guía, [1], [2], [3], [4], [5], https://nonlifemaths.github.io/. Utilizaremos algunos otras referencias de soporte, que serán de utilidad para quien desee profundizar con más detalle en algunos conceptos [6], [7], [8], [9], [10], [11]. En cuanto a la parte computacional, haremos uso del paquete para R, [12]. GIL FANA: Elementos de Matemáticas para las Ciencias del Seguro. Fundación Mapfre Estudios. 1991 Bibliografía "],["consideraciones-preliminares.html", "Capítulo 2 Consideraciones preliminares 2.1 Consideraciones de matemáticas 2.2 Consideraciones de programación en R 2.3 Consideraciones de probabilidades 2.4 Desigualdades de concentración 2.5 Consideraciones estadísticas 2.6 Consideraciones financieras", " Capítulo 2 Consideraciones preliminares 2.1 Consideraciones de matemáticas Utilizaremos alguna notación matemática a lo largo de estas notas: \\(\\mathbb{N}\\) conjunto de los números naturales \\(\\mathbb{N} = \\{0,1,\\ldots,\\}\\), \\(\\mathbb{R}\\) conjunto de los números reales, \\(\\overline{\\mathbb{R}} = \\mathbb{R} \\cup \\{ +\\infty \\} \\cup \\{ -\\infty \\}\\) el conjunto de los reales más los infinitos, \\(&lt;\\) símbolo de menor que, \\(&gt;\\) símbolo de mayor que, \\(\\leq\\) símbolo de menor o igual que, \\(\\geq\\) símbolo de mayor o igual que, \\(f: X \\longrightarrow Y\\) denota la función que toma valores en \\(X\\) y entrega valores en \\(Y\\), \\(\\sum\\limits_{k=0}^n x_k\\) suma de valores de una lista \\(x_0,\\ldots,x_n\\), \\([ a, b ] = \\left\\{ x \\in \\mathbb{R} \\middle| x \\geq a, x \\leq b \\right\\}\\) intervalo cerrado para cualquier \\(a,b \\in \\overline{\\mathbb{R}}\\), \\((a,b) = \\left\\{ x \\in \\mathbb{R} \\middle| x \\geq a, x \\leq b \\right\\}\\) intervalo abierto para cualquier \\(a,b \\in \\overline{\\mathbb{R}}\\), \\(\\{x_n\\}_{n\\in\\mathbb{N}} = \\left\\{ x_n \\in X \\middle| n \\in \\mathbb{N} \\right\\}\\) secuencia en el conjunto \\(X\\), no es más que una función de \\(\\mathbb{N}\\) con valores en \\(X\\), \\(\\underset{x \\rightarrow y}{\\lim} f(x) = a\\) noción de límite, 2.2 Consideraciones de programación en R En el transcurso del presente curso utilizaremos algunos paquetes de R, acá la lista de carga de los mismos library( actuar ) library( data.table ) library( fExtremes ) library( fitdistrplus ) library( ggplot2 ) library( googledrive ) library( kableExtra ) library( knitr ) library( latex2exp ) library( lubridate ) library( openxlsx ) library( readxl ) library( rmarkdown ) library( shiny ) library( wesanderson ) options( scipen = 9999 ) options( stringsAsFactors = FALSE ) Para definir una variable utilizamos el operador de asignación &lt;-, también se puede utilizar =. Un vector se define con la función de concatenación c x &lt;- c( 1, 2, 3 ) print( x ) ## [1] 1 2 3 Un función se define con la sentencia function f &lt;- function( t ) { return( t^2 ) } Si buscamos aplicar una función sobre un vector, podemos utilizar sapply y &lt;- sapply( x, FUN = f ) print( y ) ## [1] 1 4 9 z &lt;- lapply( x, FUN = f ) print( z ) ## [[1]] ## [1] 1 ## ## [[2]] ## [1] 4 ## ## [[3]] ## [1] 9 Para muchas tareas que están relacionadas con el manejo de datos, podemos utilizar las funcionalidades del paquete de R, data.table. Para trabajar con fechas recomendamos utilizar el paquete lubridate. 2.3 Consideraciones de probabilidades Definición 2.1 (Variable aleatoria) Una variable aleatoria \\(X: \\Omega \\longrightarrow D\\) que parte del espacio muestral \\(\\Omega\\) y toma valores en el conjunto de los números reales \\(\\mathbb{R}\\), decimos que sigue la ley \\(f : \\mathbb{R} \\longrightarrow \\mathbb{R}\\), si para cualquier evento \\(A \\subset \\Omega\\) \\[\\begin{equation} P( X \\in A ) = \\int\\limits_{A} dP_X( x ) = \\int\\limits_{A} d(P \\circ X^{-1})( x ) = \\int\\limits_{X^{-1}( A )} dP( \\omega ) \\end{equation}\\] Definición 2.2 (Variable aleatoria discreta) Una variable aleatoria \\(K: \\Omega \\longrightarrow D\\) que parte del espacio muestral \\(\\Omega\\) y toma valores en un conjunto discreto \\(D = \\left\\{k_i \\in \\mathbb{R} | i \\in \\mathbb{N} \\right\\}\\), sigue una probabilidad discreta dada por las probabilidades \\(p_i \\in [0,1]\\) , \\(i \\in \\mathbb{N}\\), si \\[\\begin{equation} P\\left( K = k_i \\right) = p_i,\\qquad \\forall i \\in \\mathbb{N} \\end{equation}\\] Además se cumple la condición de normalización que es muy importante. \\[\\begin{equation} \\sum\\limits_{i = 0}^{\\infty} p_i = 1 \\end{equation}\\] las probabilidades ¡Nunca son negativas! y !Suman siempre 1!. Definición 2.3 (Función de distribución acumulada) Consideramos una variable aleatoria a valores reales \\(X\\), la función de distribución acumulada \\(F\\) asociada a la variable aleatoria \\(X\\), está dada por la siguiente relación: \\[\\begin{equation} F( x ) = P( X \\leq x ) \\end{equation}\\] La función de distribución acumulada, tiene las siguientes propiedades: Para cualquier \\(x \\in \\mathbb{R}\\), \\(0 \\leq F( x ) \\leq 1\\), La función \\(F\\) es no decreciente, La función \\(F\\) es continua por derecha, Se satisfacen los siguientes límites: \\[\\begin{equation} \\underset{x \\rightarrow -\\infty}{\\lim} F( x ) = 0\\qquad \\underset{x \\rightarrow +\\infty}{\\lim} F( x ) = 1 \\end{equation}\\] Definición 2.4 (Función supervivencia) La función de supervivencia \\(S : \\mathbb{R} \\longrightarrow \\mathbb{R}\\) está asociada a una variable aleatoria \\(X\\), está dada por la siguiente: \\[\\begin{equation} S( x ) = 1 - F( x ) = 1 - P( X \\leq x ) = P( X &gt; x ) \\end{equation}\\] Definición 2.5 (Función de densidad de probabilidad) La densidad de probabilidad o también la ley de probabilidad de una variable aleatoria a valores reales \\(X\\), es una función \\(f: \\mathbb{R} \\longrightarrow \\mathbb{R}\\), tal que \\[\\begin{equation} P( a \\leq X \\leq b ) = F( b ) - F( a ) = \\int\\limits_a^b f( x )\\ dx \\end{equation}\\] Así se satisface la siguiente igualdad \\[\\begin{equation} F( x ) = \\int\\limits_{-\\infty}^x f( x )\\ dx \\end{equation}\\] Definición 2.6 (Esperanza matemática) Considerando una variable aleatoria discreta \\(K : \\Omega \\longrightarrow D = \\{k_1, \\ldots, k_n\\} \\subset \\mathbb{R}\\), la esperanza matemática está dada por: \\[\\begin{equation} \\mathbb{E}[ K ] = \\sum\\limits_{i=0}^{\\infty} k_i P\\left( K = k_i \\right) = \\sum\\limits_{i=0}^{\\infty} k_i p_i \\end{equation}\\] Para el caso de una variable aleatoria continua \\(X : \\Omega \\longrightarrow \\mathbb{R}\\) a valores reales, la esperanza matemática está dada por \\[\\begin{equation} \\mathbb{E}[ X ] = \\int\\limits_{\\mathbb{\\Omega}} X( \\omega )\\ dP( \\omega ) = \\int\\limits_{\\mathbb{R}} x\\ dF( x ) \\end{equation}\\] Cuando la función de densidad de probabilidad está bien definida es posible expresar y calcular la esperanza matemática como la siguiente expresión: \\[\\begin{equation} \\mathbb{E}[ X ] = \\int\\limits_{\\mathbb{R}} x f( x )\\ dx \\end{equation}\\] La esperanza matemática goza de las siguientes propiedades: Linealidad, \\(a \\in \\mathbb{R}\\) \\[\\begin{equation} \\mathbb{E}[ aX + Y ] = a \\mathbb{E}[ X ] + \\mathbb{E}[ Y ] \\end{equation}\\] Monotonía, si \\(X \\leq Y\\), entonces \\[\\begin{equation} \\mathbb{E}[X] \\leq \\mathbb{E}[Y] \\end{equation}\\] Definición 2.7 (Función generadora de momentos) La función generadora de momento de la variable aleatoria a valores reales \\(X\\), es la función: \\[\\begin{equation} M_X( t ) = \\mathbb{E}\\left[ \\exp( t X ) \\right] \\end{equation}\\] Si \\(X_1, \\ldots, X_n\\) son variables aleatorias y \\(Y = X_1 + \\cdots + X_n\\), entonces \\[\\begin{eqnarray*} M_Y( t ) &amp; = &amp; \\mathbb{E}\\left[ \\exp\\left( t Y \\right) \\right] \\\\ &amp; = &amp; \\mathbb{E}\\left[ \\exp\\left( t \\sum\\limits_{i=1}^n X_i \\right) \\right] \\\\ &amp; = &amp; \\prod\\limits_{i=1}^n \\mathbb{E}\\left[ \\exp\\left( t X_i \\right) \\right],\\qquad \\text{si las variables $X_i$ son independientes} \\\\ &amp; = &amp; \\left( \\mathbb{E}\\left[ \\exp\\left( t X \\right) \\right] \\right)^n,\\qquad \\text{si las variables $X_i$ son identicamente distribuidas} \\\\ &amp; = &amp; \\left( M_X( t ) \\right)^n \\end{eqnarray*}\\] Definición 2.6 (Varianza) Así mismo su varianza es la dada por: \\[\\begin{equation} \\mathbb{V}[ X ] = \\mathbb{E}\\left[ \\left( X - \\mathbb{E}[ X ] \\right)^2 \\right] = \\mathbb{E}\\left[ X^2 \\right] - \\mathbb{E}\\left[ X \\right]^2 \\end{equation}\\] Definición 2.8 (Independencia de variables aleatorias) Dos variables aleatorias a valores reales \\(X\\) y \\(Y\\), se dicen independientes si para cualquier par de eventos \\(A\\) y \\(B\\), sucede la siguiente factorización de probabilidades \\[\\begin{equation} P( X \\in A \\wedge Y \\in B ) = P( X \\in A ) P( Y \\in B) \\end{equation}\\] La propiedad anterior, en particular para la función de distribución conjunta, toma la siguiente forma: \\[\\begin{equation} F_{X,Y}( x, y ) = P( X \\leq x \\wedge Y \\leq y ) = P( X \\leq x ) P( Y \\leq y ) = F_{X}( x ) F_{Y}( y ) \\end{equation}\\] Así mismo, para la densidad de probabilidad conjunto, sucede la siguiente factorización \\[\\begin{equation} f_{X,Y}( x, y ) = f_X( x ) f_Y( y ) \\end{equation}\\] La siguiente función es utilidad para comprender algunos resultados en teoría de probabilidades. También, es bastante útil para realizar de forma más clara y rápida algunos cálculos. Definición 2.9 (Función indicatriz) La función indicatriz de un conjunto \\(A \\subset \\Omega\\), es la función \\(\\mathbf{1}_A : \\Omega \\longrightarrow \\{0,1\\}\\), que toma los valores \\(\\mathbf{1}_A( \\omega ) = 0\\), si \\(\\omega \\notin A\\) y \\(\\mathbf{1}_A( \\omega ) = 1\\), si \\(\\omega \\in A\\). La función indicatriz \\(\\mathbf{1}_A\\) sobre un evento \\(A\\) del espacio muestral \\(\\Omega\\), también se puede interpretar como una variable aleatoria, que tan solo tomo los valores \\(0\\) o \\(1\\). Es más, su esperanza es precisamente la probabilidad del evento \\(A\\). \\[\\begin{equation} \\mathbb{E}\\left[ \\mathbf{1}_A \\right] = \\int\\limits_\\Omega \\mathbf{1}_A( \\omega )\\ dP( \\omega ) = \\int\\limits_A dP( \\omega ) = P( A ) \\end{equation}\\] Definición 2.10 (Distribución de la suma de variables aleatorias) Dadas dos variables aleatorias a valores reales \\(X\\) y \\(Y\\), con funciones de distribución acumulada \\(F_X\\) y \\(F_Y\\) respectivamente, la distribución acumulada \\(F_Z\\) de la variable aleatoria \\(Z = X + Y\\) está dada por la siguiente expresión: \\[\\begin{equation} F_Z( z ) = P( Z \\leq z ) = F_X \\star F_Y ( z ) = \\int\\limits_{\\mathbb{R}} F_X( x - y )dF_Y( y ) \\end{equation}\\] si en caso se puede definir las densidades de probabilidad \\(f_X\\) y \\(f_Y\\) para las variables aleatorias \\(X\\) y \\(Y\\), entonces: \\[\\begin{equation} f_Z( z ) = f_X \\star f_Y ( z ) = \\int\\limits_{\\mathbb{R}} f_X( x - y ) f_Y( y )\\ dy \\end{equation}\\] El producto \\(\\star\\) se conoce como convolución de funciones, el mismo es simétrico. Para cuando se realiza la convolución de varias veces la misma función, se opta por una notación más compacta \\(f^{\\star k}\\), para el producto de convolución \\(k\\)-veces la misma función \\(f \\star f \\star \\cdots \\star f\\). La siguiente definición de distribución de exceso condicionada es útil para el estudio de los valores extremos que se pueden presentar en el estudio de los valores de siniestros que se presentan en un seguro. Definición 2.11 (Distribución de exceso condicionada) La distribución de exceso condicionada asociada a una variable aleatoria \\(X\\) con distribución de probabilidad acumulada \\(F\\) y a un umbral de condicionamiento \\(u &gt; 0\\), está dada por: \\[\\begin{equation} F_u( y ) = P\\left( X - u \\leq y \\mid X &gt; u \\right) = \\frac{P\\left( u &lt; X \\leq y + u\\right)}{P(X &gt; u)} = \\frac{F( u + y ) - F( u )}{ 1 - F( u )} \\end{equation}\\] 2.4 Desigualdades de concentración Para muchos fines prácticos es importante encontrar una buena estimación de donde se encuentran concentrados los valores de una distribución de probabilidad, para ello existen varios resultados que caracterizan precisamente ello, estos se conocen como desigualdades de concentración. Proposición 2.1 (Desigualdad de Chebyshev (Чебышёв)) Dada una variable aleatoria \\(X\\) con esperanza y varianza finitas \\(\\mathbb{E}[X] &lt;+ \\infty\\) y \\(\\mathbb{V}[X] &lt; +\\infty\\), tenemos que se satisface la siguiente desigualdad para cualquier \\(varepsilon &gt; 0\\) \\[\\begin{equation} P\\left( \\left| X - \\mathbb{E}[X] \\right| &gt; \\varepsilon \\right) &lt; \\frac{1}{\\varepsilon^2} \\mathbb{V}[ X ] \\end{equation}\\] Teorema 2.1 (Desigualdad de Berry-Esséen) Sean \\(X_1, \\ldots X_n\\) variables aleatoria i.i.d, con media y varianza finitas, i.e \\(\\mathbb{E}[X] &lt; +\\infty\\) y \\(\\mathbb{V}[X] &lt; +\\infty\\) y además con tercer momento absoluto finito \\(\\mathbb{E}\\left[\\left|X - \\mathbb{E}[X]\\right|^3\\right] &lt; +\\infty\\). Entonces, la distribución acumulada \\(F_n\\) de la variable aleatoria \\[\\begin{equation} U_n = \\frac{S_n - \\mathbb{E}[ S_n ]}{\\mathbb{V}[ S_n ]} \\end{equation}\\] con \\(S_n = \\sum\\limits_{i=1}^n X_i\\). Satisface la siguiente desigualdad respecto de la distribución acumulada de la ley normal \\(\\Phi\\). \\[\\begin{equation} \\underset{u}{\\sup}\\left| F_n( u ) - \\Phi( u ) \\right| \\leq \\frac{A}{\\sqrt{n}} \\frac{\\mathbb{E}\\left[\\left|X - \\mathbb{E}[X]\\right|^3\\right]}{\\sqrt{\\mathbb{V}[X]}^3} \\end{equation}\\] 2.5 Consideraciones estadísticas De las ramas de las Matemáticas la Estadística ciertamente es la más subestimada, en muchos casos menospreciada. Sin embargo, no sin mucha pretención, sino más bien honestidad, se puede decir que la Estadística es una de las ramas más complicadas de las Ciencias en general, ya que busca en muchos casos comprender, explicar y predecir fenómenos reales. En su fundamentación, al profundizar en ella, uno encontrará un sin número de conceptos, métodos y teorías con un amplio espectro de complejidad, que incluso se sustentan en ideas filosóficas bastante elaboradas y poco comprendidas. No olvidar, la Estadística busca de frente y sin rodeos extraer conocimiento de la realidad y no hay algo más complejo y duro que la realidad misma. Muchos de las herramientas de las estadística se resumen en algunas recetas o aplicaciones de software, sin embargo, no se debe olvidar que en muchos casos estas herramientas hacen uso de muchos métodos bastante avanzados y complejos en lo que respecta al conocimiento Matemático. Teorema 2.2 (Teorema del límite central) Consideramos las variables aleatorias \\(X_1,\\ldots,X_n\\), independientes e idénticamente distribuidas (i.i.d) con media común finita \\(\\mathbb{E}[X_i] = \\mu &lt; +\\infty\\) y varianza común finita \\(\\mathbb{V}[ X_i ] = \\sigma^2 &lt; +\\infty\\), para todo \\(i \\in \\{1, \\ldots, n \\}\\). Si consideramos la variable aleatoria de la suma total \\(S_n = \\sum\\limits_{i=1}^n X_i\\), entonces \\[\\begin{equation} \\frac{S_n - \\mathbb{E}[S_n]}{\\mathbb{V}[ S_n ]} \\overset{d}{\\longrightarrow} Z \\end{equation}\\] cuando \\(n \\rightarrow +\\infty\\), donde \\(Z \\rightsquigarrow N( 0, 1 )\\). Más aún \\[\\begin{equation} \\underset{n \\rightarrow +\\infty}{\\lim} P\\left( \\frac{S_n - \\mathbb{E}[S_n]}{\\mathbb{V}[ S_n ]} \\leq z \\right) = \\Phi( z ) \\end{equation}\\] El teorema del límite central en su forma usual no proporciona una tasa de convergencia es decir, la variable aleatoria \\(\\frac{S_n - \\mathbb{E}[S_n]}{\\mathbb{V}[ S_n ]}\\) tiende a tener un comportamiento de una variable aleatoria normal estándar conforme aumenta \\(n\\), pero no estamos seguros que tamaño debe tomar \\(n\\) para que esto se cumpla con una alta certeza. Para ello adicional al 2.2 se debe considerar otros resultados asociados a desigualdades de concentración. El siguiente teorema es de gran ayuda para estimar la tasa de convergencia del resultado anterior 2.2. Teorema 2.3 (Desigualdad Dvoretzky–Kiefer–Wolfowitz) Dada una serie de variables aleatorias a valores reales \\(X_1, \\ldots, X_n\\), independientes entre si e idénticamente distribuidas (i.i.d), con distribución acumulada \\(F\\), tenemos la siguiente desigualdad asociada a la distribución acumulada empírica \\[\\begin{equation} F_n( x ) = \\frac{1}{n}\\sum\\limits_{i=1}^n \\mathbf{1}_{(-\\infty,x]}( X_i ) \\end{equation}\\] y su aproximación a \\(F\\). \\[\\begin{equation} P\\left( \\underset{x \\in \\mathbb{R}}{\\sup} \\left| F_n( x ) - F( x ) \\right| &gt; \\varepsilon \\right) \\leq 2 e^{-2n \\varepsilon^2 }\\qquad \\forall \\varepsilon &gt; 0 \\end{equation}\\] Como podemos notar el orden de convergencia del teorema es \\(\\sqrt{n}\\) en el tamaño de observaciones, esto quiere decir que la convergencia es menos que el orden lineal. Acorde a la desigualdad 2.3, para tener un probabilidad baja de aproximación \\(\\delta &gt; 0\\) en un error de discrepancia \\(\\varepsilon &gt;0\\), necesitamos satisfacer la desigualdad. \\[\\begin{eqnarray*} 2 e^{-2n \\varepsilon^2 } &amp; \\leq &amp; \\delta \\\\ 2n \\varepsilon^2 &amp; \\geq &amp; -\\ln\\left( \\frac{\\delta}{2} \\right) \\\\ n &amp; \\geq &amp; \\left\\lceil -\\frac{1}{2\\varepsilon^2} \\ln\\left( \\frac{\\delta}{2} \\right) \\right\\rceil \\end{eqnarray*}\\] así se observa que para tener una aproximación de orden \\(\\delta\\) y con un error de discrepancia \\(\\varepsilon\\), se requiere como mínimo realizar un número de simulaciones \\(n\\) de orden logarítmico en \\(\\delta\\) y cuadrático en \\(\\varepsilon\\). delta &lt;- 1e-6 e &lt;- unlist( lapply( seq( 1, 9, 1 ), FUN = function( n ) seq( 9, 1, -1 ) * 10^{-n} ) ) n &lt;- ceiling( -log( delta / 2 ) / ( 2 * e^2 ) ) dt &lt;- data.table( delta = delta, e, n, d = 8 * n / 1024^3 ) dt %&gt;% kable( caption = &#39;Error versus número de simulaciones&#39;, row.names = FALSE, col.names = c( &quot;$\\\\delta$&quot;, &quot;$\\\\varepsilon$&quot;, &quot;$n$&quot;, &quot;GB&quot; ), align = &#39;llrr&#39;, digits = c( 10, 20, 0, 10 ), format.args = list( big.mark = &#39;,&#39;, decimal.mark = &#39;.&#39;, scientific = FALSE ), escape = FALSE ) %&gt;% kable_classic( font_size = 14, full_width = FALSE, html_font = &quot;Cambria&quot; ) %&gt;% scroll_box( width = &quot;750px&quot;, height = &quot;500px&quot; ) Tabla 2.1: Tabla 2.2: Error versus número de simulaciones \\(\\delta\\) \\(\\varepsilon\\) \\(n\\) GB 0.000001 0.900000000 9 0.0000000671 0.000001 0.800000000 12 0.0000000894 0.000001 0.700000000 15 0.0000001118 0.000001 0.600000000 21 0.0000001565 0.000001 0.500000000 30 0.0000002235 0.000001 0.400000000 46 0.0000003427 0.000001 0.300000000 81 0.0000006035 0.000001 0.200000000 182 0.0000013560 0.000001 0.100000000 726 0.0000054091 0.000001 0.090000000 896 0.0000066757 0.000001 0.080000000 1,134 0.0000084490 0.000001 0.070000000 1,481 0.0000110343 0.000001 0.060000000 2,016 0.0000150204 0.000001 0.050000000 2,902 0.0000216216 0.000001 0.040000000 4,534 0.0000337809 0.000001 0.030000000 8,061 0.0000600591 0.000001 0.020000000 18,136 0.0001351237 0.000001 0.010000000 72,544 0.0005404949 0.000001 0.009000000 89,560 0.0006672740 0.000001 0.008000000 113,349 0.0008445159 0.000001 0.007000000 148,048 0.0011030436 0.000001 0.006000000 201,510 0.0015013665 0.000001 0.005000000 290,174 0.0021619648 0.000001 0.004000000 453,396 0.0033780634 0.000001 0.003000000 806,037 0.0060054436 0.000001 0.002000000 1,813,583 0.0135122463 0.000001 0.001000000 7,254,329 0.0540489629 0.000001 0.000900000 8,955,962 0.0667271167 0.000001 0.000800000 11,334,889 0.0844515041 0.000001 0.000700000 14,804,753 0.1103040054 0.000001 0.000600000 20,150,914 0.1501360089 0.000001 0.000500000 29,017,316 0.2161958516 0.000001 0.000400000 45,339,556 0.3378060162 0.000001 0.000300000 80,603,655 0.6005440280 0.000001 0.000200000 181,358,222 1.3512240499 0.000001 0.000100000 725,432,887 5.4048961923 0.000001 0.000090000 895,596,157 6.6727113500 0.000001 0.000080000 1,133,488,886 8.4451503009 0.000001 0.000070000 1,480,475,280 11.0304003954 0.000001 0.000060000 2,015,091,353 15.0136005357 0.000001 0.000050000 2,901,731,548 21.6195847690 0.000001 0.000040000 4,533,955,544 33.7806012034 0.000001 0.000030000 8,060,365,411 60.0544021353 0.000001 0.000020000 18,135,822,174 135.1224047989 0.000001 0.000010000 72,543,288,693 540.4896191731 0.000001 0.000009000 89,559,615,670 667.2711347789 0.000001 0.000008000 113,348,888,583 844.5150299594 0.000001 0.000007000 148,047,527,945 1,103.0400391296 0.000001 0.000006000 201,509,135,258 1,501.3600532562 0.000001 0.000005000 290,173,154,771 2,161.9584766850 0.000001 0.000004000 453,395,554,329 3,378.0601198152 0.000001 0.000003000 806,036,541,030 6,005.4402130097 0.000001 0.000002000 1,813,582,217,316 13,512.2404792607 0.000001 0.000001000 7,254,328,869,263 54,048.9619170353 0.000001 0.000000900 8,955,961,566,991 66,727.1134778187 0.000001 0.000000800 11,334,888,858,223 84,451.5029953644 0.000001 0.000000700 14,804,752,794,413 110,304.0039123073 0.000001 0.000000600 20,150,913,525,729 150,136.0053250864 0.000001 0.000000500 29,017,315,477,049 216,195.8476681188 0.000001 0.000000400 45,339,555,432,889 337,806.0119814351 0.000001 0.000000300 80,603,654,102,913 600,544.0213003233 0.000001 0.000000200 181,358,221,731,553 1,351,224.0479257181 0.000001 0.000000100 725,432,886,926,212 5,404,896.1917028725 0.000001 0.000000090 895,596,156,699,026 6,672,711.3477813154 0.000001 0.000000080 1,133,488,885,822,205 8,445,150.2995357290 0.000001 0.000000070 1,480,475,279,441,247 11,030,400.3912303373 0.000001 0.000000060 2,015,091,352,572,808 15,013,600.5325079560 0.000001 0.000000050 2,901,731,547,704,845 21,619,584.7668114677 0.000001 0.000000040 4,533,955,543,288,818 33,780,601.1981429011 0.000001 0.000000030 8,060,365,410,291,231 60,054,402.1300318167 0.000001 0.000000020 18,135,822,173,155,272 135,122,404.7925716043 0.000001 0.000000010 72,543,288,692,621,088 540,489,619.1702864170 0.000001 0.000000009 89,559,615,669,902,560 667,271,134.7781312466 0.000001 0.000000008 113,348,888,582,220,448 844,515,029.9535725117 0.000001 0.000000007 148,047,527,944,124,672 1,103,040,039.1230335236 0.000001 0.000000006 201,509,135,257,280,768 1,501,360,053.2507953644 0.000001 0.000000005 290,173,154,770,484,352 2,161,958,476.6811456680 0.000001 0.000000004 453,395,554,328,881,792 3,378,060,119.8142900467 0.000001 0.000000003 806,036,541,029,123,072 6,005,440,213.0031814575 0.000001 0.000000002 1,813,582,217,315,527,168 13,512,240,479.2571601868 0.000001 0.000000001 7,254,328,869,262,108,672 54,048,961,917.0286407471 2.6 Consideraciones financieras Antes de desarrollar el contenido propio del curso, debemos tener en cuenta algunas consideraciones financieras como las siguientes: 2.6.1 Función de actualización o descuento La función de actualización de flujos \\(v: \\mathbb{R} \\times \\mathbb{R} \\longrightarrow [0,1]\\), al evaluar en \\(s, t \\in \\mathbb{R}, s\\leq t, v(s,t)\\), diremos que actualizamos los flujos que se producen en el tiempo \\(t\\), valorados desde el tiempo \\(s\\). Además la función de actualización tiene las siguientes propiedades: Si \\(s = t, v(s,t) = 1\\), Si \\(s \\leq t, v(s,t) \\leq 1\\), Si \\(r \\leq s \\leq t, v( r, s ) v( s, t ) = v( r, t )\\). El caso más particular y sencillo se presenta cuando la función de actualización es generada por una tasa constante \\(i \\in [0,1]\\), es decir, \\(v(s,t) = ( 1 + i )^{t-s}\\). La función de capitalización, es la función \\(u: \\mathbb{R} \\times \\mathbb{R} \\longrightarrow [0,1]\\), tal que \\(u( s, t ) v( s, t ) = 1\\). 2.6.2 Flujos financieros Un flujo financiero discreto \\(c\\) es una serie de valores reales \\(c(t_1), c(t_2), \\cdots, c(t_n)\\) que se producen en un número discreto de tiempos \\(t_0 &lt; t_1 &lt; \\cdots &lt; t_n\\). El valor presente de estos flujos, en un tiempo \\(t \\leq t_0\\), se lo puede calcular utilizando precisamente la función de actualización \\(v\\) \\[\\begin{equation} VP_t( c ) = \\sum\\limits_{k = 1}^n v( t, t_k ) c( t_k ) \\end{equation}\\] cuando \\(t=0\\), se suele solo expresar \\(VP( c ) = VP_0( c )\\). 2.6.3 Flujos financieros probables Un flujo financiero discreto \\(c\\) es una serie de valores reales \\(c(t_1), c(t_2), \\cdots, c(t_n)\\) que se producen en un número discreto de tiempos \\(t_0 &lt; t_1 &lt; \\cdots &lt; t_n\\). El valor actuarial presente de estos flujos, en un tiempo \\(t \\leq t_0\\), se lo puede calcular utilizando precisamente la función de actualización \\(v\\) \\[\\begin{equation} VAP_t( c ) = \\mathbb{E}\\left[ \\sum\\limits_{k = 1}^n v( t, t_k ) c( t_k ) \\right] = \\sum\\limits_{k = 1}^n v( t, t_k ) \\mathbb{E}\\left[ c( t_k ) \\right] \\end{equation}\\] cuando \\(t=0\\), se suele solo expresar \\(VAP( c ) = VAP_0( c )\\). Si cada \\(c(t_k)\\) es una variable aleatoria discreta \\[\\begin{equation} VAP_t( c ) = \\sum\\limits_{k = 1}^n v( t, t_k ) \\mathbb{E}\\left[ c( t_k ) \\right] = \\sum\\limits_{k = 1}^n \\sum\\limits_{i=1}^{\\infty} v( t, t_k ) c_i( t_k ) p_i( t_k ) \\end{equation}\\] 2.6.4 Equilibrio financiero Se dice que un flujo financiero \\(c(t_1), c(t_2), \\cdots, c(t_n)\\) como el anterior, está en equilibrio financiero si: \\[\\begin{equation} VP_0( c ) = \\sum\\limits_{k=0}^{n} v( 0, t_k ) c( t_k ) = 0 \\end{equation}\\] El equilibrio financiero se mantiene en el tiempo, basta observar que para cualquier instante \\(t \\geq 0\\) \\[\\begin{eqnarray*} 0 &amp; = &amp; u( 0, t ) VP_0( c ) \\\\ &amp; = &amp; u( 0, t ) \\sum\\limits_{k=0}^{n} v( 0, t_k ) c( t_k ) \\\\ &amp; = &amp; \\sum\\limits_{t_k \\leq t} u( 0, t ) v( 0, t_k ) c( t_k ) + \\sum\\limits_{t_k &gt; t} u( 0, t ) v( 0, t_k ) c( t_k ) \\\\ &amp; = &amp; \\sum\\limits_{t_k \\leq t} u( 0, t_k ) u( t_k, t ) v( 0, t_k ) c( t_k ) + \\sum\\limits_{t_k &gt; t} u( 0, t ) v( 0, t ) v( t, t_k ) c( t_k ) \\\\ &amp; = &amp; \\sum\\limits_{t_k \\leq t} u( t_k, t ) c( t_k ) + \\sum\\limits_{t_k &gt; t} v( t, t_k ) c( t_k ) \\\\ \\end{eqnarray*}\\] Esto implica que el valor actualizado a cualquier instante \\(t\\) de un flujo financiero \\(c\\) que está en equilibrio en un inicio, se mantiene también en equilibrio; siempre y cuando se preserve los flujos y tasas de actualización. A pesar de ser un resultado evidente, en la izquierda tenemos los flujos capitalizados hasta el tiempo \\(t\\) y en la derecha tenemos los flujos actualizados al tiempo \\(t\\). La expresión de la izquierda se conoce como la parte retrospectiva y la expresión de la derecha como la parte prospectiva. En condiciones de equilibrio financiero la parte retrospectiva se igual con menos la parte prospectiva. \\[\\begin{equation} \\sum\\limits_{t_k \\leq t} u( t_k, t ) c( t_k ) = -\\sum\\limits_{t_k &gt; t} v( t, t_k ) c( t_k ) \\end{equation}\\] algunas veces se considera la parte prospectiva con el signo menos. "],["distribuciones.html", "Capítulo 3 Distribuciones 3.1 Distribuciones discretas 3.2 Familia de Panjer 3.3 Distribuciones continuas 3.4 Estimación", " Capítulo 3 Distribuciones 3.1 Distribuciones discretas Definición 3.1 (Distribución binomial) Una variable aleatoria \\(N\\) que toma valores en \\(\\mathbb{N}\\) se dice que sigue una distribución o ley de binomial \\(N \\rightsquigarrow Bin( n, p )\\), con parámetros \\(n \\in \\mathbb{N}\\) y \\(p \\in [0, 1]\\), si: \\[\\begin{equation} P( N = k ) = \\binom{n}{k} p^k ( 1 - p )^{n-k}, \\qquad \\forall k \\in \\{0,\\ldots, n\\} \\end{equation}\\] esta distribución discreta se caracteriza por presentar el valor \\(k \\frac{p_k}{p_{k-1}}\\) decreciente conforme cambia \\(k \\in \\mathbb{N}\\) n &lt;- 50 p &lt;- 0.3 k &lt;- 2 m &lt;- 100 N &lt;- rbinom( n = m, size = n, prob = p ) # simular una muestra de tamaño m pk &lt;- dbinom( x = k, size = n, prob = p ) # cálculo de probabilidad P( N = k ) Pk &lt;- pbinom( q = k, size = n, prob = p ) # cálculo de probabilidad P( N &lt;= k ) p &lt;- dbinom( x = 0:n, size = n, prob = p ) v &lt;- 1:n * p[ 2:(n + 1) ] / p[ 1:n ] plt &lt;- ggplot() + geom_point( aes( x = 1:n, y = v ), colour = &#39;darkred&#39; ) + xlab( TeX( &quot;$k$&quot; ) ) + ylab( TeX( &quot;$k \\\\frac{p_k}{p_{k-1}}$&quot; ) ) + theme_bw() plot( plt ) Definición 3.2 (Distribución de Poisson) Una variable aleatoria \\(N\\) que toma valores en \\(\\mathbb{N}\\) se dice que sigue una distribución o ley de Poisson \\(N \\rightsquigarrow Pois( n, p )\\), con parámetro \\(\\lambda \\in \\mathbb{R}\\), si: \\[\\begin{equation} P( N = k ) = \\exp\\left( -\\lambda \\right) \\frac{\\lambda^k}{k!}, \\qquad \\forall k \\in \\mathbb{N} \\end{equation}\\] esta distribución discreta se caracteriza por presentar el valor \\(k \\frac{p_k}{p_{k-1}}\\) constante conforme cambia \\(k \\in \\mathbb{N}\\) lambda &lt;- 2 k &lt;- 2 m &lt;- 100 N &lt;- rpois( n = m, lambda = lambda ) # simular una muestra de tamaño m pk &lt;- dpois( x = k, lambda = lambda ) # cálculo de probabilidad P( N = k ) Pk &lt;- ppois( q = k, lambda = lambda ) # cálculo de probabilidad P( N &lt;= k ) n &lt;- 50 p &lt;- dpois( x = 0:n, lambda = lambda ) v &lt;- 1:n * p[ 2:(n + 1) ] / p[ 1:n ] plt &lt;- ggplot() + geom_point( aes( x = 1:n, y = v ), colour = &#39;darkred&#39; ) + xlab( TeX( &quot;$k$&quot; ) ) + ylab( TeX( &quot;$k \\\\frac{p_k}{p_{k-1}}$&quot; ) ) + theme_bw() plot( plt ) Definición 3.3 (Distribución binomial negativa) Una variable aleatoria \\(N\\) que toma valores en \\(\\mathbb{N}\\) se dice que sigue una distribución o ley de binomial negativa \\(N \\rightsquigarrow NBin( \\alpha, p )\\), con parámetro \\(\\alpha &gt; 0\\) y \\(p \\in (0,1)\\), si: \\[\\begin{equation} P( N = k ) = \\binom{\\alpha + k - 1}{k} p^\\alpha ( 1 - p )^k = \\frac{\\Gamma( \\alpha + k )}{\\Gamma(k+1) \\Gamma(\\alpha)}p^\\alpha ( 1 - p )^k, \\qquad \\forall k \\in \\mathbb{N} \\end{equation}\\] donde \\(\\Gamma( \\alpha ) = \\int\\limits_0^{+\\infty} x^{\\alpha - 1} \\exp(-x)\\ dx\\), \\(\\forall \\alpha \\geq 0\\). Esta distribución discreta se caracteriza por presentar el valor \\(k \\frac{p_k}{p_{k-1}}\\) creciente conforme cambia \\(k \\in \\mathbb{N}\\) alpha &lt;- 2.5 p &lt;- 0.3 k &lt;- 2 m &lt;- 100 N &lt;- rnbinom( n = m, size = alpha, prob = p ) # simular una muestra de tamaño m pk &lt;- dnbinom( x = k, size = alpha, prob = p ) # cálculo de probabilidad P( N = k ) Pk &lt;- pnbinom( q = k, size = alpha, prob = p ) # cálculo de probabilidad P( N &lt;= k ) n &lt;- 50 p &lt;- dnbinom( x = 0:n, size = alpha, prob = p ) v &lt;- 1:n * p[ 2:(n + 1) ] / p[ 1:n ] plt &lt;- ggplot() + geom_point( aes( x = 1:n, y = v ), colour = &#39;darkred&#39; ) + xlab( TeX( &quot;$k$&quot; ) ) + ylab( TeX( &quot;$k \\\\frac{p_k}{p_{k-1}}$&quot; ) ) + theme_bw() plot( plt ) Definición 3.4 (Distribución geométrica) Una variable aleatoria \\(N\\) que toma valores en \\(\\mathbb{N}\\) se dice que sigue una distribución o ley geométrica \\(N \\rightsquigarrow Geo( p )\\), con parámetro \\(p \\in (0,1]\\), si: \\[\\begin{equation} P( N = k ) = ( 1 - p )^k p, \\qquad \\forall k \\in \\mathbb{N} \\end{equation}\\] p &lt;- 0.3 k &lt;- 2 m &lt;- 100 N &lt;- rgeom( n = m, prob = p ) # simular una muestra de tamaño m pk &lt;- dgeom( x = k, prob = p ) # cálculo de probabilidad P( N = k ) Pk &lt;- pgeom( q = k, prob = p ) # cálculo de probabilidad P( N &lt;= k ) Es fácil darse cuenta que la distribución geométrica \\(Geo( p )\\) es una binomial negativa \\(BN( 1, p )\\), con \\(\\alpha = 1\\). Asociado a estas distribuciones discretas existe un resultado de caracterización, el cual permite seleccionar la distribución de conteo. 3.2 Familia de Panjer El criterio anterior para identificar el tipo de distribución, mediante la observación del comportamiento de la variable \\(k \\frac{p_k}{p_{k-1}}\\), se formaliza precisamente en la definición de la familia de Panjer. Definición 3.5 (Familia de Panjer) Una variable aleatoria discreta \\(N\\), que toma valores enteros positivos \\(N \\in \\mathbb{N}\\), se dice que pertenece a la familia de Panjer, si sus probabilidades \\(p_k = P( N = k )\\) para cada \\(k \\in \\mathbb{N}\\), satisfacen la siguiente relación de recurrencia. \\[\\begin{equation} p_k = \\left( a + \\frac{b}{k} \\right)p_{k-1},\\qquad \\forall k \\in \\mathbb{N} \\setminus \\{0\\} \\end{equation}\\] Además tenemos la siguiente proposición que caracteriza a la distribución de las variables aleatorias en la familia de Panjer. Proposición 3.1 (Caracterización familia de Panjer) Las únicas leyes de probabilidad que satisfacen la relación de recurrencia anterior son: La ley de Poisson, la cual se obtiene para \\(a = 0\\) y \\(b &gt; 0\\) La ley binomial negativa, la cual se obtiene para \\(0 &lt; a &lt; 1\\) y \\(a + b &gt; 0\\) La ley binomial, la cual se obtenida para \\(a &lt; 0\\) y \\(b = -a(m + 1)\\), para cierto \\(m\\) entero y positivo. Para una demostración detallada de la proposición anterior se puede consultar [4] o en https://nonlifemaths.github.io/. 3.3 Distribuciones continuas Definición 3.6 (Distribución uniforme) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución uniforme \\(X \\rightsquigarrow Unif( a, b )\\) de parámetros \\(a, b \\in \\mathbb{R}\\), si su función de distribución acumulada es de la siguiente forma: \\[\\begin{equation} F_X( x ) = \\frac{x-a}{b-a} \\mathbf{1}_{[a,b)}( x ) + \\mathbf{1}_{[b,+\\infty)}( x ) \\end{equation}\\] sin mucho esfuerzo se puede verificar que su densidad de probabilidad está dada por la función \\[\\begin{equation} f_X( x ) = \\frac{1}{b-a}\\mathbf{1}_{[a,b]}( x ) \\end{equation}\\] \\[\\begin{equation} M_X( t ) = \\frac{\\exp(bt)-\\exp(at)}{t(b-a)} \\end{equation}\\] \\[\\begin{equation} \\mathbb{E}[X] = \\frac{a + b}{2},\\qquad \\mathbb{V}[X] = \\frac{(b - a)^2}{12} \\end{equation}\\] a &lt;- 1 b &lt;- 2 x &lt;- 1.5 m &lt;- 100 X &lt;- runif( n = m, min = a, max = b ) # simular una muestra de tamaño m fx &lt;- dunif( x = x, min = a, max = b ) # cálculo de la densidad f(x) Fk &lt;- punif( q = x, min = a, max = b ) # cálculo de probabilidad F(x) Definición 3.7 (Distribución exponencial) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución exponencial \\(X \\rightsquigarrow Exp( \\lambda )\\) de parámetros \\(\\lambda &gt; 0\\), si su función de distribución acumulada es de la siguiente forma: \\[\\begin{equation} F_X( x ) = \\mathbf{1}_{(0,+\\infty)}( x ) \\left( 1 - \\exp\\left( -\\lambda x \\right) \\right) \\end{equation}\\] sin mucho esfuerzo se puede verificar que su densidad de probabilidad está dada por la función \\[\\begin{equation} f_X( x ) = \\mathbf{1}_{(0,+\\infty)}( x ) \\lambda \\exp\\left( -\\lambda x \\right) \\end{equation}\\] \\[\\begin{equation} M_X( t ) = \\frac{\\lambda}{\\lambda - t} \\end{equation}\\] \\[\\begin{equation} \\mathbb{E}[X] = \\frac{1}{\\lambda},\\qquad \\mathbb{V}[X] = \\frac{1}{\\lambda^2} \\end{equation}\\] lambda &lt;- 2 x &lt;- 1.5 m &lt;- 100 X &lt;- rexp( n = m, rate = lambda ) # simular una muestra de tamaño m fx &lt;- dexp( x = x, rate = lambda ) # cálculo de la densidad f(x) Fk &lt;- pexp( q = x, rate = lambda ) # cálculo de probabilidad F(x) Definición 3.8 (Distribución gamma) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución gamma \\(X \\rightsquigarrow Gamma( \\alpha, \\beta )\\) de parámetros \\(\\alpha &gt; 0\\), \\(\\beta &gt; 0\\), si su función de distribución acumulada es de la siguiente forma: \\[\\begin{equation} F_X( x ) = \\frac{\\beta^\\alpha}{\\Gamma( \\alpha )} \\int\\limits_{0}^{x} u^{\\alpha-1} \\exp(-\\beta u)\\ du \\end{equation}\\] la densidad de probabilidad automáticamente está dada por la función: \\[\\begin{equation} f_X( x ) = \\mathbf{1}_{[0,+\\infty}( x ) \\frac{\\beta^\\alpha}{\\Gamma( \\alpha )} x^{\\alpha-1} \\exp(-\\beta x) \\end{equation}\\] \\[\\begin{equation} M_X( t ) = \\left( \\frac{\\beta}{\\beta - t} \\right)^\\alpha,\\qquad \\text{si}\\ t &lt; \\beta \\end{equation}\\] \\[\\begin{equation} \\mathbb{E}[X] = \\frac{\\alpha}{\\beta},\\qquad \\mathbb{V}[X] = \\frac{\\alpha}{\\beta^2} \\end{equation}\\] alpha &lt;- 2 beta &lt;- 1 x &lt;- 3 m &lt;- 100 X &lt;- rgamma( n = m, shape = alpha, scale = beta ) # simular una muestra de tamaño m fx &lt;- dgamma( x = x, shape = alpha, scale = beta ) # cálculo de la densidad f(x) Fk &lt;- pgamma( q = x, shape = alpha, scale = beta ) # cálculo de probabilidad F(x) Definición 3.8 (Distribución normal) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución normal \\(X \\rightsquigarrow N( \\mu, \\sigma )\\) de parámetros \\(\\mu \\in \\mathbb{R}\\), \\(\\sigma &gt; 0\\), si su función de distribución acumulada es de la siguiente forma: \\[\\begin{equation} F_X( x ) = \\frac{1}{\\sqrt{2\\pi} \\sigma} \\int\\limits_{-\\infty}^x \\exp\\left( -\\frac{(y - \\mu)^2}{\\sigma^2} \\right)\\ dy \\end{equation}\\] la densidad de probabilidad automáticamente está dada por la función: \\[\\begin{equation} f_X( x ) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left( -\\frac{(x - \\mu)^2}{\\sigma^2} \\right) \\end{equation}\\] \\[\\begin{equation} M_X( t ) = \\exp\\left( t \\mu + \\frac{1}{2} t^2 \\sigma^2 \\right) \\end{equation}\\] \\[\\begin{equation} \\mathbb{E}[X] = \\mu,\\qquad \\mathbb{V}[X] = \\sigma^2 \\end{equation}\\] mu &lt;- 2 sigma &lt;- 1 x &lt;- 3 m &lt;- 100 X &lt;- rnorm( n = m, mean = mu, sd = sigma ) # simular una muestra de tamaño m fx &lt;- dnorm( x = x, mean = mu, sd = sigma ) # cálculo de la densidad f(x) Fk &lt;- pnorm( q = x, mean = mu, sd = sigma ) # cálculo de probabilidad F(x) Definición 3.9 (Distribución log-normal) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución log-normal \\(X \\rightsquigarrow LN( \\mu, \\sigma )\\) de parámetros \\(\\mu &gt; 0\\), \\(\\sigma &gt; 0\\), si su función de distribución acumulada es de la siguiente forma: \\[\\begin{equation} F_X( x ) = \\frac{1}{\\sqrt{2\\pi} \\sigma} \\int\\limits_{0}^{x} \\frac{1}{y} \\exp\\left( -\\frac{(\\ln(y) - \\mu)^2}{\\sigma^2} \\right)\\ dy \\end{equation}\\] la densidad de probabilidad automáticamente está dada por la función: \\[\\begin{equation} f_X( x ) = \\frac{1}{x\\sqrt{2\\pi} \\sigma} \\exp\\left( -\\frac{(\\ln(x) - \\mu)^2}{\\sigma^2} \\right) \\end{equation}\\] No hay forma analítica para \\(M_X\\) \\[\\begin{equation} \\mathbb{E}[X] = \\exp\\left( \\mu + \\frac{1}{2}\\sigma^2 \\right),\\qquad \\mathbb{V}[X] = \\exp\\left( 2 \\mu + \\sigma^2 \\right) \\left( \\exp( \\sigma^2 ) - 1 \\right) \\end{equation}\\] mu &lt;- 2 sigma &lt;- 1 x &lt;- 3 m &lt;- 100 X &lt;- rlnorm( n = m, meanlog = mu, sdlog = sigma ) # simular una muestra de tamaño m fx &lt;- dlnorm( x = x, meanlog = mu, sdlog = sigma ) # cálculo de la densidad f(x) Fk &lt;- plnorm( q = x, meanlog = mu, sdlog = sigma ) # cálculo de probabilidad F(x) En pocas, una variable aleatoria \\(X \\rightsquigarrow LN( \\mu, \\sigma )\\) sigue una distribución log-normal si y solamente si la variable aleatoria dada por su logaritmo \\(\\ln( X ) \\rightsquigarrow N( \\mu, \\sigma )\\) sigue una distribución normal. Definición 3.10 (Distribución de Pareto generalizada) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución de Pareto generalizada \\(X \\rightsquigarrow GPD( \\mu, \\sigma, \\xi )\\) de parámetros \\(\\mu \\in \\mathbb{R}, \\sigma &gt; 0, \\xi \\in \\mathbb{R}\\), si su función de distribución acumulada es de la siguiente forma: \\[\\begin{equation} F_X( x ) = \\left \\{ \\begin{array}{ll} 1 - \\left( 1 + \\xi \\frac{x-\\mu}{\\sigma} \\right)^{-\\frac{1}{\\xi}} &amp; \\text{si}\\ \\xi \\neq 0 \\\\ 1 - \\exp\\left( -\\frac{x-\\mu}{\\sigma} \\right) &amp; \\text{si}\\ \\xi = 0 \\end{array} \\right. \\end{equation}\\] y su densidad de probabilidad está dada por la función \\[\\begin{equation} f_X( x ) = \\left \\{ \\begin{array}{ll} \\frac{1}{\\sigma} \\left( 1 + \\xi \\frac{x-\\mu}{\\sigma} \\right)^{-1-\\frac{1}{\\xi}} &amp; \\text{si}\\ \\xi \\neq 0 \\\\ \\frac{1}{\\sigma} \\exp\\left( -\\frac{x-\\mu}{\\sigma} \\right) &amp; \\text{si}\\ \\xi = 0 \\end{array} \\right. \\end{equation}\\] xi &lt;- 1 mu &lt;- 2 sigma &lt;- 1 x &lt;- 3 m &lt;- 100 X &lt;- rgpd( n = m, xi = xi, mu = mu, beta = sigma ) # simular una muestra de tamaño m fx &lt;- dgpd( x = x, xi = xi, mu = mu, beta = sigma ) # cálculo de la densidad f(x) Fk &lt;- pgpd( q = x, xi = xi, mu = mu, beta = sigma ) # cálculo de probabilidad F(x) Definición 3.11 (Distribución de valores extremos generalizada) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución generalizada de valores extremos \\(X \\rightsquigarrow GEV( \\mu, \\sigma, \\xi )\\) de parámetros \\(\\mu \\in \\mathbb{R}, \\sigma &gt; 0, \\xi \\in \\mathbb{R}\\), si su función de distribución acumulada es de la siguiente forma: \\[\\begin{equation} F_X( x ) = \\left\\{ \\begin{array}{ll} \\exp\\left( -\\exp\\left( -\\frac{x-\\mu}{\\sigma} \\right) \\right) &amp; \\text{si}\\ \\xi = 0 \\\\ \\exp\\left( -\\left( 1 + \\xi \\frac{x-\\mu}{\\sigma} \\right)^{-\\frac{1}{\\xi}} \\right) &amp; \\text{si}\\ \\xi \\neq 0, 1 + \\xi\\frac{x - \\mu}{\\sigma} &gt; 0 \\end{array} \\right. \\end{equation}\\] además se puede verificar que su densidad de probabilidad está dada por la función \\[\\begin{equation} f_X( x ) = \\left\\{ \\begin{array}{ll} \\exp\\left(-\\frac{x-\\mu}{\\sigma}\\right) \\exp\\left(-\\exp\\left(-\\frac{x-\\mu}{\\sigma}\\right)\\right) &amp; \\text{si}\\ \\xi = 0 \\\\ \\left( 1 + \\xi \\frac{x - \\mu}{\\sigma}\\right)^{-1-\\frac{1}{\\xi}} \\exp\\left( -\\left( 1 + \\xi \\frac{x-\\mu}{\\sigma} \\right)^{-\\frac{1}{\\xi}} \\right) &amp; \\text{si}\\ \\xi \\neq 0, 1 + \\xi\\frac{x - \\mu}{\\sigma} &gt; 0 \\end{array} \\right. \\end{equation}\\] xi &lt;- -1 mu &lt;- 2 sigma &lt;- 1 x &lt;- 3 m &lt;- 100 X &lt;- rgev( n = m, xi = xi, mu = mu, beta = sigma ) # simular una muestra de tamaño m fx &lt;- dgev( x = x, xi = xi, mu = mu, beta = sigma ) # cálculo de la densidad f(x) Fk &lt;- pgev( q = x, xi = xi, mu = mu, beta = sigma ) # cálculo de probabilidad F(x) Definición 3.12 (Distribución t de Student) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución t de Student \\(X \\rightsquigarrow t( \\nu )\\) de parámetros \\(\\nu &gt; 0\\), si su función de distribución acumulada es de la siguiente forma: \\[\\begin{equation} F_X( x ) = \\frac{1}{2} + \\frac{x}{\\sqrt{\\pi \\nu}} \\frac{\\Gamma\\left( \\frac{\\nu + 1}{2} \\right)}{\\Gamma\\left( \\frac{\\nu}{2} \\right)} F\\left( \\frac{1}{2}, \\frac{\\nu+1}{2}, \\frac{3}{2}, -\\frac{x^2}{\\nu} \\right) \\end{equation}\\] donde \\(F\\) es la función hipergeométrica. \\[\\begin{equation} F( a, b, c, z ) = \\sum\\limits_{n=0}^{+\\infty} \\frac{(a)_n (b)_n}{(c)_n} \\frac{z^n}{n!} \\end{equation}\\] con \\[\\begin{equation} (a)_n = \\left\\{ \\begin{array}{ll} 1 &amp; n = 0 \\\\ a( a + 1 ) \\cdots (a + n - 1) &amp; n &gt; 0 \\end{array} \\right. \\end{equation}\\] Además, se puede verificar que su densidad de probabilidad está dada por la función \\[\\begin{equation} f_X( x ) = \\frac{x}{\\sqrt{\\pi \\nu}} \\frac{\\Gamma\\left(\\frac{\\nu+1}{2}\\right)}{\\Gamma\\left( \\frac{\\nu}{2} \\right)} \\left( 1 + \\frac{x^2}{\\nu} \\right)^{-\\frac{\\nu+1}{2}} \\end{equation}\\] La función generadora de momentos \\(M_X( t )\\) no está definida \\[\\begin{equation} \\mathbb{E}[X] = \\left\\{ \\begin{array}{ll} 0 &amp; \\text{si}\\ \\nu &gt; 0 \\\\ \\text{no definida} &amp; \\text{si}\\ \\nu \\leq 0 \\end{array} \\right. \\end{equation}\\] \\[\\begin{equation} \\mathbb{V}[X] = \\left\\{ \\begin{array}{ll} \\frac{\\nu}{\\nu-2} &amp; \\text{si}\\ \\nu &gt; 2 \\\\ +\\infty &amp; \\text{si}\\ 1 &lt; \\nu \\leq 2 \\\\ \\text{no definida} &amp; \\text{si}\\ \\nu \\leq 1 \\end{array} \\right. \\end{equation}\\] nu &lt;- 3 x &lt;- 4 m &lt;- 100 X &lt;- rt( n = m, df = nu ) # simular una muestra de tamaño m fx &lt;- dt( x = x, df = nu ) # cálculo de la densidad f(x) Fk &lt;- pt( q = x, df = nu ) # cálculo de probabilidad F(x) Definición 3.13 (Distribución beta transformada) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución beta transformada \\(X \\rightsquigarrow BT( \\alpha, \\gamma, \\tau, \\theta )\\) de parámetros \\(\\alpha &gt; 0, \\gamma &gt; 0, \\tau &gt; 0, \\theta &gt; 0\\), si su función de distribución acumulada es de la siguiente forma: \\[\\begin{equation} F_X( x ) = \\frac{\\Gamma(\\alpha + \\tau)}{\\Gamma( \\alpha ) \\Gamma( \\tau )} \\int\\limits_0^x \\frac{\\gamma \\left( \\frac{u}{\\theta} \\right)^{\\gamma \\tau}}{u\\left( 1 + \\left( \\frac{u}{\\theta} \\right)^{\\gamma}\\right)^{\\alpha + \\tau}}\\ du \\end{equation}\\] además se puede verificar que su densidad de probabilidad está dada por la función: \\[\\begin{equation} f_X( x ) = \\mathbf{1}_{[0,+\\infty)}( x ) \\frac{\\Gamma(\\alpha + \\tau)}{\\Gamma( \\alpha ) \\Gamma( \\tau )} \\frac{ \\gamma \\left( \\frac{x}{\\theta} \\right)^{\\gamma \\tau}}{x\\left( 1 + \\left( \\frac{x}{\\theta} \\right)^{\\gamma}\\right)^{\\alpha + \\tau}} \\end{equation}\\] \\[\\begin{eqnarray*} \\mathbb{E}[X^k] &amp; = &amp; \\frac{\\theta^k \\Gamma\\left( \\tau + \\frac{k}{\\gamma}\\right) \\Gamma\\left( \\tau - \\frac{k}{\\gamma}\\right)}{\\Gamma( \\alpha ) \\Gamma( \\tau )}, \\quad \\text{si}\\ -\\tau \\gamma &lt; k &lt; \\tau \\gamma \\\\ \\mathbb{E}[X] &amp; = &amp; \\frac{\\theta \\Gamma\\left( \\tau + \\frac{1}{\\gamma}\\right) \\Gamma\\left( \\tau - \\frac{1}{\\gamma}\\right)}{\\Gamma( \\alpha ) \\Gamma( \\tau )} \\\\ \\mathbb{V}[X] &amp; = &amp; \\frac{\\theta^2 \\Gamma\\left( \\tau + \\frac{2}{\\gamma}\\right) \\Gamma\\left( \\tau - \\frac{2}{\\gamma}\\right)}{\\Gamma( \\alpha ) \\Gamma( \\tau )} - \\frac{\\theta^2 \\Gamma\\left( \\tau + \\frac{1}{\\gamma}\\right)^2 \\Gamma\\left( \\tau - \\frac{1}{\\gamma}\\right)^2}{\\Gamma( \\alpha )^2 \\Gamma( \\tau )^2} \\end{eqnarray*}\\] alpha &lt;- 1 gamma &lt;- 1 tau &lt;- 1 theta &lt;- 1 x &lt;- 3 m &lt;- 100 X &lt;- rtrbeta( n = m, shape1 = alpha, shape2 = gamma, shape3 = tau, scale = theta ) # simular una muestra de tamaño m fx &lt;- dtrbeta( x = x, shape1 = alpha, shape2 = gamma, shape3 = tau, scale = theta ) # cálculo de la densidad f(x) Fk &lt;- ptrbeta( q = x, shape1 = alpha, shape2 = gamma, shape3 = tau, scale = theta ) # cálculo de probabilidad F(x) Dentro de la familia beta transformada se cuenta algunas distribuciones de probabilidad: La distribución de Burr para \\(\\tau = 1\\) La distribución de log-logística para \\(\\alpha = \\tau = 1\\) La distribución de paralogística para \\(\\alpha = \\gamma, \\tau = 1\\) La distribución de generalizada de Pareto para \\(\\gamma = 1\\) La distribución de Pareto para \\(\\gamma = \\tau = 1\\) La distribución de inversa de Burr para \\(\\alpha = 1\\) La distribución de inversa de Pareto para \\(\\alpha = \\gamma = 1\\) La distribución de inversa paralogística para \\(\\alpha = 1, \\gamma = \\tau\\) 3.4 Estimación Maximización de la verosimilitud Momentos Métodos no paramétricos Bibliografía "],["modelos-de-pérdida-agregada.html", "Capítulo 4 Modelos de pérdida agregada 4.1 Pasivos y activos de una aseguradora 4.2 Reservas técnicas 4.3 Mutualización del riesgo 4.4 Modelo individual 4.5 Modelo colectivo 4.6 Modelos mixtos 4.7 Modelos con variables explicativas 4.8 Aplicación del deducible 4.9 Algoritmo de Panjer 4.10 Estimación usando la transformada de Fourier", " Capítulo 4 Modelos de pérdida agregada 4.1 Pasivos y activos de una aseguradora 4.1.1 Pasivos Capitales propios Reservas técnicas Reservas para otros riesgos Deudas o depósitos en dinero recibidos por cesiones Otras deudas por pagar 4.1.2 Activos Capital suscrito no desembolsado Activos no materiales Inversiones Parte de reaseguros en reservas técnicas Deudas por cobrar Otros activos 4.2 Reservas técnicas Reservas para primas no adquiridas Reservas de riesgos en curso Reservas de siniestros a pagar Siniestros sucedidos, reportados, resueltos, no pagados Siniestros sucedidos, reportados, no resueltos, no pagados Siniestros sucedidos, no reportados, no resueltos, no pagados \\(R\\) Ganancia o rendimiento \\(P\\) Ingreso por primas \\(I\\) Ingreso por inversiones \\(S\\) Pago de siniestros \\(G\\) Gastos de subscripción \\[\\begin{equation} R = P + I - S - G \\end{equation}\\] 4.3 Mutualización del riesgo La idea de mantener un seguro está basada en la mutualización de los riesgos. La mutualización como tal nace del mismo mecanismo bajo el cual funciona un seguro, cada asegurado transfiera su riesgo individual a la compañia de seguros por su parte, la suma total de estos riesgos \\(S\\) es el riesgo total que asume el asegurador. Los riesgos de cada uno de los \\(n \\in \\mathbb{N}\\) asegurados, pueden ser representados por variables aleatorias \\(X_1,\\ldots X_n\\), las mismas pueden ser independientes o dependientes entre ellas. El costo total del portafolio está dado por la suma de todos estos riesgos. \\[\\begin{equation} S = \\sum\\limits_{i=1}^n X_i \\end{equation}\\] El conocer la distribución del costo total \\(S\\) es una tarea crucial para el asegurador. El costo total esperado esta dado claramente por la siguiente expresión. \\[\\begin{equation} \\mathbb{E}[ S ] = \\mathbb{E}\\left[ \\sum\\limits_{i=1}^n X_i \\right] = \\sum\\limits_{i=1}^n \\mathbb{E}\\left[ X_i \\right] \\end{equation}\\] la varianza de la variable aleatoria del costo total \\(S\\), está dada por: \\[\\begin{eqnarray*} \\mathbb{V}\\left[ S \\right] &amp; = &amp; \\mathbb{V}\\left[ \\sum\\limits_{i=1}^n X_i \\right] \\\\ &amp; = &amp; \\sum\\limits_{i=1}^n \\mathbb{V}\\left[ X_i \\right] + \\sum\\limits_{i=1}^n \\sum\\limits_{j=1,j\\neq i}^n \\mathbb{C}\\left[ X_i, X_j \\right] \\\\ &amp; = &amp; \\sum\\limits_{i=1}^n \\mathbb{V}\\left[ X_i \\right] + 2\\sum\\limits_{i=1}^{n-1} \\sum\\limits_{j=i+1}^n \\mathbb{C}\\left[ X_i, X_j \\right] \\end{eqnarray*}\\] \\(S_n = \\sum\\limits_{i=1}^n X_i\\) \\[\\begin{equation} W_n = \\frac{S_n}{n} \\end{equation}\\] \\[\\begin{equation} \\mathbb{E}\\left[ W_n \\right] = \\mathbb{E}\\left[ \\frac{S_n}{n} \\right] = \\frac{1}{n} \\mathbb{E}\\left[ S_n \\right] \\end{equation}\\] \\[\\begin{equation} \\mathbb{V}\\left[ W_n \\right] = \\mathbb{V}\\left[ \\frac{S_n}{n} \\right] = \\frac{1}{n^2} \\mathbb{V}\\left[ S_n \\right] \\end{equation}\\] 4.4 Modelo individual En el modelo de riesgos individuales consideramos que el número de siniestros que se producirán es conocido, por ejemplo puede ser a lo sumo el tamaño de la población asegurada, en tal caso la variable aleatoria \\(N\\) pasa a ser una constante, que representaremos por \\(n\\). De esta forma, la severidad total puede ser fácilmente representada por: \\[\\begin{equation} S = \\sum\\limits_{i=1}^n X_i \\end{equation}\\] La hipótesis más usual que sostiene a este modelo es la indenpendencia entre cada uno de los reclamos \\(X_i\\) y \\(X_j\\) son independientes para cualquier \\(1 \\leq i \\neq j \\leq n\\). El valor esperado de la severidad total \\(S\\) es: \\[\\begin{eqnarray*} \\mathbb{E}[S] &amp; = &amp; \\mathbb{E}\\left[ \\sum\\limits_{i=1}^n X_i \\right] \\\\ &amp; = &amp; \\sum\\limits_{i=1}^n \\mathbb{E}\\left[ X_i \\right] \\end{eqnarray*}\\] Así mismo con la varianza de \\(S\\). \\[\\begin{eqnarray*} \\mathbb{V}\\left[ S \\right] &amp; = &amp; \\mathbb{V}\\left[ \\sum\\limits_{i=1}^n X_i \\right] \\\\ &amp; = &amp; \\sum\\limits_{i=1}^n \\mathbb{V}\\left[ X_i \\right] + \\sum\\limits_{i=1}^n \\sum\\limits_{j=1,j\\neq i}^n \\mathbb{C}\\left[ X_i, X_j \\right] \\\\ &amp; = &amp; \\sum\\limits_{i=1}^n \\mathbb{V}\\left[ X_i \\right]\\quad \\text{si $\\{X_i\\}$ sin son independientes entre si} \\\\ &amp; = &amp; n \\mathbb{V}\\left[ X \\right]\\quad \\text{si $\\{X_i\\}$ sin son idénticamente distribuidas } \\end{eqnarray*}\\] 4.4.1 Algoritmo de simulación Se puede simular la severidad total \\(S\\) para el caso donde se asume independencia entre cada una de las severidades \\(X_1, \\ldots, X_n\\) y se conoce cada una de sus densidades de probabilidad \\(f_{X_1}, \\ldots, f_{X_n}\\) o distribuciones de probabilidad \\(F_{X_1}, \\ldots, F_{X_n}\\). Se tiene fijo \\(n \\in \\mathbb{N}\\), Se fija el número de simulaciones \\(m \\in \\mathbb{N}\\) Para cada \\(i \\in \\{1, \\ldots, m\\}\\) se extrae una muestra \\(X_{i,1} \\rightsquigarrow f_{X_1},\\ldots,X_{i,n} \\rightsquigarrow f_{X_n}\\), Para cada \\(i \\in \\{1, \\ldots, m\\}\\) se calcula la severidad total para la muestra \\(i\\), \\(S_i = \\sum\\limits_{j=1}^n X_{i,j}\\) Ejemplo 4.1 El siguiente código ejemplifica el algoritmo anterior, donde se asume que cada variable aleatoria de severidad \\(X_i\\) sigue una ley log-normal \\(LN( \\mu_i, \\sigma_i )\\), de parámetros \\(\\mu_i, \\sigma_i\\), para \\(i \\in \\{1,\\ldots, n\\}\\). # 1. número de distribuciones n &lt;- 200 # parámetros para las n distribuciones mu &lt;- seq( 1, 2, length.out = n ) sigma &lt;- seq( 2, 3, length.out = n ) # 2. número de simulaciones m &lt;- 1e4 # 3. simulación de severidades X &lt;- lapply( 1:m, FUN = function( i ) sapply( 1:n, FUN = function( j ) rlnorm( 1, meanlog = mu[ j ], sdlog = sigma[ j ] ) ) ) # 4. simulación de severidad total S &lt;- sapply( X, FUN = function( x ) sum( x ) ) En el ejemplo anterior es de notar que la densidad de probabilidad de la severidad \\(S\\) resulta de la convolución de las \\(n\\) densidades individuales \\(f_S = f_{X_1} \\star \\cdots \\star f_{X_n}\\), la cual no presenta una forma analítica conocida. De la imposibilidad anterior se se puede ver la utilidad de trabajar con la simulación aleatoria de la variable \\(S\\). Se puede estimar la distribución acumulada de probabilidad \\(F_S\\) a partir de la distribución empírica \\(F_m\\) de la muestra, con: \\[\\begin{equation} F_S( s ) \\approx F_m( s ) = \\frac{1}{m} \\sum\\limits_{i=1}^m \\mathbf {1}_{(-\\infty,s]}( S_i ) \\end{equation}\\] el resultado de acotación de 2.3 nos da un criterio de convergencia de \\(F_m\\) a \\(F_S\\) Para construir \\(F_m\\) en R, se puede utilizar la función ya empaquetada ecdf (empirical cumulative distribution function). # estimación distribución acumulada empírica de S Fm &lt;- ecdf( S ) # esperanza empírica EeS &lt;- mean( S ) # esperanza teórica ES &lt;- sum( sapply( 1:n, FUN = function( i ) exp( mu[i] + 0.5 * sigma[i]^2 ) ) ) s &lt;- seq( quantile( S, probs = 0.01 ), quantile( S, probs = 0.99 ), length.out = 1e3 ) Fms &lt;- sapply( s, FUN = Fm ) plot( s, Fms, type = &#39;s&#39; ) abline( v = EeS, col = &#39;red&#39; ) abline( v = ES, col = &#39;orange&#39; ) Para calcular la esperanza de la severidad total \\(S\\), también se puede utilizar una aproximación a la integral de Riemann-Stieltjes utilizando la distribución acumulada empírica \\(F_m\\). \\[\\begin{equation} \\mathbb{E}[ S ] = \\int\\limits_{\\mathbb{R}} s dF_S( s ) \\approx \\int\\limits_{\\mathbb{R}} s dF_m( s ) \\approx \\sum\\limits_{i=1}^N s_{i} \\left( F_m( s_{i+1} ) - F_m( s_{i} ) \\right) \\end{equation}\\] Esta aproximación en R puede ser implementada de la siguiente forma: N &lt;- 1e5 s &lt;- seq( min( S ), max( S ), length.out = N ) EmS &lt;- sum( s[-N] * diff( sapply( s, FUN = Fm ) ) ) De ello tenemos los siguientes resultados de cálculo para el valor esperado de la severidad total \\[\\begin{eqnarray*} \\mathbb{E}[S] = \\sum\\limits_{i=1}^n e^{ \\mu_i + \\frac{1}{2} \\sigma_i^2 } &amp; = &amp; 34562.7208, \\\\ \\overline{S} = \\frac{1}{m} \\sum\\limits_{i=1}^m S_i &amp; = &amp; 33544.1971, \\\\ \\sum\\limits_{i=1}^N s_{i} \\left( F_m( s_{i+1} ) - F_m( s_{i} ) \\right) &amp; = &amp; 33511.4010 \\end{eqnarray*}\\] Lo bueno de poseer una buena aproximación a la distribución acumulada de una variable aleatoria, es que podemos calcular algunos otros valores de importancia relacionados a la variable aleatoria y no tan solo utilizar medidas de tendencia central. Sin embargo, para que esta aproximación sea útil se requiere reducir el error de probabilidad 2.3. Ejemplo 4.2 Podemos considerar el caso sencillo donde el valor posible de severidad es determinista, es decir para cada póliza \\(i\\in \\{1,\\ldots,n\\}\\), el valor de severidad probable es único \\(M &gt; 0\\) si en caso se da un evento \\(A_i\\), esto lo podemos expresar como \\(X_i = M \\mathbf{1}_{A_i}\\) es constante. Así, pérdida total está dada por: \\[\\begin{equation} S = \\sum\\limits_{i=1}^n X_i = \\sum\\limits_{i=1}^n M \\mathbf{1}_{A_i} \\end{equation}\\] El valor total esperado de reclamos está dado por: \\[\\begin{equation} \\mathbf{E}[ S ] = \\sum\\limits_{i=1}^n \\mathbf{E}\\left[ M \\mathbf{1}_{A_i} \\right] = M \\sum\\limits_{i=1}^n P( A_i ) \\end{equation}\\] la última igualdad resulta de las propiedades de la función indicatriz 2.9. Si en caso todos los \\(P(A_i) = p\\) tienen la misma probabilidad, el valor total esperado de reclamos toma la siguiente forma: \\[\\begin{equation} \\mathbb{E}[S] = n M p \\end{equation}\\] 4.5 Modelo colectivo El modelo colectivo de riesgo considera un número de reclamos descritos por una variable aleatoria discreta \\(N\\). Los reclamos corresponden a un número de pólizas en un periodo específico, el valor de cada reclamo \\(i \\in \\{1,\\ldots,N\\}\\) está representado por las variables aleatorias \\(X_i\\). Usualmente, se considera que cada uno de los reclamos \\(X_i\\) están idénticamente distribuidos. \\[\\begin{equation} S = \\left\\{ \\begin{array}{ll} \\sum\\limits_{i=1}^N X_i &amp; \\text{si}\\ N &gt; 0 \\\\ 0 &amp; \\text{si}\\ N = 0 \\end{array} \\right. \\end{equation}\\] o de forma más compacta se tan solo utilizar la igualdad \\(S = \\sum\\limits_{i=1}^N X_i\\), donde se asume que la suma da \\(0\\) si \\(N = 0\\). El valor esperado del total de reclamos \\(S\\), está dado por: \\[\\begin{eqnarray*} \\mathbb{E}[S] &amp; = &amp; \\mathbb{E}\\left[ \\sum\\limits_{i=1}^N X_i \\right] \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} \\mathbb{E}\\left[ \\sum\\limits_{i=1}^n X_i\\ \\middle|\\ N = n \\right]P( N = n )\\quad \\text{utilizando la esperanza condicional} \\\\ &amp; = &amp; 0 P( N = 0 ) + \\sum\\limits_{n=1}^{+\\infty} \\mathbb{E}\\left[ \\sum\\limits_{i=1}^n X_i\\ \\middle|\\ N = n \\right]P( N = n ) \\\\ &amp; = &amp; \\sum\\limits_{n=1}^{+\\infty} \\sum\\limits_{i=1}^n \\mathbb{E}\\left[ X_i \\mid N = n \\right]P( N = n )\\quad \\text{linealidad de la esperanza} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} n \\mathbb{E}\\left[ X \\mid N = n \\right]P( N = n )\\quad \\text{si $\\{X_i\\}$ son idénticamente distribuidas} \\\\ &amp; = &amp; \\mathbb{E}\\left[ X \\right] \\sum\\limits_{n=0}^{+\\infty} n P( N = n )\\quad \\text{si $X$ y $N$ son independientes} \\\\ &amp; = &amp; \\mathbb{E}[ N ] \\mathbb{E}[ X ] \\end{eqnarray*}\\] La distribución acumulada del reclamo total \\(S\\) tiene la forma: \\[\\begin{eqnarray*} F_S( s ) &amp; = &amp; P( S \\leq s ) \\\\ &amp; = &amp; P\\left( \\sum\\limits_{i=1}^N X_i \\leq s \\right) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} P\\left( \\sum\\limits_{i=1}^n X_i \\leq s \\middle| N = n \\right) P( N = n )\\quad \\text{utilizando la probabilidad condicional} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} P\\left( \\sum\\limits_{i=1}^n X_i \\leq s \\right) p_n\\quad \\text{si $X_i$ y $N$ son independientes} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} F_{X_1} \\star \\cdots \\star F_{X_n}( s ) p_n\\quad \\text{distribución de la suma de variables aleatorias} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} F^{\\star n}_{X}( s ) p_n\\quad \\text{si $\\{X_i\\}$ son idénticamente distribuidas} \\\\ \\end{eqnarray*}\\] tomando \\(F^{\\star 0}_{X}( s ) = 1\\) 4.5.1 Algoritmo de simulación La variable del reclamo total \\(S\\) puede ser simulada mediante el siguiente método montecarlo. Si \\(N\\) sigue una ley discreta \\(f_N\\) y cada valor severidad \\(X\\) son idénticamente distribuidos con ley \\(f_X\\). Seleccionar el número de simulaciones \\(m\\), Se genera una muestra de tamaño \\(m\\) de variables \\(N_1, \\ldots, N_m\\) con ley \\(f_N\\), Se genera para cada \\(i \\in \\{1,\\ldots,m\\}\\) una muestra de tamaño \\(N_i\\) de variables aleatorias \\(X_{i,1}, \\ldots X_{i,N_i}\\) con ley \\(f_X\\), Se calcula los reclamos totales \\(S_1, \\ldots, S_m\\) para cada simulación \\(i = \\{1, \\ldots, m\\}\\), mediante la siguiente suma \\(S_i = \\sum\\limits_{j=1}^{N_i} X_{i,j}\\). En el lenguaje de programación R, este método de simulación puede ser fácilmente implementado, como ya lo hemos realizado, utilizando las funciones de aplicación vectorial sapply y lapply. Ejemplo 4.3 Consideramos el caso de un modelo colectivo para el cuál el conteo de siniestros \\(N \\rightsquigarrow Pois( \\lambda )\\) y la distribución de cada uno de los reclamos \\(\\{X_i\\}_{i\\in \\N}\\), está dada por la misma distribución de probabilidad \\(X \\rightsquigarrow LN( \\mu, \\sigma )\\), siendo además cada uno de los reclamos indepencientes entre si. # 1. selección de simulaciones m &lt;- 1e4 # 2. especificación de los parámetros para las distribuciones u &lt;- 5 s &lt;- 2 l &lt;- 3 # 3. simulación del conteo de siniestros N &lt;- rpois( n = m, lambda = l ) # 4. simulación de la severidad de los reclamos X &lt;- lapply( N, FUN = function( n ) rlnorm( n, meanlog = u, sdlog = s ) ) # 5. reclamo total, agregación por cada simulación S &lt;- sapply( X, FUN = function( x ) sum( x, na.rm = TRUE ) ) Es de notar que una algoritmo como el descrito tiene una falencia cuando la frecuencia de siniestros es poco observada, esto sucede cuando la probabilidad \\(P( N = 0 )\\) es alta y por tal razón para generar suficientes reclamos y así poder tener cálculos con una buena aproximación numérica, con el uso de simulaciones se necesitará muchas simulaciones. Es interesante observar que el modelo colectivo puede ser muchas veces calculado de forma similar a un modelo individual, para ciertos casos particulares. Por ejemplo, si consideramos el caso cuando la variable aleatoria del conteo de siniestros \\(N \\rightsquigarrow Bin( n, p )\\) sigue una distribución binomial con parámetros \\(n\\) y \\(p\\) y los reclamos individuales \\(\\{ X_i \\}\\) son i.i.d. A partir de esto, el reclamo total \\(S\\) puede ser expresado de dos formas \\[\\begin{equation} S = \\sum\\limits_{k=0}^{N} X_k = \\sum\\limits_{k=0}^n B_k X_k \\end{equation}\\] donde \\(B_k \\rightsquigarrow Ber( p )\\) y es independientes de \\(X_k\\). Así el modelo colectivo se transforma en un modelo individual con \\(n\\) constante y valores de reclamos individuales dados por la variable aleatoria \\(Y_k = B_k X_k\\). Para este caso en particular \\[\\begin{eqnarray*} \\mathbb{E}[ S ] &amp; = &amp; \\mathbb{E}\\left[ \\sum\\limits_{k=0}^{n} B_k X_k \\right] \\\\ &amp; = &amp; \\sum\\limits_{k=0}^{n} \\mathbb{E}\\left[ B_k X_k \\right] \\\\ &amp; = &amp; n \\mathbb{E}[ B X ] \\\\ &amp; = &amp; n \\mathbb{E}[ B ] \\mathbb{E}[ X ] \\\\ &amp; = &amp; n p \\mathbb{E}[ X ] \\end{eqnarray*}\\] así mismo, \\[\\begin{eqnarray*} \\mathbb{V}[ S ] &amp; = &amp; n \\mathbb{V}[ B X ] \\\\ &amp; = &amp; n \\left( \\mathbb{E}[ B^2 X^2 ] - \\mathbb{E}[ B X ]^2 \\right) \\\\ &amp; = &amp; n \\left( \\mathbb{E}[ B^2 ] \\mathbb{E}[ X^2 ] - \\mathbb{E}[ B ]^2 \\mathbb{E}[ X ]^2 \\right) \\\\ &amp; = &amp; n \\left( p \\mathbb{E}[ X^2 ] - p^2 \\mathbb{E}[ X ]^2 \\right) \\\\ &amp; = &amp; n \\left( p \\mathbb{E}[ X^2 ] - p \\mathbb{E}[ X ]^2 + p \\mathbb{E}[ X ]^2 - p^2 \\mathbb{E}[ X ]^2 \\right) \\\\ &amp; = &amp; n \\left( p \\mathbb{V}[ X ] + p ( 1 - p ) \\mathbb{E}[ X ]^2 \\right) \\\\ &amp; = &amp; n \\left( \\mathbb{E}[B] \\mathbb{V}[ X ] + \\mathbb{V}[B] \\mathbb{E}[ X ]^2 \\right) \\end{eqnarray*}\\] Ejemplo 4.3 Hacemos uso del algoritmo de simulación, pero bajo la consideración anterior donde el conteo de siniestros \\(N \\rightsquigarrow Bin( n, p )\\), en algunos casos se puede considerar \\(n\\) como el número de pólizas vendidas, esto supone que solo se presenta un reclamo por póliza. Por su parte los reclamos consideraremos \\(X_i \\rightsquigarrow LN( \\mu, \\sigma )\\), para todo \\(i \\in \\{1,\\ldots,n\\}\\). Si consideramos generar la simulación como un modelo individual, generamos variables aleatorias \\(B_i \\rightsquigarrow Ber(p)\\), para todo \\(i \\in \\{1,\\ldots,n\\}\\). m &lt;- 1e4 n &lt;- 1000 p &lt;- 0.2 mu &lt;- 5 sigma &lt;- 2 B &lt;- lapply( 1:m, FUN = function( i ) rbinom( n, size = 1, prob = p ) ) X &lt;- lapply( 1:m, FUN = function( i ) rlnorm( n, meanlog = mu, sdlog = sigma ) ) S &lt;- sapply( 1:m, FUN = function( i ) sum( B[[ i ]] * X[[ i ]], na.rm = TRUE ) ) EeS &lt;- mean( S ) ES &lt;- n * p * exp( mu + 0.5 * sigma^2 ) \\[\\begin{eqnarray*} \\mathbb{E}[S] = n p e^{ \\mu + \\frac{1}{2} \\sigma^2 } &amp; = &amp; 219326.6317, \\\\ \\overline{S} = \\frac{1}{m} \\sum\\limits_{i=1}^m S_i &amp; = &amp; 219705.4078, \\end{eqnarray*}\\] Es importante observar que si la frecuencia de reclamos es superior a \\(1\\), sea este por póliza, individuo o en general por unidad asegurada, la aproximación anterior no es la correcta si no se realiza un ajuste al valor \\(n\\) que es el número máximo de siniestros. Además, hay un gasto innecesario de valores simulados de reclamos \\(X_i\\) ya que algunos se multiplicaran por \\(B_i\\), la cual solo toma valores \\(\\{0,1\\}\\). 4.6 Modelos mixtos En algunos casos en particular se considera un modelo de agregación que es una mixtura entre el modelo individual y el modelo colectivo. Se parte de considerar un número \\(n\\) de unidades aseguradas donde para cada unidad \\(i \\in \\{1, \\ldots, n\\}\\), se considera que puede presentar una cantidad de reclamos dados por una variable aleatoria discreta \\(N_i\\), y así para cada presentar un número de reclamos \\(X_{i,1}, \\ldots, X_{i,N_i}\\). Así el reclamo total viene dado por la expresión \\[\\begin{equation} S = \\sum\\limits_{i=1}^n \\sum\\limits_{j=1}^{N_i} X_{i,j} \\end{equation}\\] 4.7 Modelos con variables explicativas En algunos casos más generales, donde la población presenta heterogeneidad respecto del riesgo al cual están expuestos, como también de las dimensiones de sus reclamos, se considera que existen variables aleatorias adicionales \\(Y_1, \\ldots, Y_n\\) que determinan el número de reclamos \\(N\\) y el valor de los siniestros \\(\\{X_i\\}\\). Es decir no hay independencia entre \\(\\{Y_j\\}\\) y \\(N\\) así como tampoco entre \\(\\{Y_j\\}\\) y \\(\\{X_i\\}\\). Es así que un modelo colectivo \\(S = \\sum\\limits_{i=1}^N X_i\\) su estudio, estimación y tarificación debe ser realizada de forma condicional respecto de las variables aleatorias explicativas \\(\\{Y_j\\}\\), \\[\\begin{equation} \\mathbb{E}[ S ] = \\mathbb{E}\\left[ \\mathbb{E}\\left[ S \\middle| Y_1, \\ldots, Y_n \\right] \\right] \\end{equation}\\] de donde es necesario estimar cada una de las esperanzas condicionadas \\(\\mathbb{E}\\left[ S \\middle| Y_1, \\ldots, Y_n \\right]\\). En la práctica las variables explicativas \\(\\{ Y_j \\}\\) suelen ser seleccionadas para caracterizar el perfil de riesgo de cada cliente. Para su selección se suele utilizar algunos criterios de tipo económico, financiero, legal y estadístico. 4.8 Aplicación del deducible En muchas ocasiones según las condiciones de los contratos de seguro y el apetito de riesgo del asegurador, se configura funciones deducibles sobre los reclamos. # 1. selección de simulaciones m &lt;- 1e4 # 2. especificación de los parámetros para las distribuciones u &lt;- 5 s &lt;- 2 l &lt;- 3 # 3. se especifica la función deducible D &lt;- function( x, d, M ) { return( min( max( x - d, 0 ), M ) ) } # 4. simulación del conteo de siniestros N &lt;- rpois( n = m, lambda = l ) # 5. simulación de la severidad de los reclamos X &lt;- lapply( N, FUN = function( n ) rlnorm( n, meanlog = u, sdlog = s ) ) # 6. se aplica el deducible a los reclamos DX &lt;- lapply( X, FUN = function( x ) sapply( x, FUN = function( y ) D( y, 10, 1000 ) ) ) # 7. reclamo total, agregación por cada simulación S &lt;- sapply( DX, FUN = function( x ) ifelse( length( x ) == 0, 0, sum( x, na.rm = TRUE ) ) ) \\(S_1, \\ldots, S_m \\rightsquigarrow F_S\\) FS &lt;- seq( 0, 1, 0.01 ) Sq &lt;- quantile( S, probs = FS ) ES &lt;- mean( S ) plot( Sq, FS, type = &#39;s&#39;, col = &#39;darkgreen&#39; ) abline( v = ES, col = &#39;red&#39; ) Ejemplo 4.4 En este caso en particular estudiaremos la velocidad de convergencia del método resultante del teorema del límite central 2.2. Generaremos una simulación aleatoria de la suma agregada \\(S_n\\) y mostraresmo s m &lt;- 500 n &lt;- 5000 u &lt;- 4 s &lt;- 2 X &lt;- lapply( 1:m, FUN = function( j ) rlnorm( n, meanlog = u, sdlog = s ) ) EX &lt;- exp( u + 0.5 * s^2 ) SDX &lt;- sqrt( ( exp( s^2 ) - 1 ) * exp( 2 * u + s^2 ) ) S &lt;- lapply( X, FUN = function( x ) cumsum( x ) ) ES &lt;- sapply( 1:n, FUN = function( i ) mean( sapply( 1:m, FUN = function( j ) S[[ j ]][ i ] ) ) ) VS &lt;- sapply( 1:n, FUN = function( i ) var( sapply( 1:m, FUN = function( j ) S[[ j ]][ i ] ) ) ) NS &lt;- lapply( S, FUN = function( s ) ( s - ES ) / sqrt( abs( VS ) ) ) z &lt;- seq( -4, 4, length.out = 100 ) FSn &lt;- lapply( 1:n, FUN = function( i ) ecdf( sapply( 1:m, FUN = function( j ) NS[[ j ]][ i ] ) )( z ) ) D &lt;- sapply( FSn, FUN = function( Fn ) max( abs( Fn - pnorm( z ) ) ) ) C &lt;- 0.015 # C &lt;- 1 / sqrt( 2 * pi ) rho &lt;- exp( 3 * u + 3^2 * s^2 / 2 ) Bn &lt;- C * rho / ( SDX^3 * sqrt( 1:n ) ) plot( 1:n, D, pch = 16, cex = 0.5, type = &#39;l&#39;, lwd = 2, lty = 1, ylim = c( 0, 0.5 ), col = &#39;royalblue4&#39; ) points( 1:n, Bn, type = &#39;l&#39;, lty = 1, col = &#39;red&#39; ) l &lt;- 3 n &lt;- 300 dt &lt;- rexp( n = n, rate = 1 / l ) t &lt;- c( 0, cumsum( dt ) ) dN &lt;- sapply( dt, FUN = function( w ) rpois( 1, lambda = l * w ) ) N &lt;- c( 0, cumsum( dN ) ) sh &lt;- 3 rt &lt;- 2 X &lt;- lapply( dN, FUN = function( n ) rgamma( n, shape = sh, rate = rt ) ) dS &lt;- sapply( X, FUN = function( x ) sum( x ) ) S &lt;- c( 0, cumsum( dS ) ) plot( t, N, type = &#39;s&#39; ) plot( t, S, type = &#39;s&#39; ) 4.9 Algoritmo de Panjer 4.10 Estimación usando la transformada de Fourier Para el caso del modelo individual de riesgos podemos hacer uso de la siguiente estimación de la densidad de probabilidad de los reclamos totales \\(S\\), utilizando la transformada de Fourier. En la implementación numérica se utiliza la transformada de Fourier rápida (FFT). \\[\\begin{equation} \\mathcal{F}\\left( f_S \\right) = \\mathcal{F}\\left( f^{\\star n}_X \\right) = \\mathcal{F}\\left( f_X \\right)^{n} \\end{equation}\\] Por tanto de esta relación como la transformada de Fourier es invertible, existe \\(\\mathcal{F}^{-1}\\). Resulta el siguiente método para calcular la densidad de \\(S\\) \\[\\begin{equation} f_S = \\mathcal{F}^{-1}\\left( \\mathcal{F}\\left( f_S \\right) \\right) = \\mathcal{F}^{-1}\\left(\\mathcal{F}\\left( f_X \\right)^{n} \\right) \\end{equation}\\] En conclusión para determinar la densidad de probabilidad de \\(S\\) basta conocer la transformada de Fourier de la distribución de los reclamos individuales, multiplicarla por si misma \\(n\\) veces y tomar la transformada de Fourier inversa. \\[\\begin{eqnarray*} \\mathcal{F}\\left( f_S \\right) &amp; = &amp; \\mathcal{F}\\left( \\sum\\limits_{n=0}^{+\\infty} p_n f_X^{\\star n} \\right) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} p_n \\mathcal{F}\\left( f_X^{\\star n} \\right) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} p_n \\mathcal{F}\\left( f_X \\right)^{n} \\end{eqnarray*}\\] como consecuencia \\[\\begin{eqnarray*} f_S &amp; = &amp; \\mathcal{F}^{-1}\\left( \\mathcal{F}\\left( f_S \\right) \\right)\\\\ &amp; = &amp; \\mathcal{F}^{-1}\\left( \\sum\\limits_{n=0}^{+\\infty} p_n \\mathcal{F}\\left( f_X \\right)^{n} \\right)\\quad \\text{Una sola inversión} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} p_n \\mathcal{F}^{-1}\\left( \\mathcal{F}\\left( f_X \\right)^{n} \\right)\\quad \\text{Una inversión por cada término en la suma} \\end{eqnarray*}\\] "],["tarificación.html", "Capítulo 5 Tarificación 5.1 Medidas de riesgo 5.2 Prima 5.3 Segmentación 5.4 Deducibles", " Capítulo 5 Tarificación 5.1 Medidas de riesgo Definición 2.4 (Medida de riesgo coherente) Una medida de riesgo coeherente es una función \\(\\zeta: \\mathbb{R} \\longrightarrow \\mathbb{R}\\), que satisface la siguientes propiedades: Homogenidad positiva, para cualquier \\(a &gt; 0\\) \\[\\begin{equation} \\zeta( a X ) = a \\zeta( X ) \\end{equation}\\] Invarianza ante las traslaciones, para cualquier \\(a &gt; 0\\) \\[\\begin{equation} \\zeta( \\alpha X + a ) = \\zeta( \\alpha X ) + a \\end{equation}\\] Monotonicidad, Si \\(X \\leq Y\\) \\[\\begin{equation} \\zeta( X ) \\leq \\zeta( Y ) \\end{equation}\\] Sub-aditividad \\[\\begin{equation} \\zeta( X + Y ) \\leq \\zeta( X ) + \\zeta( Y ) \\end{equation}\\] Definición 5.1 (Valor en riesgo) Dada una variable aleatoria a valores reales \\(X\\), el valor en riesgo (value at risk) de \\(X\\) al nivel de probabilidad \\(\\alpha \\in (0,1)\\) está dado por \\[\\begin{equation} VaR_{\\alpha}( X ) = \\inf\\left\\{ x \\in \\mathbb{R} \\middle| F_X( x ) &gt; \\alpha \\right\\} \\end{equation}\\] Proposición 5.1 Si la función de distribución acumulada \\(F_X\\) es contínua, entonces \\(VaR_{\\alpha}( X ) = F_X^{-1}( \\alpha )\\). Por otra parte, \\(VaR_{\\alpha}\\) para cualquier \\(\\alpha\\) no es una medida de riesgo sub-additiva. Definición 5.2 (Valor en riesgo en la cola) Dada una variable aleatoria a valores reales \\(X\\), el valor en riesgo en la colas (tail value at risk) de \\(X\\) al nivel de probabilidad \\(\\alpha \\in (0,1)\\) está dado por \\[\\begin{equation} TVaR_{\\alpha}( X ) = \\frac{1}{1-\\alpha} \\int\\limits_{\\alpha}^1 VaR_u( X )\\ du \\end{equation}\\] Proposición 5.2 (Coherencia de la medida TVaR) La medida de riesgo \\(TVaR_{\\alpha}\\) es una medida de riesgo coherente si la variable aleatoria sobre la cual se mide es una variable aleatoria continua. Definición 5.3 (Esperanza condicional en la cola) Dada una variable aleatoria a valores reales \\(X\\), la esperanza condicional en la cola (conditional tail expectation) de \\(X\\) al nivel de probabilidad \\(\\alpha \\in (0,1)\\) está dado por \\[\\begin{equation} CTE_{\\alpha}( X ) = \\mathbb{E}\\left[ X \\middle| X &gt; VaR_{\\alpha}( X ) \\right] \\end{equation}\\] Proposición 5.3 Si la función de distribución acumulada \\(F_X\\) de la variable aleatoria \\(X\\) es continua, entonces se tiene la siguiente igualdad \\[\\begin{equation} CTE_{\\alpha}( X ) = TVaR_{\\alpha}( X ) \\end{equation}\\] Definición 5.4 (Valor en riesgo condicionado) Dada una variable aleatoria a valores reales \\(X\\), el valor en riesgo condicionado (conditional value at risk) de \\(X\\) al nivel de probabilidad \\(\\alpha \\in (0,1)\\) está dado por \\[\\begin{equation} CVaR_{\\alpha}( X ) = \\mathbb{E}\\left[ X - VaR_{\\alpha}( X ) \\middle| X &gt; VaR_{\\alpha}( X ) \\right] = CTE_{\\alpha}( X ) - VaR_{\\alpha}( X ) \\end{equation}\\] Definición 5.5 (Déficit esperado) Dada una variable aleatoria a valores reales \\(X\\), el déficit esperado (expected shortfall) de \\(X\\) al nivel de probabilidad \\(\\alpha \\in (0,1)\\) está dado por \\[\\begin{equation} ES_{\\alpha}( X ) = \\mathbb{E}\\left[ \\max\\left( X - VaR_{\\alpha}( X ), 0 \\right) \\right] \\end{equation}\\] Definición 5.6 (Valor en riesgo entrópico) Dada una variable aleatoria a valores reales \\(X\\), el valor en riesgo entrópico (entropic value at risk) de \\(X\\) al nivel de probabilidad \\(\\alpha \\in (0,1)\\) está dado por \\[\\begin{equation} EVaR_{\\alpha}( X ) = \\inf\\left\\{ \\frac{1}{t} \\ln\\left( \\frac{M_X( t )}{1 - \\alpha} \\right) \\middle| t &gt; 0 \\right\\} \\end{equation}\\] Proposición 5.4 (Coherencia de la medida EVaR) La medida de riesgo \\(EVaR_{\\alpha}\\) es una medida de riesgo coherente. u &lt;- 4 s &lt;- 0.5 n &lt;- 1e4 X &lt;- rlnorm( n, meanlog = u, sdlog = s ) k &lt;- seq( 0, 1, 0.2 ) VaRX &lt;- quantile( X, probs = k, names = FALSE ) TVaRX &lt;- sapply( 1:length( VaRX ), FUN = function( i ) ifelse( k[ i ] &lt; 1, ( 1 / ( 1 - k[ i ] ) ) * mean( X * ( X &gt; VaRX[ i ] ) ), max( X ) ) ) hist( X, breaks = 100, xlim = c( 0, 1.1 * max( X ) ) ) abline( v = VaRX, col = &#39;red&#39; ) hist( X, breaks = 100, xlim = c( 0, 1.1 * max( X ) ) ) abline( v = TVaRX, col = &#39;blue&#39; ) plot( k, VaRX, ylim = c( 0, 1e3 ) ) points( k, TVaRX, col = &#39;red&#39; ) 5.2 Prima La prima es la cantidad de dinero que un individuo o entidad pagan por una póliza de seguro, la cual está diseñada para cubrir ciertos riesgos personales o comerciales. La determinación de las primas por parte del asegurador hace uso de la mutualización del riesgo y diversificación, para así poder asumir la transferencia del riesgo por parte de sus asegurados. Así por tanto, es deseable que cualquier método que se utilice para la estimación de primas, se satisfaga, algunas propiedades importantes. Sin consideramos dos riesgos a cubrir \\(S_1\\) y \\(S_2\\), entonces la función que estima \\(\\rho\\) las primas sería aconsejable satisfaga las siguientes propiedades. Si se decide cobrir por compleo dos riesgos \\(S_1\\) y \\(S_2\\) en un mismo producto, el valor de la prima deberá ser menor o igual al valor que se resultaría de cubrir cada uno de los riesgos con productos separados. \\[\\begin{equation} \\rho( S_1 + S_2 ) \\leq \\rho( S_1 ) + \\rho( S_2 ) \\end{equation}\\] El asumir mayor riesgo debe tener como consecuencia el aumento de la prima \\[\\begin{equation} \\rho( S_1 ) \\leq \\rho( S_1 + S_2 ) \\end{equation}\\] Esta propiedad implica que al configurar un producto de seguro con mejor cobertura, se espera una prima de mayor costo. Si el riesgo a cubrir está limitado, es decir \\(P( S \\leq M ) = 1\\), para un valor \\(M &gt; 0\\), entonces jamás la prima será superior a \\(M\\) \\[\\begin{equation} \\rho( S ) \\leq M \\end{equation}\\] Esto se traduce a que ningún asegurado estará interesado en adquirir una póliza para cubrir un riesgo por encima del valor total asegurado. Es así que hay algunos principios para la estimación de primas, aquí citamos algunos de los más conocidos: Prima neta, o prima pura de riesgo \\[\\begin{equation} \\rho( S ) = \\mathbb{E}[S] \\end{equation}\\] Prima de riesgo con recargo sobre la esperanza matemática \\[\\begin{equation} P = \\rho( S ) = (1 + \\rho) \\mathbb{E}[S] \\end{equation}\\] Prima de riesgo con recargo sobre la varianza \\[\\begin{equation} P = \\rho( S ) = \\mathbb{E}[S] + \\rho \\mathbb{V}[S] \\end{equation}\\] Prima de riesgo con recargo sobre la desviación \\[\\begin{equation} P = \\rho( S ) = \\mathbb{E}[S] + \\rho \\sqrt{\\mathbb{V}[S]} \\end{equation}\\] Prima de riesgo con principio exponencial para \\(t &gt; 0\\) \\[\\begin{equation} P = \\rho( S ) = \\frac{1}{2} \\mathbb{E}\\left[e^{tS}\\right] = \\frac{1}{2} M_N\\big( \\ln M_X( t ) \\big) \\end{equation}\\] Prima de percentiles para un valor de confianza \\(\\alpha \\in [0,1]\\) o prima de valor en riesgo \\(VaR_\\alpha\\) \\[\\begin{equation} P = \\rho( S ) = VaR_\\alpha( S ) = F_S^{-1}( \\alpha ) \\end{equation}\\] Prima de valor en riesgo en la cola (Tail Value at Risk) \\(TVaR_\\alpha\\). Es el promedio uniforme de todos los valores en riesgo \\(VaR_u\\), con \\(u \\geq \\alpha\\). \\[\\begin{equation} P = \\rho( S ) = TVaR_\\alpha( S ) = \\frac{1}{1-\\alpha} \\int\\limits_{\\alpha}^1 VaR_u( S )\\ du \\end{equation}\\] \\(X_i \\rightsquigarrow Gamma( \\alpha_i, \\theta )\\), para \\(i \\in \\{1,\\ldots,n\\}\\), \\(S \\rightsquigarrow Gamma\\left( \\sum\\limits_{i=1}^n \\alpha_i \\right)\\) n &lt;- 1000 a &lt;- runif( n, 5, 10 ) A &lt;- sum( a ) theta &lt;- 4 EX &lt;- a * theta VX &lt;- a * theta^2 ES &lt;- sum( EX ) VS &lt;- sum( VX ) SDS &lt;- sqrt( VS ) m &lt;- 1e5 S &lt;- rgamma( m, shape = A, scale = theta ) alpha &lt;- 0.95 P &lt;- ES P &lt;- mean( S ) P_avg &lt;- ( 1 + alpha ) * ES P_avg &lt;- ( 1 + alpha ) * mean( S ) P_var &lt;- ES + alpha * VS P_var &lt;- mean( S ) + alpha * var( S ) P_sde &lt;- ES + alpha * SDS P_sde &lt;- mean( S ) + alpha * sd( S ) VaRS &lt;- qgamma( alpha, shape = A, scale = theta ) P_VaR &lt;- VaRS P_VaR &lt;- quantile( S, probs = alpha ) P_TVaR &lt;- ( 1 / ( 1 - alpha ) ) * ( A * theta ) * ( 1 - pgamma( VaRS, shape = A + 1, scale = theta ) ) P_TVaR &lt;- ( 1 / ( 1 - alpha ) ) * integrate( f = function( u ) qgamma( u, shape = A, scale = theta ), alpha, 1 )$value P_TVaR &lt;- mean( sapply( runif( m, alpha, 1 ), FUN = function( k ) qgamma( k, shape = A, scale = theta ) ) ) I &lt;- as.numeric( S &gt; VaRS ) P_TVaR &lt;- mean( S * I ) / mean( I ) n &lt;- 1e3 S &lt;- rgamma( n, shape = A, scale = theta ) smin &lt;- qgamma( 0.001, shape = A, scale = theta ) smax &lt;- qgamma( 0.999, shape = A, scale = theta ) s &lt;- seq( smin, smax, length.out = 1000 ) Fns &lt;- ecdf( S )( s ) Fs &lt;- pgamma( s, shape = A, scale = theta ) alph &lt;- 0.02 er &lt;- sqrt( log( 2 / alph ) / ( 2 * n ) ) mean( abs( Fs - Fns ) &gt; er ) ## [1] 0 plot( s, Fs, type = &#39;l&#39;, ylim = c( -er, 1 + er ) ) points( s, Fns - er, col = &#39;red&#39;, type = &#39;l&#39; ) points( s, Fns + er, col = &#39;red&#39;, type = &#39;l&#39; ) hist( pgamma( S, shape = A, scale = theta ), breaks = 5 ) 5.3 Segmentación En muchas ocasiones es necesario tener en cuenta algunas características asociadas al riesgo de asegurado, de tal forma que la prima sea lo más eficiente y adecuado según el riesgo cubierto y las características del mismo. La idea de segmentar la población es obtener grupos homogéneos con riesgos similares. 5.4 Deducibles El principal objetivo de los deducibles, es el reducir los costos de atención de los reclamos usualmente mediante la exclusión de siniestros usualmente numerosos debidos a reclamos pequeños. En otras ocasiones, los deducibles están diseñados para incentivar al asegurado para evitar y prevenir siniestros por cierto monto límite. Prevención de la pérdida - as the compensation is reduced by a deductible the retention of the insured is positive; This makes out a good case for avoiding the loss; Reducción de la pérdida - the fact a deductible puts the policyholder at risk of obtaining only partial compensation provides an economic incentive to reduce the extend of the damage; Evitar pequeñas pérdidas - where administration costs are dominant for small losses, the administration costs will often exceed the loss itself, and hence the insurance company would want the policyholder to pay it himself; Reducción de la prima - premium reduction can be an important aspect for the policyholders, they may prefer to take a higher deductible to get a lower premium. n &lt;- 1e5 l &lt;- 3 dat &lt;- data.table( id = 1:n, k = rpois( n, lambda = l ) ) datf &lt;- dat[ , list( fk = .N ), by = k ] setorder( datf, k ) datf[ , fks := shift( fk, n = 1 ) ] datf[ , gk := k * fk / fks ] datf &lt;- datf[ !is.na( gk ) ] plot( datf$k, datf$gk ) dflm &lt;- lm( formula = gk ~ k, data = datf, method = &#39;qr&#39; ) a &lt;- coef( dflm )[ 2 ] b &lt;- coef( dflm )[ 1 ] p0 &lt;- exp( -b ) k &lt;- seq( 1, 100, 1 ) p &lt;- p0 * cumprod( c( 1, a + b / k ) ) sum( p ) ## [1] 2.455944 k &lt;- seq( 0, 100, 1 ) sum( dpois( k, lambda = l ) ) ## [1] 1 EN &lt;- sum( k * p ) D &lt;- function( x, d ) return( max( x - d, 0 ) ) d &lt;- 100 u &lt;- 6 s &lt;- 0.3 n &lt;- 1e3 X &lt;- rlnorm( n, meanlog = u, sdlog = s ) DX &lt;- sapply( X, FUN = D, d ) x &lt;- seq( 0, 1e3, length.out = 500 ) FXe &lt;- ecdf( X ) FDXe &lt;- ecdf( DX ) Fx &lt;- sapply( x, FUN = function( x ) FXe( x ) ) FDx &lt;- sapply( x, FUN = function( x ) FDXe( x ) ) plot( x, Fx, type = &#39;s&#39; ) points( x, FDx, type = &#39;s&#39;, col = &#39;blue&#39; ) D &lt;- function( x, M ) return( min( x, M ) ) M &lt;- 600 u &lt;- 6 s &lt;- 0.3 n &lt;- 1e4 X &lt;- rlnorm( n, meanlog = u, sdlog = s ) DX &lt;- sapply( X, FUN = D, M ) x &lt;- seq( 0, 1e3, length.out = 500 ) FXe &lt;- ecdf( X ) FDXe &lt;- ecdf( DX ) Fx &lt;- sapply( x, FUN = function( x ) FXe( x ) ) FDx &lt;- sapply( x, FUN = function( x ) FDXe( x ) ) plot( x, Fx, type = &#39;s&#39; ) points( x, FDx, type = &#39;s&#39;, col = &#39;blue&#39; ) "],["modelos-lineales-generalizados-glm.html", "Capítulo 6 Modelos lineales generalizados (GLM) 6.1 Familia exponencial 6.2 Modelo lineal generalizado (GLM)", " Capítulo 6 Modelos lineales generalizados (GLM) 6.1 Familia exponencial De forma amplia, un modelo lineal generalizado aprovecha algunas propiedades de la distribución de probabilidad \\(f_X\\) de la variable (vector) aleatoria \\(X : \\Omega \\longrightarrow \\mathbb{R}^n\\) en estudio. Se parte de asumir que \\(X\\) tiene una distribución dentro de la familia exponencial, es decir, existen: Un conjunto admisible de parámetros \\(\\Theta \\subset \\mathbb{R}^m\\), así cada parámetro \\(\\theta = ( \\theta_1, \\ldots, \\theta_m )^T \\in \\Theta\\), Una función \\(T: \\mathbb{R}^n \\longrightarrow \\mathbb{R}^p\\) Una función \\(A: \\mathbb{R}^m \\longrightarrow \\mathbb{R}\\) Una función \\(\\eta: \\mathbb{R}^m \\longrightarrow \\mathbb{R}^p\\) de tal forma que: \\[\\begin{equation} f_X( x \\mid \\theta ) = h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right) \\end{equation}\\] Al tener varias observaciones independientes de la misma variable aleatoria \\(x_1, \\ldots, x_N\\), su distribución conjunta se puede expresar como: \\[\\begin{equation} f_{X_1,\\ldots,X_N}( x_1, \\ldots, x_N \\mid \\theta ) = \\prod\\limits_{i=1}^N f_{X_i}( x_i \\mid \\theta ) \\end{equation}\\] La función de verosimilitud logarítmica, “log-likelihood”, toma una forma específica, la cual puede ser trabajada con comodidad para la maximización de verosimilitud. \\[\\begin{eqnarray*} \\ell( \\theta ) &amp; = &amp; \\log f_{X_1,\\ldots,X_N}( x_1, \\ldots, x_N \\mid \\theta ) \\\\ &amp; = &amp; \\sum\\limits_{i=1}^N \\log f_{X_i}( x_i \\mid \\theta ) \\\\ &amp; = &amp; \\sum\\limits_{i=1}^N \\left( \\log h( x_i ) + \\eta( \\theta ) \\cdot T( x_i ) - A( \\theta ) \\right) \\end{eqnarray*}\\] lo que podemos observar es que existe una casi linealidad respecto de la variable \\(\\theta\\). Esta propiedad permite obtener un problema de maximización de verosimilitud que puede ser atacado con varios paquetes de optimización numérica de una forma eficiente. \\[\\begin{equation} \\underset{\\theta \\in \\Theta}{\\sup} \\ell( \\theta ) = \\underset{\\theta \\in \\Theta}{\\sup} \\sum\\limits_{i=1}^N \\left( \\eta( \\theta ) \\cdot T( x_i ) - A( \\theta ) \\right) \\end{equation}\\] Usualmente, este problema se suele atacar mediante la anulación del gradiente de la función objetivo, esto lo realiza la mayor parte de paquetes de software. El sistema a resolver es el siguiente sistema, usualmente no lineal, de dimensión \\(m\\): \\[\\begin{equation} \\frac{\\partial \\ell}{\\partial \\theta_i}( \\theta ) = \\sum\\limits_{i=1}^N \\left( \\frac{\\partial \\eta}{\\partial \\theta_i}( \\theta ) \\cdot T( x_i ) - \\frac{\\partial A}{\\partial \\theta_i}( \\theta ) \\right) = 0,\\qquad \\forall i \\in \\{1,\\ldots, m\\} \\end{equation}\\] En la familia exponential tenemos las siguientes distribuciones: normal, exponencial, log-normal, gamma, chi-cuadrado, beta, Dirichlet, Bernoulli, Poisson, binomial, geométrica, binomial negativa, von Mises-Fisher, Pareto con valor mínimo conocido, Gaussiana inversa, gamma inversa, multinomial con número \\(n\\) conocido, Wishart, categórica. Por la condición de normalización de la densidad de probabilidad \\(f_X\\), se satisface la igualdad: \\[\\begin{eqnarray*} 1 &amp; = &amp; \\int\\limits f_X( x \\mid \\theta )\\ dx \\\\ 1 &amp; = &amp; \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right)\\ dx \\\\ 1 &amp; = &amp; \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) \\right) \\exp\\left( - A( \\theta ) \\right)\\ dx \\\\ 1 &amp; = &amp; \\exp\\left( - A( \\theta ) \\right) \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) \\right)\\ dx \\\\ \\exp\\left( A( \\theta ) \\right) &amp; = &amp; \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) \\right)\\ dx \\\\ A( \\theta ) &amp; = &amp; \\log\\left( \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) \\right)\\ dx \\right) \\end{eqnarray*}\\] de donde se determina precisamente la forma que tiene la función \\(A\\) y su el papel como factor de normalización para la distribución de la variable aleatoria \\(X\\). Así mismo, podemos establecer una cierta relación para la espera de los valores observados de \\(T(X)\\) en función de \\(A\\) \\[\\begin{eqnarray*} 0 &amp; = &amp; \\frac{\\partial}{\\partial \\theta_i} 1 \\\\ 0 &amp; = &amp; \\frac{\\partial}{\\partial \\theta_i} \\int\\limits f_X( x \\mid \\theta )\\ dx \\\\ 0 &amp; = &amp; \\int\\limits h( x ) \\frac{\\partial}{\\partial \\theta_i} \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right)\\ dx \\\\ 0 &amp; = &amp; \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right) \\left( \\frac{\\partial \\eta}{\\partial \\theta_i}( \\theta ) \\cdot T( x ) - \\frac{\\partial A}{\\partial \\theta_i}( \\theta ) \\right)\\ dx \\\\ 0 &amp; = &amp; \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right) \\frac{\\partial \\eta}{\\partial \\theta_i}( \\theta ) \\cdot T( x )\\ dx \\\\ &amp; &amp; - \\frac{\\partial A}{\\partial \\theta_i} ( \\theta ) \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right)\\ dx \\\\ 0 &amp; = &amp; \\int \\limits \\frac{\\partial \\eta}{\\partial \\theta_i}( \\theta ) \\cdot T( x ) f_X( x \\mid \\theta )\\ dx - \\frac{\\partial A}{\\partial \\theta_i}( \\theta ) \\int \\limits f_X( x \\mid \\theta )\\ dx \\end{eqnarray*}\\] estamos en la capacidad de concluir que: \\[\\begin{equation} \\mathbb{E}\\left[ \\frac{\\partial \\eta}{\\partial \\theta_i}( \\theta ) \\cdot T( X ) \\right] = \\frac{\\partial A}{\\partial \\theta_i}( \\theta ) \\end{equation}\\] Cuando se da el caso que \\(\\eta\\) y \\(T\\) son las funciones identidad, la relación anterior se reduce a la siguiente igualdad: \\[\\begin{equation} \\mathbb{E}\\left[ X_i \\right] = \\frac{\\partial A}{\\partial \\theta_i}( \\theta ) \\end{equation}\\] 6.2 Modelo lineal generalizado (GLM) Precisamente, un modelo lineal generalizado (GLM por sus siglas en inglés) busca explotar las propiedades de las variables aleatorias que poseen una densidad de probabilidad dada por alguna de la funciones de la familia exponencial. Para más detalles se puede consultar [10]. La idea general es poder describir el comportamiento de una variable aleatoria \\(Y\\) que se presume puede ser descrita por alguna función de la familia exponencial, a partir de otras variables aleatorias \\(X : \\Omega \\longrightarrow \\mathbb{R}^n\\) mediante una función de vínculo \\(g: \\mathbb{R}^q \\longrightarrow \\mathbb{R}^m\\) entre \\(\\theta\\) y \\(X\\), a través del paso por una composición con una función lineal \\(\\beta : \\mathbb{R}^n \\longrightarrow \\mathbb{R}^q\\), de tal forma que: \\[\\begin{equation} \\theta = g( \\beta( X ) ) = g( \\beta X ) \\end{equation}\\] Así, un GLM prescribe una distribución de probabilidad para \\(Y\\) que tendrá la siguiente forma y será dependiente de los parámetros \\(\\beta\\) y las variables explicativas \\(X\\) \\[\\begin{equation} f_Y( y \\mid \\theta ) = f_Y( y \\mid g( \\beta x ) ) = h( y ) \\exp\\left( \\eta( g( \\beta x ) ) \\cdot T( y ) - A( g( \\beta x ) ) \\right) \\end{equation}\\] En la aplicación, el ajuste de un modelo GLM a \\(N \\in \\mathbb{N}\\) observaciones \\(y_1, \\ldots, y_N\\) de la variable aleatoria \\(Y\\) y sus respectivas variables explicativas \\(x_1, \\ldots, x_N\\). Se asume independencias entre las observaciones y se busca maximizar la verosimilitud de los valores observados, pero en función del nuevo parámetro \\(\\beta\\), de ahí la parte lineal del modelo. \\[\\begin{equation} \\ell( \\beta ) = \\sum\\limits_{i=1}^N \\left( \\log h( y_i ) + \\eta( g( \\beta x_i ) ) \\cdot T( y_i ) - A( g( \\beta x_i ) \\right) \\end{equation}\\] En varias ocasiones no todos los parámetros \\(\\theta\\) de la densidad de probabilidad son considerados, sino tan solo una parte de los mismos, los otros parámetros se consideran como un valor constante ya dado o también como un parámetro a determinar. Así, se divide \\(\\theta = ( \\theta_1, \\theta_2 ), \\theta_1 \\in \\mathbb{R}^{m_1}, \\theta_2 \\in \\mathbb{R}^{m_2}, m = m_1 + m_2\\), donde solo se establece una función de vínculo para la primera parte \\(\\theta_1 = g( \\beta X )\\). Esta consideración en muchos casos ayuda a simplificar la formulación del modelo y el costo computacional de estimación. En este contexto la función de verosimilitud tomaría la forma: \\[\\begin{equation} \\ell( \\beta, \\theta_2 ) = \\sum\\limits_{i=1}^N \\left( \\log h( y_i ) + \\eta( g( \\beta x_i ), \\theta_2 ) \\cdot T( y_i ) - A( g( \\beta x_i ), \\theta_2 ) \\right) \\end{equation}\\] Bibliografía "],["series-de-tiempo.html", "Capítulo 7 Series de tiempo", " Capítulo 7 Series de tiempo "],["estimación-de-valores-extremos.html", "Capítulo 8 Estimación de valores extremos", " Capítulo 8 Estimación de valores extremos Definición 8.1 (Familia max-estable) dd Teorema 8.1 (Fisher-Tippett-Gnedenko) Si consideramos una secuencia de variables aleatorias \\(\\{X_i\\}_{i\\in \\mathbb{N}}\\) las mismas son i.i.d, con distribución acumulada \\(F\\). Entonces, si existen dos sucesiones de valores reales \\(\\{a_n\\}_{n \\in \\mathbb{N}}\\) y \\(\\{b_n\\}_{n \\in \\mathbb{N}}\\), tales que \\(a_n &gt; 0, \\forall n \\in \\mathbb{N}\\) y una distribución acumulada no degenerada \\(G\\), de tal forma que: \\[\\begin{equation} \\underset{n \\rightarrow +\\infty}{\\lim} ( F\\left( a_n x + b_n \\right) )^n = G( x ), \\forall x \\in \\mathbb{R} \\end{equation}\\] tenemos que \\(G\\) es una de las siguientes distribuciones acumuladas: Tipo I, una distribución de Gumbel \\(G(x) = \\exp( -\\exp( -x ) ), x \\in \\mathbb{R}\\) Tipo II, una distribución de Frechet \\(G( x ) = \\mathbf{1}_{(0,+\\infty)}( x ) \\exp( -x^{-\\alpha} )\\), para \\(x \\geq 0\\) y \\(\\alpha &gt; 0\\), Tipo III, una distribución de Weibull inversa \\(G(x) = \\mathbf{1}_{(-\\infty,0)}( x ) \\exp( -( -x )^{\\alpha} )\\), para \\(x \\leq 0, \\alpha &gt; 0\\) Teorema 8.2 (Pickands-Balkema-De Haan) Sea \\(F_u\\) la distribución de exceso asociada a la variable aleatoria \\(X\\) y con umbral de condicionamiento \\(u &gt; 0\\). Entonces, para cualquier \\(\\varepsilon \\in \\mathbb{R}\\). \\[\\begin{equation} \\underset{u \\longrightarrow x}{\\lim} \\underset{x &gt; 0}{\\sup} \\left| F_u( x ) - G_{\\varepsilon,\\beta(u)( x )} \\right| = 0 \\end{equation}\\] "],["bibliografía.html", "Capítulo 9 Bibliografía", " Capítulo 9 Bibliografía "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
