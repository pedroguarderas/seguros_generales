[["materia.html", "Matemática Actuarial de los Seguros Generales Capítulo 1 Materia Personal docente Resultados de aprendizaje Contenidos propuestos Referencias bibliográficas Requerimientos informáticos", " Matemática Actuarial de los Seguros Generales 2025-05-28 Capítulo 1 Materia Las presentes notas de curso han sido creadas para la materia Matemática Actuarial de los Seguros Generales la cual es dictada en la Maestría de Ciencias Actuariales que realizan de forma conjunta la “Escuela Politécnica Nacional” (EPN) y la “Pontificia Universidad Católica del Ecuador” (PUCE). Hemos creado estas notas con la motivación de brindar una referencia de la materia y facilitar el aprendizaje a los estudiantes, tratando de conjugar la parte teórica del curso con ejemplos prácticos implementados utilizando el lenguaje R. Este trabajo se ha realizado en colaboración entre Leonardo Vélez y Pedro Guarderas. La motivación y objetivo para haber creado las presentes notas es llegar a generar un buen material de aprendizaje y referencia. Sin embargo, será un placer para nosotros que las lean, critiquen y en especial nos hagan llegar sus observaciones y posibles mejoras. Personal docente El profesor a cargo de la materia es el actuario Leonardo Vélez Aguirre. Como docente de apoyo, especialemnte en la parte informática, también colaborará el matemático Pedro Guarderas. Resultados de aprendizaje Contrastar los criterios de valoración actuarial en los seguros generales, así como elaborar y aplicar las bases técnicas. Aprender a obtener la distribución y momentos correspondientes de la siniestralidad total pagada por el asegurador y por el reasegurador en presencia de franquicias y reaseguro. Utilizar textos informativos y de divulgación científica para el desarrollo de trabajos académicos y el desempeño profesional actuarial. Aplicar adecuadamente las fases y procedimientos de la investigación científica a fin de encauzarla de manera eficiente y tendiente a la excelencia. Desarrollar la capacidad de trabajar en equipo y el sentido de responsabilidad en el cumplimiento de sus responsabilidades. Desarrollar un espíritu crítico y creativo, y respetuoso de su docente y compañeros. Contenidos propuestos Distribuciones compuestas Series de tiempo El Proceso de Riesgo: Distribución clase (a,b) y algoritmo de Panjer, Distribución de siniestralidad agregada Modelos Lineales Generalizados (GLMs): para datos binarios y recuentos Proceso de Tarificación Tarificación a priori: cálculo de la prima pura Tarificación a posteriori: sistemas Bonus-Malus Teoría de la Ruina Referencias bibliográficas Principales libros guía [1], [2], [14], [8], [9], https://nonlifemaths.github.io/. Otras referencias de soporte De utilidad para quien desee profundizar con más detalle en algunos conceptos [11], [17], [15], [12], [5], [6]. GIL FANA: Elementos de Matemáticas para las Ciencias del Seguro. Fundación Mapfre Estudios. 1991 Requerimientos informáticos Lenguaje R Editor de código: RStudio, VScode, … Paquete R actuar [10]. "],["preliminares.html", "Capítulo 2 Preliminares 2.1 Notación matemática 2.2 Consideraciones de programación en R", " Capítulo 2 Preliminares 2.1 Notación matemática \\(\\mathbb{N}\\) el conjunto de los números naturales \\(\\mathbb{N}= \\{0,1,2,\\ldots,\\}\\) \\(\\mathbb{N}^*\\) el conjunto de los números naturales positivos \\(\\mathbb{N}^* = \\mathbb{N}\\setminus \\{0\\} = \\{1,2,3,\\ldots,\\}\\) \\(\\mathbb{Z}\\) el conjunto de los números enteros, \\(\\mathbb{Z}= \\{\\ldots,-2,-1,0,1,2, \\ldots \\}\\) \\(\\mathbb{R}\\) el conjunto de los números reales \\(\\mathbb{R}_+\\) el conjunto de los números reales no negativos \\(\\mathbb{R}_+ = \\{ x \\in \\mathbb{R}\\mid x \\geq 0 \\}\\) \\(\\mathbb{C}\\) el conjunto de los números complejos, \\(\\mathbb{C}= \\mathbb{R}\\oplus i \\mathbb{R}\\) \\(\\overline{\\mathbb{R}} = \\mathbb{R}\\cup \\{ +\\infty \\} \\cup \\{ -\\infty \\}\\) el conjunto de los reales extendido incluyendo los infinitos \\(x \\approx y\\) indica que el valor \\(y\\) es aproximado al valor \\(x\\) \\(f: X \\longrightarrow Y\\) la función que toma valores en \\(X\\) y entrega valores en \\(Y\\) \\(\\sum\\limits_{k=0}^n x_k\\) es la suma de los elementos \\(x_0,\\ldots,x_n\\) de una lista \\([ a, b ] = \\left\\{ x \\in \\mathbb{R}\\mid x \\geq a \\land x \\leq b \\right\\}\\) intervalo cerrado para cualquier \\(a,b \\in \\overline{\\mathbb{R}}\\) \\((a,b) = \\left\\{ x \\in \\mathbb{R}\\mid x &gt; a \\land x &lt; b \\right\\}\\) intervalo abierto para cualquier \\(a,b \\in \\overline{\\mathbb{R}}\\) \\(\\{x_n\\}_{n\\in\\mathbb{N}} = \\left\\{ x_n \\in X \\mid n \\in \\mathbb{N}\\right\\}\\) secuencia en el conjunto \\(X\\), no es más que una función de \\(\\mathbb{N}\\) con valores en \\(X\\) \\(\\underset{x \\rightarrow y}{\\lim} f(x) = a\\) límite de la función \\(f(x)\\) cuando \\(x\\) tiende a \\(y\\). \\(\\inf A\\) es la mayor de las cotas inferiores de \\(A\\). \\(\\sup A\\) es la menor de las cotas superiores de \\(A\\). \\(\\operatorname{Dif}f\\) conjunto de puntos donde la función \\(f\\) es diferenciable. 2.2 Consideraciones de programación en R 2.2.1 Opciones usuales Code options( scipen = 9999 ) options( stringsAsFactors = FALSE ) 2.2.2 Paquetes usuales Code library( actuar ) library( data.table ) library( fExtremes ) library( fitdistrplus ) library( ggplot2 ) library( googledrive ) library( kableExtra ) library( knitr ) library( latex2exp ) library( lubridate ) library( openxlsx ) library( readxl ) library( rmarkdown ) library( shiny ) library( wesanderson ) 2.2.3 Estructuras básicas Para definir una variable utilizamos el operador de asignación &lt;-, también se puede utilizar =. Un vector se define con la función de concatenación c Code x &lt;- c( 1, 2, 3 ) print( x ) ## [1] 1 2 3 También, se puede guardar los elementos en una lista Code x &lt;- list( 1, 2, 3 ) print( x ) ## [[1]] ## [1] 1 ## ## [[2]] ## [1] 2 ## ## [[3]] ## [1] 3 Los elementos de las listas se pueden guardar con nombres. Code x &lt;- list( &#39;a&#39; = 1, &#39;b&#39; = 2, &#39;c&#39; = 3 ) print( x ) ## $a ## [1] 1 ## ## $b ## [1] 2 ## ## $c ## [1] 3 Code x[[ &#39;b&#39; ]] ## [1] 2 Una función se define con la sentencia function Code f &lt;- function( t ) { return( t^2 ) } Si buscamos aplicar una función sobre un vector, podemos utilizar sapply Code y &lt;- sapply( x, FUN = f ) print( y ) ## a b c ## 1 4 9 Code z &lt;- lapply( x, FUN = f ) print( z ) ## $a ## [1] 1 ## ## $b ## [1] 4 ## ## $c ## [1] 9 Para muchas tareas que están relacionadas con el manejo de datos, podemos utilizar las funcionalidades del paquete de R, data.table. Para trabajar con fechas recomendamos utilizar el paquete lubridate. Para trabajar con distribuciones de probabilidad que se utilizan para modelar valores extremos utilizamos fExtremes. Para varias funcionalidades asociadas a la estimación de modelos de pérdida utilizamos actuar. "],["introduccion_operaciones_seguros.html", "Capítulo 3 Introducción a las operaciones de seguros 3.1 El sistema financiero 3.2 Riesgos financieros 3.3 La transferencia de riesgos financieros 3.4 Fundamentos técnicos de los seguros 3.5 La mutualización de riesgos 3.6 Ley de los grandes números 3.7 Microeconomía del negocio de seguros 3.8 El seguro privado 3.9 Actores 3.10 Clasificación según la materia asegurada 3.11 Clasificación según el beneficio 3.12 Clasificación según la regulación 3.13 Visita web de la SCVS y JPRF 3.14 Principios básicos del seguro 3.15 Seguro o apuesta? 3.16 Fuentes del riesgo en seguros 3.17 Problemas que enfrentan los seguros 3.18 Primas de seguro: Art. 53 RLGS 3.19 Caso Nessie", " Capítulo 3 Introducción a las operaciones de seguros 3.1 El sistema financiero En todos lo países del mundo existe un sistema financiero con el objetivo de ofrecer facilidades para poner en práctica las decisiones financieras de: Personas Empresas Gobierno. En general en un sistema financiero encontramos: Mercados de activos financieros Deuda, Derivados, Títulos… Intermediarios (públicos y privados) Bancos Empresas de seguros Fondos de pensiones Empresas de servicios Difusión de información Tarjetas de crédito, brokers… Por medio de las instituciones del sistema, se espera facilitar algunas operaciones: Transferencia de recursos A través del tiempo, regiones, entre, industrias,… Administración del riesgo Medios para administrar el riesgo financiero Compensación y establecimiento de pagos Facilitar el intercambio de bienes,servicios, activos… Concentración de recursos Financiamiento de grandes empresas y proyectos Suministro de información Toma de decisiones en iguales condiciones 3.2 Riesgos financieros Los riegos financieros son aquellos riesgos relacionados con las posibles pérdidas económicas que pueden enfrentar los actores del sistema (personas, empresas, gobierno), causadas por hechos contingentes que afectan sus operaciones en el mercado financiero, sus actividades de negocio o sus pertenencias (activos financieros). De manera natural los individuos presentan un comportamiento que traduce su “miedo” a las pérdidas cuando enfrentan situaciones de riesgo: la aversión al riesgo. La aversión al riesgo se produce hacia la parte negativa del riesgo, esto es ante la posibilidad de pérdidas financieras. En estas situaciones es necesario administrar el riesgo, para lo cual co-existen cuatro formas principales: Evitar el riesgo (no siempre posible) Prevenir y controlar el riesgo Aceptar el riesgo Transferir el riesgo Vale recordar que históricamente los grandes avances de la humanidad han sido posibles gracias a a la aceptación y correcta gestión de de riesgos muy importantes. Por lo tanto, en lugar de evitar los riesgos debemos tratar de conocerlos profundamente para aceptarlos y poder aprovechar las oportunidades que brinda su correcta gestión. Para pensar: El riesgo existe gracias a nuestra humana incapacidad de conocer el futuro, a nuestras limitaciones para identificar sus verdaderas causas. Y mientras así sea, debemos esforzarnos por comprenderlo, aceptarlo y gestionarlo inteligentemente y con humildad. – L. Vélez, 2003 3.3 La transferencia de riesgos financieros Consiste en trasladar el riesgo a otros a un costo razonable. Esto es posible en un sistema financiero gracias a mecanismos como: Protección: reducir una pérdida potencial a costa de renunciar a una ganancia. Diversificación: distribuir una pérdida potencial en varias pérdidas menores con distintas exposiciones al riesgo. Aseguramiento: pagar una prima para compensar una pérdida potencial mayor. 3.4 Fundamentos técnicos de los seguros En sus inicios el seguro era considerado como un juego de apuestas. El gran desarrollo científico de los fundamentos del seguro comienza a fines del siglo XIX con: Desarrollo del cálculo de probabilidades Ley de los grandes números El seguro comienza entonces a fundamentarse en las leyes estadísticas y nace el cálculo actuarial que demanda el análisis de la información histórica para medir los riesgos y determinar los niveles de primas que permiten financiar las operaciones de seguros. Sin embargo en algunos casos existen ciertas limitaciones técnicas, pues existen seguros que no se basan en análisis de información histórica, porque no existe o es limitada: - Seguros “especiales” o “exóticos” - Seguro de las piernas de futbolistas, bailarinas… - Seguro de satélites - Seguros nuevos - SPPAT (antiguo SOAT) al inicio! En estos casos el fundamento técnico resulta subjetivo basado en análisis de grupos de expertos que estudian los riesgos potenciales o experiencias relacionadas que permiten determinar primas. En estos casos es imprescindible el proceso de monitoreo de la evolución del riesgo. 3.5 La mutualización de riesgos La base de los seguros es la compensación o mutualización de riesgos: pagar los “pocos” siniestros por medio de las primas recolectadas de muchos asegurados a un mismo riesgo. Para que la compensación de riesgos funciones es necesario: Dispersión de riesgos Ley de los grandes números Riesgos independientes Por lo tanto, no funciona con pocos asegurados porque no aplica la ley de los grandes números. Tampoco funciona frente a riesgos catastróficos que presentan una baja dispersión y alta concentración del riesgo. En estos casos aparecen como solución el Coaseguro o el Reaseguro que permiten compensar los riesgos gracias a la dispersión, incluso a escala mundial. 3.6 Ley de los grandes números Es una de las leyes más importantes en el campo de la teoría de probabilidades: Ley de los grandes números Las frecuencias relativas (% de ocurrencia) del resultado de un experimento aleatorio, tienden a estabilizarse en un valor cuando el número de experimentos es grande. Ese número es una aproximación de la probabilidad de ese resultado. 3.7 Microeconomía del negocio de seguros El seguro es un negocio con fines de lucro y de libre competencia. 3.7.1 Ciclo de producción En el negocio del seguro se produce el fenómeno conocido como inversión del ciclo de producción: El asegurador fija el precio antes de conocer el costo del producto y por lo tanto asume obligaciones frente a los asegurados. Como consecuencias las compañías de seguros captan dinero del público y por esta razón: Deben conformar reservas técnicas Son controladas por organismos de control estatal. 3.7.2 Reservas técnicas El asegurador no puede disponer inmediatamente de las primas que recibe. Debe constituir reservas o provisiones técnicas con la finalidad de mantener niveles mínimos de solvencia al cierre de cada ejercicio y garantizar el cumplimiento de las obligaciones financieras que deberá honrar en el futuro por la cobertura de siniestros. Ver norma de reservas técnicas Las reservas representan las obligaciones del asegurador con los asegurados y se registran en el pasivo del balance: Contablemente las primas se registran en el pasivo y conforme se devengan pasan a constituir los ingresos financieros. El principal riesgo del asegurador está en su pasivo. 3.7.3 Control estatal La inversión del ciclo de producción implica que los asegurados corran el riesgo de que el asegurador no pueda cumplir con sus obligaciones de cubrir los siniestros en el futuro: -Riesgo de insolvencia del asegurador Por esta razón se justifica la existencia de entidades de control cuyo objetivo es proteger a los asegurados garantizando la solvencia del mercado asegurador en el largo plazo: Superintendencia de Compañías, Valores y Seguros (SCVS) Leyes y normas de solvencia Ej.: resoluciones de la SCVS, Solvencia I y II Otras instituciones de control Junta de Política y Regulación Financiera (JPRF) 3.8 El seguro privado El seguro (privado) es un contrato mediante el cual una de las partes, el asegurador, se obliga, a cambio del pago de una prima, a indemnizar a la otra parte, dentro de los límites convenidos, de una pérdida o un daño producido por un acontecimiento incierto; o a pagar un capital o una renta, si ocurre la eventualidad prevista en el contrato. –Art. 1, Decreto Supremo 1147 del 29/Nov/1963 3.9 Actores EL asegurado El tomador del seguro El portador del riesgo La empresa de seguros La empresa de reaseguros y retrocesiones 3.10 Clasificación según la materia asegurada Seguros de personas Destinados a asegurar los riesgos que afecten la vida, la integridad física o la situación familiar de las personas. Seguros generales o de daños Destinados a cubrir los riesgos que pueden amenazar al patrimonio de las personas o instituciones. – Decreto 1147 3.10.1 Seguros de personas Seguros de vida Seguros de salud o asistencia médica Seguros de accidentes Seguros de natalidad 3.10.2 Seguros generales o de daños Seguro de cosas El objeto amenazado es un bien del patrimonio del asegurado Ej: incendio, robo, inundación,… Seguro de responsabilidad El objeto amenazado es el patrimonio global del asegurado Ej: responsabilidad civil, responsabilidad médica 3.11 Clasificación según el beneficio Seguros de compensación o de sumas fijas El beneficio es fijado de antemano sin referencia a la magnitud del siniestro Ej: 50 USD diarios por hospitalización Ej: 20,000 USD en caso de muerte. Seguros de indemnización Cubren el perjuicio real del siniestro, según las condiciones del contrato Ej: incendio de un inmueble. 3.12 Clasificación según la regulación Seguros de vida Cubren los riesgos de las personas o garantizan a éstas, dentro o al término de un plazo, un capital o una renta periódica Seguros generales (de daños) -Cubren los riesgos causados por afecciones, pérdidas o daños de la salud, de los bienes o del patrimonio y fianzas o garantías. – Art. 3, Ley General de Seguros. 3.13 Visita web de la SCVS y JPRF 3.14 Principios básicos del seguro Buena fe Interés asegurable Indemnización Subrogación 3.14.1 Principio de buena fe Tanto el asegurador como el asegurado deben actuar con máxima honestidad, moral y buena fe. El asegurado debe declarar todas las características del riesgo que se asegura. El asegurador debe explicar con claridad y detalle las condiciones de la cobertura que ofrece. 3.14.2 Principio del interés asegurable El asegurado debe sufrir una pérdida económica si el riesgo asegurado se realiza. No se puede asegurar legalmente nada que no tenga interés asegurable. El interés debe ser lícito. En seguros de personas, toda persona tiene interés asegurable: En su propia vida; En la de las personas a quienes pueda reclamar alimentos, y En la de aquellas cuya muerte pueda aparejarle un perjuicio económico. En los amparos accesorios de gastos que tengan carácter de daño patrimonial, como gastos médicos, clínicos, quirúrgicos o farmacéuticos Son susceptibles de indemnización y se regulan por las normas relativas a los seguros de daños. En seguros de daños puede ser objeto de contrato de seguro todo interés económico en que una persona tenga en que no se produzca un siniestro. – Decreto 1147 3.14.3 Principio de indemnización La indemnización no puede exceder el valor real del interés asegurado ni el monto efectivo del prejuicio patrimonial ni el límite de la suma asegurada. El seguro no puede constituir fuente de enriquecimiento del asegurado. A opción del asegurador la indemnización es pagadera en dinero mediante la reposición, reparación o reconstrucción de la cosa asegurada. En los seguros de personas el valor del interés asegurable no tiene otro límite que el que libremente le asignen las partes contratantes. – Decreto 1147 3.14.4 Principio de subrogación El asegurador sustituye al asegurado en el ejercicio de las acciones o derechos que tendría este, a fin de recuperar la indemnización. – Diccionario MAPFRE de seguros El asegurador que haya pagado una indemnización de seguro se subroga, por Ministerio de la Ley, hasta el monto de dicha indemnización, en los derechos del asegurado contra terceros responsables del siniestro. – Decreto 1147 Consecuencia Bienes recuperables pasan a ser propiedad de la compañía Ej. Carros robados y recuperados. 3.15 Seguro o apuesta? knitr::kable( as.data.frame( matrix( c( ‘Seguro’, ‘Apuesta’, ‘Respaldo legal estricto’, ‘Puede ser ilegal’, ‘Interés asegurable indispensable’, ‘Carece de interés asegurable’, ‘Máxima buena fe’, ‘No necesariamente de buena fe’, ‘Nunca es fuente de enriquecimiento’, ‘Puede ser fuente de enriquecimiento’ ), nrow = 5, ncol = 2, byrow = TRUE ) ), booktabs = TRUE, caption = ‘Seguros vs apuestas’ ) 3.16 Fuentes del riesgo en seguros Número de reclamos: frecuencia Costo de los reclamos: severidad Período de cobertura Período de pago de primas Período de pago de siniestros Desde la fecha del reclamo hasta el cierre legal. 3.17 Problemas que enfrentan los seguros Identificamos tres problemas principales: - Asegurabilidad de riesgos - Selección adversa (anti-selección) - Azar moral 3.17.1 Asegurabilidad de riesgos Recordemos que el seguro se fundamenta en la compensación o mutualización de riesgos. Existen riesgos difícilmente asegurables Riesgos únicos en su especie No existe información histórica Límites de asegurabilidad subjetivos que dependen de capacidad financiera y aversión al riesgo de la compañía. Riesgos asegurables (deseables) Riesgos comparables y de naturaleza homogénea Es necesario que se puedan mutualizar Para que se cumpla la ley de los grandes números Riesgos medibles que responden a una ley de probabilidad permitan estimar la pérdida máxima Riesgos no potestativos: que no dependen de la voluntad del asegurado Riesgos inciertos Que no hayan ocurrido o que su ocurrencia sea desconocida 3.17.2 Selección adversa Es un fenómeno causado porque la información del asegurador es incompleta y asimétrica: - El asegurado es quien conoce mejor el riesgo Entonces el seguro atrae más a quienes tienen mayor exposición al riesgo y el portafolio puede resultar desequilibrado, asegurando demasiados “malos riesgos” que causan un desequilibrio financiero Medidas contra la selección adversa Con la finalidad de equilibrar el portafolio el mercado a puesto en práctica algunas medidas: Personalización de la prima para asegurados siniestrosos Ej. bonus malus Proceso de selección de asegurados en base a declaración del riesgo Potestad de la compañía para rechazar un seguro Obligación de asegurar? Período de carencia Límites de cobertura Copago, franquicia, deducible, suma máxima asegurada 3.17.3 Azar moral Es el riesgo de que el asegurado se desinterese de prevenir la ocurrencia de siniestros: - Ej. Seguro automotriz O se interese en que ocurra el riesgo: - Ej. Por publicidad O Incremente la frecuencia de reclamos - Ej. Seguro de salud Medidas contra el azar moral Con el objetivo de incentivar la prevención el mercado propone algunas estrategias: Copago y/o Deducible Obligaciones de prevención previstas en el contrato Cobertura máxima Por siniestro Por período Bono no-claims 3.18 Primas de seguro: Art. 53 RLGS Prima pura o prima de riesgo: es el costo del riesgo Prima neta: prima pura más un recargo de seguridad Prima de tarifa: prima neta más recargos de operación costo del riesgo gastos de adquisición, gastos de administración, utilidad razonable otros gastos justificados Prima comercial: prima de tarifa más impuestos, contribuciones, etc. Relación fundamental \\[ P_{com} = \\frac{P}{1-GA-GB-U} \\] \\(P\\): prima pura \\(PP_{com}\\): prima comercial \\(GA\\): porcentaje de gastos de administración \\(GB\\): porcentaje de gastos de adquisición (comisiones de brokers) \\(U\\): porcentaje de utilidad esperada por los accionistas 3.19 Caso Nessie "],["probabilidad_estadistica.html", "Capítulo 4 Probabilidad y Estadística 4.1 Probabilidad y conceptos asociados 4.2 Probabilidad condicional 4.3 Resultados de convergencia 4.4 Desigualdades de concentración 4.5 Transformada de Fourier, contínua y discreta 4.6 Consideraciones financieras", " Capítulo 4 Probabilidad y Estadística Antes de introducir algunos conceptos necesarios para nuestro estudio, necesitamos de algunos conceptos de base. 4.1 Probabilidad y conceptos asociados Definición 4.1 (Conceptos base) En breves términos, utilizaremos los siguientes conceptos Un fenómeno es un hecho que puede ser observado. Un fenómeno estocástico es un fenómeno sobre el que se realiza un experimento que puede arrojar más de un resultado posible. Un experimento es la observación de un fenómeno bajo condiciones específicas. Un resultado es la información obtenida de un experimento. En relación a lo anterior, también tenemos estas definiciones ya más formales. Definición 4.2 (Espacio muestral y eventos) El conjunto de todos los resultados lo denominamos espacio muestral y usualmente lo notamos por \\(\\Omega\\). Un evento es un conjunto de uno o más resultados posibles. En pocas palabras un evento \\(A\\) es un subcojunto de \\(\\Omega\\), i.e. \\(A \\subset \\Omega\\). En algunas ocasiones, para dar mayor precisión a la naturaleza de los eventos, si este está asociado a un fenómeno estocástico se denomina evento contingente. No todos los subconjuntos de \\(\\Omega\\) necesariamente son un evento, usualmente hay subconjuntos que no pueden resultar de un experimento. Así, si agrupamos todos los eventos usualmente tenemos un conjunto menor a las partes \\(\\mathcal{P}(\\Omega)\\) de \\(\\Omega\\). El conjunto de todos los eventos se conoce como una álgebra de eventos, \\(\\sigma\\)-álgebra o tribu. Usualmente se la nota por \\(\\mathcal{F}\\), es claro que \\(\\mathcal{F}\\subset \\mathcal{P}(\\Omega)\\). El álgebra de eventos, se denomina así, ya que usualmente es cerrada para algunas operaciones de conjuntos. Tiene las siguientes propiedades: Todos los resultados de espacio muestral están en \\(\\mathcal{F}\\), es decir \\(\\Omega \\in \\mathcal{F}\\) El complemento de un evento también es parte de \\(\\mathcal{F}\\), es decir si \\(A \\in \\mathcal{F}\\), entonces \\(A^c = \\Omega \\setminus A \\in \\mathcal{F}\\). La unión de eventos es un evento, si \\(A, B \\in \\mathcal{F}\\), entonces \\(A \\cup B \\in \\mathcal{F}\\), Aunque redunde, la intersección de eventos es un evento, si \\(A, B \\in \\mathcal{F}\\), entonces \\(A \\cap B \\in \\mathcal{F}\\). Definición 4.3 (Medida de probabilidad) La probabilidad es una medida de las posibilidades de que ocurra un evento contingente que toma valores en \\([0,1]\\). Formalmente, la probabilidad se la define como una medida, esto es una función de conjuntos \\[ P: \\mathcal{F}\\longrightarrow [0,1] \\] sobre los eventos \\(\\mathcal{F}\\subset \\mathcal{P}( \\Omega )\\) del espacio muestral \\(\\Omega\\). Si \\(A, B \\in \\mathcal{F}\\) son disjuntos \\(A \\cap B = \\emptyset\\), entonces \\(P( A \\cup B ) = P( A ) + P( B )\\) \\(P( \\Omega ) = 1\\) \\(P( \\emptyset ) = 0\\) Una propiedad sobre sobre \\(\\Omega\\) viene caracterizada por una función de verificación \\(V : \\Omega \\longrightarrow \\{0,1\\}\\) de tal forma, se dice que un evento \\(A \\in \\mathcal{F}\\) satisface la propiedad dada por \\(V\\) si \\(V(\\omega) = 1\\), para todo \\(\\omega \\in A\\). Entonces decimos que se satisface la propiedad en \\(V\\) en casi en todas partes o casi seguramente si para todo evento \\(N \\in \\mathcal{F}\\) que no satisfaga \\(V\\) mantiene una medida nula, es decir \\(P( N ) = 0\\) y para cualquier \\(\\omega \\in \\Omega \\setminus N\\) se satisface \\(V\\), \\(V( \\omega ) = 1\\). En otras palabras en ciertos experimentos hay resultados que se pueden presentar, están dentro de las opciones, sin embargo en caso de presentarse no hay forma que se pueda medirlos. En muchas ocasiones se observa los resultados a través de la realización de un experimento, y es usual que a cada experimente se le asocie un único resultado. Esta noción permite la definición de una variable aleatoria. Definición 4.4 (Variable aleatoria) Una variable aleatoria es una función que asigna un valor numérico a todo evento contingente. Una variable aleatoria \\(X: \\Omega \\longrightarrow D\\) que parte del espacio muestral \\(\\Omega\\) y toma valores en el conjunto de los números reales \\(\\mathbb{R}\\). Como la variable aleatoria es el resultado de un experimento, el cual debe ser medible, es natural esperar que todo intervalo observado sea el resultado de un evento en el espacio muestra \\(\\Omega\\). De forma más clara, la imagen recíproca de un cualquier intervalo \\(A \\subset \\mathbb{R}\\) es un evento en \\(\\mathcal{F}\\), i.e. \\(X^{-1}( A ) \\in \\mathcal{F}\\) esto precisamente se designa como una función medible. De \\(X\\) se puede construir o heredar otra medida a partir de \\(P\\), esta se representa \\(P_X\\) y tan solo mide los eventos que son imagen de \\(X\\). Es decir para cualquier intervalo \\(A \\in \\mathbb{R}\\) \\[ \\begin{eqnarray*} P_X( A ) &amp; = &amp; P( X^{-1}( A ) )\\qquad \\text{definición de la notación} \\\\ &amp; = &amp; P(\\{ \\omega \\in \\Omega \\mid X( \\omega ) \\in A \\})\\qquad \\text{definición de imagen recíproca} \\\\ &amp; = &amp; \\int\\limits_{X^{-1}( A )} dP( \\omega )\\qquad \\text{representación en forma integral} \\end{eqnarray*} \\] a partir de la medida \\(P_X\\) precisamente se puede determinar algunas funciones que se conocen como distribuciones o densidades de probabilidad. De la idea de variable aleatoria a valores reales se puede extender fácilmente al caso de varias variables aleatorias, un vector aleatorio que toma valores en \\(\\mathbb{R}^n\\), i.e. una función medible \\(X : \\Omega \\longrightarrow \\mathbb{R}^n\\). Definición 4.5 (Variable aleatoria discreta) Una variable aleatoria \\(K: \\Omega \\longrightarrow D\\) que parte del espacio muestral \\(\\Omega\\) y toma valores en un conjunto discreto \\(D = \\left\\{k_i \\in \\mathbb{R}| i \\in \\mathbb{N} \\right\\}\\), sigue una probabilidad discreta dada por las probabilidades \\(p_i \\in [0,1]\\) , \\(i \\in \\mathbb{N}\\), si \\[ P\\left( K = k_i \\right) = p_i,\\qquad \\forall i \\in \\mathbb{N} \\] Además se cumple la condición de normalización que es muy importante. \\[ \\sum\\limits_{i = 0}^{\\infty} p_i = 1 \\] las probabilidades ¡Nunca son negativas! y !Suman siempre 1!. Definición 4.6 (Función de distribución acumulada) Consideramos una variable aleatoria a valores reales \\(X\\), la función de distribución acumulada \\(F\\) asociada a la variable aleatoria \\(X\\), está dada por la siguiente relación: \\[ F( x ) = P( X \\leq x ) = P_X( (-\\infty, x] ) = P( X \\in (-\\infty, x] ) = P\\left( X^{-1}\\left( (-\\infty, x ] \\right) \\right) \\] La función de distribución acumulada, tiene las siguientes propiedades: Para cualquier \\(x \\in \\mathbb{R}\\), \\(0 \\leq F( x ) \\leq 1\\), La función \\(F\\) es no decreciente, La función \\(F\\) es continua por derecha, Se satisfacen los siguientes límites: \\[ \\underset{x \\rightarrow -\\infty}{\\lim} F( x ) = 0\\qquad \\underset{x \\rightarrow +\\infty}{\\lim} F( x ) = 1 \\] 5. La función \\(F\\) es a variación acotada. Esto quiere decir que existe un real \\(C &gt; 0\\), para cualquier partición \\(\\{x_i\\}_{i\\in\\mathbb{Z}}\\), tal que: \\[ \\sum\\limits_{i\\in\\mathbb{Z}} \\left| F( x_{i+1} ) - F( x_i ) \\right| &lt; C \\] Cuando se trata de un variable aleatoria con varias componentes reales \\(X = ( X_1, \\ldots, X_n )\\) toma valores en \\(\\mathbb{R}^n\\). Se extiende la definición de distribución acumulada por para valores reales \\(x = ( x_1, \\ldots, x_n ) \\in \\mathbb{R}^n\\) \\[ F\\left( x_1, \\ldots, x_n \\right) = P\\left( X_1 \\leq x_1 \\land \\cdots \\land X_n \\leq x_n \\right) = P\\left( \\bigcap_{i=1}^n X_i^{-1}\\left( (-\\infty, x_i ] \\right) \\right) \\] Definición 4.7 (Función supervivencia) La función de supervivencia \\(S : \\mathbb{R}\\longrightarrow \\mathbb{R}\\) está asociada a una variable aleatoria \\(X\\), está dada por la siguiente: \\[ S( x ) = 1 - F( x ) = 1 - P( X \\leq x ) = P( X &gt; x ) \\] Definición 4.8 (Función de densidad de probabilidad) La densidad de probabilidad o también la ley de probabilidad de una variable aleatoria a valores reales \\(X\\), es una función \\(f: \\mathbb{R}\\longrightarrow \\mathbb{R}\\), tal que \\[ P( a \\leq X \\leq b ) = F( b ) - F( a ) = \\int\\limits_a^b f( x )\\ dx \\] Así se satisface la siguiente igualdad \\[ F( x ) = \\int\\limits_{(-\\infty,x]} f( x )\\ dx = \\int\\limits_{-\\infty}^x f( x )\\ dx \\] Esto implica que \\(f\\) es la derivada de \\(F\\), i.e. \\(\\frac{dF}{dx} = f\\), por tal razón \\(f\\) estará bien definida siempre y cuando la derivada de \\(F\\) esté bien definida. Code n &lt;- 1e3 x &lt;- seq( -6, 6, length = n ) xbrk &lt;- seq( -6, 6, 1 ) xlbl &lt;- formatC( xbrk, digits = 0, format = &#39;f&#39; ) xlim &lt;- c( -6, 6 ) ybrk &lt;- seq( 0, 1, length = 11 ) ylbl &lt;- formatC( ybrk, digits = 2, format = &#39;f&#39; ) ylim &lt;- c( 0, 1 ) Fx &lt;- sapply( x, FUN = function( x ) pnorm( x ) ) plt &lt;- ggplot( ) + geom_step( aes( x = x, y = Fx, colour = &#39;a&#39; ), linewidth = 1 ) + geom_vline( xintercept = c( 0 ), colour = &#39;orange&#39;, linewidth = 0.7 ) + scale_colour_manual( breaks = c( &#39;a&#39; ), values = c( &#39;dodgerblue4&#39; ) ) + scale_x_continuous( breaks = xbrk, labels = xlbl, limits = xlim, expand = c( 0.008, 0.008 ) ) + scale_y_continuous( breaks = ybrk, labels = ylbl, limits = ylim, expand = c( 0.005, 0.005 ) ) + xlab( TeX( &quot;$x$&quot; ) ) + ylab( TeX( &quot;$F$&quot; ) ) + theme_bw() + theme( legend.position = &quot;none&quot; ) plot( plt ) Definición 4.9 (Independencia de variables aleatorias) Dos variables aleatorias a valores reales \\(X\\) y \\(Y\\), se dicen independientes si para cualquier par de eventos \\(A\\) y \\(B\\), sucede la siguiente factorización de probabilidades \\[ P( X \\in A \\land Y \\in B ) = P( X \\in A ) P( Y \\in B) \\] La propiedad anterior, en particular para la función de distribución conjunta, toma la siguiente forma: \\[ F_{X,Y}( x, y ) = P( X \\leq x \\land Y \\leq y ) = P( X \\leq x ) P( Y \\leq y ) = F_{X}( x ) F_{Y}( y ) \\] Para cuando tratamos con dos variables aleatorias \\(X\\) y \\(Y\\), si en caso existe y está bien definida las derivadas hasta el segundo orden de la función de distribución acumulada conjunta \\(F_{X,Y}\\). En tal caso se puede definir la respectiva densidad de probabilidad \\[ f_{X,Y}( x, y ) = \\frac{\\partial^2 F_{X,Y}}{\\partial x \\partial y}( x, y ) \\] Así mismo, para la densidad de probabilidad conjunta, si en caso las variables aleatoria \\(X\\) y \\(Y\\) son independientes, también se puede factorar la densidad de probabilidad. \\[ f_{X,Y}( x, y ) = f_X( x ) f_Y( y ) \\] En el desarrollo a continuación haremos bastante uso de familias de variables aleatorias \\(X_1, \\ldots, X_n\\) las cuales muchas de las veces se consideraran que son independientes entre si e idénticamente distribuidas, es usual designarlas con las siglas i.i.d.. Esta situación si las \\(X_1, \\ldots, X_n\\) siguen la misma distribución, su distribución conjunta tiene la siguiente forma: \\[ F( x_1, \\ldots, x_n ) = P( X_1 \\leq x_1 \\land \\cdots \\land X_n \\leq x_n ) = \\prod\\limits_{i=1}^n P( X_i \\leq x_i ) = \\prod\\limits_{i=1}^n F( x_i ) \\] La siguiente función es utilidad para comprender algunos resultados en teoría de probabilidades. También, es bastante útil para realizar de forma más clara y rápida algunos cálculos. Definición 4.10 (Función indicatriz) La función indicatriz de un conjunto \\(A \\subset \\Omega\\), es la función \\(\\mathbf{1}_A : \\Omega \\longrightarrow \\{0,1\\}\\), que toma los valores \\(\\mathbf{1}_A( \\omega ) = 0\\), si \\(\\omega \\notin A\\) y \\(\\mathbf{1}_A( \\omega ) = 1\\), si \\(\\omega \\in A\\). Además esta función indicatriz tiene las siguientes propiedades Si \\(A, B \\subset \\Omega\\), entonces \\(\\mathbf{1}_{A \\cap B} = \\mathbf{1}_A \\mathbf{1}_B\\) Si \\(A \\subset \\Omega\\), entonces \\(\\mathbf{1}_{A^c} = 1 - \\mathbf{1}_A\\) Si \\(A, B \\subset \\Omega\\), entonces \\(\\mathbf{1}_{A\\cup B} = \\mathbf{1}_A + \\mathbf{1}_B - \\mathbf{1}_A \\mathbf{1}_B\\) \\(\\mathbf{1}_\\Omega = 1\\) Hay un caso atípico que suele ser útil, esto sucede cuando la variable aleatoria \\(X : \\Omega \\longrightarrow \\mathbb{R}\\), es constante, quiere decir que tenemos un \\(a \\in \\mathbb{R}\\), tal que \\(X( \\omega ) = a\\) para todo \\(\\omega \\in \\mathbb{R}\\). En este caso la distribución de probabilidad acumulada \\(F\\) de \\(X\\), tiene la siguiente forma particular. \\[ F( x ) = P( X \\leq x ) = \\mathbf{1}_{[a, +\\infty)}( x ) \\] Proposición 4.1 Las constantes o variables aleatorias constantes son independientes de cualquier otra variable aleatoria. Demostración. Consideremos \\(X\\) una constante o variable aleatoria constante, tal que existe un \\(a \\in \\mathbb{R}\\), tal que \\(X( \\omega ) = a\\) para cualquier \\(\\omega \\in \\Omega\\) y \\(Y\\) una variable aleatoria cualquiera a valores reales. Para cualesquier intervalos \\(A, B \\subset \\mathbb{R}\\). Entonces tenemos dos casos, primero \\(X \\notin A\\), entonces \\(\\emptyset = \\{ \\omega \\in \\Omega \\mid X( \\omega ) \\in A \\}\\), por otra parte si \\(y \\in A\\), entonces \\(\\Omega = \\{ \\omega \\in \\Omega \\mid X( \\omega ) \\in A \\}\\), como consecuencia \\[ P( X \\in A ) = P\\left( X^{-1}(A) \\right) = P\\left( \\{ \\omega \\in \\Omega \\mid X( \\omega ) \\in A \\} \\right) = \\mathbf{1}_{A}( a ) \\] Ahora consideramos los casos anteriores para la probabilidad conjunta, primero el caso \\(X \\notin A\\) \\[ \\begin{eqnarray*} P\\left( X \\in A \\land Y \\in B \\right) &amp; = &amp; P\\left( X^{-1}(A) \\cap Y^{-1}(B) \\right) \\\\ &amp; = &amp; P\\left( \\left\\{ \\omega \\in \\Omega \\middle| X( \\omega ) \\in A \\right\\} \\cap \\left\\{ \\omega \\in \\Omega \\middle| Y( \\omega ) \\in B \\right\\} \\right) \\\\ &amp; = &amp; P\\left( \\emptyset \\cap \\left\\{ \\omega \\in \\Omega \\middle| Y( \\omega ) \\in B \\right\\} \\right) \\\\ &amp; = &amp; P( \\emptyset ) \\\\ &amp; = &amp; 0 \\end{eqnarray*} \\] El segundo caso \\(X \\in A\\) \\[ \\begin{eqnarray*} P\\left( X \\in A \\land Y \\in B \\right) &amp; = &amp; P\\left( X^{-1}(A) \\cap Y^{-1}(B) \\right) \\\\ &amp; = &amp; P\\left( \\left\\{ \\omega \\in \\Omega \\middle| X( \\omega ) \\in A \\right\\} \\cap \\left\\{ \\omega \\in \\Omega \\middle| Y( \\omega ) \\in B \\right\\} \\right) \\\\ &amp; = &amp; P\\left( \\Omega \\cap \\left\\{ \\omega \\in \\Omega \\middle| Y( \\omega ) \\in B \\right\\} \\right) \\\\ &amp; = &amp; P( Y \\in B ) \\end{eqnarray*} \\] Esto quiere decir en conclusión que \\[ P( X \\in A \\land Y \\in B ) = \\mathbf{1}_{A}( a ) P( Y \\in B ) = P( X \\in A ) P( Y \\in B ) \\] por tanto \\(X\\) y \\(Y\\) son independientes Definición 4.11 (Medida de probabilidad empírica) A partir de una muestra de \\(X_1, \\ldots, X_n\\) de una variable aleatoria \\(X\\), podemos definir también la medida de probabilidad empírica asociada a la muestra \\(X_1, \\ldots, X_n\\). Así para cualquier evento del espacio muestral \\(\\Omega\\), \\(A \\subset \\Omega\\) \\[ P_n( B ) = \\frac{1}{n} \\sum\\limits_{i=1}^n \\mathbf{1}_{B}\\left( X_i \\right) \\] A partir de la medida empírica de probabilidad, podemos extraer la de para la distribución acumulada empírica \\(F_n\\), la cual la hemos definido con anterioridad, para ello consideremos \\(P_n( (-\\infty,x])\\) para cualquier \\(x \\in \\mathbb{R}\\) \\[ P_n( (-\\infty,x]) = \\frac{1}{n} \\sum\\limits_{i=1}^n \\mathbf{1}_{(-\\infty,x]}\\left( X_i \\right) = F_n( x ) \\] Para muchos resultados asociados a la estimación de estadística la variantes empíricas \\(P_n\\) y \\(F_n\\) son de utilidad. Definición 4.12 (Esperanza de una variable aleatoria) Considerando una variable aleatoria discreta \\(K : \\Omega \\longrightarrow D \\subset \\mathbb{R}\\), donde \\(D\\) es un conjunto discreto, es decir sus elementos se pueden contar y poner en correspondencia con \\(\\mathbb{N}\\). Entonces, la esperanza se define como: \\[ \\mathbb{E}[ K ] = \\mathbb{E}_P[ K ] = \\sum\\limits_{i=0}^{\\infty} k_i P\\left( K = k_i \\right) = \\sum\\limits_{i=0}^{\\infty} k_i p_i \\] Para el caso de una variable aleatoria a valores reales, es decir una función medible \\(X : \\Omega \\longrightarrow \\mathbb{R}\\), la esperanza matemática está dada por \\[ \\mathbb{E}[ X ] = \\mathbb{E}_P[ K ] = \\int\\limits_{\\mathbb{\\Omega}} X( \\omega )\\ dP( \\omega ) = \\int\\limits_{\\mathbb{R}} x\\ dF( x ) \\] donde la última integral de tipo Riemann-Stieltjes tiene sentido, ya que \\(F\\) es una función de variación acotada. Cuando la función de densidad de probabilidad está bien definida es posible expresar y calcular la esperanza matemática como la siguiente expresión: \\[ \\mathbb{E}[ X ] = \\int\\limits_{\\mathbb{R}} x f( x )\\ dx \\] La esperanza matemática goza de las siguientes propiedades: Linealidad, \\(a \\in \\mathbb{R}\\) \\[ \\mathbb{E}[ aX + Y ] = a \\mathbb{E}[ X ] + \\mathbb{E}[ Y ] \\] Monotonía, si \\(X \\leq Y\\), entonces \\[ \\mathbb{E}[X] \\leq \\mathbb{E}[Y] \\] La esperanza de una constante \\(a \\in \\mathbb{R}\\) es la misma constante. \\[ \\mathbb{E}[a] = \\int\\limits_{\\mathbb{R}} a\\ dF_X( x ) = a\\int\\limits_{\\mathbb{R}} dF_X( x ) = a \\] De esto resulta que la esperanza jamás puede ser mayor que cualquiera de los valores que toma la variable aleatoria \\(X\\). La función indicatriz \\(\\mathbf{1}_A\\) sobre un evento \\(A\\) del espacio muestral \\(\\Omega\\), también se puede interpretar como una variable aleatoria, que tan solo tomo los valores \\(0\\) o \\(1\\). Es más, su esperanza es precisamente la probabilidad del evento \\(A\\). \\[ \\mathbb{E}\\left[ \\mathbf{1}_A \\right] = \\int\\limits_\\Omega \\mathbf{1}_A( \\omega )\\ dP( \\omega ) = \\int\\limits_A dP( \\omega ) = P( A ) \\] Con esta propiedad, podemos obtener la siguiente representación para la función de distribución acumulada de una variable aleatoria a valores reales \\(X\\). \\[ F( X \\leq x ) = P( X \\leq x ) = \\mathbb{E}\\left[ \\mathbf{1}_{(-\\infty,x]}( X ) \\right] \\] Definición 4.13 (Función generadora de momentos) La función generadora de momentos de una variable aleatoria a valores reales \\(X\\), es la función: \\[ M_X( t ) = \\mathbb{E}\\left[ \\exp( t X ) \\right] \\] Si \\(X_1, \\ldots, X_n\\) son variables aleatorias y \\(Y = X_1 + \\cdots + X_n\\), entonces \\[ \\begin{eqnarray*} M_Y( t ) &amp; = &amp; \\mathbb{E}\\left[ \\exp\\left( t Y \\right) \\right] \\\\ &amp; = &amp; \\mathbb{E}\\left[ \\exp\\left( t \\sum\\limits_{i=1}^n X_i \\right) \\right] \\\\ &amp; = &amp; \\prod\\limits_{i=1}^n \\mathbb{E}\\left[ \\exp\\left( t X_i \\right) \\right],\\qquad \\text{si las variables $X_i$ son independientes} \\\\ &amp; = &amp; \\left( \\mathbb{E}\\left[ \\exp\\left( t X \\right) \\right] \\right)^n,\\qquad \\text{si las variables $X_i$ son identicamente distribuidas} \\\\ &amp; = &amp; \\left( M_X( t ) \\right)^n \\end{eqnarray*} \\] Definición 4.14 (Función característica) La función característica de una variable aleatoria a valores reales \\(X\\), es la función: \\[ \\varphi_X( t ) = M_X( it ) = \\mathbb{E}\\left[ \\exp( i t X ) \\right] \\] Definición 4.12 (Varianza de una variable aleatoria) Así mismo su varianza es la dada por: \\[ \\mathbb{V}[ X ] = \\mathbb{E}\\left[ \\left( X - \\mathbb{E}[ X ] \\right)^2 \\right] = \\mathbb{E}\\left[ X^2 \\right] - \\mathbb{E}\\left[ X \\right]^2 \\] Definición 4.15 (Covarianza) La covarianza de dos variables aleatorias, está dada por la siguiente expresión: \\[ \\mathbb{C}[ X, Y ] = \\mathbb{E}\\left[ \\left( X - \\mathbb{E}[ X ] \\right)\\left( Y - \\mathbb{E}[ Y ] \\right) \\right] = \\mathbb{E}\\left[ X Y \\right] - \\mathbb{E}\\left[ X \\right]\\mathbb{E}\\left[ Y \\right] \\] De forma integral esta se la puede expresar como: \\[ \\begin{eqnarray*} \\mathbb{C}[ X, Y ] &amp; = &amp; \\int\\limits_{\\mathbb{R}^2} xy\\ dP( x, y ) - \\int\\limits_{\\mathbb{R}^2} x\\ dP( x, y )\\int\\limits_{\\mathbb{R}^2} y\\ dP( x, y ) \\\\ &amp; = &amp; \\int\\limits_{\\mathbb{R}^2} xy f_{X,Y}( x, y )\\ dx dy - \\int\\limits_{\\mathbb{R}^2} x f_{X,Y}( x, y )\\ dx dy\\int\\limits_{\\mathbb{R}^2} y f_{X,Y}( x, y )\\ dx dy \\end{eqnarray*} \\] No está por demás notar que \\(\\mathbb{C}[ X, X ] = \\mathbb{V}[ X ]\\) Definición 4.16 (Distribución de la suma de variables aleatorias) Dadas dos variables aleatorias a valores reales \\(X\\) y \\(Y\\), con funciones de distribución acumulada \\(F_X\\) y \\(F_Y\\) respectivamente, la distribución acumulada \\(F_Z\\) de la variable aleatoria \\(Z = X + Y\\) está dada por la siguiente expresión: \\[ F_Z( z ) = P( Z \\leq z ) = F_X \\star F_Y ( z ) = \\int\\limits_{\\mathbb{R}} F_X( x - y )dF_Y( y ) \\] si en caso se puede definir las densidades de probabilidad \\(f_X\\) y \\(f_Y\\) para las variables aleatorias \\(X\\) y \\(Y\\), entonces: \\[ f_Z( z ) = f_X \\star f_Y ( z ) = \\int\\limits_{\\mathbb{R}} f_X( x - y ) f_Y( y )\\ dy \\] El producto \\(\\star\\) se conoce como convolución de funciones, el mismo es simétrico. Para cuando se realiza la convolución de varias veces la misma función, se opta por una notación más compacta \\(f^{\\star k}\\), para el producto de convolución \\(k\\)-veces la misma función \\(f \\star f \\star \\cdots \\star f\\). Cuando se tiene dos variables aleatorias independientes \\(X\\) y \\(Y\\), muchas de las veces nos interesamos a trabajar con la variable aleatoria dada por el mínimo entre estas variables, i.e. \\(Z = \\min( X, Y )\\). De ello surge la necesidad de determinar la distribución de probabilidad acumulada \\(F_Z\\) de \\(Z\\), a partir de las distribuciones de \\(F_X\\) de \\(X\\) y \\(F_Y\\) de \\(Y\\). \\[ \\begin{eqnarray*} F_Z( z ) &amp; = &amp; P( Z \\leq z ) \\\\ &amp; = &amp; 1 - P( Z &gt; z ) \\\\ &amp; = &amp; 1 - P( \\min(X,Y) &gt; z ) \\\\ &amp; = &amp; 1 - P( X &gt; z \\land Y &gt; z ) \\\\ &amp; = &amp; 1 - P( X &gt; z ) P( Y &gt; z ) \\\\ &amp; = &amp; 1 - \\left( 1 - F_X( z ) \\right) \\left( 1 - F_Y( z ) \\right) \\\\ &amp; = &amp; F_X( z ) + F_Y( z ) - F_X( z ) F_Y( z ) \\end{eqnarray*} \\] En particular cuando \\(Y = a\\) es constante tenemos la siguiente distribución de probabilidad para \\(Z = \\min( X, Y ) = \\min( X, a )\\) \\[ F_Z( z ) = F_X( z ) + \\mathbf{1}_{[a,+\\infty)}( z ) - \\mathbf{1}_{[a,+\\infty)}( z ) F_X( z ) = \\mathbf{1}_{(-\\infty,a)}( z ) F_X( z ) + \\mathbf{1}_{[a,+\\infty)}( z ) \\] Esta función tiene las siguientes propiedades. si \\(z &gt; a\\), entonces \\(F_Z( z ) = 1\\) si \\(z &lt; a\\), entonces \\(F_Z( z ) = F_X( z )\\) si \\(z = a\\), entonces \\(F_Z( a ) = 1\\) la función \\(F\\) es discontinua en \\(a\\) \\[ \\underset{z \\nearrow a}{\\lim} F_Z( z ) = \\underset{z \\nearrow a}{\\lim} F_X( z ) = F_X( a ) \\] por otra parte \\[ \\underset{z \\searrow a}{\\lim} F_Z( z ) = \\underset{z \\searrow a}{\\lim} \\mathbf{1}_{[a,+\\infty)}( z ) = \\underset{z \\searrow a}{\\lim} 1 = 1 \\] donde no necesariamente \\(F_X( a )\\) es igual \\(1\\). el evento puntual \\(\\{Z = a\\}\\) no tiene necesariamente probabilidad nula, hay un fenómeno de concentración de la probabilidad en el punto \\(a\\). \\[ \\begin{eqnarray*} P( Z = a ) &amp; = &amp; P\\left( \\min( X, a ) = a \\right) \\\\ &amp; = &amp; P\\left( X \\geq a \\right) \\\\ &amp; = &amp; 1 - F_X( a ) \\end{eqnarray*} \\] De forma similar nos podemos también interesar a la variable aleatoria que expresa el máximo entre otras dos variables, i.e. \\(Z = \\max( X, Y )\\), por un razonamiento similar podemos obtener la distribución de probabilidad \\(F_Z\\) de \\(Z\\). \\[ \\begin{eqnarray*} F_Z( z ) &amp; = &amp; P( Z \\leq z ) \\\\ &amp; = &amp; P( \\max(X,Y) \\leq z ) \\\\ &amp; = &amp; P( X \\leq z \\land Y \\leq z ) \\\\ &amp; = &amp; P( X \\leq z ) P( Y \\leq z ) \\\\ &amp; = &amp; F_X( z ) F_Y( z ) \\end{eqnarray*} \\] De forma análoga el caso cuando \\(Y = a\\) es una constante se reduce a la siguiente distribución de probabilidad para \\(Z\\). \\[ F_Z( z ) = \\mathbf{1}_{[a,+\\infty)}( z ) F_X( z ) \\] Teorema 4.1 (Inversión) Sea \\(\\varphi\\) la función característica de la distribución de probabilidad \\(F\\) de una variable aleatoria \\(X\\). Si \\(x,y \\in \\mathbb{R}\\) son dos puntos de continuidad de la distribución \\(F\\), then \\[ F( y ) - F( x ) = \\frac{1}{2\\pi} \\underset{c \\rightarrow +\\infty}{\\lim} \\int\\limits_{-c}^c \\frac{\\exp(-itx) - \\exp(-ity)}{it} \\varphi( t )\\ dt \\] 4.2 Probabilidad condicional Definición 4.17 (Probabilidad condicional) Para cualquier par de eventos \\(A, B \\in \\mathcal{F}\\), la probabilidad condicional de \\(A\\) dado \\(B\\), está dada por: \\[ P\\left( A \\middle| B \\right) = \\frac{P( A \\cap B)}{P(B)} \\] Definición 4.18 (Distribución acumulada condicionada) Si consideramos un evento cualquiera \\(A \\in \\mathcal{F}\\), \\(X\\) una variable aleatoria a valores reales y \\(x \\in \\mathbb{R}\\). Surge el interés de estudiar la distribución acumulada de \\(X\\) pero considerando dado que se produce el evento \\(A\\), esto resulta en estudiar: \\[ P\\left( X \\leq x \\middle| A \\right) = \\frac{P(X \\leq x \\land A )}{P(A)} = \\frac{P( \\{X \\leq x \\} \\cap A )}{P(A)} \\] Esto precisamente da paso a la definición de la distribución acumulada de \\(X\\) condicionada a \\(A\\) \\[ F( x | A ) = P\\left( X \\leq x \\middle| A \\right) \\] Se satisface algunas propiedades: Si \\(A, B \\in \\mathcal{F}\\) son dos eventos disjuntos, entonces: \\[ \\begin{eqnarray*} F\\left( x \\middle| A \\cup B \\right) &amp; = &amp; P\\left( X \\leq x \\middle| A \\right) \\\\ &amp; = &amp; \\frac{P\\left( X \\leq x \\cap ( A \\cup B ) \\right)}{P\\left( A \\cup B \\right)} \\\\ &amp; = &amp; \\frac{P\\left( X \\leq x \\cap A \\right) + P\\left( X \\leq x \\cap B \\right)}{P\\left( A \\cup B \\right)} \\\\ &amp; = &amp; \\frac{P\\left( X \\leq x \\cap A \\right)P( A )}{P(A)P\\left( A \\cup B \\right)} + \\frac{P\\left( X \\leq x \\cap B \\right)P( B )}{P( B )P\\left( A \\cup B \\right)} \\\\ &amp; = &amp; P\\left( X \\leq x \\middle| A \\right) \\frac{P( A )}{P\\left( A \\cup B \\right)} + P\\left( X \\leq x \\middle| B \\right) \\frac{P( B )}{P\\left( A \\cup B \\right)} \\\\ &amp; = &amp; P\\left( X \\leq x \\middle| A \\right) P\\left( A \\middle| A \\cup B \\right) + P\\left( X \\leq x \\middle| B \\right) P\\left( B \\middle| A \\cup B \\right) \\\\ &amp; = &amp; F\\left( x \\middle| A \\right) P\\left( A \\middle| A \\cup B \\right) + F\\left( x \\middle| B \\right) P\\left( B \\middle| A \\cup B \\right) \\end{eqnarray*} \\] 2. La distribución acumulada condicionada con respecto a todo el espacio muestral \\(\\Omega\\), es la distribución acumulada. \\[ \\begin{eqnarray*} F\\left( x \\middle| \\Omega \\right) &amp; = &amp; P\\left( X \\leq x \\middle| \\Omega \\right) \\\\ &amp; = &amp; \\frac{P\\left( X \\leq x \\cap \\Omega \\right)}{P(\\Omega)} \\\\ &amp; = &amp; \\frac{P\\left( X \\leq x \\right)}{P(\\Omega)} \\\\ &amp; = &amp; P\\left( X \\leq x \\right) \\\\ &amp; = &amp; F( x ) \\end{eqnarray*} \\] Para cualquier \\(A \\in \\mathcal{F}\\), el evento \\(\\{ X \\leq x \\} \\cap A \\subset A\\) y por tanto \\(P\\left( X \\leq x \\middle| A \\right) \\leq P( A )\\), entonces \\(0 \\leq F(x | A) \\leq 1\\), Para cualquier \\(A \\in \\mathcal{F}\\), la función de distribución acumulada condicionada \\(F( \\cdot | A )\\) es no decreciente, Para cualquier \\(A \\in \\mathcal{F}\\), la función de distribución acumulada condicionada \\(F( \\cdot | A )\\) es continua por derecha, En algunos casos la distribución acumulada de la variable aleatoria \\(X\\) se nota por \\(F_X\\) y la distribución acumulada de \\(X\\) condicionada por el evento \\(A\\), se nota por \\(F_{X|A}\\). Como hemos visto la función de distribución acumulada satisface todas las propiedades de una función de distribución acumulada y por tal razón se puede calcular una esperanza, la cual vendrá condicionada. Gracias a las propiedades 1 y 2 antes señaladas, tenemos fácilmente la siguiente igualdad para cualquier evento \\(A \\in \\mathcal{F}\\). \\[ F( x ) = F\\left( x \\middle| \\Omega \\right) = F\\left( x \\middle| A \\cup A^c \\right) = F\\left( x \\middle| A \\right) P( A ) + F\\left( x \\middle| A^c \\right) P( A^c ) \\] de donde surge la idea de generalizar la interpretación de la distribución acumulada de \\(X\\) condicionada por un evento \\(A\\). No solo puede ser interpretada como una función, sino como una variable aleatoria. Para ello, observemos que la distribución acumulada condicionada admite también la siguiente representación con el uso de la esperanza y las funciones indicatrices. \\[ F\\left( x \\middle| A \\right) = \\frac{P( X \\leq x \\land A )}{P( A )} = \\frac{\\mathbb{E}\\left[ \\mathbf{1}_{(-\\infty,x]}( X ) \\mathbf{1}_{A} \\right]}{\\mathbb{E}\\left[ \\mathbf{1}_{A} \\right]} \\] Esto sugiere la siguiente extensión de la distribución acumulada condicional a ser una variable aleatoria, ya no tan solo condicionada por eventos sino condicionada por variables aleatorias, en este primer caso por variables aleatorias de la forma \\(\\mathbf{1}_A\\). Así damos sentido a la variable aleatoria \\(F\\left( x \\middle| \\mathbf{1}_A \\right) : \\Omega \\longrightarrow \\mathbb{R}_+\\), para cualquier \\(\\omega \\in \\Omega\\), definimos \\[ F\\left( x \\middle| \\mathbf{1}_A( \\omega ) \\right) = \\left\\{ \\begin{array}{ll} F\\left( x \\middle| A \\right) &amp; \\text{si}\\ \\mathbf{1}_A( \\omega ) = 1 \\\\ F\\left( x \\middle| A^c \\right) &amp; \\text{si}\\ \\mathbf{1}_A( \\omega ) = 0 \\end{array} \\right. \\] de la definición anterior se sigue de forma inmediata la igualdad \\[ \\begin{eqnarray*} \\mathbb{E}\\left[ F\\left( x \\middle| \\mathbf{1}_A \\right) \\right] &amp; = &amp; F\\left( x \\middle| A \\right) P( A ) + F\\left( x \\middle| A^c \\right) P( A^c ) \\\\ &amp; = &amp; \\frac{P\\left( X \\leq x \\land A \\right)}{P(A)} P( A ) + \\frac{P\\left( X \\leq x \\land A^c \\right)}{P(A^c)} P( A^c ) \\\\ &amp; = &amp; P\\left( X \\leq x \\land A \\right) + P\\left( X \\leq x \\land A^c \\right) \\\\ &amp; = &amp; P\\left( X \\leq x \\right) \\\\ &amp; = &amp; F( x ) \\end{eqnarray*} \\] Las variables aleatorias también generan eventos, ya que son medibles, por tal razón si tomamos en cuenta la definición anterior, podemos ciertamente extender la definición anterior de distribución acumulada condicionada, pero considerando variables aleatorias en su condicionamiento. Así si consideramos dos variables aleatorias \\(X\\) y \\(Y\\) a valores reales, a partir de la definición podemos tranquilamente considerar la distribución acumulada de \\(X\\) condicionada al evento \\(Y \\leq y\\) \\[ F\\left( x \\middle| Y \\leq y \\right) = \\frac{P( X \\leq x \\land Y \\leq y )}{P(Y \\leq y)} = \\frac{F_{X,Y}( x, y )}{F_Y( y )} \\] está bien definida para \\(F_Y( y ) \\neq 0\\) Definición 4.19 (Esperanza condicionada) Para una variable aleatoria \\(X\\) y un evento cualquiera \\(A \\in \\mathcal{F}\\), se define la esperanza condicionada respecto del evento \\(A\\), como: \\[ \\mathbb{E}\\left[ X \\middle| A \\right] = \\mathbb{E}_{P|A}\\left[ X \\right] = \\mathbb{E}_P\\left[ X \\middle| A \\right] = \\int\\limits_{A} X( \\omega )\\ dP \\left( \\omega \\middle| A \\right) = \\int\\limits_{\\mathbb{R}} x\\ dF\\left( x \\middle| A \\right) \\] cuando \\(F(x | A)\\) es derivable, con densidad de probabilidad \\(f(x|A)\\), la esperanza condicionada también se puede escribir como: \\[ \\mathbb{E}\\left[ X \\middle| A \\right] = \\int\\limits_{\\mathbb{R}} x\\ f( x | A )\\ dx \\] La distribución acumulada condicionada satisface las mismas propiedades de una distribución acumulada, y por tanto la esperanza que resulta de esta también satisface las mismas propiedades que cualquier esperanza. Al igual que lo realizamos con la distribución acumulada condicionada, podemos reinterpretar a la esperanza condicionada como una variable aleatoria. \\[ \\mathbb{E}\\left[ X \\middle| \\mathbf{1}_A \\right] = \\int\\limits_{\\mathbb{R}} x\\ dF\\left( x \\middle| \\mathbf{1}_A \\right) \\] Por otra parte, para cualquier evento \\(A \\in \\mathcal{F}\\), las distribuciones \\(F( \\cdot ), F( \\cdot | A )\\) y \\(F( x | A^c)\\) son funciones de variación acotada y por tanto sus integrales de Riemann-Stieltjes están bien definidas, de donde resulta la siguiente igualdad. \\[ \\begin{eqnarray*} \\mathbb{E}\\left[ X \\right] &amp; = &amp; \\int\\limits_{\\mathbb{R}} x dF( x ) \\\\ &amp; = &amp; \\int\\limits_{\\mathbb{R}} x dF( x | A ) P( A ) + \\int\\limits_{\\mathbb{R}} x dF( x | A^c ) P( A^c ) \\\\ &amp; = &amp; \\mathbb{E}\\left[ X \\middle| A \\right] P( A ) + \\mathbb{E}\\left[ X \\middle| A^c \\right] P( A^c ) \\\\ &amp; = &amp; \\mathbb{E}\\left[ \\mathbb{E}\\left[ X \\middle| \\mathbf{1}_A \\right] \\right] \\end{eqnarray*} \\] por abuso de notación se suele utilizar la misma notación \\(\\mathbb{E}\\left[ X \\middle| A \\right]\\) para indicar también la variable aleatoria \\(\\mathbb{E}\\left[ X \\middle| \\mathbf{1}_A \\right]\\). Así la siguiente expresión tienen sentido. \\[ \\mathbb{E}\\left[ \\mathbb{E}\\left[ X \\middle| A \\right] \\right] = \\mathbb{E}\\left[ \\mathbb{E}\\left[ X \\middle| \\mathbf{1}_A \\right] \\right] \\] La siguiente definición de distribución de exceso condicionada es útil para el estudio de los valores extremos que se pueden presentar en el estudio de los valores de siniestros que se presentan en un seguro. Definición 4.20 (Distribución de exceso condicionada) La distribución de exceso condicionada asociada a una variable aleatoria \\(X\\) con distribución de probabilidad acumulada \\(F\\) y a un umbral de condicionamiento \\(u &gt; 0\\), está dada por: \\[ F_u( y ) = P\\left( X - u \\leq y \\middle| X &gt; u \\right) = \\frac{P\\left( u &lt; X \\leq y + u\\right)}{P(X &gt; u)} = \\frac{F( u + y ) - F( u )}{ 1 - F( u )} \\] Definición 4.19 (Varianza condicionada) La varianza condicionada se puede definir de forma directa a partir de los anterior. Para una variable aleatoria a valores reales \\(X\\) y un evento \\(A \\in \\mathcal{F}\\). \\[ \\mathbb{V}[X|A] = \\mathbb{E}[Y^2|A] - \\mathbb{E}[Y|A]^2 \\] Definición 4.21 (Ley de la varianza total) Consideremos dos variables aleatorias \\(X, Y\\), ambas a valores reales, entonces se satisface la siguiente igualdad: \\[ \\mathbb{V}[ Y ] = \\mathbb{E}\\left[ \\mathbb{V}[ Y| X ] \\right] + \\mathbb{V}\\left[ \\mathbb{E}[ Y | X ] \\right] \\] Demostración. \\[ \\begin{eqnarray*} \\mathbb{E}\\left[ \\mathbb{V}[ Y| X ] \\right] &amp; = &amp; \\mathbb{E}\\left[ \\mathbb{E}[ Y^2 | X ] - \\mathbb{E}[ Y | X ]^2 \\right] \\\\ &amp; = &amp; \\mathbb{E}\\left[ \\mathbb{E}[ Y^2 | X ] \\right] - \\mathbb{E}\\left[ \\mathbb{E}[ Y | X ]^2 \\right] \\\\ &amp; = &amp; \\mathbb{E}\\left[ Y^2 \\right] - \\mathbb{E}\\left[ \\mathbb{E}[ Y | X ]^2 \\right] + \\mathbb{E}\\left[ \\mathbb{E}[ Y | X ] \\right]^2 - \\mathbb{E}\\left[ \\mathbb{E}[ Y | X ] \\right]^2 \\\\ &amp; = &amp; \\mathbb{E}\\left[ Y^2 \\right] - \\mathbb{V}\\left[ \\mathbb{E}[ Y | X ] \\right] - \\mathbb{E}\\left[ Y \\right]^2 \\\\ &amp; = &amp; \\mathbb{V}[ Y ] - \\mathbb{V}\\left[ \\mathbb{E}[ Y | X ] \\right] \\end{eqnarray*} \\] Basta con ordenar los términos y se tiene la igualdad que buscamos. Definición 4.22 (Mixtura de distribuciones) Un caso de especial interés para estudiar algunos problemas actuariales se da cuando se dispone de dos variables aleatorias, \\(N\\) que toma solo valores discretos (numerables) los cuales pueden ser finitos como infinitos, por ejemplo: \\(N\\) toma valores en los números naturales \\(\\mathbb{N}\\) y otra variable aleatoria \\(X\\) que toma valores continuos reales en \\(\\mathbb{R}\\). La distribución conjunta puede generarse de la siguiente forma \\[ \\begin{eqnarray*} F( n, x ) &amp; = &amp; P( N = n \\land X \\leq x ) \\\\ &amp; = &amp; P\\left( X \\leq x \\middle| N = n \\right) P( N = n )\\qquad \\text{propiedades de la probabilidad condicional} \\\\ &amp; = &amp; F( x | n ) p_n\\qquad \\text{simplificando notación} \\\\ \\end{eqnarray*} \\] \\(F( x | n )\\) es la ley condicionada de \\(X\\) dado que \\(N = n\\) y \\(p_n = P( N = n )\\) Además, es de notar que: \\[ \\begin{eqnarray*} F_X( x ) &amp; = &amp; P( X \\leq x ) \\\\ &amp; = &amp; P( X \\leq x \\land N \\in \\mathbb{N} ) \\\\ &amp; = &amp; P\\left( X \\leq x \\land N \\in \\bigcup_{n \\in \\mathbb{N}} \\{n\\} \\right) \\\\ &amp; = &amp; P\\left( \\bigcup_{n \\in \\mathbb{N}} \\left\\{ X \\leq x \\land N \\in \\{n\\} \\right\\} \\right) \\\\ &amp; = &amp; \\sum\\limits_{n \\in \\mathbb{N}} P\\left( X \\leq x \\land N \\in \\{n\\} \\right) \\\\ &amp; = &amp; \\sum\\limits_{n \\in \\mathbb{N}} P\\left( X \\leq x \\land N = n \\right) \\\\ &amp; = &amp; \\sum\\limits_{n \\in \\mathbb{N}} P\\left( X \\leq x\\ \\middle|\\ N = n \\right) P( N = n ) \\\\ &amp; = &amp; \\sum\\limits_{n \\in \\mathbb{N}} F( x | n ) p_n \\end{eqnarray*} \\] la distribución de \\(F_X\\) de \\(X\\) no es más que una mixtura de las distribuciones condicionales de \\(X\\) para cada \\(n \\in \\mathbb{N}\\). 4.3 Resultados de convergencia De las ramas de las Matemáticas la Estadística ciertamente es la más subestimada, en muchos casos menospreciada. Sin embargo, no sin mucha pretención, sino más bien honestidad, se puede decir que la Estadística es una de las ramas más complicadas de las Ciencias en general, ya que busca en muchos casos comprender, explicar y predecir fenómenos reales. En su fundamentación, al profundizar en ella, uno encontrará un sin número de conceptos, métodos y teorías con un amplio espectro de complejidad, que incluso se sustentan en ideas filosóficas bastante elaboradas y poco comprendidas. No olvidar, la Estadística busca de frente y sin rodeos extraer conocimiento de la realidad y no hay algo más complejo y duro que la realidad misma. Muchos de las herramientas de las estadística se resumen en algunas recetas o aplicaciones de software, sin embargo, no se debe olvidar que en muchos casos estas herramientas hacen uso de muchos métodos bastante avanzados y complejos en lo que respecta al conocimiento Matemático. Teorema 4.2 (Ley débil de los grandes números) Consideramos la secuencia de variables aleatorias \\(\\{X_i\\}_{i\\in \\mathbb{N}}\\) las cuales consideraremos que son i.i.d. y con media común finita \\(\\mathbb{E}[X_i] = \\mu &lt; +\\infty\\). Entonces, se satisface el siguiente límite en probabilidad \\[ \\frac{1}{n} \\sum\\limits_{i=1}^n X_i \\rightarrow \\mu \\] esto quiere decir que para cualquier \\(\\varepsilon &gt; 0\\) se satisface el siguiente límite \\[ \\underset{n \\rightarrow +\\infty}{\\lim} P\\left( \\left| \\frac{1}{n}\\sum\\limits_{i=1}^n X_i - \\mu \\right| &gt; \\varepsilon\\right) = 0 \\] Teorema 4.3 (Teorema del límite central) Consideramos las variables aleatorias \\(X_1,\\ldots,X_n\\) i.i.d. con media común finita \\(\\mathbb{E}[X_i] = \\mu &lt; +\\infty\\) y varianza común finita \\(\\mathbb{V}[ X_i ] = \\sigma^2 &lt; +\\infty\\), para todo \\(i \\in \\{1, \\ldots, n \\}\\). Si consideramos la variable aleatoria de la suma total \\(S_n = \\sum\\limits_{i=1}^n X_i\\), entonces \\[ \\frac{S_n - \\mathbb{E}[S_n]}{\\mathbb{V}[ S_n ]} \\overset{d}{\\longrightarrow} Z \\] cuando \\(n \\rightarrow +\\infty\\), donde \\(Z \\rightsquigarrow N( 0, 1 )\\). Más aún \\[ \\underset{n \\rightarrow +\\infty}{\\lim} P\\left( \\frac{S_n - \\mathbb{E}[S_n]}{\\mathbb{V}[ S_n ]} \\leq z \\right) = \\Phi( z ) \\] El teorema del límite central en su forma usual no proporciona una tasa de convergencia es decir, la variable aleatoria \\(\\frac{S_n - \\mathbb{E}[S_n]}{\\mathbb{V}[ S_n ]}\\) tiende a tener un comportamiento de una variable aleatoria normal estándar conforme aumenta \\(n\\), pero no estamos seguros que tamaño debe tomar \\(n\\) para que esto se cumpla con una alta certeza. Para ello adicional al 4.3 se debe considerar otros resultados asociados a desigualdades de concentración. El siguiente teorema es de gran ayuda para estimar la tasa de convergencia del resultado anterior 4.3. 4.4 Desigualdades de concentración Para muchos fines prácticos es importante encontrar una buena estimación de donde se encuentran concentrados los valores de una distribución de probabilidad, para ello existen varios resultados que caracterizan precisamente ello, estos se conocen como desigualdades de concentración. Proposición 4.2 (Desigualdad de Chebyshev (Чебышёв)) Dada una variable aleatoria \\(X\\) con esperanza y varianza finitas \\(\\mathbb{E}[X] &lt;+ \\infty\\) y \\(\\mathbb{V}[X] &lt; +\\infty\\), tenemos que se satisface la siguiente desigualdad para cualquier \\(varepsilon &gt; 0\\) \\[ P\\left( \\left| X - \\mathbb{E}[X] \\right| &gt; \\varepsilon \\right) &lt; \\frac{1}{\\varepsilon^2} \\mathbb{V}[ X ] \\] Teorema 4.4 (Desigualdad de Berry-Esséen) Sean \\(X_1, \\ldots X_n\\) variables aleatorias i.i.d., con media y varianza finitas, i.e \\(\\mathbb{E}[X] &lt; +\\infty\\) y \\(\\mathbb{V}[X] &lt; +\\infty\\) y además con tercer momento absoluto finito \\(\\mathbb{E}\\left[\\left|X - \\mathbb{E}[X]\\right|^3\\right] &lt; +\\infty\\). Entonces, la distribución acumulada \\(F_{U_n}\\) de la variable aleatoria \\[ U_n = \\frac{S_n - \\mathbb{E}[ S_n ]}{\\mathbb{V}[ S_n ]} \\] con \\(S_n = \\sum\\limits_{i=1}^n X_i\\). Satisface la siguiente desigualdad respecto de la distribución acumulada de la ley normal \\(\\Phi\\). \\[ \\underset{u}{\\sup}\\left| F_{U_n}( u ) - \\Phi( u ) \\right| \\leq \\frac{A}{\\sqrt{n}} \\frac{\\mathbb{E}\\left[\\left|X - \\mathbb{E}[X]\\right|^3\\right]}{\\sqrt{\\mathbb{V}[X]}^3} \\] Teorema 4.5 (Desigualdad Dvoretzky–Kiefer–Wolfowitz) Dada una serie de variables aleatorias a valores reales \\(X_1, \\ldots, X_n\\), i.i.d., con distribución acumulada \\(F\\), tenemos la siguiente desigualdad asociada a la distribución acumulada empírica \\[ F_n( x ) = \\frac{1}{n}\\sum\\limits_{i=1}^n \\mathbf{1}_{(-\\infty,x]}( X_i ) \\] y su aproximación a \\(F\\). \\[ P\\left( \\underset{x \\in \\mathbb{R}}{\\sup} \\left| F_n( x ) - F( x ) \\right| &gt; \\varepsilon \\right) \\leq 2 e^{-2n \\varepsilon^2 }\\qquad \\forall \\varepsilon &gt; 0 \\] Como podemos notar el orden de convergencia del teorema es \\(\\sqrt{n}\\) en el tamaño de observaciones, esto quiere decir que la convergencia es menos que el orden lineal. Acorde a la desigualdad 4.5, para tener un probabilidad baja de aproximación \\(\\delta &gt; 0\\) en un error de discrepancia \\(\\varepsilon &gt;0\\), necesitamos satisfacer la desigualdad. \\[ \\begin{eqnarray*} 2 e^{-2n \\varepsilon^2 } &amp; \\leq &amp; \\delta \\\\ 2n \\varepsilon^2 &amp; \\geq &amp; -\\ln\\left( \\frac{\\delta}{2} \\right) \\\\ n &amp; \\geq &amp; \\left\\lceil -\\frac{1}{2\\varepsilon^2} \\ln\\left( \\frac{\\delta}{2} \\right) \\right\\rceil \\end{eqnarray*} \\] así se observa que para tener una aproximación de orden \\(\\delta\\) y con un error de discrepancia \\(\\varepsilon\\), se requiere como mínimo realizar un número de simulaciones \\(n\\) de orden logarítmico en \\(\\delta\\) y cuadrático en \\(\\varepsilon\\). Code delta &lt;- 0.01 e &lt;- unlist( lapply( seq( 1, 9, 1 ), FUN = function( n ) seq( 9, 1, -1 ) * 10^{-n} ) ) n &lt;- ceiling( -log( delta / 2 ) / ( 2 * e^2 ) ) Code dt &lt;- data.table( delta = delta, e, n, d = 8 * n / 1024^3 ) dt %&gt;% kable( label = NA, caption = &#39;Error versus número de simulaciones&#39;, row.names = FALSE, col.names = c( &quot;$\\\\delta$&quot;, &quot;$\\\\varepsilon$&quot;, &quot;$n$&quot;, &quot;GB&quot; ), align = &#39;llrr&#39;, digits = c( 10, 20, 0, 10 ), format.args = list( big.mark = &#39;,&#39;, decimal.mark = &#39;.&#39;, scientific = FALSE ), escape = FALSE, centering = TRUE ) %&gt;% kable_classic( font_size = 14, full_width = FALSE, html_font = &quot;Cambria&quot;, position = &#39;center&#39; ) %&gt;% scroll_box( width = &quot;100%&quot;, height = &quot;500px&quot; ) Tabla 4.1: Error versus número de simulaciones \\(\\delta\\) \\(\\varepsilon\\) \\(n\\) GB 0.01 0.900000000 4 0.0000000298 0.01 0.800000000 5 0.0000000373 0.01 0.700000000 6 0.0000000447 0.01 0.600000000 8 0.0000000596 0.01 0.500000000 11 0.0000000820 0.01 0.400000000 17 0.0000001267 0.01 0.300000000 30 0.0000002235 0.01 0.200000000 67 0.0000004992 0.01 0.100000000 265 0.0000019744 0.01 0.090000000 328 0.0000024438 0.01 0.080000000 414 0.0000030845 0.01 0.070000000 541 0.0000040308 0.01 0.060000000 736 0.0000054836 0.01 0.050000000 1,060 0.0000078976 0.01 0.040000000 1,656 0.0000123382 0.01 0.030000000 2,944 0.0000219345 0.01 0.020000000 6,623 0.0000493452 0.01 0.010000000 26,492 0.0001973808 0.01 0.009000000 32,706 0.0002436787 0.01 0.008000000 41,394 0.0003084093 0.01 0.007000000 54,065 0.0004028156 0.01 0.006000000 73,588 0.0005482733 0.01 0.005000000 105,967 0.0007895157 0.01 0.004000000 165,573 0.0012336150 0.01 0.003000000 294,351 0.0021930858 0.01 0.002000000 662,290 0.0049344450 0.01 0.001000000 2,649,159 0.0197377726 0.01 0.000900000 3,270,567 0.0243676230 0.01 0.000800000 4,139,311 0.0308402702 0.01 0.000700000 5,406,447 0.0402811691 0.01 0.000600000 7,358,775 0.0548271462 0.01 0.000500000 10,596,635 0.0789510831 0.01 0.000400000 16,557,242 0.1233610660 0.01 0.000300000 29,435,097 0.2193085626 0.01 0.000200000 66,228,968 0.4934442639 0.01 0.000100000 264,915,869 1.9737770334 0.01 0.000090000 327,056,628 2.4367617667 0.01 0.000080000 413,931,045 3.0840266123 0.01 0.000070000 540,644,630 4.0281163901 0.01 0.000060000 735,877,413 5.4827139750 0.01 0.000050000 1,059,663,474 7.8951081187 0.01 0.000040000 1,655,724,178 12.3361064345 0.01 0.000030000 2,943,509,649 21.9308558777 0.01 0.000020000 6,622,896,709 49.3444257155 0.01 0.000010000 26,491,586,833 197.3777028397 0.01 0.000009000 32,705,662,757 243.6761763468 0.01 0.000008000 41,393,104,427 308.4026606902 0.01 0.000007000 54,064,462,924 402.8116384447 0.01 0.000006000 73,587,741,203 548.2713967785 0.01 0.000005000 105,966,347,331 789.5108113512 0.01 0.000004000 165,572,417,705 1,233.6106427386 0.01 0.000003000 294,350,964,809 2,193.0855870917 0.01 0.000002000 662,289,670,819 4,934.4425709471 0.01 0.000001000 2,649,158,683,275 19,737.7702837810 0.01 0.000000900 3,270,566,275,647 24,367.6176342890 0.01 0.000000800 4,139,310,442,616 30,840.2660683990 0.01 0.000000700 5,406,446,292,396 40,281.1638444364 0.01 0.000000600 7,358,774,120,206 54,827.1396771520 0.01 0.000000500 10,596,634,733,097 78,951.0811351016 0.01 0.000000400 16,557,241,770,463 123,361.0642735884 0.01 0.000000300 29,435,096,480,823 219,308.5587086007 0.01 0.000000200 66,228,967,081,851 493,444.2570943460 0.01 0.000000100 264,915,868,327,402 1,973,777.0283773690 0.01 0.000000090 327,056,627,564,694 2,436,761.7634288520 0.01 0.000000080 413,931,044,261,566 3,084,026.6068396419 0.01 0.000000070 540,644,629,239,596 4,028,116.3844436109 0.01 0.000000060 735,877,412,020,561 5,482,713.9677149132 0.01 0.000000050 1,059,663,473,309,608 7,895,108.1135094762 0.01 0.000000040 1,655,724,177,046,262 12,336,106.4273585528 0.01 0.000000030 2,943,509,648,082,242 21,930,855.8708596379 0.01 0.000000020 6,622,896,708,185,045 49,344,425.7094341889 0.01 0.000000010 26,491,586,832,740,180 197,377,702.8377367556 0.01 0.000000009 32,705,662,756,469,352 243,676,176.3428848386 0.01 0.000000008 41,393,104,426,156,528 308,402,660.6839636564 0.01 0.000000007 54,064,462,923,959,544 402,811,638.4443606734 0.01 0.000000006 73,587,741,202,056,032 548,271,396.7714908123 0.01 0.000000005 105,966,347,330,960,720 789,510,811.3509470224 0.01 0.000000004 165,572,417,704,626,112 1,233,610,642.7358546257 0.01 0.000000003 294,350,964,808,224,128 2,193,085,587.0859632492 0.01 0.000000002 662,289,670,818,504,448 4,934,442,570.9434185028 0.01 0.000000001 2,649,158,683,274,017,792 19,737,770,283.7736740112 Ejemplo 4.1 En este caso en particular estudiaremos la velocidad de convergencia del método resultante del teorema del límite central 4.3. Generaremos una simulación aleatoria de la suma agregada \\(S_n\\) y mostrar Code m &lt;- 600 n &lt;- 3000 u &lt;- 4 s &lt;- 2 set.seed( 5143829 ) X &lt;- lapply( 1:m, FUN = function( j ) rlnorm( n, meanlog = u, sdlog = s ) ) S &lt;- lapply( X, FUN = function( x ) cumsum( x ) ) ES &lt;- sapply( 1:n, FUN = function( i ) mean( sapply( 1:m, FUN = function( j ) S[[ j ]][ i ] ) ) ) VS &lt;- sapply( 1:n, FUN = function( i ) var( sapply( 1:m, FUN = function( j ) S[[ j ]][ i ] ) ) ) NS &lt;- lapply( S, FUN = function( s ) ( s - ES ) / sqrt( abs( VS ) ) ) z &lt;- seq( -5, 5, length.out = 200 ) FSn &lt;- lapply( 1:n, FUN = function( i ) ecdf( sapply( 1:m, FUN = function( j ) NS[[ j ]][ i ] ) )( z ) ) phi &lt;- pnorm( z ) D &lt;- sapply( FSn, FUN = function( Fn ) max( abs( Fn - phi ) ) ) Code plt &lt;- ggplot() + geom_line( aes( x = 1:n, y = D ), colour = &#39;darkred&#39;, linewidth = 0.5 ) + scale_x_continuous( breaks = seq( 0, n, 500 ), limits = c( 1, n ), expand = c( 0, 0 ) ) + scale_y_continuous( breaks = seq( 0, 0.5, length = 11 ), limits = c( 0, 0.5 ), expand = c( 0, 0 ) ) + xlab( TeX( &quot;$n$&quot; ) ) + ylab( TeX( &quot;$D_n$&quot; ) ) + theme_bw() plot( plt ) Code dat &lt;- NULL for ( k in 1:n ) { dat &lt;- rbindlist( list( dat, data.table( z = z, n = as.factor( k ), FSn = FSn[[ k ]] ) ) ) } cols &lt;- wes_palette( n, name = &quot;BottleRocket2&quot;, type = &quot;continuous&quot; ) plt &lt;- ggplot( ) + geom_step( data = dat, aes( x = z, y = FSn, group = n, colour = n ), linewidth = 0.07 ) + geom_line( aes( x = z, y = phi, colour = &#39;olivedrab3&#39; ), linewidth = 1 ) + scale_color_manual( values = c( cols, &#39;olivedrab3&#39; ) ) + scale_x_continuous( breaks = seq( -5, 5, 1 ), labels = formatC( seq( -5, 5, 1 ), digits = 1, format = &#39;f&#39; ), limits = c( -5, 5 ), expand = c( 0, 0 ) ) + scale_y_continuous( breaks = seq( 0, 1, length = 11 ), labels = formatC( seq( 0, 1, length = 11 ), digits = 2, format = &#39;f&#39; ), limits = c( 0, 1 ), expand = c( 0, 0 ) ) + xlab( TeX( &quot;$z$&quot; ) ) + ylab( TeX( &quot;$F_n$&quot; ) ) + theme_bw() + theme( legend.position = &quot;none&quot; ) plot( plt ) Teorema 4.6 (Desigualdad de Chernoff) Dada una variable aleatoria \\(X\\) a valores reales, para la cual si existe y está bien definida su función generadora de momentos \\(M\\), entonces se satisface la siguientes desigualdades para cualquier \\(\\varepsilon \\in \\mathbb{R}\\). \\[ P( X \\geq \\varepsilon ) \\leq \\underset{t &gt; 0}{\\inf} \\exp( -t \\varepsilon ) M( t ) \\] así mismo \\[ P( X \\leq \\varepsilon ) \\leq \\underset{t &lt; 0}{\\inf} \\exp( -t \\varepsilon ) M( t ) \\] Teorema 4.7 (Desigualdad de Paley-Zygmund) Dada una variable aleatoria \\(X\\) a valores reales, que solo toma valores no negativos \\(X \\geq 0\\) y que además tiene varianza finita \\(\\mathbb{V}[X] &lt; +\\infty\\), entonces si tomamos un valor \\(\\rho \\in [0,1]\\), se satisface la siguiente desigualdad: \\[ P( X \\geq \\rho \\mathbb{E}[ X ] ) \\geq ( 1 - \\rho )^2 \\frac{\\mathbb{E}[ X ]^2}{\\mathbb{E}[ X^2 ]} \\] 4.5 Transformada de Fourier, contínua y discreta Definición 4.23 (Tansformada de Fourier) La transformada de Fourier para una función integrable \\(f : \\mathbb{R}^n \\longrightarrow \\mathbb{R}\\), está definida como un funcional que toma funciones acotadas y general una función usualmente integrable a valores complejos en general. De forma más formal, se puede definir la transformada de Fourier como una función \\(\\mathscr{F}: L^1( \\mathbb{R}^n ) \\longrightarrow L^{\\infty} \\left( \\mathbb{R}^n, \\mathbb{C} \\right)\\) \\[ \\mathscr{F}( f )( \\omega ) = \\int\\limits_{\\mathbb{R}^n} f( x ) \\exp( -2 \\pi i \\omega \\cdot x )\\ dx \\] donde \\(i\\) es la cantidad compleja \\(i = \\sqrt{-1}\\). la inversa de la transformada de Fourier, para una función \\(g : \\mathbb{R}^n \\longrightarrow \\mathbb{R}\\), está dada por: \\[ \\mathscr{F}^{-1}( g ) = \\int\\limits_{\\mathbb{R}^n} g( x ) \\exp( 2 \\pi i \\omega \\cdot x )\\ dx \\] se satisface la siguiente igualdad \\[ \\mathscr{F}^{-1}\\left( \\mathscr{F}( f ) \\right) = f \\] Además, la transformada de Fourier satisface las siguientes propiedades: La transformada de Fourier es lineal, si \\(a,b \\in \\mathbb{R}\\) y \\(f :\\mathbb{R}^n \\longrightarrow \\mathbb{R}\\) y \\(g :\\mathbb{R}^n \\longrightarrow \\mathbb{R}\\), funciones integrables. \\[ \\mathscr{F}\\left( a f + b g \\right) = a \\mathscr{F}( f ) + b \\mathscr{F}( g ) \\] La transformada de Fourier de la convolución de funciones es el producto de las transformadas de Fourier. \\[ \\mathscr{F}\\left( f \\star g \\right) = \\mathscr{F}( f ) \\mathscr{F}( g ) \\] Definición 4.24 (Tansformada de Fourier discreta) Dada una secuencia finita de números \\(x_0, \\ldots, x_{N-1}\\), también notada por \\(\\{x_k\\}_{k \\in \\{0,\\ldots,N-1\\}}\\) o simplemente \\(\\{x_k\\}\\) cuando quede entendida su dimensión, claramente \\(\\{x_k\\}\\) puede ser interpretada como un vector en \\(\\mathbb{R}^n\\), indexado desde \\(0\\). Entonces, la transformada de Fourier discreta de la secuencia \\(\\{x_k\\}\\) es la función \\(\\operatorname{DFT}: \\mathbb{R}^n \\longrightarrow \\mathbb{R}^n\\), definida por: \\[ \\operatorname{DFT}\\left[ \\{x_k\\} \\right] = \\left\\{ \\sum\\limits_{k=0}^{N-1} x_k \\exp\\left( -2\\pi i \\frac{jk}{N} \\right) \\right\\}_j \\] con \\(j \\in \\{0, \\ldots, N-1 \\}\\). la inversa de la transformada de Fourier discreta, está simplemente dada por: \\[ \\operatorname{DFT}^{-1}\\left[ \\{x_k\\} \\right] = \\left\\{ \\frac{1}{N} \\sum\\limits_{k=0}^{N-1} x_k \\exp\\left( 2\\pi i \\frac{jk}{N} \\right) \\right\\}_j \\] En lo que sigue trabajaremos con series \\(\\{x_k\\}\\). Para medir la distancia entre una serie \\(\\{x_k\\}\\) y otra serie \\(\\{y_k\\}\\), ambas de igual dimensión; podemos utilizar la norma cuadrática. \\[ \\left\\| \\{x_k\\} - \\{y_k\\} \\right\\|_2 = \\left( \\sum\\limits_{k=0}^{N-1} \\left( x_k - y_k \\right)^2 \\right)^{\\frac{1}{2}} \\] 4.5.1 Aproximación numérica en una dimensión Para el caso de 1-dimensional podemos tener la siguiente aproximación a la transformada de Fourier. Consideramos el caso donde la función \\(f\\) está concentrada en su mayoría en un intervalo \\([a,b]\\), la mayor parte de su integral está ahí. Luego para aproximar la integral consideramos una discretización uniforme del intervalo \\([a,b]\\), seleccionando un tamaño \\(N \\in \\mathbb{N}\\) y tomando una secuencia de valores discretos \\(x_k = a + k h\\), con \\(h = \\frac{b-a}{N}\\) y \\(k \\in \\{0, \\ldots, N\\}\\). Así, tenemos la siguiente aproximación a la transformada de Fourier. \\[ \\begin{eqnarray*} \\mathscr{F}( f )( \\omega ) &amp; = &amp; \\int\\limits_{\\mathbb{R}} f( x ) \\exp( -2\\pi i \\omega x )\\ dx \\\\ &amp; \\approx &amp; \\int\\limits_{a}^b f( x ) \\exp( -2\\pi i \\omega x )\\ dx \\quad \\text{dominio finito $[ a, b ]$ que concentra la integral} \\\\ &amp; \\approx &amp; \\sum\\limits_{k=0}^{N-1} f( x_k ) \\exp( -2 \\pi i \\omega x_k ) h \\quad \\text{discretización de la integral} \\\\ &amp; = &amp; h \\sum\\limits_{k=0}^{N-1} f( x_k ) \\exp( -2\\pi i \\omega ( a + k h ) ) \\\\ &amp; = &amp; h \\exp( -i 2\\pi \\omega a ) \\sum\\limits_{k=0}^{N-1} f( x_k ) \\exp\\left( -2\\pi i \\omega k \\frac{b - a}{N} \\right) \\end{eqnarray*} \\] donde \\(\\{f_k\\}\\) es la secuencia finita de números \\(f_k = f( x_k )\\) y \\(\\operatorname{DFT}\\) es la transformada de Fourier Discreta. La anterior relación es una aproximación para todo \\(\\omega\\). En particular se puede considerar \\(\\omega_j = \\frac{j}{b-a}\\), para \\(j \\in \\{0,\\ldots,N-1\\}\\) \\[ \\begin{eqnarray*} \\mathscr{F}( f )\\left( \\omega_j \\right) &amp; = &amp; h \\exp\\left( -2\\pi i \\frac{j}{b-a} a \\right) \\sum\\limits_{k=0}^{N-1} f_k \\exp\\left( -2\\pi i \\frac{jk}{N} \\right) \\\\ \\hat{f}_j &amp; = &amp; h \\exp\\left( -2\\pi i \\frac{j}{b-a} a \\right) \\left( \\operatorname{DFT}\\left[ \\{f_k\\} \\right] \\right)_j \\quad \\text{por definición de la $\\operatorname{DFT}$} \\end{eqnarray*} \\] entonces, lo anterior implica que podemos recuperar los valores aproximados a \\(f(x_k)\\) utilizando la transformada de Fourier discreta y su inversión. \\[ \\{f( x_k )\\} \\approx \\operatorname{DFT}^{-1}\\left[ \\operatorname{DFT}\\left[ \\{f_k\\} \\right] \\right] = \\operatorname{DFT}^{-1}\\left[ \\left\\{ \\frac{1}{h} \\exp\\left( 2\\pi i \\frac{j}{b-a} a \\right) \\hat{f}_j \\right\\} \\right] \\] es de notar que numérica por la aritmética en coma flotante la expresión \\(\\operatorname{DFT}^{-1}\\left[ \\left\\{ \\frac{1}{h} \\exp\\left( 2\\pi i \\omega_j a \\right) \\hat{f}_j \\right\\} \\right]\\) puede tener parte compleja muy pequeña, cercana a \\(0\\). Para superar este posible problema numérico tomamos solo la parte real. \\[ \\{f( x_k )\\} \\approx \\operatorname{Re}\\left( \\operatorname{DFT}^{-1}\\left[ \\left\\{ \\frac{1}{h} \\exp\\left( 2\\pi i \\frac{j}{b-a} a \\right) \\hat{f}_j \\right\\} \\right] \\right) \\] Code N &lt;- 3000 alpha &lt;- 2 theta &lt;- 3 b &lt;- qgamma( 0.9999, shape = alpha, scale = theta ) a &lt;- 0 h &lt;- ( b - a ) / N n &lt;- 0:N x &lt;- a + n * h w &lt;- n / ( b - a ) eta &lt;- h * exp( -2 * pi * 1i * w * a ) f &lt;- sapply( x, FUN = function( x ) dgamma( x, shape = alpha, scale = theta ) ) Ff &lt;- eta * fft( f ) IFf &lt;- fft( eta^(-1) * Ff, inverse = TRUE ) / ( N + 1 ) IFf &lt;- Re( IFf ) err &lt;- norm( f - IFf, type = &#39;2&#39; ) El error cuadrático de esta aproximación para el caso de la distribución \\(Gamma( \\alpha, \\theta )\\), como es de esperar es bastante pequeño. \\[ \\left\\| \\{f( x_k ) \\} - \\operatorname{DFT}^{-1}\\left[ \\left\\{ \\frac{1}{h} \\exp\\left( 2\\pi i \\omega_j a \\right) \\hat{f}_j \\right\\} \\right] \\right\\|_2 = 0.00000000000035173800 \\] Como se puede observar se superponen cada una de las distribuciones la discretización \\(f_k\\) y la calculada con inversión de la transformada de Fourier discreta. Code xbrk &lt;- seq( 0, 40, length = 9 ) xlbl &lt;- formatC( xbrk, digits = 0, format = &#39;f&#39; ) xlim &lt;- c( 0, 40 ) ybrk &lt;- seq( 0, 0.125, length = 10 ) ylbl &lt;- formatC( ybrk, digits = 3, format = &#39;f&#39; ) ylim &lt;- c( 0, 0.125 ) plt &lt;- ggplot() + geom_line( aes( x = x, y = f ), colour = &#39;darkred&#39;, linewidth = 1 ) + geom_point( aes( x = x, y = IFf ), colour = &#39;olivedrab3&#39;, size = 0.25 ) + scale_x_continuous( breaks = xbrk, labels = xlbl, limits = xlim, expand = c( 0, 0 ) ) + scale_y_continuous( breaks = ybrk, labels = ylbl, limits = ylim, expand = c( 0, 0 ) ) + xlab( TeX( &quot;$x$&quot; ) ) + ylab( TeX( &quot;$f(x)$&quot; ) ) + theme_bw() plot( plt ) Code e &lt;- f - IFf xmax &lt;- max( abs( e ) ) xbrk &lt;- seq( -xmax, xmax, length = 9 ) xlbl &lt;- formatC( xbrk, digits = 2, format = &#39;e&#39; ) xlim &lt;- c( -xmax, xmax ) plt &lt;- ggplot() + geom_histogram( aes( x = e, y = after_stat( density ) ), fill = &#39;grey50&#39;, colour = &#39;dodgerblue3&#39;, bins = nclass.scott( e ) ) + geom_density() + scale_x_continuous( breaks = xbrk, labels = xlbl, limits = xlim, expand = c( 0, 0 ) ) + scale_y_continuous( labels = label_scientific( digits = 4 ) ) + ylab( TeX( &quot;distribución del error&quot; ) ) + xlab( TeX( &quot;error&quot; ) ) + theme_bw() plot( plt ) 4.6 Consideraciones financieras Antes de desarrollar el contenido propio del curso, debemos tener en cuenta algunas consideraciones financieras como las siguientes: 4.6.1 Función de actualización o descuento Definición 4.25 (Funciones de atualización y capitalización) La función de actualización de flujos \\(v: \\mathbb{R}\\times \\mathbb{R}\\longrightarrow [0,1]\\), al evaluar en \\(s, t \\in \\mathbb{R}, s\\leq t, v(s,t)\\), diremos que actualizamos los flujos que se producen en el tiempo \\(t\\), valorados desde el tiempo \\(s\\). Además la función de actualización tiene las siguientes propiedades: Si \\(s = t, v(s,t) = 1\\), Si \\(s \\leq t, v(s,t) \\leq 1\\), Si \\(r \\leq s \\leq t, v( r, s ) v( s, t ) = v( r, t )\\). La función de capitalización, es la función \\(u: \\mathbb{R}\\times \\mathbb{R}\\longrightarrow [0,1]\\), tal que \\(u( s, t ) v( s, t ) = 1\\). El caso más particular y sencillo se presenta cuando la función de actualización es generada por una tasa constante \\(i \\in \\mathbb{R}\\) en el tiempo, es decir, la función de actualización toma la forma \\[ v(s,t) = ( 1 + i )^{-(t-s)} \\] 4.6.2 Flujos financieros Un flujo financiero discreto \\(c\\) es una serie de valores reales \\(c(t_1), c(t_2), \\cdots, c(t_n)\\) que se producen en un número discreto de tiempos \\(t_0 &lt; t_1 &lt; \\cdots &lt; t_n\\). El valor presente de estos flujos, en un tiempo \\(t \\leq t_0\\), se lo puede calcular utilizando precisamente la función de actualización \\(v\\) \\[ VP_t( c ) = \\sum\\limits_{k = 1}^n v( t, t_k ) c( t_k ) \\] cuando \\(t=0\\), se suele solo expresar \\(VP( c ) = VP_0( c )\\). 4.6.3 Flujos financieros probables Un flujo financiero discreto \\(c\\) es una serie de valores reales \\(c(t_1), c(t_2), \\cdots, c(t_n)\\) que se producen en un número discreto de tiempos \\(t_0 &lt; t_1 &lt; \\cdots &lt; t_n\\). El valor actuarial presente de estos flujos, en un tiempo \\(t \\leq t_0\\), se lo puede calcular utilizando precisamente la función de actualización \\(v\\) \\[ VAP_t( c ) = \\mathbb{E}\\left[ \\sum\\limits_{k = 1}^n v( t, t_k ) c( t_k ) \\right] = \\sum\\limits_{k = 1}^n v( t, t_k ) \\mathbb{E}\\left[ c( t_k ) \\right] \\] cuando \\(t=0\\), se suele solo expresar \\(VAP( c ) = VAP_0( c )\\). Si cada \\(c(t_k)\\) es una variable aleatoria discreta \\[ VAP_t( c ) = \\sum\\limits_{k = 1}^n v( t, t_k ) \\mathbb{E}\\left[ c( t_k ) \\right] = \\sum\\limits_{k = 1}^n \\sum\\limits_{i=1}^{\\infty} v( t, t_k ) c_i( t_k ) p_i( t_k ) \\] 4.6.4 Equilibrio financiero Se dice que un flujo financiero \\(c(t_1), c(t_2), \\cdots, c(t_n)\\) como el anterior, está en equilibrio financiero si: \\[ VP_0( c ) = \\sum\\limits_{k=0}^{n} v( 0, t_k ) c( t_k ) = 0 \\] El equilibrio financiero se mantiene en el tiempo, basta observar que para cualquier instante \\(t \\geq 0\\) \\[ \\begin{eqnarray*} 0 &amp; = &amp; u( 0, t ) VP_0( c ) \\\\ &amp; = &amp; u( 0, t ) \\sum\\limits_{k=0}^{n} v( 0, t_k ) c( t_k ) \\\\ &amp; = &amp; \\sum\\limits_{t_k \\leq t} u( 0, t ) v( 0, t_k ) c( t_k ) + \\sum\\limits_{t_k &gt; t} u( 0, t ) v( 0, t_k ) c( t_k ) \\\\ &amp; = &amp; \\sum\\limits_{t_k \\leq t} u( 0, t_k ) u( t_k, t ) v( 0, t_k ) c( t_k ) + \\sum\\limits_{t_k &gt; t} u( 0, t ) v( 0, t ) v( t, t_k ) c( t_k ) \\\\ &amp; = &amp; \\sum\\limits_{t_k \\leq t} u( t_k, t ) c( t_k ) + \\sum\\limits_{t_k &gt; t} v( t, t_k ) c( t_k ) \\\\ \\end{eqnarray*} \\] Esto implica que el valor actualizado a cualquier instante \\(t\\) de un flujo financiero \\(c\\) que está en equilibrio en un inicio, se mantiene también en equilibrio; siempre y cuando se preserve los flujos y tasas de actualización. A pesar de ser un resultado evidente, en la izquierda tenemos los flujos capitalizados hasta el tiempo \\(t\\) y en la derecha tenemos los flujos actualizados al tiempo \\(t\\). La expresión de la izquierda se conoce como la parte retrospectiva y la expresión de la derecha como la parte prospectiva. En condiciones de equilibrio financiero la parte retrospectiva es igual a menos la parte prospectiva. \\[ \\sum\\limits_{t_k \\leq t} u( t_k, t ) c( t_k ) = -\\sum\\limits_{t_k &gt; t} v( t, t_k ) c( t_k ) \\] algunas veces se considera la parte prospectiva con el signo menos. "],["distribuciones.html", "Capítulo 5 Distribuciones 5.1 Distribuciones discretas 5.2 Familia de Panjer 5.3 Distribuciones continuas 5.4 Estimación", " Capítulo 5 Distribuciones 5.1 Distribuciones discretas 5.1.1 Distribución binomial Definición 5.1 (Distribución binomial) Una variable aleatoria \\(N\\) que toma valores en \\(\\mathbb{N}\\) se dice que sigue una distribución o ley de binomial \\(N \\rightsquigarrow Bin( n, p )\\), con parámetros \\(n \\in \\mathbb{N}\\) y \\(p \\in [0, 1]\\), si: \\[ P( N = k ) = \\binom{n}{k} p^k ( 1 - p )^{n-k}, \\qquad \\forall k \\in \\{0,\\ldots, n\\} \\] esta distribución discreta se caracteriza por presentar el valor \\(k \\frac{p_k}{p_{k-1}}\\) decreciente conforme cambia \\(k \\in \\mathbb{N}\\) Code set.seed(94312) n &lt;- 50 p &lt;- 0.3 k &lt;- 2 m &lt;- 100 N &lt;- rbinom( n = m, size = n, prob = p ) # simular una muestra de tamaño m pk &lt;- dbinom( x = k, size = n, prob = p ) # cálculo de probabilidad P( N = k ) Pk &lt;- pbinom( q = k, size = n, prob = p ) # cálculo de probabilidad P( N &lt;= k ) p &lt;- dbinom( x = 0:n, size = n, prob = p ) v &lt;- 1:n * p[ 2:(n + 1) ] / p[ 1:n ] Code plt &lt;- ggplot() + geom_point( aes( x = 1:n, y = v ), colour = &#39;darkred&#39; ) + xlab( TeX( &quot;$k$&quot; ) ) + ylab( TeX( &quot;$k \\\\frac{p_k}{p_{k-1}}$&quot; ) ) + theme_bw() plot( plt ) 5.1.2 Distribución de Poisson Definición 5.2 (Distribución de Poisson) Una variable aleatoria \\(N\\) que toma valores en \\(\\mathbb{N}\\) se dice que sigue una distribución o ley de Poisson \\(N \\rightsquigarrow Pois( n, p )\\), con parámetro \\(\\lambda \\in \\mathbb{R}\\), si: \\[ P( N = k ) = \\exp\\left( -\\lambda \\right) \\frac{\\lambda^k}{k!}, \\qquad \\forall k \\in \\mathbb{N} \\] esta distribución discreta se caracteriza por presentar el valor \\(k \\frac{p_k}{p_{k-1}}\\) constante conforme cambia \\(k \\in \\mathbb{N}\\) Code lambda &lt;- 2 k &lt;- 2 m &lt;- 100 N &lt;- rpois( n = m, lambda = lambda ) # simular una muestra de tamaño m pk &lt;- dpois( x = k, lambda = lambda ) # cálculo de probabilidad P( N = k ) Pk &lt;- ppois( q = k, lambda = lambda ) # cálculo de probabilidad P( N &lt;= k ) n &lt;- 50 p &lt;- dpois( x = 0:n, lambda = lambda ) v &lt;- 1:n * p[ 2:(n + 1) ] / p[ 1:n ] Code plt &lt;- ggplot() + geom_point( aes( x = 1:n, y = v ), colour = &#39;darkred&#39; ) + xlab( TeX( &quot;$k$&quot; ) ) + ylab( TeX( &quot;$k \\\\frac{p_k}{p_{k-1}}$&quot; ) ) + theme_bw() plot( plt ) 5.1.3 Distribución binomial negativa Definición 5.3 (Distribución binomial negativa) Una variable aleatoria \\(N\\) que toma valores en \\(\\mathbb{N}\\) se dice que sigue una distribución o ley de binomial negativa \\(N \\rightsquigarrow NBin( \\alpha, p )\\), con parámetro \\(\\alpha &gt; 0\\) y \\(p \\in (0,1)\\), si: \\[ P( N = k ) = \\binom{\\alpha + k - 1}{k} p^\\alpha ( 1 - p )^k = \\frac{\\Gamma( \\alpha + k )}{\\Gamma(k+1) \\Gamma(\\alpha)}p^\\alpha ( 1 - p )^k, \\qquad \\forall k \\in \\mathbb{N} \\] donde \\(\\Gamma( \\alpha ) = \\int\\limits_0^{+\\infty} x^{\\alpha - 1} \\exp(-x)\\ dx\\), \\(\\forall \\alpha \\geq 0\\). Esta distribución discreta se caracteriza por presentar el valor \\(k \\frac{p_k}{p_{k-1}}\\) creciente conforme cambia \\(k \\in \\mathbb{N}\\) Code alpha &lt;- 2.5 p &lt;- 0.3 k &lt;- 2 m &lt;- 100 N &lt;- rnbinom( n = m, size = alpha, prob = p ) # simular una muestra de tamaño m pk &lt;- dnbinom( x = k, size = alpha, prob = p ) # cálculo de probabilidad P( N = k ) Pk &lt;- pnbinom( q = k, size = alpha, prob = p ) # cálculo de probabilidad P( N &lt;= k ) n &lt;- 50 p &lt;- dnbinom( x = 0:n, size = alpha, prob = p ) v &lt;- 1:n * p[ 2:(n + 1) ] / p[ 1:n ] Code plt &lt;- ggplot() + geom_point( aes( x = 1:n, y = v ), colour = &#39;darkred&#39; ) + xlab( TeX( &quot;$k$&quot; ) ) + ylab( TeX( &quot;$k \\\\frac{p_k}{p_{k-1}}$&quot; ) ) + theme_bw() plot( plt ) Definición 5.4 (Distribución geométrica) Una variable aleatoria \\(N\\) que toma valores en \\(\\mathbb{N}\\) se dice que sigue una distribución o ley geométrica \\(N \\rightsquigarrow Geo( p )\\), con parámetro \\(p \\in (0,1]\\), si: \\[ P( N = k ) = ( 1 - p )^k p, \\qquad \\forall k \\in \\mathbb{N} \\] Code p &lt;- 0.3 k &lt;- 2 m &lt;- 100 N &lt;- rgeom( n = m, prob = p ) # simular una muestra de tamaño m pk &lt;- dgeom( x = k, prob = p ) # cálculo de probabilidad P( N = k ) Pk &lt;- pgeom( q = k, prob = p ) # cálculo de probabilidad P( N &lt;= k ) Es fácil darse cuenta que la distribución geométrica \\(Geo( p )\\) es una binomial negativa \\(BN( 1, p )\\), con \\(\\alpha = 1\\). Asociado a estas distribuciones discretas existe un resultado de caracterización, el cual permite seleccionar la distribución de conteo. 5.2 Familia de Panjer El criterio anterior para identificar el tipo de distribución, mediante la observación del comportamiento de la variable \\(k \\frac{p_k}{p_{k-1}}\\), se formaliza precisamente en la definición de la familia de Panjer. Definición 5.5 (Familia de Panjer) Una variable aleatoria discreta \\(N\\), que toma valores enteros positivos \\(N \\in \\mathbb{N}\\), se dice que pertenece a la familia de Panjer, si sus probabilidades \\(p_k = P( N = k )\\) para cada \\(k \\in \\mathbb{N}\\), satisfacen la siguiente relación de recurrencia. \\[ p_k = \\left( a + \\frac{b}{k} \\right)p_{k-1},\\qquad \\forall k \\in \\mathbb{N}\\setminus \\{0\\} \\] Además tenemos la siguiente proposición que caracteriza a la distribución de las variables aleatorias en la familia de Panjer. Proposición 5.1 (Caracterización familia de Panjer) Las únicas leyes de probabilidad que satisfacen la relación de recurrencia anterior son: La ley de Poisson, la cual se obtiene para \\(a = 0\\) y \\(b &gt; 0\\) \\[ k \\frac{p_k}{p_{k-1}} = b &gt; 0,\\quad \\text{constante en $k$} \\] La ley binomial negativa, la cual se obtiene para \\(0 &lt; a &lt; 1\\) y \\(a + b &gt; 0\\) \\[ k \\frac{p_k}{p_{k-1}} = a k + b &gt; 0,\\quad \\text{creciente en $k$} \\] La ley binomial, la cual se obtenida para \\(a &lt; 0\\) y \\(b = -a(m + 1)\\), para cierto \\(m\\) entero y positivo. \\[ k \\frac{p_k}{p_{k-1}} = a( k - m - 1 ) &lt; 0, \\quad \\text{decreciente en $k$} \\] Para una demostración detallada de la proposición anterior se puede consultar [8] o en https://nonlifemaths.github.io/. Code # la librería CASdatasets fue previamente cargada data( beMTPL97 ) beMTPL97 &lt;- as.data.table( beMTPL97 ) conteo &lt;- beMTPL97[ , list( fn = .N ), by = list( sex, fuel, N = nclaims ) ] conteo[ , pn := fn / sum( fn ), by = list( sex, fuel ) ] setorder( conteo, sex, fuel, N ) conteo[ , pns := shift( pn, type = &#39;lag&#39;, fill = 0 ) ] conteo[ , jn := N * pns / pn ] conteo %&gt;% kable( label = NA, caption = &#39;Estimación conteos por sexo&#39;, row.names = FALSE, col.names = c( &quot;sexo&quot;, &quot;fuel&quot;, &quot;$N$&quot;, &quot;$f_k$&quot;, &quot;$p_k$&quot;, &quot;$p_{k+1}$&quot;, &quot;$k \\\\frac{p_{k+1}}{p_k}$&quot; ), align = &#39;llrrrrr&#39;, digits = c( 0, 0, 0, 0, 5, 5, 5 ), format.args = list( big.mark = &#39;,&#39;, decimal.mark = &#39;.&#39;, scientific = FALSE ), escape = FALSE, centering = TRUE ) %&gt;% kable_classic( font_size = 14, full_width = FALSE, html_font = &quot;Cambria&quot;, position = &quot;center&quot; ) %&gt;% scroll_box( width = &quot;100%&quot;, height = &quot;500px&quot; ) Tabla 5.1: Estimación conteos por sexo sexo fuel \\(N\\) \\(f_k\\) \\(p_k\\) \\(p_{k+1}\\) \\(k \\frac{p_{k+1}}{p_k}\\) female gasoline 0 29,533 0.88741 0.00000 0.00000 female gasoline 1 3,384 0.10168 0.88741 8.72725 female gasoline 2 326 0.00980 0.10168 20.76074 female gasoline 3 33 0.00099 0.00980 29.63636 female gasoline 4 3 0.00009 0.00099 44.00000 female gasoline 5 1 0.00003 0.00009 15.00000 female diesel 0 8,557 0.86539 0.00003 0.00000 female diesel 1 1,206 0.12197 0.86539 7.09536 female diesel 2 109 0.01102 0.12197 22.12844 female diesel 3 14 0.00142 0.01102 23.35714 female diesel 4 2 0.00020 0.00142 28.00000 male gasoline 0 71,357 0.89714 0.00020 0.00000 male gasoline 1 7,417 0.09325 0.89714 9.62074 male gasoline 2 682 0.00857 0.09325 21.75073 male gasoline 3 74 0.00093 0.00857 27.64865 male gasoline 4 7 0.00009 0.00093 42.28571 male gasoline 5 1 0.00001 0.00009 35.00000 male diesel 0 35,489 0.87614 0.00001 0.00000 male diesel 1 4,532 0.11188 0.87614 7.83076 male diesel 2 439 0.01084 0.11188 20.64692 male diesel 3 41 0.00101 0.01084 32.12195 male diesel 4 5 0.00012 0.00101 32.80000 Code plt &lt;- ggplot() + geom_point( data = conteo, aes( x = N, y = jn ), colour = &#39;purple&#39; ) + xlab( TeX( &quot;$k$&quot; ) ) + ylab( TeX( &quot;$k \\\\frac{p_k}{p_{k-1}}$&quot; ) ) + theme_bw() plot( plt ) Además, una forma sencilla de estimar si una variable sigue una distribución de las tres antes descritas es estudiando su coeficiente de variación \\(\\operatorname{VC}( N ) = \\frac{\\mathbb{V}[N]}{\\mathbb{E}[N]}\\). Si \\(N\\) sigue una ley de Poisson \\(Pois(\\lambda)\\), entonces: \\[ \\operatorname{VC}( N ) = \\frac{\\mathbb{V}[N]}{\\mathbb{E}[N]} = \\frac{\\lambda}{\\lambda} = 1 \\] Si \\(N\\) sigue una ley de binomial negativa \\(NBinom( \\alpha, p )\\), entonces: \\[ \\operatorname{VC}( N ) = \\frac{\\mathbb{V}[N]}{\\mathbb{E}[N]} = \\frac{\\alpha\\frac{1-p}{p^2}}{\\alpha\\frac{1-p}{p}} = \\frac{1}{p} &gt; 1 \\] Si \\(N\\) sigue una ley de binomial \\(Binom( n, p )\\), entonces: \\[ \\operatorname{VC}( N ) = \\frac{\\mathbb{V}[N]}{\\mathbb{E}[N]} = \\frac{np(1-p)}{np} = 1 - p &lt; 1 \\] 5.3 Distribuciones continuas 5.3.1 Distribución uniforme Definición 5.6 (Distribución uniforme) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución uniforme \\(X \\rightsquigarrow Unif( a, b )\\) de parámetros \\(a, b \\in \\mathbb{R}\\), si su función de distribución acumulada es de la siguiente forma: \\[ F_X( x ) = \\frac{x-a}{b-a} \\mathbf{1}_{[a,b)}( x ) + \\mathbf{1}_{[b,+\\infty)}( x ) \\] sin mucho esfuerzo se puede verificar que su densidad de probabilidad está dada por la función \\[ f_X( x ) = \\frac{1}{b-a}\\mathbf{1}_{[a,b]}( x ) \\] \\[ M_X( t ) = \\frac{\\exp(bt)-\\exp(at)}{t(b-a)} \\] \\[ \\mathbb{E}[X] = \\frac{a + b}{2},\\qquad \\mathbb{V}[X] = \\frac{(b - a)^2}{12} \\] Code a &lt;- 1 b &lt;- 2 x &lt;- 1.5 m &lt;- 100 X &lt;- runif( n = m, min = a, max = b ) # simular una muestra de tamaño m fx &lt;- dunif( x = x, min = a, max = b ) # cálculo de la densidad f(x) Fk &lt;- punif( q = x, min = a, max = b ) # cálculo de probabilidad F(x) 5.3.2 Distribución exponencial Definición 5.7 (Distribución exponencial) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución exponencial \\(X \\rightsquigarrow Exp( \\lambda )\\) de parámetros \\(\\lambda &gt; 0\\), si su función de distribución acumulada es de la siguiente forma: \\[ F_X( x ) = \\mathbf{1}_{(0,+\\infty)}( x ) \\left( 1 - \\exp\\left( -\\lambda x \\right) \\right) \\] sin mucho esfuerzo se puede verificar que su densidad de probabilidad está dada por la función \\[ f_X( x ) = \\mathbf{1}_{(0,+\\infty)}( x ) \\lambda \\exp\\left( -\\lambda x \\right) \\] \\[ M_X( t ) = \\frac{\\lambda}{\\lambda - t} \\] \\[ \\mathbb{E}[X] = \\frac{1}{\\lambda},\\qquad \\mathbb{V}[X] = \\frac{1}{\\lambda^2} \\] Code lambda &lt;- 2 x &lt;- 1.5 m &lt;- 100 X &lt;- rexp( n = m, rate = lambda ) # simular una muestra de tamaño m fx &lt;- dexp( x = x, rate = lambda ) # cálculo de la densidad f(x) Fk &lt;- pexp( q = x, rate = lambda ) # cálculo de probabilidad F(x) 5.3.3 Distribución gamma Definición 5.8 (Distribución gamma) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución gamma \\(X \\rightsquigarrow Gamma( \\alpha, \\beta )\\) de parámetros \\(\\alpha &gt; 0\\), \\(\\beta &gt; 0\\), si su función de distribución acumulada es de la siguiente forma: \\[ F_X( x ) = \\frac{\\beta^\\alpha}{\\Gamma( \\alpha )} \\int\\limits_{0}^{x} u^{\\alpha-1} \\exp(-\\beta u)\\ du \\] si en caso \\(\\alpha\\) un entero positivo, i.e. \\(\\alpha \\in \\mathbb{N}^*\\), se puede calcular \\(F_X( x )\\) con la siguiente serie \\[ F_X( x ) = 1 - \\exp( -\\lambda x ) \\sum\\limits_{n=0}^{\\alpha-1} \\frac{(\\lambda x)^n}{n!} = \\exp( -\\lambda x ) \\sum\\limits_{n=\\alpha}^{+\\infty} \\frac{(\\lambda x)^n}{n!} \\] por su parte, la densidad de probabilidad automáticamente está dada por la función: \\[ f_X( x ) = \\mathbf{1}_{[0,+\\infty}( x ) \\frac{\\beta^\\alpha}{\\Gamma( \\alpha )} x^{\\alpha-1} \\exp(-\\beta x) \\] \\[ M_X( t ) = \\left( \\frac{\\beta}{\\beta - t} \\right)^\\alpha,\\qquad \\text{si}\\ t &lt; \\beta \\] \\[ \\mathbb{E}[X] = \\frac{\\alpha}{\\beta},\\qquad \\mathbb{V}[X] = \\frac{\\alpha}{\\beta^2} \\] Code alpha &lt;- 2 beta &lt;- 1 x &lt;- 3 m &lt;- 100 X &lt;- rgamma( n = m, shape = alpha, scale = beta ) # simular una muestra de tamaño m fx &lt;- dgamma( x = x, shape = alpha, scale = beta ) # cálculo de la densidad f(x) Fk &lt;- pgamma( q = x, shape = alpha, scale = beta ) # cálculo de probabilidad F(x) 5.3.4 Distribución normal Definición 5.9 (Distribución normal) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución normal \\(X \\rightsquigarrow N( \\mu, \\sigma )\\) de parámetros \\(\\mu \\in \\mathbb{R}\\), \\(\\sigma &gt; 0\\), si su función de distribución acumulada es de la siguiente forma: \\[ F_X( x ) = \\frac{1}{\\sqrt{2\\pi} \\sigma} \\int\\limits_{-\\infty}^x \\exp\\left( -\\frac{(y - \\mu)^2}{\\sigma^2} \\right)\\ dy \\] la densidad de probabilidad automáticamente está dada por la función: \\[ f_X( x ) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left( -\\frac{(x - \\mu)^2}{\\sigma^2} \\right) \\] \\[ M_X( t ) = \\exp\\left( t \\mu + \\frac{1}{2} t^2 \\sigma^2 \\right) \\] \\[ \\mathbb{E}[X] = \\mu,\\qquad \\mathbb{V}[X] = \\sigma^2 \\] Code mu &lt;- 2 sigma &lt;- 1 x &lt;- 3 m &lt;- 100 X &lt;- rnorm( n = m, mean = mu, sd = sigma ) # simular una muestra de tamaño m fx &lt;- dnorm( x = x, mean = mu, sd = sigma ) # cálculo de la densidad f(x) Fk &lt;- pnorm( q = x, mean = mu, sd = sigma ) # cálculo de probabilidad F(x) 5.3.5 Distribución log-normal Definición 5.10 (Distribución log-normal) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución log-normal \\(X \\rightsquigarrow LN( \\mu, \\sigma )\\) de parámetros \\(\\mu &gt; 0\\), \\(\\sigma &gt; 0\\), si su función de distribución acumulada es de la siguiente forma: \\[ F_X( x ) = \\frac{1}{\\sqrt{2\\pi} \\sigma} \\int\\limits_{0}^{x} \\frac{1}{y} \\exp\\left( -\\frac{(\\ln(y) - \\mu)^2}{\\sigma^2} \\right)\\ dy \\] la densidad de probabilidad automáticamente está dada por la función: \\[ f_X( x ) = \\frac{1}{x\\sqrt{2\\pi} \\sigma} \\exp\\left( -\\frac{(\\ln(x) - \\mu)^2}{\\sigma^2} \\right) \\] No hay forma analítica para \\(M_X\\) \\[ \\mathbb{E}[X] = \\exp\\left( \\mu + \\frac{1}{2}\\sigma^2 \\right),\\qquad \\mathbb{V}[X] = \\exp\\left( 2 \\mu + \\sigma^2 \\right) \\left( \\exp( \\sigma^2 ) - 1 \\right) \\] Code mu &lt;- 2 sigma &lt;- 1 x &lt;- 3 m &lt;- 100 X &lt;- rlnorm( n = m, meanlog = mu, sdlog = sigma ) # simular una muestra de tamaño m fx &lt;- dlnorm( x = x, meanlog = mu, sdlog = sigma ) # cálculo de la densidad f(x) Fk &lt;- plnorm( q = x, meanlog = mu, sdlog = sigma ) # cálculo de probabilidad F(x) En pocas, una variable aleatoria \\(X \\rightsquigarrow LN( \\mu, \\sigma )\\) sigue una distribución log-normal si y solamente si la variable aleatoria dada por su logaritmo \\(\\ln( X ) \\rightsquigarrow N( \\mu, \\sigma )\\) sigue una distribución normal. 5.3.6 Distribución de Pareto generalizada Definición 5.11 (Distribución de Pareto generalizada) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución de Pareto generalizada \\(X \\rightsquigarrow GPD( \\mu, \\sigma, \\xi )\\) de parámetros \\(\\mu \\in \\mathbb{R}, \\sigma &gt; 0, \\xi \\in \\mathbb{R}\\), si su función de distribución acumulada es de la siguiente forma: \\[ F_X( x ) = \\left \\{ \\begin{array}{ll} 1 - \\left( 1 + \\xi \\frac{x-\\mu}{\\sigma} \\right)^{-\\frac{1}{\\xi}} &amp; \\text{si}\\ \\xi \\neq 0 \\\\ 1 - \\exp\\left( -\\frac{x-\\mu}{\\sigma} \\right) &amp; \\text{si}\\ \\xi = 0 \\end{array} \\right. \\] y su densidad de probabilidad está dada por la función \\[ f_X( x ) = \\left \\{ \\begin{array}{ll} \\frac{1}{\\sigma} \\left( 1 + \\xi \\frac{x-\\mu}{\\sigma} \\right)^{-1-\\frac{1}{\\xi}} &amp; \\text{si}\\ \\xi \\neq 0 \\\\ \\frac{1}{\\sigma} \\exp\\left( -\\frac{x-\\mu}{\\sigma} \\right) &amp; \\text{si}\\ \\xi = 0 \\end{array} \\right. \\] \\[ M_X( t ) = \\exp(\\theta \\mu) \\sum\\limits_{j=0}^{+\\infty} \\frac{\\theta^j \\sigma^j} {\\prod\\limits_{k=0}^j ( 1 - k \\xi )} \\] Code xi &lt;- 1 mu &lt;- 2 sigma &lt;- 1 x &lt;- 3 m &lt;- 100 X &lt;- rgpd( n = m, xi = xi, mu = mu, beta = sigma ) # simular una muestra de tamaño m fx &lt;- dgpd( x = x, xi = xi, mu = mu, beta = sigma ) # cálculo de la densidad f(x) Fk &lt;- pgpd( q = x, xi = xi, mu = mu, beta = sigma ) # cálculo de probabilidad F(x) 5.3.7 Distribución de valores extremos generalizada Definición 5.12 (Distribución de valores extremos generalizada) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución generalizada de valores extremos \\(X \\rightsquigarrow GEV( \\mu, \\sigma, \\xi )\\) de parámetros \\(\\mu \\in \\mathbb{R}, \\sigma &gt; 0, \\xi \\in \\mathbb{R}\\), si su función de distribución acumulada es de la siguiente forma: \\[ F_X( x ) = \\left\\{ \\begin{array}{ll} \\exp\\left( -\\exp\\left( -\\frac{x-\\mu}{\\sigma} \\right) \\right) &amp; \\text{si}\\ \\xi = 0 \\\\ \\exp\\left( -\\left( 1 + \\xi \\frac{x-\\mu}{\\sigma} \\right)^{-\\frac{1}{\\xi}} \\right) &amp; \\text{si}\\ \\xi \\neq 0, 1 + \\xi\\frac{x - \\mu}{\\sigma} &gt; 0 \\end{array} \\right. \\] además se puede verificar que su densidad de probabilidad está dada por la función \\[ f_X( x ) = \\left\\{ \\begin{array}{ll} \\exp\\left(-\\frac{x-\\mu}{\\sigma}\\right) \\exp\\left(-\\exp\\left(-\\frac{x-\\mu}{\\sigma}\\right)\\right) &amp; \\text{si}\\ \\xi = 0 \\\\ \\left( 1 + \\xi \\frac{x - \\mu}{\\sigma}\\right)^{-1-\\frac{1}{\\xi}} \\exp\\left( -\\left( 1 + \\xi \\frac{x-\\mu}{\\sigma} \\right)^{-\\frac{1}{\\xi}} \\right) &amp; \\text{si}\\ \\xi \\neq 0, 1 + \\xi\\frac{x - \\mu}{\\sigma} &gt; 0 \\end{array} \\right. \\] Code xi &lt;- -1 mu &lt;- 2 sigma &lt;- 1 x &lt;- 3 m &lt;- 100 X &lt;- rgev( n = m, xi = xi, mu = mu, beta = sigma ) # simular una muestra de tamaño m fx &lt;- dgev( x = x, xi = xi, mu = mu, beta = sigma ) # cálculo de la densidad f(x) Fk &lt;- pgev( q = x, xi = xi, mu = mu, beta = sigma ) # cálculo de probabilidad F(x) 5.3.8 Distribución t de Student Definición 5.13 (Distribución t de Student) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución t de Student \\(X \\rightsquigarrow t( \\nu )\\) de parámetros \\(\\nu &gt; 0\\), si su función de distribución acumulada es de la siguiente forma: \\[ F_X( x ) = \\frac{1}{2} + \\frac{x}{\\sqrt{\\pi \\nu}} \\frac{\\Gamma\\left( \\frac{\\nu + 1}{2} \\right)}{\\Gamma\\left( \\frac{\\nu}{2} \\right)} F\\left( \\frac{1}{2}, \\frac{\\nu+1}{2}, \\frac{3}{2}, -\\frac{x^2}{\\nu} \\right) \\] donde \\(F\\) es la función hipergeométrica. \\[ F( a, b, c, z ) = \\sum\\limits_{n=0}^{+\\infty} \\frac{(a)_n (b)_n}{(c)_n} \\frac{z^n}{n!} \\] con \\[ (a)_n = \\left\\{ \\begin{array}{ll} 1 &amp; n = 0 \\\\ a( a + 1 ) \\cdots (a + n - 1) &amp; n &gt; 0 \\end{array} \\right. \\] Además, se puede verificar que su densidad de probabilidad está dada por la función \\[ f_X( x ) = \\frac{x}{\\sqrt{\\pi \\nu}} \\frac{\\Gamma\\left(\\frac{\\nu+1}{2}\\right)}{\\Gamma\\left( \\frac{\\nu}{2} \\right)} \\left( 1 + \\frac{x^2}{\\nu} \\right)^{-\\frac{\\nu+1}{2}} \\] La función generadora de momentos \\(M_X( t )\\) no está definida \\[ \\mathbb{E}[X] = \\left\\{ \\begin{array}{ll} 0 &amp; \\text{si}\\ \\nu &gt; 0 \\\\ \\text{no definida} &amp; \\text{si}\\ \\nu \\leq 0 \\end{array} \\right. \\] \\[ \\mathbb{V}[X] = \\left\\{ \\begin{array}{ll} \\frac{\\nu}{\\nu-2} &amp; \\text{si}\\ \\nu &gt; 2 \\\\ +\\infty &amp; \\text{si}\\ 1 &lt; \\nu \\leq 2 \\\\ \\text{no definida} &amp; \\text{si}\\ \\nu \\leq 1 \\end{array} \\right. \\] Code nu &lt;- 3 x &lt;- 4 m &lt;- 100 X &lt;- rt( n = m, df = nu ) # simular una muestra de tamaño m fx &lt;- dt( x = x, df = nu ) # cálculo de la densidad f(x) Fk &lt;- pt( q = x, df = nu ) # cálculo de probabilidad F(x) 5.3.9 Distribución gamma transformada Definición 5.14 (Distribución gamma transformada) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución gamma transformada \\(X \\rightsquigarrow GT( \\alpha, \\tau, \\theta )\\) de parámetros \\(\\alpha &gt; 0, \\tau &gt; 0, \\theta &gt; 0\\), si su función de distribución acumulada es de la siguiente forma: \\[ F_X( x ) = \\frac{\\tau}{\\Gamma( \\alpha )} \\int\\limits_{0}^x \\frac{1}{u} \\left( \\frac{u}{\\theta} \\right)^{\\alpha} \\exp\\left(-\\left( \\frac{u}{\\theta} \\right)^{\\tau}\\right)\\ du \\] además se puede verificar que su densidad de probabilidad está dada por la función: \\[ f_X( x ) = \\left\\{ \\begin{array}{ll} 0 &amp; \\text{si}\\ x \\leq 0 \\\\ \\frac{\\tau}{x \\Gamma( \\alpha )} \\left( \\frac{x}{\\theta} \\right)^{\\alpha} \\exp\\left(-\\left( \\frac{x}{\\theta} \\right)^{\\tau}\\right) &amp; \\text{si}\\ x &gt; 0 \\end{array} \\right. \\] \\[ \\begin{eqnarray*} \\mathbb{E}[X^k] &amp; = &amp; \\frac{\\theta^k \\Gamma\\left( \\alpha + \\frac{k}{\\tau}\\right)}{\\Gamma( \\alpha )}, \\quad \\text{si}\\ k &gt; -\\alpha \\tau \\\\ \\mathbb{E}[X] &amp; = &amp; \\frac{\\theta \\Gamma\\left( \\alpha + \\frac{1}{\\tau}\\right)}{\\Gamma( \\alpha )}, \\quad \\text{si}\\ 1 &gt; -\\alpha \\tau \\\\ \\mathbb{V}[X] &amp; = &amp; \\frac{\\theta^2 \\Gamma\\left( \\alpha + \\frac{2}{\\tau}\\right)}{\\Gamma( \\alpha )} - \\frac{\\theta^2 \\Gamma\\left( \\alpha + \\frac{1}{\\tau}\\right)^2}{\\Gamma( \\alpha )^2} \\end{eqnarray*} \\] Code alpha &lt;- 1 tau &lt;- 1 theta &lt;- 1 x &lt;- 3 m &lt;- 100 X &lt;- rtrgamma( n = m, shape1 = alpha, shape2 = tau, scale = theta ) # simular una muestra de tamaño m fx &lt;- dtrgamma( x = x, shape1 = alpha, shape2 = tau, scale = theta ) # cálculo de la densidad f(x) Fk &lt;- ptrgamma( q = x, shape1 = alpha, shape2 = tau, scale = theta ) # cálculo de probabilidad F(x) En la familia gamma se incluyen las siguientes distribuciones: La distribución inversa gamma transformada, es decir es una familia estable por inversión La distribución gamma para \\(\\alpha = n/2\\) y \\(\\theta = 2\\) La distribución inversa gamma La distribución de Weibull La distribución inversa de Weibull La distribución exponencial La distribución inversa exponencial 5.3.10 Distribución beta transformada Definición 5.15 (Distribución beta transformada) Una variable aleatoria \\(X\\) a valores reales, sigue una distribución beta transformada \\(X \\rightsquigarrow BT( \\alpha, \\gamma, \\tau, \\theta )\\) de parámetros \\(\\alpha &gt; 0, \\gamma &gt; 0, \\tau &gt; 0, \\theta &gt; 0\\), si su función de distribución acumulada es de la siguiente forma: \\[ F_X( x ) = \\frac{\\Gamma(\\alpha + \\tau)}{\\Gamma( \\alpha ) \\Gamma( \\tau )} \\int\\limits_0^x \\frac{\\gamma \\left( \\frac{u}{\\theta} \\right)^{\\gamma \\tau}}{u\\left( 1 + \\left( \\frac{u}{\\theta} \\right)^{\\gamma}\\right)^{\\alpha + \\tau}}\\ du \\] además se puede verificar que su densidad de probabilidad está dada por la función: \\[ f_X( x ) = \\mathbf{1}_{[0,+\\infty)}( x ) \\frac{\\Gamma(\\alpha + \\tau)}{\\Gamma( \\alpha ) \\Gamma( \\tau )} \\frac{ \\gamma \\left( \\frac{x}{\\theta} \\right)^{\\gamma \\tau}}{x\\left( 1 + \\left( \\frac{x}{\\theta} \\right)^{\\gamma}\\right)^{\\alpha + \\tau}} \\] \\[ \\begin{eqnarray*} \\mathbb{E}[X^k] &amp; = &amp; \\frac{\\theta^k \\Gamma\\left( \\tau + \\frac{k}{\\gamma}\\right) \\Gamma\\left( \\tau - \\frac{k}{\\gamma}\\right)}{\\Gamma( \\alpha ) \\Gamma( \\tau )}, \\quad \\text{si}\\ -\\tau \\gamma &lt; k &lt; \\tau \\gamma \\\\ \\mathbb{E}[X] &amp; = &amp; \\frac{\\theta \\Gamma\\left( \\tau + \\frac{1}{\\gamma}\\right) \\Gamma\\left( \\tau - \\frac{1}{\\gamma}\\right)}{\\Gamma( \\alpha ) \\Gamma( \\tau )} \\\\ \\mathbb{V}[X] &amp; = &amp; \\frac{\\theta^2 \\Gamma\\left( \\tau + \\frac{2}{\\gamma}\\right) \\Gamma\\left( \\tau - \\frac{2}{\\gamma}\\right)}{\\Gamma( \\alpha ) \\Gamma( \\tau )} - \\frac{\\theta^2 \\Gamma\\left( \\tau + \\frac{1}{\\gamma}\\right)^2 \\Gamma\\left( \\tau - \\frac{1}{\\gamma}\\right)^2}{\\Gamma( \\alpha )^2 \\Gamma( \\tau )^2} \\end{eqnarray*} \\] Code alpha &lt;- 1 gamma &lt;- 1 tau &lt;- 1 theta &lt;- 1 x &lt;- 3 m &lt;- 100 X &lt;- rtrbeta( n = m, shape1 = alpha, shape2 = gamma, shape3 = tau, scale = theta ) # simular una muestra de tamaño m fx &lt;- dtrbeta( x = x, shape1 = alpha, shape2 = gamma, shape3 = tau, scale = theta ) # cálculo de la densidad f(x) Fk &lt;- ptrbeta( q = x, shape1 = alpha, shape2 = gamma, shape3 = tau, scale = theta ) # cálculo de probabilidad F(x) Dentro de la familia beta transformada se cuenta algunas distribuciones de probabilidad: La distribución de Burr para \\(\\tau = 1\\) La distribución de log-logística para \\(\\alpha = \\tau = 1\\) La distribución de paralogística para \\(\\alpha = \\gamma, \\tau = 1\\) La distribución de generalizada de Pareto para \\(\\gamma = 1\\) La distribución de Pareto para \\(\\gamma = \\tau = 1\\) La distribución de inversa de Burr para \\(\\alpha = 1\\) La distribución de inversa de Pareto para \\(\\alpha = \\gamma = 1\\) La distribución de inversa paralogística para \\(\\alpha = 1, \\gamma = \\tau\\) La distribución transformada gamma es un caso límite de la distribución transformada beta, cuando \\(\\theta \\rightarrow +\\infty, \\alpha \\rightarrow +\\infty\\) y \\(\\theta \\alpha^{-\\frac{1}{\\gamma}} \\rightarrow \\xi\\) 5.4 Estimación En la práctica se observa la realización de una variable aleatoria \\(X\\), es decir se tiene una muestra de la misma \\(X_1, \\ldots, X_n\\). Pero, no se dispone de la distribución \\(F\\) o de la densidad \\(f\\) que la describe. Como ya hemos mencionado, conociendo la distribución se puede inferir algunas propiedades sobre la variable. De ahí surge la necesidad de buscar la mejor distribución \\(F\\) posible a partir de la muestra [7], [12], [5], [11]. La estimación usualmente consiste en tratar de determinar la probabilidad \\(P_X\\) asociada a \\(X\\), o en su defecto su función de distribución acumulada. Bajo la consideración, usualmente, de alguna información adicional, se considera que para la medida de de probabilidad \\(P_X\\) que caracteriza a la variable aleatoria \\(X\\) está dentro de una familia probabilidades que dependen de un parámetro \\(\\theta\\) el cual pertenece a un conjunto \\(\\Theta\\), precisamente parametriza a la familia, es decir, para cada \\(\\theta \\in \\Theta\\), \\(P_{\\theta}\\) es una medida de probabilidad y para algún \\(\\theta \\in \\Theta, P_X = P_{\\theta}\\). Ya en la práctica se tiene una muestra, por lo regular finita, \\(X_1, \\ldots, X_n\\) de la variable aleatoria \\(X\\) que se desea comprender. Es a partir de la muestra que se intenta crear un estimador \\(\\tau\\) el cual sea precisamente el “mejor” bajo un cierto criterio que aproxime a la probabilidad \\(P_X\\), en términos algo más matemáticos \\(P_X \\approx P_{\\tau}\\). Por lo regular, se propone un estimador \\(\\tau\\) como función de la muestra y su tamaño \\(\\tau_n( X_1, \\ldots, X_n ) = \\tau( n, X_1, \\ldots, X_n )\\), en muchos casos se considera construir una función medible, que precisamente genere eventos observables. Es de notar que el estimador \\(\\tau_n\\) al depender de una muestra, la cual está constituida por variables aleatorias, como función de variables aleatorias se convierte también en una variable aleatoria al ser evaluada en estas. Hay algunas propiedades deseables para una familia de estimadores \\(\\mathcal{E}\\), estas son: Consistencia Insesgamiento Eficiencia Suficiencia Para, cada adjuntamos sus respectivas definiciones Definición 5.16 (Estimadores consistentes) Consideramos una variable aleatoria \\(X\\), cuya medida de probabilidad asociada \\(P_X\\) pertenece a una familia de distribuciones de probabilidad \\(\\{P_\\theta\\}_{\\theta \\in \\Theta}\\), esto quiere decir que \\(P_X\\) está determinada por algún \\(\\theta \\in \\Theta\\), i.e. \\(P_X = P_{\\theta}\\). Entonces, la familia de estimadores \\(\\mathcal{E} = \\{ \\tau_n \\}_n\\) es consistente para la familia de probabilidades \\(\\{P_\\theta\\}_{\\theta \\in \\Theta}\\) si para cualquier \\(n \\in \\mathbb{N}\\) y muestra \\(X_1, \\ldots, X_n\\) de \\(X\\) el estimador \\(\\tau_n( X_1,\\ldots,X_n)\\) converge en probabilidad a \\(\\theta\\). Para todo \\(\\varepsilon &gt; 0\\) \\[ \\underset{n \\rightarrow +\\infty}{\\lim} P_{\\theta}\\left( \\left| \\tau_n( X_1,\\ldots,X_n) - \\theta \\right| &gt; \\varepsilon\\right) = 0 \\] también se dice que la familia de estimadores es convergente. Decimos que converge fuertemente si la convergencia de la familia de estimadores \\(\\mathcal{E} = \\{ \\tau_n \\}_n\\) al parámetro \\(\\theta\\) se da casi seguramente o en casi todas partes. Esto en término de límites implica que: \\[ P_{\\theta}\\left( \\underset{n \\rightarrow +\\infty}{\\lim} \\tau_n\\left( X_1, \\ldots, X_n \\right) = \\theta \\right) = 1 \\] En otras palabras, la probabilidad de que el límite del estimador \\(\\tau_n( X_1, \\ldots, X_n )\\) sea igual a \\(\\theta\\) es \\(1\\), salvo un conjunto de medida nula para \\(P_{\\theta}\\). De ahí resulta la terminología de convergencia casi segura o convergencia en casi todas partes. Definición 5.17 (Estimadores insesgados) Bajo el mismo contexto de la definición anterior. Decimos que el estimador \\(\\tau_n\\) es insesgado si precisamente su esperanza es igual al parámetro a estimar \\(\\theta \\in \\Theta\\). \\[ \\mathbb{E}\\left[ \\tau_n( X_1,\\ldots,X_n) \\right] = \\theta \\] La familia de estimadores \\(\\mathcal{E} = \\{ \\tau_n \\}_n\\) será insesgada si para cada \\(n\\) se satisface lo anterior. El siguiente teorema es de importancia para caracterizar una familia de estimadores consistentes. Teorema 5.1 Una familia de estimadores \\(\\{ \\tau_n \\}_n\\) para la cual se cumplen los siguientes límites \\(\\mathbb{E}\\left[ \\tau_n( X_1,\\ldots,X_n) \\right] \\rightarrow \\theta\\), conforme \\(n \\rightarrow +\\infty\\), \\(\\mathbb{V}\\left[ \\tau_n( X_1,\\ldots,X_n) \\right] \\rightarrow 0\\), conforme \\(n \\rightarrow +\\infty\\). Entonces, la familia \\(\\{ \\tau_n \\}_n\\) es consistente como estimadores de \\(\\theta\\). Definición 5.17 (Estimador más eficiente) De igual forma en el contexto anterior. En una familia de estimadores consistentes para estimar un parámetro, si entre estos estimadores existe uno para el cual su varianza sea mínima, entonces si existe tal estimador se dice que este es el estimador más eficiente. Sin \\(\\mathcal{E}\\) es la familia de estimadores y \\(\\xi\\) es el estimador más eficiente, entonces para cualquier otro estimador \\(\\tau \\in \\mathcal{E}\\), se tiene la siguiente desigualdad \\[ \\mathbb{V}\\left[ \\xi \\right] \\leq \\mathbb{V}\\left[ \\tau \\right] \\] la eficiencia \\(E\\) de los estimadores en la familia \\(\\mathcal{E}\\) está dada por \\[ 0 \\leq E( \\tau ) = \\frac{\\mathbb{V}\\left[ \\xi \\right]}{\\mathbb{V}\\left[ \\tau \\right]} \\leq 1 \\] Si además el estimador más eficiente \\(\\xi\\) es insesgado se dirá que este es un estimador de varianza mínima insesgado, o de forma corta MVUE por el término en inglés (minimum variance unbiased estimator). Teorema 5.2 Si en una familia de estimadores \\(\\mathcal{E}\\) tenemos dos estimadores MVUE para el mismo parámetro \\(\\theta \\in \\Theta\\), entonces estos dos estimadores son iguales en casi todas partes o lo que es lo mismo solo son diferentes en un conjunto de medida nula. Definición 5.18 (Estimador suficiente) Dada una muestra \\(X_1, \\ldots, X_n\\) de la variable aleatoria \\(X\\). Un estimador \\(\\tau\\left( X_1, \\ldots, X_n \\right)\\) se dice un estimador suficiente para el parámetro \\(\\theta \\in \\Theta\\), si la distribución condicionada de la muestra \\(X_1, \\ldots X_n\\) dado el estimador \\(\\tau\\) es independiente del parámetro \\(\\theta\\). El resultado a continuación es una caracterización del criterio de suficiencia, para una demostración se puede consultar [18], [11]. Teorema 5.3 (Teorema de factorización) Un estimador \\(\\tau\\) es suficiente para el parámetro \\(\\theta\\) si y solo si la densidad conjunta de la muestra \\(X_1, \\ldots, X_n\\) puede ser expresada en la forma. \\[ f\\left( x_1, \\ldots, x_n \\right) = g\\left( \\theta, \\tau\\left( x_1, \\ldots, x_n \\right) \\right) h\\left( x_1, \\ldots, x_n \\right) \\] Definición 5.19 (Familia completa) Data un estimador \\(\\tau\\) que depende de una muestra aleatoria \\(X_1, \\ldots, X_n\\) y una familia de medidas de probabilidad \\(\\{ P_\\theta \\}_{\\theta \\in \\Theta}\\), para cada \\(\\theta \\in \\Theta\\), se puede construir la medida \\(P_{\\tau,\\theta}\\) asociada a la variable aleatoria \\(\\tau(X_1, \\ldots,X_n)\\) y al parámetro \\(\\theta\\) que determina la medida \\(P_\\theta\\). Para cualquier evento \\(A \\in \\mathcal{F}\\). \\[ P_{\\tau,\\theta}( A ) = P_\\theta\\left( \\tau\\left(X_1, \\ldots,X_n\\right) \\in A \\right) \\] Así, la familia de medidas de probabilidad \\(\\{ P_{\\tau,\\theta} \\}_{\\theta \\in \\Theta}\\) se dice completa si se satisface la siguiente implicación. Si una función \\(h : \\mathbb{R}\\longrightarrow \\mathbb{R}\\), tiene esperanza nula para cualquier esperanza tomada bajo la medida \\(P_{\\tau, \\theta}\\), entonces la función \\(h\\) es nula en casi todas partes para toda medida \\(P_\\theta\\). De forma más compacta. \\[ \\forall P_{\\tau,\\theta}, \\mathbb{E}_{P_{\\tau,\\theta}}\\left[ h\\left( \\tau\\left( X_1,\\ldots, X_n \\right) \\right) \\right] = 0 \\Longrightarrow \\forall P_\\theta, P_\\theta\\left( h\\left( \\tau\\left( X_1,\\ldots, X_n \\right) \\right) = 0 \\right) = 1 \\] Por extensión si sucede esta implicación, se dice que \\(\\tau\\) es un estimador completo respecto de la familia \\(\\{ P_\\theta \\}_{\\theta \\in \\Theta}\\). Para ello se ha formulado diferentes aproximaciones, entre las cuales citamos las siguientes: Método de sustitución, Método de los momentos, Método de la distancia mínima, 3.1 Método de mínimos cuadrados, 3.2 Método de mínimo Chi-cuadrado, 3.3 Método de varianza mínima, 3.4 Método de minimización de la divergencia de Kullback–Leibler (máxima verosimilitud). Método de máxima verosimilitud, Método de Stein. 5.4.1 Método de sustitución Entonces, se parte de suponer que existe funcional \\(G\\) actuando sobre el conjunto de medidas de probabilidad \\(\\mathcal{P}\\) que contiene al conjunto \\(P( \\Theta ) = \\{ P_{\\theta} \\mid \\theta \\in \\Theta\\} \\subset \\mathcal{P}\\) y que toma valores en \\(\\Theta\\), i.e. \\(G: \\mathcal{P} \\longrightarrow \\Theta\\). De tal forma que \\(P_{\\theta}\\) es invariante, es decir: \\[ G( P_{\\theta} ) = \\theta,\\quad \\forall \\theta \\in \\Theta \\] Así se construye un estimador por el método de sustitución si a partir de la medida de probabilidad empírica \\(P_n\\) construida con una muestra \\(X_1, \\ldots, X_n\\) de la variable aleatoria \\(X\\), se toma como parámetro el dado por: \\[ \\widehat{\\theta} = G\\left( P_n \\right) \\] En otras palabras se sustituye el parámetro \\(\\theta\\) por \\(\\widehat{\\theta}\\). Esto implica que se aproxima la medida \\(P_X\\) que caracteriza a \\(X\\), con la aproximación \\(P_X \\approx P_{\\widehat{\\theta}}\\). Es de notar que a priori no se hace establece ninguna medida de la calidad de la aproximación, para ello hay que adjuntar algunos otros criterios que caracterizan un buen tipo de estimador. En otras ocasiones a partir de la muestra se define un estimador del parámetro \\(\\theta \\in \\Theta\\) a partir de una familia de funciones medibles que dependen directamente de la muestra \\(X_1, \\ldots, X_n\\) y su tamaño \\(n\\), i.e. una función \\(\\theta_n( X_1, \\ldots, X_n )\\). Se puede considerar el caso anterior como un caso en particular de este tipo de funciones, ya que se puede definir \\(\\theta_n( X_1, \\ldots, X_n ) = G( P_n )\\), pero hay que tener cuidado que \\(G\\) es un funcional y como tal puede resultar una función que no es medible. 5.4.2 Método de momentos Un estimador de momento se construye a partir de una relación función entre la media de una función medible \\(g\\) y el parámetro \\(\\theta \\in \\Theta\\) que caracteriza a la distribución o medida de probabilidad de la variable aleatoria \\(X\\). Es decir, existen funciones \\(g\\) y \\(m\\) a valores reales de tal forma que \\[ m( \\theta ) = \\mathbb{E}_{P_X} \\left[ g( X ) \\right] = \\int\\limits_{\\mathbb{R}} g( x ) dP_X( x ) = \\int\\limits_{\\mathbb{R}} g( x ) dP_{\\theta}( x ) \\] Si de alguna forma se puede invertir \\(m\\), de tal forma que se pueda determinar \\(\\theta\\), en tal caso se pude utilizar un estimador por momentos a partir de una muestra de la variable aleatoria \\(X_1, \\ldots, X_n\\) \\[ \\widehat{\\theta} = \\theta_n\\left( X_1, \\ldots, X_n \\right) = m^{-1}\\left( \\overline{g} \\right) \\] donde \\[ \\overline{g} = \\int\\limits_{\\mathbb{R}} g( x ) dP_n( x ) = \\frac{1}{n}\\sum\\limits_{i=1}^n g\\left( X_i \\right) \\] Si en caso \\(\\overline{g}\\) está fuera de la imagen de \\(m\\), \\(\\overline{g} \\notin m( \\Theta )\\), la inversión no sería posible. Para resolver este problema se puede recurrir a una distancia \\(d\\) y buscar \\(\\hat{g}\\) tal que minimize la distancia a \\(m( \\Theta )\\), i.e.  \\(\\hat{g} = \\underset{h \\in m( \\Theta )}{\\operatorname{arginf}}\\ d( \\overline{g}, h)\\). Una vez determinado \\(\\hat{g}\\) se toma como estimador de momentos su inversa con \\(m\\), i.e.  \\(\\widehat{\\theta} = m^{-1}( \\hat{g} )\\). Es de notar que en el caso anterior, la selección de la mejor distancia \\(d\\) no es para nada evidente y puede ser un problema tanto o más difícil que la misma estimación del parámetro \\(\\theta\\) o la inversión de \\(m\\). La estimación por momentos en los casos más elaborados lleva a buscar la solución de problemas no lineales, que no suelen ser estables y que deben estar bien definidos para proveer una solución única. 5.4.3 Método de la distancia mínima Este método requiere de la definición de una distancia sobre el espacio de distribuciones de probabilidad \\(\\mathcal{P}\\), i.e. una función \\(d : \\mathcal{P} \\times \\mathcal{P} \\longrightarrow \\mathbb{R}_+\\) que satisface las siguientes propiedades: Propiedad de simetría, para cualquier \\(P, Q \\in \\mathcal{P}\\), \\(d( P, Q ) = d( Q, P )\\), Para cualquier \\(P \\in \\mathcal{P}\\), \\(d( P, P ) = 0\\). Desigualdad triangular, para cualquier \\(P,Q,R \\in \\mathcal{P}\\) \\[ d( P, Q ) \\leq d( P, R ) + d( R, Q ) \\] A partir de la medida empírica de probabilidad \\(P_n\\), se busca una probabilidad \\(P_{\\theta}\\) que minimize la distancia medida con \\(d\\). Así resulta el estimador con el método de distancia mínima \\[ \\widehat{\\theta} = \\underset{\\theta \\in \\Theta}{\\operatorname{arginf}} d\\left( P_{\\theta}, P_n \\right) \\] Entra las distancias que se puede considerar tenemos las siguientes Distancia del supremo entre las distribuciones acumuladas correspondientes \\[ d(P,Q) = \\underset{x}{\\sup} \\left| F_P( x ) - F_Q( x ) \\right| \\] Distancia cuadrática entre las distribuciones acumuladas correspondientes \\[ d( P, Q ) = \\int\\limits_{\\mathbb{R}} \\left( F_P( x ) - F_Q( x ) \\right)^2\\ dF_Q( x ) \\] Distancia de Wasserstein, para \\(p &gt; 1\\) \\[ d( P, Q ) = W_p( P, Q ) = \\underset{(X,Y) \\rightsquigarrow \\mu \\in \\Gamma( P, Q )}{\\inf} \\mathbb{E}_{\\mu}\\left[ |X - Y|^p \\right]^{\\frac{1}{p}} \\] donde \\[ \\Gamma( P, Q ) = \\left\\{ \\mu \\middle| \\text{$\\mu$ es medida de probabilidad sobre $\\Omega \\times \\Omega$, cuyas distribuciones marginales son $P$ y $Q$}\\right\\} \\] 5.4.4 Método de maximización de la verosimilitud La estimación de verosimilitud parte de asumir que se observan una cierta cantidad de eventos independientes \\(B_1, \\ldots, B_n\\), relacionados precisamente a la variable aleatoria en estudio \\(X\\). Se postula precisamente que la mejor medida de probabilidad es aquella que maximiza la probabilidad de observar estos eventos independientes. En el caso en particular de la estimación de una medida de probabilidad en una familia \\(\\{P_{\\theta}\\}\\) con \\(\\theta \\in \\Theta\\), se busca maximizar la probabilidad: \\[ \\underset{\\theta \\in \\Theta}{\\sup} \\prod\\limits_{i=1}^n P_{\\theta}\\left( B_i \\right) \\] o de forma equivalente, se puede utilizar una transformación con un logaritmo y tratar de maximizar lo que conocemos como función de verosimilitud logarítmica \\[ \\ell = \\sum\\limits_{i=1}^n \\log P_{\\theta} \\left( B_i \\right) \\] el problema de estimación se reduce a la siguiente optimización \\[ \\underset{\\theta \\in \\Theta}{\\sup} \\ell( \\theta ) \\] Precisamente, el estimador de verosimilitud \\(\\widehat{\\theta}\\), es el que resuelve el problema de optimización donde \\(\\ell\\) es la función objetivo y \\(\\Theta\\) representa el conjunto de restricciones. \\[ \\widehat{\\theta} = \\underset{\\theta \\in \\Theta}{\\operatorname{argsup}} \\ell( \\theta ) \\] En la práctica los eventos que se observa \\(B_i\\) son puntuales y son precisamente los valores que toma la variable aleatoria \\(X\\) para diferentes valores en el espacio muestra \\(\\Omega\\). Es decir, se observa una muestra \\(x_1 = X( \\omega_1 ), \\ldots, x_n = X( \\omega_n )\\). Una forma de atacar el problema de estimación, cuando las observaciones son puntuales es trabar de encerrar cada una de las observaciones en intervalos lo suficientemente pequeños. Se puede tomar un valor \\(h &gt; 0\\), y los eventos \\(B_i = \\left\\{ \\omega \\in \\Omega \\middle| x_i - h \\leq X( \\omega ) \\leq x_i + h \\right\\}\\) y una aproximación de la función de verosimilitud en función de \\(h\\), con la siguiente forma: \\[ \\begin{eqnarray*} \\ell_h( \\theta ) &amp; = &amp; \\sum\\limits_{i=1}^n \\log P_{\\theta} \\left( B_i \\right) \\\\ &amp; = &amp; \\sum\\limits_{i=1}^n \\log P_{\\theta} \\left( x_i - h \\leq X \\leq x_i + h \\right) \\\\ &amp; = &amp; \\sum\\limits_{i=1}^n \\log \\left( F\\left( x_i + h, \\theta \\right) - F\\left( x_i - h, \\theta \\right) \\right) \\\\ \\end{eqnarray*} \\] Sabemos de los diferentes resultados de análisis para funciones de variación acotada, como es el caso de las distribuciones de probabilidad, que tienen diferenciales en casi todo punto, es decir que las singularidades de estas son conjuntos con medida nula. Además la cantidad de singularidades, de saltos que puede presentar una función de variación acotada es a lo sumo numerable. Entonces, cada valor observado \\(x_i \\in \\operatorname{Dif}F\\) es un punto de continuidad donde la función de distribución \\(F\\) es diferenciable o es un punto de singularidad, así los valores observados en la muestra se pueden clasificar en estos dos tipos [13]. De ello se puede dividir la suma anterior. \\[ \\begin{eqnarray*} \\ell_h( \\theta ) &amp; = &amp; \\sum\\limits_{x_i \\in \\operatorname{Dif}F} \\log \\left( F\\left( x_i + h, \\theta \\right) - F\\left( x_i - h, \\theta \\right) \\right) + \\sum\\limits_{x_i \\notin \\operatorname{Dif}F} \\log \\left( F\\left( x_i + h, \\theta \\right) - F\\left( x_i - h, \\theta \\right) \\right) \\\\ \\end{eqnarray*} \\] maximizar \\(\\ell_h\\) es equivalente a maximizar la siguiente función equivalente que notaremos con el mismo nombre \\[ \\begin{eqnarray*} \\ell_h( \\theta ) &amp; = &amp; \\frac{1}{h} \\sum\\limits_{x_i \\in \\operatorname{Dif}F} \\log \\left( F\\left( x_i + h, \\theta \\right) - F\\left( x_i - h, \\theta \\right) \\right) + \\sum\\limits_{x_i \\notin \\operatorname{Dif}F} \\log \\left( F\\left( x_i + h, \\theta \\right) - F\\left( x_i - h, \\theta \\right) \\right) \\\\ \\end{eqnarray*} \\] la multiplicación de la primera suma por la constante \\(\\frac{1}{h}\\) tan solo escala la función, pero no cambia sus puntos críticos. Tomando al límite, un valor \\(h\\) cada vez más pequeño, para encerrar aún más en un intervalo los valores observados \\(\\{x_i\\}\\), tenemos lo siguiente: \\[ \\begin{eqnarray*} \\underset{h \\searrow 0}{\\lim} \\ell_h( \\theta ) &amp; = &amp; \\underset{h \\searrow 0}{\\lim} \\frac{1}{h} \\sum\\limits_{x_i \\in \\operatorname{Dif}F} \\log \\left( F\\left( x_i + h, \\theta \\right) - F\\left( x_i - h, \\theta \\right) \\right) + \\underset{h \\searrow 0}{\\lim} \\sum\\limits_{x_i \\notin \\operatorname{Dif}F} \\log \\left( F\\left( x_i + h, \\theta \\right) - F\\left( x_i - h, \\theta \\right) \\right) \\\\ &amp; = &amp; \\sum\\limits_{x_i \\in \\operatorname{Dif}F} \\log \\left( f(x_i,\\theta) \\right) + \\sum\\limits_{x_i \\notin \\operatorname{Dif}F} \\log \\left( F\\left( x_i, \\theta \\right) - F\\left( x_i-, \\theta \\right) \\right),\\quad \\text{si existe el límite por izquierda de $F$} \\end{eqnarray*} \\] siendo \\(F\\left( x_i-, \\theta \\right)\\) el límite por izquierda de la función de distribución \\(F\\) en el punto \\(x_i\\). Además, recordamos que toda función de distribución es continua por derecha, esto implica que \\(F\\left( x_i, \\theta \\right) = F\\left( x_i+, \\theta \\right)\\). Para el caso puntual esta es precisamente la expresión de la función de verosimilitud logarítmica, la cual podemos utilizar para estimar el mejor parámetro \\(\\theta \\in \\Theta\\) que maximice el valor de verosimilitud. \\[ \\ell( \\theta ) = \\sum\\limits_{x_i \\in \\operatorname{Dif}F} \\log \\left( f(x_i,\\theta) \\right) + \\sum\\limits_{x_i \\notin \\operatorname{Dif}F} \\log \\left( F\\left( x_i, \\theta \\right) - F\\left( x_i-, \\theta \\right) \\right) \\tag{5.1} \\] En los casos más sencillos de estimación por verosimilitud se suele cumplir una de las siguientes hipótesis: todos los puntos \\(x_i\\) sobre los cuales se calcula son puntos de continuidad, o la función de distribución acumulada \\(F\\) no tiene puntos singulares, siendo este último caso el más usual. Pero, en la práctica esto no sucede y la suma adicional a la derecha en la expresión anterior es precisamente necesaria, ya que la distribución \\(F\\) si puede tener singularidades. Al utilizar solo la primera suma sobre los puntos donde hay diferenciabilidad, la estimación por verosimilitud para el parámetro \\(\\theta\\) no será la correcta. Los estimadores que resulta de la maximización de verosimilitud satisfacen algunas propiedades deseables. Teorema 5.4 Los estimadores por maximización de verosimilitud son consistentes. Teorema 5.5 Los estimadores por máximización de verosimilitud, si en caso de existen, estos son eficientes. Teorema 5.6 Si en caso existe un estimador suficiente, este es función del estimador de máxima verosimilitud. Un estimador de máxima verosimilitud no necesariamente es insesgado. Teorema 5.7 Un estimador por maximización de verosimilitud se comporta normalmente de forma asintótica alrededor del verdadero parámetro \\(\\theta \\in \\Theta\\). Más claramente, si \\(\\tau_n\\) es el estimador por maximización de verosimilitud, se tiene que \\(\\tau_n( X_1, \\ldots, X_n ) \\rightsquigarrow F_n\\), entonces en el límite \\(n \\rightarrow +\\infty\\), se tiene la convergencia en distribución \\(F_n \\rightarrow N\\left( \\theta, I( \\theta )^{-1} \\right)\\). Donde \\(I(\\theta)\\), es un criterio de información, dado por la matriz \\[ \\left[ I(\\theta) \\right]_{i,j} = \\left[ \\mathbb{E}\\left[ -\\frac{\\partial^2}{\\partial\\theta_i \\partial\\theta_j}\\log f( X, \\theta )\\, \\middle|\\, \\theta \\right] \\right]_{i,j} \\] 5.4.5 Pruebas de hipótesis Usualmente sobre un variable aleatoria \\(X\\) a valores en \\(\\mathbb{R}^n\\), se suele establecer una decisión basada en el valores que toma la variable aleatoria, la selección se realiza entre diferentes hipótesis. De manera más formal, esta decisión puede ser representada por una función \\(\\delta : \\mathbb{R}^n \\longrightarrow D\\), donde \\(D = \\{d_1,\\ldots,d_n\\}\\) es un conjunto discreto que representa las hipótesis. Se conoce a \\(\\delta\\) como un test estadístico de elección. En muchos casos uno nos interesa encontrar el test estadístico \\(\\delta\\) que tenga el menor error de cometer una selección errada, así para cada decisión en \\(d \\in D\\), el test \\(\\delta\\) tendrá probabilidades \\(P( \\delta( X ) \\neq d )\\), es decir, para cualquier otro test \\(\\eta\\), se debe tener que \\[ P( \\delta( X ) \\neq d ) \\leq P( \\eta( X ) \\neq d ),\\qquad \\forall d \\in D \\] En muchos casos uno no se interesa en cualquier tipo de test estadístico, sino en un cierto tipo de pruebas, más interesados en un subconjunto \\(K \\subset \\{ \\delta : \\mathbb{R}^n \\longrightarrow D \\}\\), a este se lo conoce como una clase. Así se dice que un test \\(\\delta \\in K\\) es el test más potente en la clase \\(K\\) para la hipótesis \\(d \\in D\\) si para cualquier otro test \\(\\eta \\in K\\), se tiene la desigualdad. \\[ P( \\delta( X ) \\neq d ) \\leq P( \\eta( X ) \\neq d ) \\] "],["modelos_perdida.html", "Capítulo 6 Modelos de pérdida agregada 6.1 Mutualización del riesgo 6.2 Modelo individual 6.3 Modelo colectivo 6.4 Modelos mixtos 6.5 Modelos con variables explicativas 6.6 Aplicación del deducible 6.7 Algoritmo de Panjer 6.8 Estimación usando la transformada de Fourier 6.9 Temporalidad y ajustes del número de reclamos 6.10 Proceso estocástico de reclamos totales", " Capítulo 6 Modelos de pérdida agregada 6.1 Mutualización del riesgo La idea de mantener un seguro está basada en la mutualización de los riesgos. La mutualización como tal nace del mismo mecanismo bajo el cual funciona un seguro, cada asegurado transfiera su riesgo individual a la compañía de seguros por su parte, la suma total de estos riesgos \\(S\\) es el riesgo total que asume el asegurador. Los riesgos de cada uno de los \\(n \\in \\mathbb{N}\\) asegurados, pueden ser representados por variables aleatorias \\(X_1,\\ldots X_n\\), las mismas pueden ser independientes o dependientes entre ellas. El costo total del portafolio está dado por la suma de todos estos riesgos. \\[ S = \\sum\\limits_{i=1}^n X_i \\] El conocer la distribución del costo total \\(S\\) es una tarea crucial para el asegurador. El valore esperado de de los reclamos totales, puede ser calculado fácilmente utilizando las propiedades de linealidad de la esperanza matemática \\(\\mathbb{E}\\) \\[ \\mathbb{E}[ S ] = \\mathbb{E}\\left[ \\sum\\limits_{i=1}^n X_i \\right] = \\sum\\limits_{i=1}^n \\mathbb{E}\\left[ X_i \\right] \\] por su parte, la varianza de la variable aleatoria del costo total \\(S\\), está dada por: \\[ \\begin{eqnarray*} \\mathbb{V}\\left[ S \\right] &amp; = &amp; \\mathbb{V}\\left[ \\sum\\limits_{i=1}^n X_i \\right] \\\\ &amp; = &amp; \\sum\\limits_{i=1}^n \\mathbb{V}\\left[ X_i \\right] + \\sum\\limits_{i=1}^n \\sum\\limits_{j=1,j\\neq i}^n \\mathbb{C}\\left[ X_i, X_j \\right] \\\\ &amp; = &amp; \\sum\\limits_{i=1}^n \\mathbb{V}\\left[ X_i \\right] + 2\\sum\\limits_{i=1}^{n-1} \\sum\\limits_{j=i+1}^n \\mathbb{C}\\left[ X_i, X_j \\right] \\end{eqnarray*} \\] Muchas de las veces el número total de reclamos \\(n\\) es incierto y por tal razón es mejor considerar que el número de siniestros vendrá dado por otra variable aleatoria discreta \\(N\\) que solo tomará valores en \\(\\mathbb{N}\\) \\[ S = \\sum\\limits_{i=1}^N X_i \\] Esto nos lleva a considerar diferentes modelos de agregación de reclamos o pérdidas como se suele decir en inglés “loss models” [1], [2]. De forma preliminar estudiemos la forma general que podría tener la distribución de \\(S\\), sin realizar alguna hipótesis (previa sobre el comportamiento de las variables aleatorias \\(X_1, \\ldots, X_n\\) y \\(N\\). \\[ \\begin{eqnarray*} F_S( s ) &amp; = &amp; P( S \\leq s ) \\\\ &amp; = &amp; P\\left( \\sum\\limits_{i=1}^N X_i \\leq s \\right) \\\\ &amp; = &amp; P\\left( \\sum\\limits_{i=1}^N X_i \\leq s \\land N \\in \\mathbb{N}\\right) \\\\ &amp; = &amp; P\\left( \\bigcup\\limits_{n\\in \\mathbb{N}} \\left\\{ \\sum\\limits_{i=1}^N X_i \\leq s \\land N \\in \\{n\\} \\right\\}\\right) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} P\\left( \\sum\\limits_{i=1}^n X_i \\leq s \\land N = n \\right) \\qquad \\text{probabilidad de eventos disjuntos} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} P\\left( \\sum\\limits_{i=1}^n X_i \\leq s\\ \\middle|\\ N = n \\right) P( N = n ) \\qquad \\text{propiedades de la probabilidad condicional} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} \\int\\limits_{\\left\\{\\sum\\limits_{i=1}^n x_i \\leq s\\right\\}} dF_n( x_1, \\ldots, x_n )\\ p_n \\qquad \\text{$F_n$ es la distribución conjunta de $X_1, \\ldots, X_n$ dado $N = n$} \\end{eqnarray*} \\] la última expresión es importante de retener, nos dice que para comprender el comportamiento de los reclamos totales \\(S\\), debemos estudiar y estimar la frecuencia de los reclamos \\(N\\), y también debemos comprender y estimar cada uno de los reclamos \\(X_i\\) y también su interacción, siendo al menos estos una infinidad si \\(N\\) puede tomar valores tendiendo al infinito. En términos resumidos, hay que comprender y estimar la frecuencia y severidad de los reclamos que están asociados al riesgo cubierto. Los términos integrales \\(\\int\\limits_{\\left\\{\\sum\\limits_{i=1}^n x_i \\leq s\\right\\}} dF_n( x_1, \\ldots, x_n )\\) asociados a la severidad presentan un verdadero reto estadístico y computacional; hace unos años atrás se desarrolló unos nuevos algoritmos para calcular estos términos [3], [4]. 6.2 Modelo individual En el modelo de riesgos individuales consideramos que el número de siniestros que se producirán es conocido, por ejemplo puede ser a lo sumo el tamaño de la población asegurada, en tal caso la variable aleatoria \\(N\\) pasa a ser una constante, que representaremos por \\(n\\). De esta forma, la severidad total puede ser fácilmente representada por: \\[ S = \\sum\\limits_{i=1}^n X_i \\] La hipótesis más usual que sostiene a este modelo es la indenpendencia entre cada uno de los reclamos \\(X_i\\) y \\(X_j\\) son independientes para cualquier \\(1 \\leq i \\neq j \\leq n\\). El valor esperado de la severidad total \\(S\\) es: \\[ \\begin{eqnarray*} \\mathbb{E}[S] &amp; = &amp; \\mathbb{E}\\left[ \\sum\\limits_{i=1}^n X_i \\right] \\\\ &amp; = &amp; \\sum\\limits_{i=1}^n \\mathbb{E}\\left[ X_i \\right] \\\\ &amp; = &amp; n \\mathbb{E}[X] \\quad \\text{si $\\{X_i\\}$ son idénticamente distribuidas} \\end{eqnarray*} \\] Así mismo con la varianza de \\(S\\). \\[ \\begin{eqnarray*} \\mathbb{V}\\left[ S \\right] &amp; = &amp; \\mathbb{V}\\left[ \\sum\\limits_{i=1}^n X_i \\right] \\\\ &amp; = &amp; \\sum\\limits_{i=1}^n \\mathbb{V}\\left[ X_i \\right] + \\sum\\limits_{i=1}^n \\sum\\limits_{j=1,j\\neq i}^n \\mathbb{C}\\left[ X_i, X_j \\right] \\\\ &amp; = &amp; \\sum\\limits_{i=1}^n \\mathbb{V}\\left[ X_i \\right]\\quad \\text{si $\\{X_i\\}$ sin son independientes entre si} \\\\ &amp; = &amp; n \\mathbb{V}\\left[ X \\right]\\quad \\text{si $\\{X_i\\}$ sin son idénticamente distribuidas} \\end{eqnarray*} \\] Al tener un número determinado de reclamos \\(n \\in \\mathbb{N}\\), la distribución de probabilidad del total de reclamos \\(S\\) puede ser calculada de una forma maś sencilla. \\[ \\begin{eqnarray*} F_S( x ) &amp; = &amp; F_{X_1} \\star \\cdots \\star F_{X_n} ( s )\\quad \\text{sin $\\{X_i\\}$ son independientes} \\\\ &amp; = &amp; F_{X}^{\\star n}( s )\\quad \\text{si $\\{X_i\\}$ son idénticamente distribuidas} \\end{eqnarray*} \\] así mismo, si las densidades de probabilidad están bien definidas, entonces \\[ \\begin{eqnarray*} f_S( s ) &amp; = &amp; f_{X_1} \\star \\cdots \\star f_{X_n} ( s )\\quad \\text{sin $\\{X_i\\}$ son independientes} \\\\ &amp; = &amp; f_{X}^{\\star n}( s )\\quad \\text{si $\\{X_i\\}$ son idénticamente distribuidas} \\end{eqnarray*} \\] Una posible estrategia para estimar \\(F_S\\) o \\(f_S\\) es utilizar la transformada de Fourier \\(\\mathscr{F}\\), la cual convierte las convoluciones en productos y luego invertir de nuevo la transformada de Fourier. \\[ \\begin{eqnarray*} F_S &amp; = &amp; \\mathscr{F}^{-1}\\left( \\mathscr{F}\\left( F_S \\right) \\right) \\\\ &amp; = &amp; \\mathscr{F}^{-1}\\left( \\mathscr{F}\\left( F_{X_1} \\star \\cdots \\star F_{X_n} \\right) \\right) \\quad \\text{sin $\\{X_i\\}$ son independientes} \\\\ &amp; = &amp; \\mathscr{F}^{-1}\\left( \\prod\\limits_{i=1}^n \\mathscr{F}\\left( F_{X_i} \\right) \\right) \\\\ &amp; = &amp; \\mathscr{F}^{-1}\\left( \\mathscr{F}\\left( F_{X} \\right)^n \\right) \\quad \\text{si $\\{X_i\\}$ sin son idénticamente distribuidas } \\end{eqnarray*} \\] o de forma equivalente para la densidad \\(f_S\\) \\[ \\begin{eqnarray*} f_S &amp; = &amp; \\mathscr{F}^{-1}\\left( \\mathscr{F}\\left( f_S \\right) \\right) \\\\ &amp; = &amp; \\mathscr{F}^{-1}\\left( \\mathscr{F}\\left( f_{X_1} \\star \\cdots \\star f_{X_n} \\right) \\right) \\quad \\text{sin $\\{X_i\\}$ son independientes} \\\\ &amp; = &amp; \\mathscr{F}^{-1}\\left( \\prod\\limits_{i=1}^n \\mathscr{F}\\left( f_{X_i} \\right) \\right) \\\\ &amp; = &amp; \\mathscr{F}^{-1}\\left( \\mathscr{F}\\left( f_{X} \\right)^n \\right) \\quad \\text{si $\\{X_i\\}$ sin son idénticamente distribuidas } \\end{eqnarray*} \\] Por otra parte, la función característica de la variable aleatoria \\(S\\), está dada para todo \\(t \\in \\mathbb{R}\\): \\[ \\begin{eqnarray*} \\varphi_S( t ) &amp; = &amp; \\mathbb{E}\\left[ \\exp\\left( it S \\right) \\right] \\\\ &amp; = &amp; \\mathbb{E}\\left[ \\exp\\left( it \\sum\\limits_{i=1}^n X_i \\right) \\right] \\\\ &amp; = &amp; \\mathbb{E}\\left[ \\prod\\limits_{i=1}^n \\exp\\left( it X_i \\right) \\right] \\\\ &amp; = &amp; \\prod\\limits_{i=1}^n \\mathbb{E}\\left[ \\exp\\left( it X_i \\right) \\right],\\quad \\text{si $\\{X_i\\}$ son independientes} \\\\ &amp; = &amp; \\prod\\limits_{i=1}^n \\varphi_{X_i}\\left( t \\right) \\\\ &amp; = &amp; \\varphi_{X}\\left( t \\right)^n,\\quad \\text{si $\\{X\\}$ son identicamente distribuidas} \\\\ \\end{eqnarray*} \\] 6.2.1 Algoritmo de simulación Se puede simular la severidad total \\(S\\) para el caso donde se asume independencia entre cada una de las severidades \\(X_1, \\ldots, X_n\\) y se conoce cada una de sus densidades de probabilidad \\(f_{X_1}, \\ldots, f_{X_n}\\) o distribuciones de probabilidad \\(F_{X_1}, \\ldots, F_{X_n}\\). Se tiene fijo \\(n \\in \\mathbb{N}\\), Se fija el número de simulaciones \\(m \\in \\mathbb{N}\\) Para cada \\(i \\in \\{1, \\ldots, m\\}\\) se extrae una muestra \\(X_{i,1} \\rightsquigarrow f_{X_1},\\ldots,X_{i,n} \\rightsquigarrow f_{X_n}\\), Para cada \\(i \\in \\{1, \\ldots, m\\}\\) se calcula la severidad total para la muestra \\(i\\), \\(S_i = \\sum\\limits_{j=1}^n X_{i,j}\\) Ejemplo 6.1 El siguiente código ejemplifica el algoritmo anterior, donde se asume que cada variable aleatoria de severidad \\(X_i\\) sigue una ley log-normal \\(LN( \\mu_i, \\sigma_i )\\), de parámetros \\(\\mu_i, \\sigma_i\\), para cada \\(i \\in \\{1,\\ldots, n\\}\\). El reclamo total \\(S = \\sum\\limits_{i=1}^n X_i\\) sigue una ley de probabilidad que estará dada por la convolución de cada una de las leyes de probabilidad de cada reclamo \\(X_i\\), sin embargo estas leyes en este ejemplo son log-normales y no se conoce una forma explícita, analítica para la convolución de log-normales. Por tal razón, debemos aproximar la distribución de probabilidad de \\(F_S\\) a partir de la distribución empírica. Code set.seed(94312) # 1. número de distribuciones n &lt;- 200 # parámetros para las n distribuciones mu &lt;- seq( 1, 2, length.out = n ) sigma &lt;- seq( 2, 3, length.out = n ) # 2. número de simulaciones m &lt;- 1e3 # 3. simulación de severidades X &lt;- lapply( 1:m, FUN = function( i ) sapply( 1:n, FUN = function( j ) rlnorm( 1, meanlog = mu[ j ], sdlog = sigma[ j ] ) ) ) # 4. simulación de severidad total S &lt;- sapply( X, FUN = function( x ) sum( x ) ) Con ya lo mencionamos en este ejemplo densidad de probabilidad de la severidad \\(S\\) resulta de la convolución de las \\(n\\) densidades individuales \\(f_S = f_{X_1} \\star \\cdots \\star f_{X_n}\\), la cual no presenta una forma analítica conocida. De la imposibilidad anterior, como ya mencionamos se puede ver la utilidad de trabajar con la muestra aleatoria de la variable \\(S\\). De esta manera poder estimar la distribución acumulada de probabilidad \\(F_S\\) a partir de la distribución empírica \\(F_m\\) generada con la muestra \\(\\{S_i\\}\\). \\[ F_S( s ) \\approx F_m( s ) = \\frac{1}{m} \\sum\\limits_{i=1}^m \\mathbf {1}_{(-\\infty,s]}( S_i ) \\] el resultado de concentración 4.5 es más nos brinda un criterio de convergencia de \\(F_m\\) a \\(F_S\\) Para construir \\(F_m\\) en R, se puede utilizar la función ya empaquetada ecdf (empirical cumulative distribution function). Code # estimación distribución acumulada empírica de S Fm &lt;- ecdf( S ) # esperanza empírica EeS &lt;- mean( S ) # esperanza teórica ES &lt;- sum( sapply( 1:n, FUN = function( i ) exp( mu[i] + 0.5 * sigma[i]^2 ) ) ) s &lt;- sort( unique( S ) ) Fms &lt;- sapply( s, FUN = Fm ) Code smax &lt;- 2.0e5 plt &lt;- ggplot() + geom_step( aes( x = s, y = Fms ), colour = &#39;dodgerblue4&#39;, linewidth = 1 ) + geom_vline( xintercept = c( EeS, ES ), colour = c( &#39;olivedrab3&#39;, &#39;gold3&#39; ), linewidth = 1 ) + scale_x_continuous( breaks = seq( 0, smax, length = 11 ), labels = formatC( seq( 0, smax, length = 11 ), digits = 2, format = &#39;f&#39; ), limits = c( 0, smax ), expand = c( 0, 0 ) ) + scale_y_continuous( breaks = seq( 0, 1, length = 11 ), labels = formatC( seq( 0, 1, length = 11 ), digits = 2, format = &#39;f&#39; ), limits = c( 0.0, 1.0 ), expand = c( 0.005, 0.005 ) ) + xlab( TeX( &quot;$s$&quot; ) ) + ylab( TeX( &quot;$F_m(s)$&quot; ) ) + theme_bw() plot( plt ) Para calcular la esperanza de la severidad total \\(S\\), también se puede utilizar una aproximación a la integral de Riemann-Stieltjes utilizando la distribución acumulada empírica \\(F_m\\). \\[ \\mathbb{E}[ S ] = \\int\\limits_{\\mathbb{R}} s dF_S( s ) \\approx \\int\\limits_{\\mathbb{R}} s dF_m( s ) \\approx \\sum\\limits_{i=1}^N s_{i} \\left( F_m( s_{i+1} ) - F_m( s_{i} ) \\right) \\] Esta aproximación en R puede ser implementada de la siguiente forma: Code N &lt;- 1e5 s &lt;- seq( min( S ), max( S ), length.out = N ) EmS &lt;- sum( s[-N] * diff( sapply( s, FUN = Fm ) ) ) De ello tenemos los siguientes resultados de cálculo para el valor esperado de la severidad total \\[ \\begin{eqnarray*} \\mathbb{E}[S] = \\sum\\limits_{i=1}^n e^{ \\mu_i + \\frac{1}{2} \\sigma_i^2 } &amp; = &amp; 34562.7208, \\\\ \\overline{S} = \\frac{1}{m} \\sum\\limits_{i=1}^m S_i &amp; = &amp; 33515.9195, \\\\ \\sum\\limits_{i=1}^N s_{i} \\left( F_m( s_{i+1} ) - F_m( s_{i} ) \\right) &amp; = &amp; 33494.1981 \\end{eqnarray*} \\] Lo bueno de poseer una buena aproximación a la distribución acumulada de una variable aleatoria, es que podemos calcular algunos otros valores de importancia relacionados a la variable aleatoria y no tan solo utilizar medidas de tendencia central. Sin embargo, para que esta aproximación sea útil se requiere reducir el error de probabilidad 4.5. Ejemplo 6.2 Podemos considerar el caso sencillo donde el valor posible de severidad es determinista, es decir para cada póliza \\(i\\in \\{1,\\ldots,n\\}\\), el valor de severidad probable es único \\(M &gt; 0\\) si en caso se da un evento \\(A_i\\), esto lo podemos expresar como \\(X_i = M \\mathbf{1}_{A_i}\\) es constante. Así, pérdida total está dada por: \\[ S = \\sum\\limits_{i=1}^n X_i = \\sum\\limits_{i=1}^n M \\mathbf{1}_{A_i} \\] El valor total esperado de reclamos está dado por: \\[ \\mathbb{E}[ S ] = \\sum\\limits_{i=1}^n \\mathbb{E}\\left[ M \\mathbf{1}_{A_i} \\right] = M \\sum\\limits_{i=1}^n P( A_i ) \\] la última igualdad resulta de las propiedades de la función indicatriz 4.10. Si en caso todos los \\(P(A_i) = p\\) tienen la misma probabilidad, el valor total esperado de reclamos toma la siguiente forma: \\[ \\mathbb{E}[S] = n M p \\] 6.3 Modelo colectivo El modelo colectivo de riesgo considera un número de reclamos descritos por una variable aleatoria discreta \\(N\\). Los reclamos corresponden a un número de pólizas en un periodo específico, el valor de cada reclamo \\(i \\in \\{1,\\ldots,N\\}\\) está representado por las variables aleatorias \\(X_i\\). Usualmente, se considera que cada uno de los reclamos \\(X_i\\) están idénticamente distribuidos. \\[ S = \\left\\{ \\begin{array}{ll} \\sum\\limits_{i=1}^N X_i &amp; \\text{si}\\ N &gt; 0 \\\\ 0 &amp; \\text{si}\\ N = 0 \\end{array} \\right. \\] o de forma más compacta se puede tan definir \\(S = \\sum\\limits_{i=1}^N X_i\\), donde se asume que la suma da \\(0\\) si el número de elementos en la suma \\(N = 0\\). El valor esperado del total de reclamos \\(S\\), está dado por: \\[ \\begin{eqnarray*} \\mathbb{E}[S] &amp; = &amp; \\mathbb{E}\\left[ \\sum\\limits_{i=1}^N X_i \\right] \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} \\mathbb{E}\\left[ \\sum\\limits_{i=1}^n X_i\\ \\middle|\\ N = n \\right]P( N = n ) \\quad \\text{utilizando la esperanza condicional} \\\\ &amp; = &amp; 0 P( N = 0 ) + \\sum\\limits_{n=1}^{+\\infty} \\mathbb{E}\\left[ \\sum\\limits_{i=1}^n X_i\\ \\middle|\\ N = n \\right]P( N = n ) \\\\ &amp; = &amp; \\sum\\limits_{n=1}^{+\\infty} \\sum\\limits_{i=1}^n \\mathbb{E}\\left[ X_i \\mid N = n \\right]P( N = n ) \\quad \\text{linealidad de la esperanza} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} n \\mathbb{E}\\left[ X \\mid N = n \\right]P( N = n ) \\quad \\text{si $\\{X_i\\}$ son idénticamente distribuidas} \\\\ &amp; = &amp; \\mathbb{E}\\left[ X \\right] \\sum\\limits_{n=0}^{+\\infty} n P( N = n ) \\quad \\text{si $X$ y $N$ son independientes} \\\\ &amp; = &amp; \\mathbb{E}[ N ] \\mathbb{E}[ X ] \\end{eqnarray*} \\] También podemos calcular la varianza de los reclamos totales \\(S\\), para ello necesitamos primeramente calcular su segundo momento. \\[ \\begin{eqnarray*} \\mathbb{E}[S^2] &amp; = &amp; \\mathbb{E}\\left[ \\left( \\sum\\limits_{i=1}^N X_i \\right)^2 \\right] \\\\ &amp; = &amp; \\sum\\limits_{n=0}^\\infty \\mathbb{E}\\left[ \\sum\\limits_{i, j=1}^n X_i X_j \\middle| N = n \\right] P( N = n ) \\quad \\text{propiedades de la esperanza condicional} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^\\infty \\sum\\limits_{i, j=1}^n \\mathbb{E}\\left[ X_i X_j \\right] P( N = n ) \\quad \\text{si $\\{X_i\\}$ y $N$ son independientes} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^\\infty \\left( \\sum\\limits_{i=1}^n \\mathbb{E}\\left[ X_i^2 \\right] + \\sum\\limits_{i,j=1,i\\neq j}^n \\mathbb{E}\\left[ X_i X_j \\right] \\right) P( N = n ) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^\\infty \\left( n \\mathbb{E}\\left[ X^2 \\right] + n(n-1) \\mathbb{E}\\left[ X \\right]^2 \\right) P( N = n ) \\quad \\text{si $\\{X_i\\}$ son i.i.d} \\\\ &amp; = &amp; \\mathbb{E}\\left[N\\right] \\mathbb{E}\\left[X^2\\right] + \\mathbb{E}\\left[N^2\\right] \\mathbb{E}\\left[X\\right]^2 - \\mathbb{E}\\left[N\\right] \\mathbb{E}\\left[X\\right]^2 \\\\ &amp; = &amp; \\mathbb{E}\\left[N\\right] \\mathbb{V}\\left[X\\right] + \\mathbb{E}\\left[N^2\\right] \\mathbb{E}\\left[X\\right]^2 \\end{eqnarray*} \\] finalmente la varianza de \\(S\\) tiene la siguiente expresión \\[ \\begin{eqnarray*} \\mathbb{V}\\left[S\\right] &amp; = &amp; \\mathbb{E}\\left[S^2\\right] - \\mathbb{E}\\left[S\\right]^2 \\\\ &amp; = &amp; \\mathbb{E}\\left[N\\right] \\mathbb{V}\\left[X\\right] + \\mathbb{E}\\left[N^2\\right] \\mathbb{E}\\left[X\\right]^2 - \\mathbb{E}\\left[N\\right]^2 \\mathbb{E}\\left[X\\right]^2 \\\\ &amp; = &amp; \\mathbb{E}\\left[N\\right] \\mathbb{V}\\left[X\\right] + \\mathbb{V}\\left[N\\right] \\mathbb{E}\\left[X\\right]^2 \\end{eqnarray*} \\] La distribución acumulada del reclamo total \\(S\\) tiene la forma: \\[ \\begin{eqnarray*} F_S( s ) &amp; = &amp; P( S \\leq s ) \\\\ &amp; = &amp; P\\left( \\sum\\limits_{i=1}^N X_i \\leq s \\right) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} P\\left( \\sum\\limits_{i=1}^n X_i \\leq s \\middle| N = n \\right) P( N = n )\\quad \\text{utilizando la probabilidad condicional} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} P\\left( \\sum\\limits_{i=1}^n X_i \\leq s \\right) p_n\\quad \\text{si $X_i$ y $N$ son independientes} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} F_{X_1} \\star \\cdots \\star F_{X_n}( s ) p_n\\quad \\text{si $\\{X_i\\}$ son independientes} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} F^{\\star n}_{X}( s ) p_n\\quad \\text{si $\\{X_i\\}$ son idénticamente distribuidas} \\end{eqnarray*} \\] tomando \\(F^{\\star 0}_{X}( s ) = 1\\). Este último resultado muestra que la distribución de probabilidad de \\(S\\) no es más que una mixtura de las distribuciones para los modelos individuales \\(F^{\\star n}_{X}\\) tomando para mezclarlas las probabilidades \\(p_n = P( N = n )\\) de la variable aleatoria discreta \\(N\\) que describe la frecuencia de los reclamos. Al igual que lo realizamos para el modelo individual, podemos estimar \\(F_S\\) o \\(f_S\\) utilizando la transformada de Fourier \\(\\mathscr{F}\\) \\[ \\begin{eqnarray*} F_S &amp; = &amp; \\mathscr{F}^{-1}\\left( \\mathscr{F}\\left( F_S \\right) \\right) \\\\ &amp; = &amp; \\mathscr{F}^{-1}\\left( \\mathscr{F}\\left( \\sum\\limits_{n=0}^{+\\infty} F_{X_1} \\star \\cdots \\star F_{X_n}( s ) p_n \\right) \\right) \\quad \\text{sin $\\{X_i\\}$ son independientes} \\\\ &amp; = &amp; \\mathscr{F}^{-1}\\left( \\sum\\limits_{n=0}^{+\\infty} \\prod\\limits_{i=1}^n \\mathscr{F}\\left( F_{X_i} \\right) p_n \\right) \\\\ &amp; = &amp; \\mathscr{F}^{-1}\\left( \\sum\\limits_{n=0}^{+\\infty} \\mathscr{F}\\left( F_{X} \\right)^n p_n \\right) \\quad \\text{si $\\{X_i\\}$ sin son idénticamente distribuidas } \\end{eqnarray*} \\] o de forma equivalente para la densidad \\(f_S\\) \\[ \\begin{eqnarray*} f_S &amp; = &amp; \\mathscr{F}^{-1}\\left( \\mathscr{F}\\left( f_S \\right) \\right) \\\\ &amp; = &amp; \\mathscr{F}^{-1}\\left( \\mathscr{F}\\left( \\sum\\limits_{n=0}^{+\\infty} f_{X_1} \\star \\cdots \\star f_{X_n}( s ) p_n \\right) \\right) \\quad \\text{sin $\\{X_i\\}$ son independientes} \\\\ &amp; = &amp; \\mathscr{F}^{-1}\\left( \\sum\\limits_{n=0}^{+\\infty} \\prod\\limits_{i=1}^n \\mathscr{F}\\left( f_{X_i} \\right) p_n \\right) \\\\ &amp; = &amp; \\mathscr{F}^{-1}\\left( \\sum\\limits_{n=0}^{+\\infty} \\mathscr{F}\\left( f_{X} \\right)^n p_n \\right) \\quad \\text{si $\\{X_i\\}$ sin son idénticamente distribuidas } \\end{eqnarray*} \\] En la práctica es imposible realizar la suma hasta infinito, de donde se puede utilizar una aproximación escogiendo un número máximo \\(M \\in \\mathbb{N}\\) de términos en la suma. Así, tenemos las aproximaciones. Por otra parte, la función característica de la variable aleatoria \\(S\\), está dada para todo \\(t \\in \\mathbb{R}\\): \\[ \\begin{eqnarray*} \\varphi_S( t ) &amp; = &amp; \\mathbb{E}\\left[ \\exp\\left( it S \\right) \\right] \\\\ &amp; = &amp; \\mathbb{E}\\left[ \\exp\\left( it \\sum\\limits_{i=1}^N X_i \\right) \\right] \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} \\mathbb{E}\\left[ \\exp\\left( it \\sum\\limits_{i=1}^n X_i \\right) \\middle| N = n \\right] P( N = n ) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} \\mathbb{E}\\left[ \\prod\\limits_{i=1}^n \\exp\\left( it X_i \\right) \\middle| N = n \\right] p_n \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} \\prod\\limits_{i=1}^n \\mathbb{E}\\left[ \\exp\\left( it X_i \\right) \\middle| N = n \\right] p_n,\\quad \\text{si $\\{X_i\\}$ son independientes} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} \\prod\\limits_{i=1}^n \\varphi_{X_i}\\left( t \\right) p_n,\\quad \\text{si $\\{X_i\\}$ y $N$ son independientes} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} \\varphi_{X}\\left( t \\right)^n p_n,\\quad \\text{si $\\{X\\}$ son identicamente distribuidas} \\\\ &amp; = &amp; \\mathbb{E}\\left[ \\varphi_{X}\\left( t \\right)^N \\right] \\\\ &amp; = &amp; \\mathbb{E}\\left[ \\exp\\left( N \\log\\left( \\varphi_{X}\\left( t \\right) \\right) \\right) \\right] \\\\ &amp; = &amp; \\varphi_N\\left( -i\\log\\left( \\varphi_{X}\\left( t \\right) \\right) \\right) \\\\ \\end{eqnarray*} \\] 6.3.1 Algoritmo de simulación La variable del reclamo total \\(S\\) puede ser simulada mediante el siguiente método montecarlo. Si \\(N\\) sigue una ley discreta \\(f_N\\) y cada valor severidad \\(X\\) son idénticamente distribuidos con ley \\(f_X\\). Seleccionar el número de simulaciones \\(m\\), Se genera una muestra de tamaño \\(m\\) de variables \\(N_1, \\ldots, N_m\\) con ley \\(f_N\\), Se genera para cada \\(i \\in \\{1,\\ldots,m\\}\\) una muestra de tamaño \\(N_i\\) de variables aleatorias \\(X_{i,1}, \\ldots X_{i,N_i}\\) con ley \\(f_X\\), Se calcula los reclamos totales \\(S_1, \\ldots, S_m\\) para cada simulación \\(i = \\{1, \\ldots, m\\}\\), mediante la siguiente suma \\(S_i = \\sum\\limits_{j=1}^{N_i} X_{i,j}\\). En el lenguaje de programación R, este método de simulación puede ser fácilmente implementado, como ya lo hemos realizado, utilizando las funciones de aplicación vectorial sapply y lapply. Ejemplo 6.3 Consideramos el caso de un modelo colectivo para el cuál el conteo de siniestros \\(N \\rightsquigarrow Pois( \\lambda )\\) y la distribución de cada uno de los reclamos \\(\\{X_i\\}_{i\\in \\mathbb{N}}\\), está dada por la misma distribución de probabilidad \\(X \\rightsquigarrow LN( \\mu, \\sigma )\\), siendo además cada uno de los reclamos indepencientes entre si. Code # 1. selección de simulaciones m &lt;- 1e4 # 2. especificación de los parámetros para las distribuciones u &lt;- 5 s &lt;- 2 l &lt;- 3 # 3. simulación del conteo de siniestros N &lt;- rpois( n = m, lambda = l ) # 4. simulación de la severidad de los reclamos X &lt;- lapply( N, FUN = function( n ) rlnorm( n, meanlog = u, sdlog = s ) ) # 5. reclamo total, agregación por cada simulación S &lt;- sapply( X, FUN = function( x ) sum( x, na.rm = TRUE ) ) Es de notar que una algoritmo como el descrito tiene una falencia cuando la frecuencia de siniestros es poco observada, esto sucede cuando la probabilidad \\(P( N = 0 )\\) es alta y por tal razón para generar suficientes reclamos y así poder tener cálculos con una buena aproximación numérica, con el uso de simulaciones se necesitará muchas simulaciones. Es interesante observar que el modelo colectivo puede ser muchas veces calculado de forma similar a un modelo individual, para ciertos casos particulares. Por ejemplo, si consideramos el caso cuando la variable aleatoria del conteo de siniestros \\(N \\rightsquigarrow Bin( n, p )\\) sigue una distribución binomial con parámetros \\(n\\) y \\(p\\) y los reclamos individuales \\(\\{ X_i \\}\\) son i.i.d. A partir de esto, el reclamo total \\(S\\) puede ser expresado de dos formas \\[ S = \\sum\\limits_{k=0}^{N} X_k = \\sum\\limits_{k=0}^n B_k X_k \\] donde las variables aleatorias \\(B_k \\rightsquigarrow Ber( p )\\) son independientes de las variables aleatorias \\(X_k\\) de cada uno de los reclamos. Así el modelo colectivo se transforma en un modelo individual con \\(n\\) constante y valores de reclamos individuales dados por la variable aleatoria \\(Y_k = B_k X_k\\). Para este caso en particular \\[ \\begin{eqnarray*} \\mathbb{E}[ S ] &amp; = &amp; \\mathbb{E}\\left[ \\sum\\limits_{k=0}^{n} B_k X_k \\right] \\\\ &amp; = &amp; \\sum\\limits_{k=0}^{n} \\mathbb{E}\\left[ B_k X_k \\right] \\\\ &amp; = &amp; n \\mathbb{E}[ B X ] \\\\ &amp; = &amp; n \\mathbb{E}[ B ] \\mathbb{E}[ X ] \\\\ &amp; = &amp; n p \\mathbb{E}[ X ] \\end{eqnarray*} \\] así mismo, \\[ \\begin{eqnarray*} \\mathbb{V}[ S ] &amp; = &amp; n \\mathbb{V}[ B X ] \\\\ &amp; = &amp; n \\left( \\mathbb{E}[ B^2 X^2 ] - \\mathbb{E}[ B X ]^2 \\right) \\\\ &amp; = &amp; n \\left( \\mathbb{E}[ B^2 ] \\mathbb{E}[ X^2 ] - \\mathbb{E}[ B ]^2 \\mathbb{E}[ X ]^2 \\right) \\\\ &amp; = &amp; n \\left( p \\mathbb{E}[ X^2 ] - p^2 \\mathbb{E}[ X ]^2 \\right) \\\\ &amp; = &amp; n \\left( p \\mathbb{E}[ X^2 ] - p \\mathbb{E}[ X ]^2 + p \\mathbb{E}[ X ]^2 - p^2 \\mathbb{E}[ X ]^2 \\right) \\\\ &amp; = &amp; n \\left( p \\mathbb{V}[ X ] + p ( 1 - p ) \\mathbb{E}[ X ]^2 \\right) \\\\ &amp; = &amp; n \\left( \\mathbb{E}[B] \\mathbb{V}[ X ] + \\mathbb{V}[B] \\mathbb{E}[ X ]^2 \\right) \\end{eqnarray*} \\] Ejemplo 6.4 Hacemos uso del algoritmo de simulación, pero bajo la consideración anterior donde el conteo de siniestros \\(N \\rightsquigarrow Bin( n, p )\\), en algunos casos se puede considerar \\(n\\) como el número de pólizas vendidas, esto supone que solo se presenta un reclamo por póliza. Por su parte los reclamos consideraremos \\(X_i \\rightsquigarrow LN( \\mu, \\sigma )\\), para todo \\(i \\in \\{1,\\ldots,n\\}\\). Si consideramos generar la simulación como un modelo individual, generamos variables aleatorias \\(B_i \\rightsquigarrow Ber(p)\\), para todo \\(i \\in \\{1,\\ldots,n\\}\\). Code m &lt;- 1e4 n &lt;- 1000 p &lt;- 0.2 mu &lt;- 5 sigma &lt;- 2 B &lt;- lapply( 1:m, FUN = function( i ) rbinom( n, size = 1, prob = p ) ) X &lt;- lapply( 1:m, FUN = function( i ) rlnorm( n, meanlog = mu, sdlog = sigma ) ) S &lt;- sapply( 1:m, FUN = function( i ) sum( B[[ i ]] * X[[ i ]], na.rm = TRUE ) ) EeS &lt;- mean( S ) ES &lt;- n * p * exp( mu + 0.5 * sigma^2 ) \\[ \\begin{eqnarray*} \\mathbb{E}[S] = n p e^{ \\mu + \\frac{1}{2} \\sigma^2 } &amp; = &amp; 219326.6317, \\\\ \\overline{S} = \\frac{1}{m} \\sum\\limits_{i=1}^m S_i &amp; = &amp; 219346.3972, \\end{eqnarray*} \\] Es importante observar que si la frecuencia de reclamos es superior a \\(1\\), sea este por póliza, individuo o en general por unidad asegurada, la aproximación anterior no es la correcta si no se realiza un ajuste al valor \\(n\\) que es el número máximo de siniestros. Sino también, se puede considera que las variables de los reclamos es la suma total de reclamos por póliza. Por otra parte, es de notar que en el cálculo hay un gasto innecesario de valores simulados de reclamos \\(X_i\\) ya que algunos se multiplicaran por \\(B_i\\), la cual solo toma valores \\(\\{0,1\\}\\). 6.4 Modelos mixtos En algunos casos en particular se considera un modelo de agregación que es una mixtura entre el modelo individual y el modelo colectivo. Se parte de considerar un número \\(n\\) de unidades aseguradas donde para cada unidad \\(i \\in \\{1, \\ldots, n\\}\\), se considera que puede presentar una cantidad de reclamos dados por una variable aleatoria discreta \\(N_i\\), y así para cada presentar un número de reclamos \\(X_{i,1}, \\ldots, X_{i,N_i}\\). Así el reclamo total viene dado por la expresión \\[ S = \\sum\\limits_{i=1}^n X_i = \\sum\\limits_{i=1}^n \\sum\\limits_{j=1}^{N_i} X_{i,j} \\] 6.5 Modelos con variables explicativas En algunos casos más generales, donde la población presenta heterogeneidad respecto del riesgo al cual están expuestos, como también de las dimensiones de sus reclamos, se considera que existen variables aleatorias adicionales \\(Y_1, \\ldots, Y_n\\) que determinan el número de reclamos \\(N\\) y el valor de los siniestros \\(\\{X_i\\}\\). Es decir no hay independencia entre \\(\\{Y_j\\}\\) y \\(N\\) así como tampoco entre \\(\\{Y_j\\}\\) y \\(\\{X_i\\}\\). Es así que un modelo colectivo \\(S = \\sum\\limits_{i=1}^N X_i\\) su estudio, estimación y tarificación debe ser realizada de forma condicional respecto de las variables aleatorias explicativas \\(\\{Y_j\\}\\), \\[ \\mathbb{E}[ S ] = \\mathbb{E}\\left[ \\mathbb{E}\\left[ S \\middle| Y_1, \\ldots, Y_n \\right] \\right] \\] de donde es necesario estimar cada una de las esperanzas condicionadas \\(\\mathbb{E}\\left[ S \\middle| Y_1, \\ldots, Y_n \\right]\\). En la práctica las variables explicativas \\(\\{ Y_j \\}\\) suelen ser seleccionadas para caracterizar el perfil de riesgo de cada cliente. Para su selección se suele utilizar algunos criterios de tipo económico, financiero, legal y estadístico. 6.6 Aplicación del deducible En muchas ocasiones según las condiciones de los contratos de seguro y el apetito de riesgo del asegurador, se configura funciones deducibles sobre los reclamos. El objetivo de aplicar un deducible es evitar valores de reclamo en determinados rangos que no están acorde a las configuraciones y estructuración de productos de seguro. Por ejemplo: se puede colocar un deducible para evitar el pago de valores muy pequeños de reclamos, cuya atención incluso puede implicar costos operativos o administrativos mayores al valor mismo de los reclamos, ante esta situación se coloca una cota mínima para que de esta forma el asegurado se haga cargo por su cuenta por estos valores menores. Es usual colocar mínimos en las colas de la distribución de reclamos, evitando así valores muy pequeños o valores muy grandes, pero no sería sustentable, ni financieramente o económicamente, el colocar un deducible justo donde se presenta la mayor parte de los valores de reclamos. Desde la perspectiva de un asegurado, ¿De qué serviría adquirir una póliza que no cubre precisamente los siniestros más usuales?, esta no sería una póliza apetecible en el mercado y por otra parte un producto difícil de comercializar. De forma algo más puntual, un deducible es una función \\(D : \\mathbb{R}\\longrightarrow \\mathbb{R}_+\\), tal que para toda variable aleatoria \\(X\\), se satisface la siguiente desigualdad \\(D( X ) \\leq X\\). Para evitar pérdidas pequeñas se suele configurar la función deducible \\[ D( X ) = \\max( X - d, 0 ) \\] que se aplicará sobre las variables aleatorias de los reclamos \\(X \\rightsquigarrow F_X\\). Así, el valor ya deducido \\(Z = D( X ) \\rightsquigarrow F_Z( z )\\), donde \\[ F_Z( z ) = \\mathbf{1}_{[0,+\\infty)}( z ) F_X( z + d ) \\] Code D &lt;- function( x, d ) return( max( x - d, 0 ) ) d &lt;- 50 alpha &lt;- 2 gamma &lt;- 4 tau &lt;- 5 theta &lt;- 80 n &lt;- 1e3 xmax &lt;- 5e2 x &lt;- seq( 0, xmax, length = n ) FX &lt;- sapply( x, FUN = function( x ) ptrbeta( x, shape1 = alpha, shape2 = gamma, shape3 = tau, scale = theta ) ) FDX &lt;- sapply( x, FUN = function( x ) ifelse( x &gt;= d, 1, 0 ) * ptrbeta( x + d, shape1 = alpha, shape2 = gamma, shape3 = tau, scale = theta ) ) plt &lt;- ggplot( ) + geom_line( aes( x = x, y = FX, colour = &#39;a&#39; ), linewidth = 2 ) + geom_line( aes( x = x, y = FDX, colour = &#39;b&#39; ), linewidth = 1 ) + scale_colour_manual( breaks = c( &#39;a&#39;, &#39;b&#39; ), values = c( &#39;dodgerblue3&#39;, &#39;red3&#39; ) ) + scale_x_continuous( breaks = seq( 0, xmax, length = 11 ), labels = formatC( seq( 0, xmax, length = 11 ), digits = 2, format = &#39;f&#39; ), limits = c( 0, xmax ), expand = c( 0, 0 ) ) + scale_y_continuous( breaks = seq( 0, 1, length = 11 ), labels = formatC( seq( 0, 1, length = 11 ), digits = 2, format = &#39;f&#39; ), limits = c( 0.0, 1.0 ), expand = c( 0.005, 0.005 ) ) + xlab( TeX( &quot;$x$&quot; ) ) + ylab( TeX( &quot;$F_X, F_{D(X)}$&quot; ) ) + theme_bw() + theme( legend.position = &quot;none&quot; ) plot( plt ) Para prevenir los excesos de pérdida (stop loss) se propone el deducible con un tope máximo dado por una constante \\(M &gt; 0\\), el cual se aplica a las variables aleatorias de los reclamos \\(X \\rightsquigarrow F_X\\). \\[ D( X ) = \\min( X, M ) \\], en este caso, si la variable aleatoria del pago correspondiente al reclamo ya deducido \\(Z = D( X ) \\rightsquigarrow F_Z( z )\\), donde \\[ F_Z( z ) = \\mathbf{1}_{(-\\infty,M)}( z ) F_X( z ) + \\mathbf{1}_{[M,+\\infty)}( z ) \\] Code D &lt;- function( x, M ) return( min( x, M ) ) M &lt;- 150 alpha &lt;- 2 gamma &lt;- 4 tau &lt;- 5 theta &lt;- 80 n &lt;- 1e3 xmax &lt;- 5e2 x &lt;- seq( 0, xmax, length = n ) FX &lt;- sapply( x, FUN = function( x ) ptrbeta( x, shape1 = alpha, shape2 = gamma, shape3 = tau, scale = theta ) ) FDX &lt;- sapply( x, FUN = function( x ) ifelse( x &lt; M, 1, 0 ) * ptrbeta( x, shape1 = alpha, shape2 = gamma, shape3 = tau, scale = theta ) + ifelse( x &gt;= M, 1, 0 ) ) plt &lt;- ggplot( ) + geom_line( aes( x = x, y = FX, colour = &#39;a&#39; ), linewidth = 2 ) + geom_line( aes( x = x, y = FDX, colour = &#39;b&#39; ), linewidth = 1 ) + scale_colour_manual( breaks = c( &#39;a&#39;, &#39;b&#39; ), values = c( &#39;dodgerblue3&#39;, &#39;red3&#39; ) ) + scale_x_continuous( breaks = seq( 0, xmax, length = 11 ), labels = formatC( seq( 0, xmax, length = 11 ), digits = 2, format = &#39;f&#39; ), limits = c( 0, xmax ), expand = c( 0, 0 ) ) + scale_y_continuous( breaks = seq( 0, 1, length = 11 ), labels = formatC( seq( 0, 1, length = 11 ), digits = 2, format = &#39;f&#39; ), limits = c( 0.0, 1.0 ), expand = c( 0.005, 0.005 ) ) + xlab( TeX( &quot;$x$&quot; ) ) + ylab( TeX( &quot;$F_X, F_{D(X)}$&quot; ) ) + theme_bw() + theme( legend.position = &quot;none&quot; ) plot( plt ) Caso mixto para evitar pérdidas pequeñas y exceso de pérdida, se propone la siguiente composición de deducibles que se aplicará sobre las variables aleatorias de los reclamos \\(X \\rightsquigarrow F_X\\) \\[ D( X ) = \\min( \\max( X - d, 0 ), M ) \\] en este caso, si la variable aleatoria del pago correspondiente al reclamo ya deducido \\(Z = D( X ) \\rightsquigarrow F_Z( z )\\), tenemos que \\(Z \\rightsquigarrow F_Z\\), con: \\[ F_Z( z ) = \\mathbf{1}_{[0,M)}( z ) F_X( z + d ) + \\mathbf{1}_{[M,+\\infty)}( z ) \\] Code D &lt;- function( x, M ) return( min( max( x - d ), M ) ) d &lt;- 50 M &lt;- 150 alpha &lt;- 2 gamma &lt;- 4 tau &lt;- 5 theta &lt;- 80 n &lt;- 1e3 xmax &lt;- 5e2 x &lt;- seq( 0, xmax, length = n ) FX &lt;- sapply( x, FUN = function( x ) ptrbeta( x, shape1 = alpha, shape2 = gamma, shape3 = tau, scale = theta ) ) FDX &lt;- sapply( x, FUN = function( x ) ifelse( x &lt; M &amp; x &gt;= d, 1, 0 ) * ptrbeta( x + d, shape1 = alpha, shape2 = gamma, shape3 = tau, scale = theta ) + ifelse( x &gt;= M, 1, 0 ) ) plt &lt;- ggplot( ) + geom_line( aes( x = x, y = FX, colour = &#39;a&#39; ), linewidth = 2 ) + geom_line( aes( x = x, y = FDX, colour = &#39;b&#39; ), linewidth = 1 ) + scale_colour_manual( breaks = c( &#39;a&#39;, &#39;b&#39; ), values = c( &#39;dodgerblue3&#39;, &#39;red3&#39; ) ) + scale_x_continuous( breaks = seq( 0, xmax, length = 11 ), labels = formatC( seq( 0, xmax, length = 11 ), digits = 2, format = &#39;f&#39; ), limits = c( 0, xmax ), expand = c( 0, 0 ) ) + scale_y_continuous( breaks = seq( 0, 1, length = 11 ), labels = formatC( seq( 0, 1, length = 11 ), digits = 2, format = &#39;f&#39; ), limits = c( 0.0, 1.0 ), expand = c( 0.005, 0.005 ) ) + xlab( TeX( &quot;$x$&quot; ) ) + ylab( TeX( &quot;$F_X, F_{D(X)}$&quot; ) ) + theme_bw() + theme( legend.position = &quot;none&quot; ) plot( plt ) Otro tipo de deducible acota el número de pagos de reclamos a un número fijo máximo de reclamos es decir, se establece un deducible en función para la frecuencia. Usualmente, esto se realiza cuando se considera un modelo donde se dispone de la frecuencia de reclamos por póliza. \\[ D(N) = \\min( N, W ) \\] con la constante \\(W \\in \\mathbb{N}\\). Para el reclamo total, si se considera un portafolio con \\(n\\) pólizas tenemos las siguiente variación del modelo. \\[ S = \\sum\\limits_{i=1}^n \\sum\\limits_{j=1}^{D(N_i)} X_{i,j} \\] En otros casos más elaborados se segmenta el riesgo cubierto, al existir variables explicativas de la naturaleza del riesgo \\(Y_1, \\ldots, Y_m\\), las cuales pueden tomar valores en un conjunto \\(E\\) solo se toma un subconjunto de valores posibles \\(A\\subset E\\), para los cuales es válida la cobertura. Así si un reclamo \\(X\\) se explica o caracteriza por las variables anteriores se configura el deducibles \\[ D( X ) = \\mathbf{1}_{A}\\left( Y_1, \\ldots, Y_m \\right) X \\] Un ejemplo del anterior deducible se suele dar en el caso de seguros de salud, donde se cubre ciertos tipos de enfermedades, usualmente se suele evitar las enfermedades de tipo catastrófico que estén ya presentes, en otros productos se evita los gastos odontológicos, etc. Los deducibles, pueden ser configurados de forma genérica para todos los asegurados o incluso de forma personalizada por asegurado, según los productos que estos han adquirido. En general, al emplear deducibles para cada uno de los reclamos individuales, el reclamo total \\(S\\) se ve modificado, y toma la forma: \\[ S = \\sum\\limits_{i=1}^{N} D_i\\left( X_i \\right) \\] Hay casos donde se aplica el deducible al grupo de siniestros que presenta una póliza o grupo de pólizas. Esto precisamente se lo puede ver cuando se utiliza un modelo mixto de pérdida. \\[ S = \\sum\\limits_{i=1}^n D_i\\left( \\sum\\limits_{n=1}^{N_i} X_{i,j} \\right) \\] Este caso se suele presentar en los productos que partir de una suma parcial de reclamos individuales, el deducible comienza a regir. Es de notar además que la distribución acumulada de la variable aleatoria correspondiente a los reclamos ya deducidos comienza a presentar singularidades, esto complica el estudio del comportamiento de los reclamos totales. 6.6.1 Algoritmo de simulación Presentamos una adaptación sencilla de los algoritmos de simulación anterior, incluyendo el caso que se tenga un deducible aplicado de forma uniforme a todas las pólizas. Seleccionar el número de simulaciones \\(m\\), Se genera una muestra de tamaño \\(m\\) de variables \\(N_1, \\ldots, N_m\\) con ley \\(f_N\\), Se genera para cada \\(i \\in \\{1,\\ldots,m\\}\\) una muestra de tamaño \\(N_i\\) de variables aleatorias \\(X_{i,1}, \\ldots X_{i,N_i}\\) con ley \\(f_X\\), Se establece la función deducible \\(D : \\mathbb{R}\\longrightarrow \\mathbb{R}_+\\) y los parámetros y condiciones necesarias para su definición, Se calcula los reclamos totales utilizando el deducible \\(S_1, \\ldots, S_m\\) para cada simulación \\(i = \\{1, \\ldots, m\\}\\), mediante la siguiente suma \\(S_i = \\sum\\limits_{j=1}^{N_i} D\\left( X_{i,j} \\right)\\), Para la determinación de varios estadísticos se puede utilizar la simulación generada \\(\\{S_i\\}\\) y generar la distribución de probabilidad empírica \\(F_m\\). Ejemplo 6.5 Consideremos el caso de un modelo colectivo de pérdida donde el proceso de conteo \\(N \\rightsquigarrow Pois( \\lambda )\\) y la sucesión \\(\\{X_i\\}\\) de reclamos individuales se considera conformada por variables i.i.d, con distribución de probabilidad \\(LN( \\mu, \\sigma )\\). El deducible a aplicar será una función mixta de la forma \\(D( X ) = \\min( \\max( X - d, 0 ), M )\\). Code # 1. selección de simulaciones m &lt;- 5e4 # 2. especificación de los parámetros para las distribuciones u &lt;- 2 s &lt;- 3 lambda &lt;- 6 # 3. se especifica la función deducible D &lt;- function( x, d, M ) { return( min( max( x - d, 0 ), M ) ) } set.seed( 312341 ) # 4. simulación del conteo de siniestros N &lt;- rpois( n = m, lambda = lambda ) # 5. simulación de la severidad de los reclamos X &lt;- lapply( N, FUN = function( n ) rlnorm( n, meanlog = u, sdlog = s ) ) # 6. se aplica el deducible a los reclamos d &lt;- 100 M &lt;- 1000 DX &lt;- lapply( X, FUN = function( x ) sapply( x, FUN = function( y ) D( y, d, M ) ) ) # 7. reclamo total, agregación por cada simulación S &lt;- sapply( X, FUN = function( x ) ifelse( length( x ) == 0, 0, sum( x, na.rm = TRUE ) ) ) DS &lt;- sapply( DX, FUN = function( x ) ifelse( length( x ) == 0, 0, sum( x, na.rm = TRUE ) ) ) El efecto del deducible sobre la distribución del reclamo es evidente, produciendo así una densidad multimodal, como se observa en el gráfico a continuación, en el mismo incluimos dos histogramas, uno correspondiente a los reclamos totales sin aplicar el deducible y el otro el histograma de los reclamos totales aplicados el deducible.. Code smax &lt;- lambda * M fmax &lt;- 0.002 plt &lt;- ggplot( ) + geom_histogram( aes( S, after_stat( density ) ), fill = &#39;olivedrab3&#39;, colour = &#39;olivedrab4&#39;, alpha = 0.3, bins = nclass.FD( DS ) ) + geom_histogram( aes( DS, after_stat( density ) ), fill = &#39;dodgerblue3&#39;, colour = &#39;dodgerblue4&#39;, alpha = 0.6, bins = nclass.FD( DS ) ) + scale_x_continuous( breaks = seq( 0, smax, length = 7 ), labels = formatC( seq( 0, smax, length = 7 ), digits = 2, format = &#39;f&#39; ), limits = c( 0, smax ), expand = c( 0, 0 ) ) + scale_y_continuous( breaks = seq( 0, fmax, length = 11 ), labels = formatC( seq( 0, fmax, length = 11 ), digits = 4, format = &#39;f&#39; ), limits = c( 0, fmax ), expand = c( 0, 0 ) ) + xlab( TeX( &quot;$s$&quot; ) ) + ylab( TeX( &quot;$f_S$&quot; ) ) + theme_bw() + theme( legend.position = &quot;none&quot; ) plot( plt ) Es de notar que la probabilidad del evento \\(\\{S=0\\}\\) no es nula y se debe a la aplicación del deducible. \\[ \\begin{eqnarray*} P( S = 0 ) &amp; = &amp; P\\left( \\left\\{ S = 0 \\middle| N \\in \\mathbb{N}\\right\\} \\right) \\\\ &amp; = &amp; P\\left( \\bigcup\\limits_{n=0}^{+\\infty} \\left\\{ S = 0 \\land N = n \\right\\} \\right) \\\\ &amp; = &amp; P\\left( \\bigcup\\limits_{n=0}^{+\\infty} \\left\\{ D( X_1 ) + \\cdots + D( X_N ) = 0 \\land N = n \\right\\} \\right) \\\\ &amp; = &amp; P\\left( \\bigcup\\limits_{n=0}^{+\\infty} \\left\\{ X_1 \\leq d \\land \\cdots \\land X_N \\leq d \\land N = n \\right\\} \\right) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} P\\left( X_1 \\leq d \\land \\cdots \\land X_N \\leq d \\land N = n \\right) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} P\\left( X_1 \\leq d \\land \\cdots \\land X_n \\leq d \\middle| N = n \\right)P( N = n ) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} P\\left( X_1 \\leq d \\land \\cdots \\land X_n \\leq d \\right) P( N = n ) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} P\\left( X \\leq d \\right)^n p_n \\\\ &amp; = &amp; \\mathbb{E}\\left[ P\\left( X \\leq d \\right)^N \\right] \\\\ &amp; \\approx &amp; \\sum\\limits_{n=0}^{n&#39;} P( X \\leq d )^n p_n,\\quad \\text{para un valor $n&#39;$ suficientemente grande} \\end{eqnarray*} \\] Code np &lt;- 1e3 ns &lt;- 0:np PS0 &lt;- sum( ( plnorm( d, meanlog = u, sdlog = s )^ns ) * dpois( ns, lambda = lambda ) ) \\[ P( S = 0 ) = 0.314886664 \\] Así mismo, se puede estudiar el evento extremo, caso en el cual se paga el valor máximo que admite el deducible, en este caso en particular es \\(M\\) por cada siniestro y si se producen \\(n\\), entonces como máximo se pagara \\(n M\\). Por tanto, nos interesa la probabilidad del evento \\(\\{ S\\ \\text{es máximo} \\}\\), el cual lo podemos calcular como: \\[ \\begin{eqnarray*} P( S\\ \\text{es máximo} ) &amp; = &amp; P\\left( \\left\\{ S = NM \\middle| N \\in \\mathbb{N}\\right\\} \\right) \\\\ &amp; = &amp; P\\left( \\bigcup\\limits_{n=0}^{+\\infty} \\left\\{ S = N M \\land N = n \\right\\} \\right) \\\\ &amp; = &amp; P\\left( \\bigcup\\limits_{n=0}^{+\\infty} \\left\\{ D( X_1 ) + \\cdots + D( X_N ) = N M \\land N = n \\right\\} \\right) \\\\ &amp; = &amp; P\\left( \\bigcup\\limits_{n=0}^{+\\infty} \\left\\{ X_1 - d &gt; M \\land \\cdots \\land X_N - d \\geq M \\land N = n \\right\\} \\right) \\\\ &amp; = &amp; P\\left( \\bigcup\\limits_{n=0}^{+\\infty} \\left\\{ X_1 &gt; M + d \\land \\cdots \\land X_N \\geq M + d \\land N = n \\right\\} \\right) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} P\\left( X_1 &gt; M + d \\land \\cdots \\land X_N &gt; M + d \\land N = n \\right) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} P\\left( X_1 &gt; M + d \\land \\cdots \\land X_n &gt; M + d \\middle| N = n \\right) P( N = n ) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} P\\left( X_1 &gt; M + d \\land \\cdots \\land X_n &gt; M + d \\right) P( N = n ) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} P\\left( X &gt; M + d \\right)^n p_n \\\\ &amp; = &amp; \\mathbb{E}\\left[ P\\left( X &gt; M + d \\right)^N \\right] \\\\ &amp; \\approx &amp; \\sum\\limits_{n=0}^{n&#39;} P( X &gt; M + d )^n p_n,\\quad \\text{para un valor $n&#39;$ suficientemente grande} \\end{eqnarray*} \\] Code PSmax &lt;- sum( ( ( 1 - plnorm( M + d, meanlog = u, sdlog = s ) )^ns ) * dpois( ns, lambda = lambda ) ) \\[ P( S\\ \\text{es máximo} ) = 0.003299886 \\] Además, podemos calcular el valor máximo esperado de \\(S\\). \\[ \\begin{eqnarray*} \\mathbb{E}\\left[ S \\middle| S\\ \\text{es máximo} \\right] &amp; = &amp; \\mathbb{E}\\left[ S \\middle| \\left\\{ S = NM \\middle| N \\in \\mathbb{N}\\right\\} \\right] \\\\ &amp; = &amp; \\mathbb{E}\\left[ S \\middle| \\bigcup\\limits_{n=0}^{+\\infty} \\left\\{ S = NM \\land N = n \\right\\} \\right] \\\\ &amp; = &amp; \\mathbb{E}\\left[ NM \\middle| \\bigcup\\limits_{n=0}^{+\\infty} \\left\\{ N = n \\right\\} \\right] \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} \\mathbb{E}\\left[ n M \\middle| N = n \\right] P( N = n ) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} n M P( N = n ) \\\\ &amp; = &amp; M \\sum\\limits_{n=0}^{+\\infty} n P( N = n ) \\\\ &amp; = &amp; M \\mathbb{E}\\left[ N \\right] \\\\ \\end{eqnarray*} \\] Code ESmax &lt;- M * sum( ns * dpois( ns, lambda = lambda ) ) \\[ \\mathbb{E}\\left[ S \\middle| S\\ \\text{es máximo} \\right] = 6000.00 \\] De este razonamiento se puede evidenciar que al aplicar un deducible con cota superior, se corta la cola de la distribución y por tal razón no se puede esperar valores extremos por parte de la severidad, sino tan solo por un aumento de frecuencia, e incluso el valor máximo esperado es proporcional a la cota superior \\(M\\) veces la frecuencia esperada. De ahí que, al aplicar un deducible con cota superior no se puede esperar un encarecimiento de primas por aumento de severidad, ya que los reclamos están acotados, así como el máximo esperado; lo único que puede encarecer la prima es un aumento de frecuencia. Como ya se lo mencionó, utilizando la simulación \\(\\{S_i\\}\\) podemos determinar la distribución de probabilidad empírica \\(F_m\\) que aproxima la distribución de \\(F_S\\). Code FeS &lt;- ecdf( S ) FeDS &lt;- ecdf( DS ) s &lt;- seq( 0, ESmax, length = 1000 ) Fes &lt;- sapply( s, FUN = FeS ) FeDs &lt;- sapply( s, FUN = FeDS ) Code Smax &lt;- ESmax xbrk &lt;- sort( unique( c( d, M, seq( 0, Smax, length = 7 ) ) ) ) xlbl &lt;- formatC( xbrk, digits = 0, format = &#39;f&#39; ) xlim &lt;- c( 0, Smax ) ybrk &lt;- seq( 0, 1, length = 11 ) ylbl &lt;- formatC( ybrk, digits = 2, format = &#39;f&#39; ) ylim &lt;- c( 0, 1 ) plt &lt;- ggplot( ) + geom_step( aes( x = s, y = Fes, colour = &#39;a&#39; ), linewidth = 1 ) + geom_step( aes( x = s, y = FeDs, colour = &#39;b&#39; ), linewidth = 1 ) + geom_vline( xintercept = c( d, M ), colour = &#39;orange&#39;, linewidth = 0.7 ) + geom_point( aes( 0, PS0 ), colour = &#39;red3&#39;, size = 3 ) + scale_colour_manual( breaks = c( &#39;a&#39;, &#39;b&#39; ), values = c( &#39;olivedrab4&#39;, &#39;dodgerblue4&#39; ) ) + scale_x_continuous( breaks = xbrk, labels = xlbl, limits = xlim, expand = c( 0.008, 0.008 ) ) + scale_y_continuous( breaks = ybrk, labels = ylbl, limits = ylim, expand = c( 0.005, 0.005 ) ) + xlab( TeX( &quot;$s$&quot; ) ) + ylab( TeX( &quot;$F_{S,m},F_{S^D,m}$&quot; ) ) + theme_bw() + theme( legend.position = &quot;none&quot; ) plot( plt ) 6.7 Algoritmo de Panjer El siguiente algoritmo es de especial interés para determinar la densidad de probabilidad \\(f_S\\) del total de reclamos \\(S\\). Se asume que el conteo de siniestro \\(N\\) viene dado por alguna de las distribuciones en la familia \\((a,b,0)\\) y los reclamos individuales son \\(\\{X_i\\}\\) son i.i.d y también independientes de \\(N\\). En ese contexto podemos observar que para cualquier \\(s &gt; 0\\), tenemos: \\[ \\begin{eqnarray*} f_S( s ) &amp; = &amp; \\sum\\limits_{n=1}^{+\\infty} p_n f_X^{\\star n}( s ) \\\\ &amp; = &amp; p_1 f_X( s ) + \\sum\\limits_{n=2}^{+\\infty} p_n f_X^{\\star n}( s ) \\\\ &amp; = &amp; p_1 f_X( s ) + \\sum\\limits_{n=1}^{+\\infty} p_{n+1} f_X^{\\star n + 1}( s ) \\\\ &amp; = &amp; p_1 f_X( s ) + \\sum\\limits_{n=1}^{+\\infty} \\left( a + \\frac{b}{n+1} \\right) p_{n} f_X^{\\star n + 1}( s ) \\\\ &amp; = &amp; p_1 f_X( s ) + \\sum\\limits_{n=1}^{+\\infty} p_{n} \\int\\limits_0^s \\left( a + \\frac{b y}{s} \\right) f_X( y ) f_X^{\\star n}( s - y )\\ dy \\\\ &amp; = &amp; p_1 f_X( s ) + \\int\\limits_0^s \\left( a + \\frac{b y}{s} \\right) f_X( y ) \\sum\\limits_{n=1}^{+\\infty} p_{n} f_X^{\\star n}( s - y )\\ dy \\\\ &amp; = &amp; p_1 f_X( s ) + \\int\\limits_0^s \\left( a + \\frac{b y}{s} \\right) f_X( y ) f_S( s - y )\\ dy \\end{eqnarray*} \\] cuando \\(s = 0\\), la probabilidad se concentra en \\(0\\), y por tanto \\(f_S( 0 ) = p_0\\) Como consecuencia del análisis anterior resulta la relación recurrente, la cual es precisamente explotada de forma numérica por el algoritmo de Panjer. \\[ f_S( s ) = p_1 f_X( s ) + \\int\\limits_0^s \\left( a + \\frac{b y}{s} \\right) f_X( y ) f_S( s - y )\\ dy, \\qquad \\forall s &gt; 0 \\] Si se toma una discretización \\(0 = s_0 &lt; s_1 &lt; \\cdots &lt; s_n\\) para aproximar la integral anterior \\[ f_S\\left( s_k \\right) = p_1 f_X\\left( s_k \\right) + \\sum\\limits_{i=0}^{k-1} \\left( a + \\frac{b s_i}{s_k} \\right) f_X\\left( s_i \\right) f_S\\left( s_{k-i} \\right) \\left( s_{i+1} - s_i \\right) \\] Al tomar un división uniforme para la malla utilizada para aproximar la integral, por ejemplo \\(s_k = k h\\), tenemos que: \\[ f_S\\left( s_k \\right) = p_1 f_X\\left( s_k \\right) + h \\sum\\limits_{i=0}^{k-1} \\left( a + \\frac{b i}{k} \\right) f_X\\left( s_i \\right) f_S\\left( s_{k-i} \\right) \\] de donde resulta una forma bien conocida para el algoritmo de Panjer. sin embargo, es importante tener en cuenta que una malla de paso no constante puede ser mejor adaptada para realizar la integral. Ejemplo 6.6 Consideremos el caso para un reclamo total \\(S\\) donde el conteo de los siniestros \\(N \\rightsquigarrow NBin( \\alpha, p )\\) y las severidades \\(\\{X_i\\}\\) son i.i.d con distribución \\(LN( \\mu, \\sigma )\\). Utilizaremos el algoritmo de Panjer para aproximar la densidad de probabilidad de \\(f_S\\) de \\(S\\). Code n &lt;- 7e4 p &lt;- 0.3 alpha &lt;- 3 a &lt;- 1 - p b &lt;- ( 1 - p ) * ( alpha - 1 ) p0 &lt;- p^alpha u &lt;- 5 s &lt;- 0.3 smax &lt;- 5e3 dist &lt;- dlnorm pardist &lt;- list( meanlog = u, sdlog = s ) sg &lt;- seq( 0, smax, length = n ) ds &lt;- diff( sg ) fX &lt;- sapply( sg, FUN = function( y ) do.call( dist, c( y, pardist ) ) ) fS &lt;- p0 K &lt;- 1 p1 &lt;- ( a + b ) * p0 for ( k in 2:n ) { fS &lt;- c( fS, p1 * fX[ k ] + sum( ( a + b * sg[ K ] / sg[ k ] ) * fX[ K ] * fS[ rev( K ) ] * ds[ K ] ) ) K &lt;- c( K, k ) } set.seed( 32141223 ) m &lt;- 1e5 N &lt;- rnbinom( n = m, size = alpha, prob = p ) X &lt;- lapply( N, FUN = function( n ) rlnorm( n, meanlog = u, sdlog = s ) ) S &lt;- sapply( X, FUN = function( x ) sum( x, na.rm = TRUE ) ) El algoritmo de Panjer suele tener problemas para ajustarse en los primeros valores de la densidad \\(f_S\\), tal como lo muestra el gráfico a continuación, usualmente hay una sobre estimación. Además, el algoritmo solo es válido cuando el conteo de siniestros pertenece a la familia de distribuciones \\((a,b,0)\\). Code fmax &lt;- 0.0007 plt &lt;- ggplot( ) + geom_histogram( aes( S, after_stat( density ) ), fill = &#39;dodgerblue4&#39;, colour = &#39;white&#39;, alpha = 0.6, bins = nclass.FD( S ) ) + geom_line( aes( x = sg, y = fS ), colour = &#39;purple3&#39;, linewidth = 1 ) + scale_x_continuous( breaks = seq( 0, smax, length = 7 ), labels = formatC( seq( 0, smax, length = 7 ), digits = 2, format = &#39;f&#39; ), limits = c( 0, smax ), expand = c( 0, 0 ) ) + scale_y_continuous( breaks = seq( 0, fmax, length = 11 ), labels = formatC( seq( 0, fmax, length = 11 ), digits = 4, format = &#39;f&#39; ), limits = c( 0, fmax ), expand = c( 0, 0 ) ) + xlab( TeX( &quot;$s$&quot; ) ) + ylab( TeX( &quot;$f_S$&quot; ) ) + theme_bw() + theme( legend.position = &quot;none&quot; ) plot( plt ) Code e &lt;- cumsum( fS[ -1 ] * ds ) - ecdf( S )( sg[ -1 ] ) eb &lt;- max( abs( e ) ) plt &lt;- ggplot() + geom_histogram( aes( x = e, y = after_stat( density ) ), fill = &#39;grey50&#39;, colour = &#39;dodgerblue3&#39;, bins = nclass.scott( e ) ) + scale_y_continuous( labels = label_scientific( digits = 2 ) ) + ylab( TeX( &quot;$e$&quot; ) ) + theme_bw() plot( plt ) 6.8 Estimación usando la transformada de Fourier Se puede utilizar la transformada de Fourier para determinar la densidad de la suma \\(S_n = \\sum\\limits_{i=1}^n X_i\\) de varias variables aleatorias \\(X_1 \\rightsquigarrow f_{X_1}, \\ldots, X_n \\rightsquigarrow f_{X_n}\\) que son independientes, pero que podrían ser o no idénticamente distribuidas. Claramente, la densidad de probabilidad de \\(S\\) está dada por la convolución de las densidades de probabilidad de cada una de las variables aleatorias \\(X_1, \\ldots, X_n\\). \\[ f_S = f_{X_1} \\star \\cdots \\star f_{X_n} \\] sin embargo esta convolución implica el realizar una interacción en \\(n\\)-dimensiones. Si las las variables aleatorias \\(\\{X_i\\}\\) son independientes sabemos además que \\[ \\mathscr{F}\\left( f_S \\right) = \\prod\\limits_{i=1}^n \\mathscr{F}\\left( f_{X_i} \\right) \\] Por otra parte, con lo anterior sabemos que es posible aproximar numéricamente cada \\(\\mathscr{F}\\left( f_{X_i} \\right)\\) con una serie \\(\\{\\hat{f}_{i,j}\\}\\) dada por la discretización de la transformada de Fourier y su aplicación sobre la discretización de la densidad de probabilidad \\(f_{i,k} = f_{X_i}( s_k )\\). Por tanto, para cada de las densidades con \\(i \\in \\{1, \\ldots, n\\}\\) y \\(\\omega_j = \\frac{j}{b-a}\\) con \\(j \\in \\{0,\\ldots, N-1\\}\\), se puede calcular de forma separada las aproximaciones a cada una de las transformadas \\[ \\mathscr{F}( f_{X_i} )\\left( \\omega_j \\right) \\approx \\hat{f}_{i,j} = h \\exp\\left( -2\\pi i \\omega_j a \\right) \\left( \\operatorname{DFT}\\left[ \\{f_{i,k}\\} \\right] \\right)_j \\] con lo anterior, también, se puede realizar una aproximación a la trasformada de Fourier \\(\\mathscr{F}\\left( f_S \\right)\\) de la densidad de probabilidad que buscamos \\(f_S\\), como el producto de sus transformadas de Fourier. \\[ \\mathscr{F}( f_{S} )\\left( \\omega_j \\right) = \\prod\\limits_{i=1}^n \\mathscr{F}\\left( f_{X_i} \\right)\\left( \\omega_j \\right) \\approx \\prod\\limits_{i=1}^n \\hat{f}_{i,j} \\] utilizando la inversión de la transformada de Fourier discreta podemos calcular una serie que precisamente aproxima a la densidad \\(f_S\\) \\[ \\{ f_{S}( s_k ) \\} \\approx \\operatorname{Re}\\left( \\operatorname{DFT}^{-1}\\left[ \\left\\{ \\frac{1}{h} \\exp\\left( 2\\pi i \\omega_j a \\right) \\prod\\limits_{i=1}^n \\hat{f}_{i,j} \\right\\} \\right] \\right) \\] Code N &lt;- 10000 set.seed(94312) alpha &lt;- sample( x = seq( 1, 20, length = 40 ), size = 50, replace = TRUE ) theta &lt;- 3 b &lt;- sum( sapply( alpha, FUN = function( a ) qgamma( 0.9999, shape = a, scale = theta ) ) ) a &lt;- 0 h &lt;- ( b - a ) / N n &lt;- 0:N s &lt;- a + n * h w &lt;- n / ( b - a ) eta &lt;- h * exp( -2 * pi * 1i * w * a ) f &lt;- lapply( alpha, function( a ) sapply( s, FUN = function( sk ) dgamma( sk, shape = a, scale = theta ) ) ) Fof &lt;- lapply( f, FUN = function( fi ) eta * fft( fi ) ) FoS &lt;- rep( 1, N + 1 ) for ( i in 1:length( f ) ) { FoS &lt;- FoS * Fof[[ i ]] } fS &lt;- fft( eta^(-1) * FoS, inverse = TRUE ) / ( N + 1 ) fS &lt;- Re( fS ) fs &lt;- sapply( s, FUN = function( sk ) dgamma( sk, shape = sum( alpha ), scale = theta ) ) Code plt &lt;- ggplot() + geom_line( aes( x = s, y = fS ), colour = &#39;darkred&#39;, linewidth = 1 ) + geom_point( aes( x = s, y = fs ), colour = &#39;olivedrab3&#39;, size = 0.25 ) + xlab( TeX( &quot;$x$&quot; ) ) + ylab( TeX( &quot;$f_{S}(x)$&quot; ) ) + theme_bw() plot( plt ) Code e &lt;- fS - fs eb &lt;- max( abs( e ) ) plt &lt;- ggplot() + geom_histogram( aes( x = e, y = after_stat( density ) ), fill = &#39;grey50&#39;, colour = &#39;dodgerblue3&#39;, bins = nclass.scott( e ) ) + scale_y_continuous( labels = label_scientific( digits = 4 ) ) + ylab( TeX( &quot;$e$&quot; ) ) + theme_bw() plot( plt ) Utilizando la misma idea anterior, se puede aproximar cada uno de los términos presentes en la serie que determina la densidad de probabilidad \\(f_S\\) de un modelo colectivo. Se selecciona un número máximo \\(M \\in \\mathbb{N}\\) de términos a ser considerados en la serie, \\(M\\) lo suficientemente grande como para que la siguiente aproximación resulte adecuada. \\[ \\{ f_{S}( s_k ) \\} \\approx \\operatorname{Re}\\left( \\operatorname{DFT}^{-1}\\left[ \\sum\\limits_{n=1}^{M} \\left\\{ \\frac{1}{h} \\exp\\left( 2\\pi i \\omega_j a \\right) \\prod\\limits_{i=1}^n \\hat{f}_{i,j} \\right\\}\\ p_n \\right] \\right), \\qquad \\forall s_k &gt; 0 \\] para el caso cuando \\(s_o = 0\\), tenemos que \\(f_S( s_0 ) = f_S( 0 ) = p_0\\). Code M &lt;- 200 N &lt;- 7e4 p &lt;- 0.3 alpha &lt;- 3 pn &lt;- dnbinom( 0:M, size = alpha, prob = p ) u &lt;- 5 s &lt;- 0.3 b &lt;- 5e3 a &lt;- 0 h &lt;- ( b - a ) / N n &lt;- 0:N sg &lt;- a + n * h w &lt;- n / ( b - a ) eta &lt;- h * exp( -2 * pi * 1i * w * a ) f &lt;- sapply( sg, FUN = function( sk ) dlnorm( sk, meanlog = u, sdlog = s ) ) Fof &lt;- eta * fft( f ) FoS &lt;- rep( 0, N + 1 ) for ( n in 1:M ) { FoS &lt;- FoS + pn[ n + 1 ] * Fof^n } fS &lt;- fft( eta^(-1) * FoS, inverse = TRUE ) / ( N + 1 ) fS &lt;- Re( fS ) fS[1] = pn[1] set.seed( 32141223 ) m &lt;- 1e5 N &lt;- rnbinom( n = m, size = alpha, prob = p ) X &lt;- lapply( N, FUN = function( n ) rlnorm( n, meanlog = u, sdlog = s ) ) S &lt;- sapply( X, FUN = function( x ) sum( x, na.rm = TRUE ) ) Code fmax &lt;- 0.0007 smax &lt;- 5e3 plt &lt;- ggplot() + geom_histogram( aes( S, after_stat( density ) ), fill = &#39;dodgerblue4&#39;, colour = &#39;white&#39;, alpha = 0.6, bins = nclass.FD( S ) ) + geom_line( aes( x = sg, y = fS ), colour = &#39;purple3&#39;, linewidth = 1 ) + scale_x_continuous( breaks = seq( 0, b, length = 7 ), labels = formatC( seq( 0, smax, length = 7 ), digits = 2, format = &#39;f&#39; ), limits = c( 0, smax ), expand = c( 0, 0 ) ) + scale_y_continuous( breaks = seq( 0, fmax, length = 11 ), labels = formatC( seq( 0, fmax, length = 11 ), digits = 4, format = &#39;f&#39; ), limits = c( 0, fmax ), expand = c( 0, 0 ) ) + xlab( TeX( &quot;$s$&quot; ) ) + ylab( TeX( &quot;$f_S$&quot; ) ) + theme_bw() + theme( legend.position = &quot;none&quot; ) plot( plt ) Code e &lt;- cumsum( fS[ -1 ] * diff( sg ) ) - ecdf( S )( sg[-1] ) eb &lt;- max( abs( e ) ) plt &lt;- ggplot() + geom_histogram( aes( x = e, y = after_stat( density ) ), fill = &#39;grey50&#39;, colour = &#39;dodgerblue3&#39;, bins = nclass.FD( e ) ) + scale_y_continuous( labels = label_scientific( digits = 2 ) ) + ylab( TeX( &quot;$e$&quot; ) ) + theme_bw() plot( plt ) 6.9 Temporalidad y ajustes del número de reclamos Hasta el momento no hemos tomado en cuenta cierta componente de temporalidad que muestra la frecuencia de los reclamos. Debemos ser muy consientes que los reclamos se producen en el tiempo y que el número de estos dependerá del periodo de exposición de cada uno de los asegurados, en otras palabras en la estimación de la frecuencia se debe tomar en cuenta que las pólizas tienen un periodo de cobertura, una fecha inicial y una fecha final. Más puntualmente, para una inferencia sencilla si estimamos reclamos de pólizas que duran 2 años entonces la frecuencia del número de reclamos \\(N\\) será bianual. Si por el contrario se quiere utilizar esta frecuencia para estimar el número de reclamos para pólizas con cobertura anual entonces, es necesario realizar un ajuste acorde. Dando algo más de sentido matemático a este razonamiento, a cada póliza podemos asociar su respectiva exposición al riesgo, que no es más que el ancho de intervalo dado por la fecha inicial de la póliza, menos la fecha final de la póliza. Usualmente la unidad que su utiliza para medir este intervalo es en años, pero puede cambiársela, siempre y cuando la formulación del modelo sea clara y el uso de estas unidades sea consistente para cálculos futuros. Así si tenemos \\(n\\) pólizas para cada una de ellas hay un tiempo de inicio \\(s_i\\) y un tiempo \\(e_i\\) final, para todo \\(i \\in \\{1, \\ldots, n\\}\\), así la exposición al riesgo \\(ER_i\\) está dada por una distancia \\(d\\) \\[ ER_i = d( s_i, e_i ) \\] por ejemplo, una buena distancia puede ser \\[ d( s, e ) = \\frac{\\# \\left\\{ \\text{días entre $s$ y $e$} \\right\\}}{365.25} \\] En la librería lubridate de R, tenemos una implementación que puede utilizarse fácilmente para calcular la distancia en años entre dos fechas dadas. Code s &lt;- ymd( &#39;1951-04-09&#39; ) e &lt;- ymd( &#39;2025-04-09&#39; ) d1 &lt;- interval( s, e ) / dyears( 1 ) d2 &lt;- length( seq( s, e, by = &#39;day&#39;) ) / 365.25 La idea es ajustar la estimación de la frecuencia de forma proporcional a la exposición al riesgo, esto se puede realizar postulando que la variable aleatoria del conteo de siniestros, tienen una esperanza proporcional a la exposición al riesgo. \\[ \\mathbb{E}\\left[ N \\right] = \\lambda ER \\] además se puede ajustar la distribución de probabilidad que se desee estimar en función del parámetro \\(\\lambda\\), es así que para las distribuciones de probabilidad discretas que hemos introducido con anterioridad, tenemos la siguiente modificación. Para la distribución de Poisson, tenemos la ley de probabilidad \\[ P( N = k ) = \\exp\\left( -\\lambda ER \\right) \\frac{( \\lambda ER )^k}{k!}, \\qquad \\forall k \\in \\mathbb{N} \\] entonces \\(N \\rightsquigarrow Pois( \\lambda ER )\\). En caso de disponer de una muestra de \\(N_1, \\ldots, N_m\\) de variables aleatorias independientes, y por otra parte exposiciones al riesgo \\(ER_1, \\ldots, ER_m\\) asociadas a cada una de las variables aleatorias, de tal forma que \\(N_i \\rightsquigarrow Pois( \\lambda ER_i )\\), entonces la función de verosimilitud logarítmica toma la forma: \\[ \\ell( \\lambda ) = - \\lambda \\sum\\limits_{i=1}^m ER_i + \\sum\\limits_{i=1}^m N_i \\log\\left( ER_i \\right) + \\sum\\limits_{i=1}^m N_i \\log\\left( \\lambda \\right) - \\sum\\limits_{i=1}^m \\log\\left( N_i! \\right) \\] en este caso el estimador por maximización de verosimilitud es bien sencillo de determinar y está dado por: \\[ \\lambda = \\frac{\\sum\\limits_{i=1}^m N_i}{\\sum\\limits_{i=1}^m ER_i } \\] Para la distribución binomial begativa, tenemos que si \\[ \\lambda ER = \\alpha \\frac{1-p}{p} \\Rightarrow p = \\frac{\\alpha}{\\lambda ER + \\alpha} \\] de donde la ley de probabilidad queda modificada como \\[ P( N = k ) = \\frac{\\Gamma( \\alpha + k )}{\\Gamma(k+1) \\Gamma(\\alpha)} \\left( \\frac{\\alpha}{\\lambda ER + \\alpha} \\right)^\\alpha \\left( \\frac{\\lambda ER}{\\lambda ER + \\alpha} \\right)^k, \\qquad \\forall k \\in \\mathbb{N} \\] entonces \\(N \\rightsquigarrow NBinom\\left( \\alpha, \\frac{\\alpha}{\\lambda ER + \\alpha} \\right)\\). Similar que antes, si disponemos de una muestra de \\(N_1, \\ldots, N_m\\) de variables aleatorias independientes y también exposiciones al riesgo \\(ER_1, \\ldots, ER_m\\) asociadas a cada una de las variables aleatorias, de tal forma que \\(N_i \\rightsquigarrow NBinom\\left( \\alpha, \\frac{\\alpha}{\\lambda ER_i + \\alpha} \\right)\\), entonces la función de verosimilitud logarítmica toma la forma: \\[ \\begin{eqnarray*} \\ell( \\alpha, \\lambda ) &amp; = &amp; \\sum\\limits_{i=1}^m \\log \\Gamma( \\alpha + N_i ) - \\sum\\limits_{i=1}^m \\log \\Gamma( N_i + 1 ) - m \\log \\Gamma( \\alpha ) \\\\ &amp; &amp; + \\sum\\limits_{i=1}^m N_i \\log\\left( \\lambda \\right) + \\sum\\limits_{i=1}^m N_i \\log\\left( ER_i \\right) - \\sum\\limits_{i=1}^m N_i \\log\\left( \\lambda ER_i + \\alpha \\right) + m \\alpha \\log\\left( \\alpha \\right) \\\\ &amp; &amp; - \\alpha \\sum\\limits_{i=1}^m \\log\\left( \\lambda ER_i + \\alpha \\right) \\end{eqnarray*} \\] Para la distribución binomial, tenemos que si \\[ \\lambda ER = np \\Rightarrow p = \\frac{\\lambda ER}{n} \\] de donde la ley de probabilidad queda modificada como \\[ P( N = k ) = \\binom{n}{k} \\left( \\frac{\\lambda ER}{n} \\right)^k \\left( 1 - \\frac{\\lambda ER}{n} \\right)^{n-k}, \\qquad \\forall k \\in \\{0,\\ldots, n\\} \\] entonces \\(N \\rightsquigarrow Binom\\left( n, \\frac{\\lambda ER}{n} \\right)\\) Mismo razonamiento, si disponemos de una muestra de \\(N_1, \\ldots, N_m\\) de variables aleatorias independientes y también exposiciones al riesgo \\(ER_1, \\ldots, ER_m\\) asociadas a cada una de las variables aleatorias, de tal forma que \\(N_i \\rightsquigarrow Binom\\left( n, \\frac{\\lambda ER_i}{n} \\right)\\), entonces la función de verosimilitud logarítmica toma la forma: \\[ \\begin{eqnarray*} \\ell( n, \\lambda ) &amp; = &amp; m \\log( n! ) - \\sum\\limits_{i=1}^m \\log( N_i! ) - \\sum\\limits_{i=1}^m \\log( (n - N_i)! ) \\\\ &amp; &amp; + \\sum\\limits_{i=1}^m N_i \\log \\lambda + \\sum\\limits_{i=1}^m N_i \\log ER_i - n \\sum\\limits_{i=1}^m N_i \\\\ &amp; &amp; + n \\sum\\limits_{i=1}^m \\log\\left( 1 - \\frac{\\lambda ER_i}{n} \\right) - \\sum\\limits_{i=1}^m N_i \\log\\left( 1 - \\frac{\\lambda ER_i}{n} \\right) \\end{eqnarray*} \\] En los tres casos anteriores, hemos desarrollado una metodología para la estimación de la distribución de frecuencia de los reclamos, tomando en cuenta la exposición al riesgo de cada una de las pólizas a las cuales estos reclamos corresponden. Ejemplo 6.7 Ahora bien, pongamos en aplicación todo lo aprendido hasta el momento. Para ello, trabajaremos con información de pólizas de un seguro de salud. La información está compuesta de dos objetos, uno la producción de pólizas y dos los reclamos de varios productos asociados al ramo. La información corresponde a un seguro de salud el cual tiene pólizas individuales y colectivas, para cada una de sus contratos se especifica un deducible de la forma \\(D( X ) = \\min( \\max( X - d, 0 ), M )\\), donde precisamente \\(d\\) es lo que se conoce como el deducible y \\(M\\) como el monto máximo de cobertura. Code load( &#39;../RData/production_claims_health.RData&#39; ) El objeto con la producción de pólizas tienen la siguiente estructura. Es un objeto con una forma usual que uno puede encontrar en las bases de producción de un asegurador. Se incluye en particular campos de especial interés como la fecha de nacimiento bdate, el inicio de vigencia de la cobertura start y el final de vigencia de la cobertura end. Code production[ 1:100 ] %&gt;% kable( label = NA, caption = &#39;Pólizas&#39;, row.names = FALSE, align = &#39;llllrrrrrrrl&#39;, digits = c( 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0 ), format.args = list( big.mark = &#39;,&#39;, decimal.mark = &#39;.&#39;, scientific = FALSE ), escape = FALSE, centering = TRUE ) %&gt;% kable_classic( font_size = 14, full_width = FALSE, html_font = &quot;Cambria&quot;, position = &quot;center&quot; ) %&gt;% scroll_box( width = &quot;100%&quot;, height = &quot;500px&quot; ) Tabla 6.1: Pólizas id policy insured sex bdate premium fpremium start end type deductible amount 59f51c382ebf 288dd685 00 MALE 1986-09-14 297.68 4 2017-12-22 2018-09-01 COL 25 11,250 f1b316dbca9c 708ee54e 00 MALE 1998-11-30 390.00 4 2018-02-22 2018-06-05 IND 35 12,250 9924a3ba6b5c 16fa4935 00 FEMALE 1996-09-15 380.00 4 2018-06-03 2018-08-24 IND 35 14,500 59e63ffc9688 66d6f1d0 00 FEMALE 1973-07-28 288.64 4 2017-12-18 2018-12-17 COL 25 9,250 d28db8f7c754 6d64a583 00 MALE 1979-02-14 564.08 12 2018-01-11 2021-01-10 IND 30 12,750 fb9e3f6e5c6f b16ef666 00 FEMALE 1964-12-19 375.00 4 2018-01-23 2018-05-06 IND 25 15,000 78e98ce3bcdd 4ab54a09 00 MALE 1962-07-11 615.00 2 2020-12-02 2020-12-16 COL 100 13,750 7e723f43e928 1f9bde7f 00 FEMALE 1966-11-23 370.00 4 2018-02-08 2018-06-05 IND 35 14,750 2aac4c6a8625 c74ca3ae 00 FEMALE 1984-11-02 478.36 12 2018-01-28 2018-07-05 IND 40 11,250 08cf0c0c7a47 e735ef11 00 FEMALE 1972-09-28 518.72 12 2018-01-11 2018-08-31 IND 15 13,750 d0332f625103 c6c80ce5 00 FEMALE 1945-11-22 370.00 4 2018-02-07 2018-05-21 IND 30 15,000 b60509d03db0 6420fe73 00 FEMALE 1980-03-24 508.72 12 2017-12-27 2018-04-29 IND 25 11,250 ed8044964cf9 fe22392e 00 FEMALE 1990-01-01 375.00 4 2018-03-17 2018-08-24 IND 30 12,500 693f6ba96d4b 27533fb7 00 MALE 1983-08-11 473.40 12 2017-12-12 2018-07-26 IND 10 14,250 a458e84b508d a9f6e0e5 00 FEMALE 1986-11-09 458.36 12 2017-12-27 2018-03-21 IND 30 11,250 086d2fc06fa5 b742fdf5 00 FEMALE 1965-04-22 564.08 4 2018-02-15 2018-05-10 IND 35 14,500 6cf21642b8a6 2645883f 00 FEMALE 1990-12-07 370.00 4 2018-02-22 2018-06-05 IND 25 12,500 f5feba266c1e 9ebbaf8b 00 FEMALE 1963-09-16 990.08 12 2018-07-02 2018-08-24 IND 10 13,250 f5feba266c1e 83eb70f3 00 FEMALE 1963-09-16 1,005.08 12 2018-07-12 2018-09-03 IND 40 12,000 367e5a78523f 9ebbaf8b 01 FEMALE 2009-11-15 975.08 12 2018-06-17 2018-08-09 IND 10 13,250 367e5a78523f 83eb70f3 01 FEMALE 2009-11-15 1,000.08 12 2018-06-22 2018-08-14 IND 40 12,000 79a092a2171a e19d530b 00 FEMALE 1962-12-05 564.08 12 2017-12-02 2018-05-22 IND 20 13,000 449f7e5d96d1 637f033a 00 FEMALE 1961-03-16 293.64 4 2017-12-11 2018-12-10 COL 30 12,000 9553a3b1b709 16831eac 00 FEMALE 1981-05-09 544.16 12 2018-01-11 2019-02-18 IND 15 11,500 47c0db2f2f15 f76767c8 00 MALE 1961-01-24 395.00 4 2018-03-28 2018-06-12 IND 40 14,750 c0cae1169a47 6eedf6f0 00 FEMALE 1995-05-18 380.00 4 2018-03-29 2018-07-25 IND 20 12,500 670a52e9abcc 4bd9d436 00 FEMALE 1989-07-31 478.36 12 2017-12-07 2018-03-08 IND 30 11,750 6c1bf8784103 c081174a 00 FEMALE 1983-04-29 944.84 12 2019-09-19 2019-12-30 IND 15 13,250 a4b509d29f6f c081174a 01 FEMALE 2013-01-12 929.84 12 2019-09-19 2019-12-30 IND 15 13,250 e65823d07f3d 5340ad46 00 FEMALE 1952-04-02 365.00 4 2018-07-14 2018-10-06 IND 25 11,750 a9fa71a009c3 b1d298e8 00 FEMALE 1975-03-03 533.72 12 2017-12-28 2018-06-20 IND 25 14,750 6aa8155ed74d 0948ff70 00 FEMALE 1975-02-09 303.64 4 2017-12-13 2018-12-12 COL 15 9,000 e5b3aae5372a c8f03350 00 MALE 1954-04-04 549.08 12 2018-01-16 2018-08-15 IND 40 12,750 2ffab5a8a81b 0ed09e9f 00 MALE 1950-03-24 669.68 4 2017-12-02 2018-07-01 IND 30 13,500 a3f19ec6d908 042f4725 00 MALE 1997-11-02 525.76 12 2017-12-27 2020-12-26 IND 20 11,000 b3b47d112d83 45f84974 00 FEMALE 1959-01-01 340.32 4 2017-12-22 2019-08-25 COL 35 11,250 c84f86a61c12 328cc71d 00 FEMALE 1989-10-19 298.64 4 2017-12-28 2018-12-27 COL 25 10,500 838cdb5c95e5 7ed6effd 00 MALE 1990-10-26 395.00 4 2018-02-03 2018-05-31 IND 35 14,250 a475e345ea3a 9694916f 00 MALE 1987-06-09 491.36 12 2018-01-31 2018-10-19 IND 25 13,250 945676111f6b 88dd0d92 00 MALE 1996-06-19 293.64 4 2018-01-19 2019-01-18 COL 35 11,000 377361536af3 8415c840 00 MALE 1995-05-26 463.36 12 2018-08-05 2018-09-08 IND 15 11,750 90314b5fd6c8 e8a58e9a 00 MALE 1993-02-01 380.00 4 2018-05-13 2018-07-19 IND 40 13,500 11fd0040ddb6 1de25947 00 FEMALE 1969-02-20 375.00 4 2018-03-07 2018-06-20 IND 40 15,000 7cdc26a2b97c 47ce60a5 00 FEMALE 1950-08-04 697.08 12 2018-01-24 2019-04-28 IND 25 13,250 a7e204e3a2f6 e5dfeb33 00 MALE 1958-05-29 293.64 4 2018-01-28 2019-01-27 COL 20 9,750 1166a18e8f85 f5187692 00 FEMALE 1948-09-04 390.00 4 2018-06-01 2018-09-01 IND 40 12,750 29619694984b 649078e2 00 FEMALE 1958-02-17 380.00 4 2018-03-23 2018-07-09 IND 10 12,000 b850c90a4d06 0a027908 00 MALE 1997-10-16 511.52 12 2019-06-28 2020-06-12 IND 35 11,500 7aa77bfdab46 240668fa 00 MALE 1995-10-08 257.34 2 2020-07-19 2020-12-31 IND 45 12,500 c4180f22d5da 6cd68e9b 00 MALE 1948-07-22 488.00 12 2020-08-21 2020-12-06 COL 125 7,250 9e79fe640d95 25f958ed 00 FEMALE 1986-09-03 308.64 4 2018-01-26 2019-01-25 COL 10 10,750 8aadc2a7da8d 4ba33a92 00 MALE 1993-04-25 506.52 12 2017-12-02 2019-08-31 IND 30 11,500 589daf9bf1bf 4d8b85e4 00 FEMALE 1994-07-11 303.64 4 2018-01-16 2019-01-15 COL 40 10,500 a0cf5868bc94 018fb85e 00 MALE 1985-09-04 375.00 4 2018-02-05 2018-12-05 IND 10 12,000 d9d28e8d34fb dcb4b1bc 00 FEMALE 1959-12-16 471.48 12 2018-01-16 2021-01-15 IND 10 11,000 09c8b587704f 7b71aa2d 00 FEMALE 1986-07-14 483.36 12 2020-08-14 2021-01-20 IND 15 12,250 6176e05fe37b 523a8184 00 FEMALE 1995-08-10 413.40 12 2018-01-01 2018-01-27 COL 95 31,250 6388f55c3c45 ea8f037d 00 FEMALE 1990-10-21 365.00 4 2018-02-04 2018-05-31 IND 10 11,500 1ff3d4d756a1 2a976767 00 MALE 1984-07-29 5.00 12 2020-09-06 2020-11-15 IND 30 13,500 2b27dfa98ba6 84da3253 00 FEMALE 1988-07-09 283.64 4 2018-01-03 2018-11-30 COL 25 8,750 46cc071482dd 130b1e7a 00 FEMALE 1983-07-29 313.64 4 2018-02-20 2019-02-19 COL 35 12,500 9a89aa056623 54aa73f3 00 MALE 1981-08-15 385.00 4 2018-03-28 2018-06-22 IND 10 12,250 449a436377b5 17b1e8e4 00 MALE 1958-11-14 385.00 4 2018-03-21 2018-06-12 IND 20 12,750 e494721f0afa 869c2e94 00 FEMALE 1964-11-21 385.00 4 2018-01-10 2018-05-01 IND 15 13,500 39cb15e7a25d b8ad4dd7 00 FEMALE 1981-09-23 390.00 4 2018-01-14 2018-05-11 IND 15 14,000 39cb15e7a25d 273f72b2 00 FEMALE 1981-09-23 390.00 4 2018-02-18 2018-06-15 IND 15 15,000 5c80fe8e60e7 b8ad4dd7 01 MALE 2005-07-29 365.00 4 2018-02-13 2018-06-10 IND 15 14,000 5c80fe8e60e7 273f72b2 01 MALE 2005-07-29 395.00 4 2018-01-09 2018-05-06 IND 15 15,000 cbf93f00ac55 aeb21c1a 00 MALE 1983-06-10 508.72 12 2019-04-01 2020-02-24 IND 30 12,500 75e78de5a26f e008f688 00 FEMALE 1949-09-23 395.00 4 2018-01-19 2019-01-18 COL 15 9,250 cc16d0e8816c 324eaeb9 00 FEMALE 1994-10-01 380.00 4 2018-03-23 2018-07-10 IND 35 12,000 edbb83c8aa9f 0558c926 00 FEMALE 1990-12-24 473.36 4 2020-07-13 2020-09-29 IND 15 12,500 b92af59ae515 8676499c 00 MALE 1966-08-10 365.00 4 2018-01-24 2018-05-16 IND 10 14,250 c39186b1d549 b368e14f 00 FEMALE 1985-04-16 1,378.56 12 2018-02-12 2019-10-25 IND 35 11,000 c39186b1d549 74de8928 00 FEMALE 1985-04-16 1,388.56 12 2017-12-29 2019-09-10 IND 20 11,750 1ca7db363470 b368e14f 01 MALE 2000-02-16 1,388.56 12 2018-01-08 2019-09-20 IND 35 11,000 1ca7db363470 74de8928 01 MALE 2000-02-16 1,383.56 12 2018-01-18 2019-09-30 IND 20 11,750 d3a9824e37b6 b368e14f 02 MALE 2004-10-21 1,383.56 12 2018-01-08 2019-09-20 IND 35 11,000 d3a9824e37b6 74de8928 02 MALE 2004-10-21 1,383.56 12 2018-02-17 2019-10-30 IND 20 11,750 fe69c198ed23 8f8053c6 00 FEMALE 1999-11-05 375.00 4 2018-03-12 2018-06-25 IND 35 11,500 f180a3ea9688 1cc3231c 00 MALE 1977-12-22 375.00 4 2018-02-09 2018-04-25 IND 15 12,500 b1f8122f2ea3 1fb06788 00 FEMALE 1999-08-10 365.00 4 2018-02-21 2018-05-13 IND 20 13,500 78005b4c20e9 aa9e9594 00 FEMALE 1977-12-05 498.00 12 2020-12-21 2021-01-20 COL 135 8,250 ff5a958336b6 811602f2 00 FEMALE 1982-10-26 380.00 4 2018-03-11 2018-05-25 IND 30 14,500 5675d23f83b5 a1a6326a 00 FEMALE 1998-11-10 375.00 4 2018-05-10 2018-08-09 IND 35 13,500 10f3205488e5 cb229bc7 00 FEMALE 1979-08-28 370.00 4 2018-02-27 2018-11-10 IND 10 14,500 1258d7b772e6 e0f43a45 00 MALE 1969-06-06 308.64 4 2017-12-29 2018-12-28 COL 25 11,250 423bdb231a76 3ffc5baf 00 MALE 1963-03-13 385.00 4 2018-05-11 2018-08-24 IND 20 13,000 be5aa3957223 65caa424 00 FEMALE 1986-08-25 572.24 4 2018-01-02 2019-01-01 COL 15 9,750 ed1e16b4b2c4 65caa424 01 MALE 2009-05-20 572.24 4 2018-01-07 2019-01-06 COL 15 9,750 7f5ee69f4d1a 2839d1d4 00 MALE 1969-09-24 303.64 4 2018-02-13 2019-02-12 COL 20 11,750 1915ac4b5ced f5e1ced7 00 FEMALE 1987-06-30 390.00 4 2018-03-19 2018-06-02 IND 40 11,750 79bc06f22fbf 9842008e 00 MALE 1983-07-02 385.00 4 2018-01-30 2018-04-15 IND 15 11,500 7b65fa4290bb 48635a85 00 FEMALE 1934-04-24 313.64 4 2018-01-24 2019-01-23 COL 20 11,500 10a44f5df469 e3a2813f 00 MALE 1988-03-16 10.00 12 2020-09-16 2020-11-25 IND 40 13,000 ae73a89f8d66 af36b5aa 00 FEMALE 1989-07-03 390.00 4 2018-03-03 2018-05-23 IND 40 14,250 a54dc5240f4a 7df595c0 00 FEMALE 1998-05-06 277.48 2 2019-09-29 2020-12-16 IND 25 11,750 86d646217c47 7f9dabda 00 FEMALE 1990-12-28 277.34 2 2020-05-14 2020-12-11 IND 25 9,000 e8b1c4afcad1 95016988 00 FEMALE 1993-06-12 449.16 12 2018-01-31 2019-03-04 COL 65 32,250 cead062d811b 0de2802c 00 FEMALE 1969-10-23 478.00 12 2020-12-05 2021-01-20 COL 110 10,750 Los reclamos se detallan en la tabla a continuación. En la información no se dispone del valor original del reclamo, sino tan solo del valor pagado, después de aplicar la función deducible \\(D\\). En la misma información se incluye el deducible \\(d\\) y el monto de máximo de cobertura \\(M\\) que se utilizó para aplicar la deducción. Code claims[ 1:100 ] %&gt;% kable( label = NA, caption = &#39;Reclamos&#39;, row.names = FALSE, align = &#39;lllllrrrll&#39;, digits = c( 0, 0, 0, 0, 0, 0, 2, 0, 0, 0 ), format.args = list( big.mark = &#39;,&#39;, decimal.mark = &#39;.&#39;, scientific = FALSE ), escape = FALSE, centering = TRUE ) %&gt;% kable_classic( font_size = 14, full_width = FALSE, html_font = &quot;Cambria&quot;, position = &quot;center&quot; ) %&gt;% scroll_box( width = &quot;100%&quot;, height = &quot;500px&quot; ) Tabla 6.2: Reclamos policy id idc type service cdate claim icd deductible amount insured bdate sex start end 708ee54e f1b316dbca9c f3481be7c3be56 IND AMB 2018-04-08 27.95 M545 35 12,250 00 1998-11-30 MALE 2018-02-22 2018-06-05 708ee54e f1b316dbca9c aea75b4dbe7d32 IND AMB 2018-04-06 35.45 M545 35 12,250 00 1998-11-30 MALE 2018-02-22 2018-06-05 708ee54e f1b316dbca9c 427923d6709ea8 IND AMB 2018-04-06 96.06 I10 35 12,250 00 1998-11-30 MALE 2018-02-22 2018-06-05 708ee54e f1b316dbca9c 46406cc78413ac IND AMB 2018-04-07 71.06 I10 35 12,250 00 1998-11-30 MALE 2018-02-22 2018-06-05 708ee54e f1b316dbca9c dc95b57f0c4c93 IND AMB 2018-04-05 93.56 I10 35 12,250 00 1998-11-30 MALE 2018-02-22 2018-06-05 66d6f1d0 59e63ffc9688 191c26c896d6f8 COL AMB 2018-02-25 55.00 R10 25 9,250 00 1973-07-28 FEMALE 2017-12-18 2018-12-17 66d6f1d0 59e63ffc9688 08a64b4465231f COL AMB 2018-02-25 52.50 R10 25 9,250 00 1973-07-28 FEMALE 2017-12-18 2018-12-17 66d6f1d0 59e63ffc9688 28e2eb59a7cf35 COL AMB 2018-02-23 42.00 R10 25 9,250 00 1973-07-28 FEMALE 2017-12-18 2018-12-17 6d64a583 d28db8f7c754 c0aa9870615af5 IND AMB 2018-08-31 37.50 H57 30 12,750 00 1979-02-14 MALE 2018-01-11 2021-01-10 6d64a583 d28db8f7c754 afc1e924e9c9b5 IND AMB 2018-09-02 55.00 H10 30 12,750 00 1979-02-14 MALE 2018-01-11 2021-01-10 6d64a583 d28db8f7c754 71daf236711c0b IND AMB 2018-09-04 55.00 H10 30 12,750 00 1979-02-14 MALE 2018-01-11 2021-01-10 e735ef11 08cf0c0c7a47 5679bb14741d5e IND AMB 2018-06-20 24.20 R10 15 13,750 00 1972-09-28 FEMALE 2018-01-11 2018-08-31 e735ef11 08cf0c0c7a47 6689badac3e275 IND AMB 2018-06-19 41.70 R10 15 13,750 00 1972-09-28 FEMALE 2018-01-11 2018-08-31 e735ef11 08cf0c0c7a47 564bbd95004a1d IND AMB 2018-06-19 44.20 R10 15 13,750 00 1972-09-28 FEMALE 2018-01-11 2018-08-31 e735ef11 08cf0c0c7a47 f77878fdb7844b IND AMB 2018-06-20 44.20 R10 15 13,750 00 1972-09-28 FEMALE 2018-01-11 2018-08-31 e735ef11 08cf0c0c7a47 1dc614dfe14a2f IND AMB 2018-06-20 26.70 R10 15 13,750 00 1972-09-28 FEMALE 2018-01-11 2018-08-31 16831eac 9553a3b1b709 30a17effcd58dd IND AMB 2018-08-29 130.00 M771 15 11,500 00 1981-05-09 FEMALE 2018-01-11 2019-02-18 16831eac 9553a3b1b709 9b14eda24ccbeb IND AMB 2018-08-30 107.50 M771 15 11,500 00 1981-05-09 FEMALE 2018-01-11 2019-02-18 16831eac 9553a3b1b709 378b664e9d9b09 IND AMB 2018-08-29 117.50 M771 15 11,500 00 1981-05-09 FEMALE 2018-01-11 2019-02-18 16831eac 9553a3b1b709 99e05038bc7803 IND AMB 2018-08-31 110.00 M771 15 11,500 00 1981-05-09 FEMALE 2018-01-11 2019-02-18 16831eac 9553a3b1b709 9c6b27cfd452dc IND AMB 2018-08-28 132.50 M771 15 11,500 00 1981-05-09 FEMALE 2018-01-11 2019-02-18 4bd9d436 670a52e9abcc 20a5f24095e89d IND AMB 2018-01-11 42.96 B82 30 11,750 00 1989-07-31 FEMALE 2017-12-07 2018-03-08 4bd9d436 670a52e9abcc 83d2e944888da2 IND AMB 2018-01-12 42.50 Z51 30 11,750 00 1989-07-31 FEMALE 2017-12-07 2018-03-08 dcb4b1bc d9d28e8d34fb ef9c7067f5430e IND AMB 2018-09-05 37.00 J02 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb 3eaf6e5b6e4024 IND AMB 2019-02-23 27.00 N39 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb 1fe23d46a6d212 IND AMB 2019-02-21 26.60 N72 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb 4f6377fbd6744c IND AMB 2019-02-25 24.10 N72 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb 21dca6e62bc9a0 IND AMB 2018-09-07 49.50 J02 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb 6f00709917b7df IND AMB 2018-09-05 47.83 E78 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb e59f55a60a4f07 IND AMB 2018-09-07 42.83 E78 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb 5b2d8d2caade31 IND AMB 2018-09-08 55.33 E78 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb 7f0ccbee657c28 IND AMB 2018-09-04 29.50 J02 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb be72d3d73ae2a3 IND AMB 2019-08-20 27.00 J00 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb 25985fc3a73922 IND AMB 2019-02-23 39.50 N39 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb 0ac201f503c61a IND AMB 2018-09-06 34.50 J01 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb efe4f32160d484 IND AMB 2019-02-23 22.00 N39 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb fab55453d82f47 IND AMB 2019-08-20 52.00 J00 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb 2c05f278c08864 IND AMB 2018-09-05 59.15 M192 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb 9738acaea2460d IND AMB 2019-08-20 52.00 J00 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb de54f494887634 IND AMB 2018-09-07 37.00 J02 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb ba5745a71249ef IND AMB 2019-08-24 32.00 NA 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb f76b305a579e4a IND AMB 2019-08-23 32.00 NA 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb 65be8706aab79c IND AMB 2018-09-05 30.33 E78 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb e9ad79cc02a0b9 IND AMB 2019-02-24 16.60 N72 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb fddb27b1d408c6 IND AMB 2018-09-07 54.50 J01 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb 54f3c49544c7d0 IND AMB 2019-08-22 24.50 NA 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb db3f6a0c9903af IND AMB 2018-09-06 52.00 J02 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb 41d1687ce491da IND AMB 2018-09-06 29.50 J02 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb d42a8971140bd0 IND AMB 2019-02-24 47.00 J00 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb 181f64e0937f4c IND AMB 2019-02-25 31.98 N72 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb 0a5ba74b1d7c77 IND AMB 2018-09-05 27.00 J02 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb e17251d6a61237 IND AMB 2019-02-23 42.00 N39 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb 7d369199291100 IND AMB 2019-02-23 30.00 H57 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb 05a20357c1f688 IND AMB 2019-02-25 42.00 N39 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb f3ed0160ba2c9a IND AMB 2018-09-03 49.50 J02 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb 6eff07d2980b84 IND AMB 2018-09-06 45.33 E78 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 dcb4b1bc d9d28e8d34fb cafadeffeed86a IND AMB 2018-09-04 31.65 M192 10 11,000 00 1959-12-16 FEMALE 2018-01-16 2021-01-15 130b1e7a 46cc071482dd 64cc8bc759b579 COL AMB 2018-04-04 24.50 N72 35 12,500 00 1983-07-29 FEMALE 2018-02-20 2019-02-19 0558c926 edbb83c8aa9f d803bfbb89229b IND AMB 2020-08-19 29.24 H10 15 12,500 00 1990-12-24 FEMALE 2020-07-13 2020-09-29 0558c926 edbb83c8aa9f a1f257b5600f86 IND AMB 2020-08-16 26.74 H10 15 12,500 00 1990-12-24 FEMALE 2020-07-13 2020-09-29 2839d1d4 7f5ee69f4d1a 22eac3559a6be4 COL AMB 2018-03-05 25.00 R072 20 11,750 00 1969-09-24 MALE 2018-02-13 2019-02-12 2839d1d4 7f5ee69f4d1a b129ac49a5134e COL AMB 2018-03-04 15.00 Z51 20 11,750 00 1969-09-24 MALE 2018-02-13 2019-02-12 2839d1d4 7f5ee69f4d1a 73dc2532b3297e COL AMB 2018-03-10 35.00 Z51 20 11,750 00 1969-09-24 MALE 2018-02-13 2019-02-12 2839d1d4 7f5ee69f4d1a a48bb0d16fe6c2 COL AMB 2018-02-28 45.00 Z51 20 11,750 00 1969-09-24 MALE 2018-02-13 2019-02-12 2839d1d4 7f5ee69f4d1a 0490a5a5429654 COL AMB 2018-03-04 42.50 R072 20 11,750 00 1969-09-24 MALE 2018-02-13 2019-02-12 2839d1d4 7f5ee69f4d1a c4c6c67f1fe421 COL AMB 2018-03-04 20.00 Z51 20 11,750 00 1969-09-24 MALE 2018-02-13 2019-02-12 2839d1d4 7f5ee69f4d1a 9bab6a1a787155 COL AMB 2018-03-04 35.00 Z51 20 11,750 00 1969-09-24 MALE 2018-02-13 2019-02-12 2839d1d4 7f5ee69f4d1a 32204581f9760e COL AMB 2018-03-04 35.00 Z51 20 11,750 00 1969-09-24 MALE 2018-02-13 2019-02-12 2839d1d4 7f5ee69f4d1a 62f9e2820793d3 COL AMB 2018-03-09 32.50 Z51 20 11,750 00 1969-09-24 MALE 2018-02-13 2019-02-12 2839d1d4 7f5ee69f4d1a c326079c1ddedb COL AMB 2018-03-01 45.00 Z51 20 11,750 00 1969-09-24 MALE 2018-02-13 2019-02-12 2839d1d4 7f5ee69f4d1a 5f4be74810ca11 COL AMB 2018-03-08 47.50 I49 20 11,750 00 1969-09-24 MALE 2018-02-13 2019-02-12 36f08160 3218a791a9f2 4b1eae9a528d2f COL AMB 2020-12-19 50.00 NA 165 13,000 01 1946-09-08 FEMALE 2020-10-27 2020-12-26 88e5aef5 3218a791a9f2 4b1eae9a528d2f COL AMB 2020-12-19 42.50 NA 160 15,750 01 1946-09-08 FEMALE 2020-11-26 2021-01-25 36f08160 3218a791a9f2 9849c2750ba44c COL AMB 2020-12-18 50.00 NA 165 13,000 01 1946-09-08 FEMALE 2020-10-27 2020-12-26 88e5aef5 3218a791a9f2 9849c2750ba44c COL AMB 2020-12-17 40.00 NA 160 15,750 01 1946-09-08 FEMALE 2020-11-26 2021-01-25 36f08160 3218a791a9f2 1d53b315198601 COL AMB 2020-12-20 37.50 NA 165 13,000 01 1946-09-08 FEMALE 2020-10-27 2020-12-26 88e5aef5 3218a791a9f2 1d53b315198601 COL AMB 2020-12-19 37.50 NA 160 15,750 01 1946-09-08 FEMALE 2020-11-26 2021-01-25 ab397f28 aadfb8df7e08 a52233e7a9a28a COL HOS 2020-05-20 1,612.50 K35 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 ab397f28 aadfb8df7e08 68a840f412d167 COL AMB 2018-11-29 17.00 M54 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 ab397f28 aadfb8df7e08 cc3fa189863aac COL AMB 2018-12-08 29.50 M54 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 ab397f28 aadfb8df7e08 2828bcc4f87fac COL AMB 2019-07-24 44.50 M25 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 ab397f28 aadfb8df7e08 463add619bde85 COL AMB 2019-08-14 29.50 NA 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 ab397f28 aadfb8df7e08 2c4c55d8ff13ff COL AMB 2018-10-01 49.50 J02 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 ab397f28 aadfb8df7e08 c8abab11e79c39 COL HOS 2020-05-19 1,612.50 K35 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 ab397f28 aadfb8df7e08 765b0dce14eeb8 COL AMB 2018-02-27 20.00 J00 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 ab397f28 aadfb8df7e08 9cc70c75f0bcab COL AMB 2020-07-24 49.50 M54 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 ab397f28 aadfb8df7e08 f23b67ced06a6a COL AMB 2018-09-30 29.50 J02 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 ab397f28 aadfb8df7e08 aff43e60049a42 COL AMB 2019-01-05 37.00 J00 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 ab397f28 aadfb8df7e08 cdd87756944455 COL AMB 2020-07-25 62.00 M54 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 ab397f28 aadfb8df7e08 b2042a36dc6d6b COL AMB 2018-04-19 11.90 N32 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 ab397f28 aadfb8df7e08 5eaa4a1eaa64f7 COL AMB 2020-07-22 54.50 M54 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 ab397f28 aadfb8df7e08 b06b871209e784 COL AMB 2019-08-25 80.00 M94 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 ab397f28 aadfb8df7e08 89e11844bae3c8 COL AMB 2018-11-29 17.00 M54 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 ab397f28 aadfb8df7e08 d547e7f9f51791 COL AMB 2019-03-04 29.50 J00 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 ab397f28 aadfb8df7e08 d12ad87146d39f COL AMB 2018-05-27 52.00 Z51 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 ab397f28 aadfb8df7e08 b7b3541967ea41 COL AMB 2020-07-27 60.50 M54 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 ab397f28 aadfb8df7e08 778b6898b528ba COL AMB 2018-02-27 28.92 G44 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 ab397f28 aadfb8df7e08 72344eb8af3e69 COL AMB 2018-05-26 37.00 Z51 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 ab397f28 aadfb8df7e08 2739a30c7ee5cb COL AMB 2019-05-28 32.00 J00 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 ab397f28 aadfb8df7e08 4330186330bba3 COL AMB 2018-02-24 31.42 G44 15 16,250 00 1952-01-31 FEMALE 2018-01-31 2021-01-30 Primero definimos algunos parámetros que consideramos serán útiles en el desarrollo del ejemplo. Lo primero es definir las fechas que marcan el periodo para el cual estamos interesados en estudiar, con ello seleccionamos la periodicidad con la cual vamos a medir la frecuencia de los reclamos, en este caso de forma anual year. También, seleccionamos de antemano unas edades para formar grupos de riesgo por edad. Code idate &lt;- ymd( &#39;2018-01-01&#39; ) edate &lt;- ymd( &#39;2021-01-01&#39; ) sdate &lt;- seq( idate, edate, by = &#39;year&#39; ) dates &lt;- data.table( di = sdate[ -length( sdate ) ], de = sdate[ -1 ] ) dates[ , tid := 1 ] xgs &lt;- c( 0, 20, 40, 60, Inf ) Para generar un modelo de pérdida, asumiremos que la frecuencia de los siniestros \\(N\\) es independiente de los reclamos \\(\\{X_i\\}\\). Con ellos estaremos en la capacidad de formular un modelo colectivo de riesgo. Ahora tratamos la información correspondiente a la producción de las pólizas, en particular extrayendo las pólizas que intersectan con los periodo de observación y creando los grupos de edades xg. Code production[ , tid := 1 ] prod_prep &lt;- merge.data.table( dates, production, by = &#39;tid&#39;, all.x = TRUE, allow.cartesian = TRUE ) prod_prep[ , tid := NULL ] prod_prep &lt;- prod_prep[ start &lt; de &amp; end &gt;= di ] prod_prep[ , fi := pmax( start, di ) ] prod_prep[ , fe := pmin( end, de ) ] prod_prep[ , fm := fi + ( fe - fi ) / 2 ] prod_prep[ , x := pmax( round( interval( bdate, fm ) / dyears( 1 ), 0 ), 0 ) ] prod_prep[ , xg := cut( x = x, breaks = xgs, include.lowest = TRUE, ordered_result = TRUE, right = FALSE ) ] noclaims_prep &lt;- unique( prod_prep[ , list( policy, id, sex, xg, bdate, di, de, N = 0, S = 0 ) ] ) noclaims_prep &lt;- noclaims_prep[ , list( policy, id, sex, xg, bdate, di, de, N, S ) ] Así mismo, trabajamos con la información correspondiente a los reclamos. Primeramente los agregados por código único de siniestro idc, fecha de siniestro cdate y periodo de observación di a de, esto para agrupar los reclamos que corresponden a un solo siniestros por periodo. Luego, filtramos los siniestros que solo se presentan en el periodo de observación. También, se cuenta cuantos siniestros presenta cada asegurado según por su código único de identificación id y también la póliza a la que pertenecen policy. Finalmente, se hace una estadística de frecuencia por cada grupo de riesgo dados por el sexo sex y el grupo de edad xg. En particular se calcula el indicador para la familia de Panjer, esto con la finalidad de caracterizar el tipo de distribución que determina la frecuencia de los reclamos. Code claims_prep &lt;- claims[ , list( DX = sum( claim ) ), by = list( policy, id, idc, type, sex, bdate, cdate ) ] claims_prep[ , x := round( interval( bdate, cdate ) / dyears( 1 ), 0 ) ] claims_prep[ , xg := cut( x = x, breaks = xgs, include.lowest = TRUE, ordered_result = TRUE, right = FALSE ) ] claims_prep[ , tid := 1 ] claims_prep &lt;- merge.data.table( dates, claims_prep, by = c( &#39;tid&#39; ), all.x = TRUE, allow.cartesian = TRUE ) claims_prep[ , tid := NULL ] claims_prep &lt;- claims_prep[ cdate &gt;= di &amp; cdate &lt; de ] claims_prep &lt;- claims_prep[ , list( N = .N, S = sum( DX ) ), by = list( policy, id, sex, xg, bdate, di, de ) ] claims_prep &lt;- rbind( claims_prep, noclaims_prep ) claims_prep &lt;- claims_prep[ , list( N = sum( N ), S = sum( S ) ), by = list( policy, id, sex, xg, bdate, di, de ) ] count &lt;- copy( claims_prep ) count &lt;- count[ , list( fn = .N, S = sum( S ) ), by = list( sex, xg, N ) ] expand &lt;- count[ , list( N = max( N ) ), by = list( sex, xg ) ] expand &lt;- expand[ , list( N = seq( 0, N, 1 ) ), by = list( sex, xg ) ] count &lt;- merge.data.table( expand, count, by = c( &#39;sex&#39;, &#39;xg&#39;, &#39;N&#39; ), all.x = TRUE ) count[ is.na( fn ), fn := 0 ] count[ is.na( S ), S := 0 ] setorder( count, sex, xg, N ) count[ , pn := fn / sum( fn ), by = list( sex, xg ) ] count[ , vn := shift( pn, fill = 0 ), by = list( sex, xg ) ] count[ vn != 0, vn := N * pn / vn ] count[ vn == 0, vn := 0 ] grpcl &lt;- unique( count[ , list( sex, xg ) ] ) grpcl[ , grp := paste0( sex, &#39; &#39;, xg ) ] setorder( grpcl, sex, xg ) count[ , grp := factor( paste0( sex, &#39; &#39;, xg ), labels = grpcl$grp, ordered = TRUE ) ] claims_prep[ , grp := factor( paste0( sex, &#39; &#39;, xg ), labels = grpcl$grp, ordered = TRUE ) ] Los grupos de riesgo, que designaremos con un índice \\(g\\), los hemos seleccionado para estudiar la frecuencia y severidad de los reclamos, estos son los siguientes: Code grpcl %&gt;% kable( label = NA, caption = &#39;Grupos de clasificación del riesgo&#39;, row.names = FALSE, col.names = c( &#39;sex&#39;, &#39;$x_g$&#39;, &#39;grupo&#39; ), align = &#39;lll&#39;, digits = c( 0, 0, 0 ), format.args = list( big.mark = &#39;,&#39;, decimal.mark = &#39;.&#39;, scientific = FALSE ), escape = FALSE, centering = TRUE ) %&gt;% kable_classic( font_size = 14, full_width = FALSE, html_font = &quot;Cambria&quot;, position = &quot;center&quot; ) %&gt;% scroll_box( width = &quot;100%&quot;, height = &quot;500px&quot; ) Tabla 6.3: Grupos de clasificación del riesgo sex \\(x_g\\) grupo FEMALE [0,20) FEMALE [0,20) FEMALE [20,40) FEMALE [20,40) FEMALE [40,60) FEMALE [40,60) FEMALE [60,Inf] FEMALE [60,Inf] MALE [0,20) MALE [0,20) MALE [20,40) MALE [20,40) MALE [40,60) MALE [40,60) MALE [60,Inf] MALE [60,Inf] El gráfico a continuación muestra el comportamiento del indicador \\(v_n = n \\frac{p_n}{p_{n-1}}\\), para cada uno de los grupos \\(g\\) de riesgo. Code plt &lt;- ggplot( ) + geom_point( data = count, aes( x = N, y = vn ), colour = &#39;red3&#39;, size = 0.5 ) + facet_wrap( vars( grp ), ncol = 4 ) + xlab( TeX( &quot;$n$&quot; ) ) + ylab( TeX( &quot;$v_n$&quot; ) ) + theme_bw() + theme( legend.position = &quot;none&quot; ) plot( plt ) Como hemos evidenciado, para todos los casos en consideración el indicador \\(v_n\\) tiene un tendencia creciente y se evidencia un crecimiento con orden lineal, esto sugiere que la distribución discreta más adecuada para explicar la frecuencia de los reclamos para cada grupo es una binomial negativa \\(N \\rightsquigarrow NBin( \\alpha, p )\\). Para la estimación por maximización de verosimilitud, hacemos uso de la función fitdist con la cual estimaremos los parámetros dentro de una familia de distribuciones binomiales negativas. Por su parte, la función de verosimilitud logarítmica para la frecuencia tiene la siguiente forma para cada grupo \\(g\\). \\[ \\begin{eqnarray*} \\ell_g( \\alpha, p ) &amp; = &amp; \\sum\\limits_{i=1}^{n_g} \\left\\{ \\log\\left( \\Gamma( \\alpha + N_i ) \\right) - \\log\\left( \\Gamma(N_i + 1) \\right) - \\log\\left( \\Gamma(\\alpha) \\right) + \\alpha \\log(p) + N_i \\log( 1 - p ) \\right\\} \\\\ &amp; = &amp; \\sum\\limits_{i=1}^{n_g} \\left\\{ \\log\\left( \\Gamma( \\alpha + N_i ) \\right) - \\log\\left( \\Gamma(N_i + 1) \\right) \\right\\} - n_g \\log\\left( \\Gamma(\\alpha) \\right) + n_g \\alpha \\log(p) + n \\log( 1 - p ) \\end{eqnarray*} \\] Como ya lo mencionamos, para cada grupo \\(g\\) podemos maximizar la verosimilitud logarítmica de la frecuencia utilizando la función fitdist del paquete fitdistrplus. Code fit_count &lt;- list() estim_frec &lt;- NULL for ( g in grpcl$grp ) { fit_count[[ g ]] &lt;- fitdistrplus::fitdist( claims_prep[ grp == g ]$N, distr = dnbinom, method = &#39;mle&#39;, keepdata = TRUE, discrete = TRUE ) estim_frec &lt;- rbind( estim_frec, data.table( grp = g, a = fit_count[[ g ]]$estimate[1], EN = fit_count[[ g ]]$estimate[2], loglik = fit_count[[ g ]]$loglik, aic = fit_count[[ g ]]$aic, bic = fit_count[[ g ]]$bic ) ) } estim_frec[ , p := a / ( a + EN ) ] estim_frec[ , SDN := sqrt( a * ( 1 - p ) / p^2 ) ] estim_frec &lt;- estim_frec[ , list( grp, a, p, EN, SDN, loglik, aic, bic )] En la lista que hemos creado fit_count hemos almacenado cada una de los objetos con las estimaciones de la frecuencia para cada uno de los grupos. A continuación, presentamos los resultados de la estimación para la frecuencia. Code estim_frec %&gt;% kable( label = NA, caption = &#39;Estimación de frecuencia&#39;, row.names = FALSE, col.names = c( &#39;$g$&#39;, &#39;$\\\\alpha$&#39;, &#39;$p$&#39;, &#39;$\\\\E[ N ]$&#39;, &#39;$\\\\sqrt{\\\\V[ N ]}$&#39;, &#39;$\\\\ell( n, p )$&#39;, &#39;$AIC$&#39;, &#39;$BIC$&#39; ), align = &#39;lrrrrrrr&#39;, digits = c( 0, 5, 5, 5, 5, 5, 2, 2 ), format.args = list( big.mark = &#39;,&#39;, decimal.mark = &#39;.&#39;, scientific = FALSE ), escape = FALSE, centering = TRUE ) %&gt;% kable_classic( font_size = 14, full_width = FALSE, html_font = &quot;Cambria&quot;, position = &quot;center&quot; ) %&gt;% scroll_box( width = &quot;100%&quot;, height = &quot;500px&quot; ) Tabla 6.4: Estimación de frecuencia \\(g\\) \\(\\alpha\\) \\(p\\) \\(\\mathbb{E}[ N ]\\) \\(\\sqrt{\\mathbb{V}[ N ]}\\) \\(\\ell( n, p )\\) \\(AIC\\) \\(BIC\\) FEMALE [0,20) 0.07114 0.02922 2.36335 8.99292 -1,159.649 2,323.30 2,332.90 FEMALE [20,40) 0.06690 0.01515 4.34957 16.94494 -2,497.060 4,998.12 5,008.94 FEMALE [40,60) 0.13472 0.01344 9.88593 27.11744 -3,159.785 6,323.57 6,333.88 FEMALE [60,Inf] 0.16226 0.01003 16.01106 39.94829 -1,918.017 3,840.03 3,848.98 MALE [0,20) 0.06076 0.02672 2.21317 9.10109 -1,250.564 2,505.13 2,515.06 MALE [20,40) 0.05065 0.02508 1.96877 8.86002 -1,294.692 2,593.38 2,603.65 MALE [40,60) 0.10530 0.01725 5.99728 18.64330 -2,163.142 4,330.28 4,340.30 MALE [60,Inf] 0.17932 0.01091 16.26105 38.61118 -1,568.422 3,140.84 3,149.33 Ahora, nos enfocamos en estudiar la severidad de los reclamos. Desde un inicio sabemos que los valores de los reclamos ya vienen censurados, a causa de la aplicación de la función deducible \\(D\\), como consecuencia tenemos pérdida de información que no podemos recuperar, por tal razón es de esperar que la función de distribución acumulada de los reclamos deducidos \\(D(X)\\) tenga singularidades. Si buscamos utilizar el método de máxima verosimilitud para la estimación de la mejor distribución, debemos hacer uso de la expresión completa que presentamos en (5.1). Code sev_claims &lt;- claims[ , list( policy, id, idc, type, sex, bdate, cdate, deductible, amount, claim ) ] sev_claims[ , x := round( interval( bdate, cdate ) / dyears( 1 ), 0 ) ] sev_claims[ , xg := cut( x = x, breaks = xgs, include.lowest = TRUE, ordered_result = TRUE, right = FALSE ) ] sev_claims[ , tid := 1 ] sev_claims &lt;- merge.data.table( dates, sev_claims, by = c( &#39;tid&#39; ), all.x = TRUE, allow.cartesian = TRUE ) sev_claims &lt;- sev_claims[ cdate &gt;= di &amp; cdate &lt; de ] sev_claims[ , tid := NULL ] sev_claims[ , grp := factor( paste0( sex, &#39; &#39;, xg ), labels = grpcl$grp, ordered = TRUE ) ] Los histogramas a continuación muestran como se distribuyen los reclamos ya censurados por cada grupos de riesgo. Code xlim &lt;- c( 0, 1e3 ) xbrk &lt;- seq( xlim[1], xlim[2], length = 5 ) xlbl &lt;- xbrk bins &lt;- sev_claims[ , list( bins = nclass.scott( claim ) ), by = list( grp ) ] plt &lt;- ggplot( ) + geom_histogram( data = sev_claims, aes( claim, after_stat( density ) ), fill = &#39;dodgerblue3&#39;, colour = &#39;dodgerblue4&#39;, alpha = 0.3, bins = min( bins$bins ) ) + facet_wrap( vars( grp ), scale = &#39;free_x&#39;, ncol = 4 ) + scale_x_continuous( breaks = xbrk, labels = xlbl, limits = xlim, expand = c( 0, 0 ) ) + xlab( TeX( &quot;$D(X)$&quot; ) ) + ylab( TeX( &quot;$f_{D(X)}$&quot; ) ) + theme_bw() + theme( legend.position = &quot;none&quot; ) plot( plt ) Por no incrementar la complejidad del ejemplo, asumiremos que los reclamos \\(X\\) por cada grupo de riesgo son i.i.d. y estos siguen como distribución alguna presente en la familia log-normal, es decir \\(X \\rightsquigarrow LN( \\mu, \\sigma )\\). Además, es de notar que el razonamiento es válido para cualquier otra distribución. Más aún, sabemos que para cada reclamo \\(i\\)-ésimo se aplicó un deducible \\(d_i\\) y un monto máximo asegurado \\(M_i\\) determinado por la cobertura de la póliza y estos valores a su vez determinan el deducible \\(D_i\\), la distribución de probabilidad para los valores aleatorios ya deducidos \\(Z = D_i(X)\\), según lo ya estudiado en 6.6, tiene la forma: \\[ F( z ) = \\mathbf{1}_{[0,M_i)}( z ) F_X( z + d_i ) + \\mathbf{1}_{[M_i,+\\infty)}( z ) \\] Entonces, tomando en cuenta la forma general que hemos desarrollado en (5.1) y la forma anterior para la distribución acumulada de probabilidad, podemos determinar una expresión más precisa para la función de verosimilitud logarítmica, donde debemos tomar en cuenta las singularidades que producen los deducibles para cada póliza. \\[ \\begin{eqnarray*} \\ell( \\mu, \\sigma ) &amp; = &amp; \\sum\\limits_{x_i \\in \\operatorname{Dif}F} \\log \\left( f(x_i,\\mu, \\sigma) \\right) + \\sum\\limits_{x_i \\notin \\operatorname{Dif}F} \\log \\left( F\\left( x_i, \\mu, \\sigma \\right) - F\\left( x_i-, \\mu, \\sigma \\right) \\right) \\\\ &amp; = &amp; \\sum\\limits_{x_i \\notin\\{0,M_i\\}} \\log \\left( f(x_i,\\mu, \\sigma) \\right) + \\sum\\limits_{x_i \\in\\{0,M_i\\}} \\log \\left( F\\left( x_i, \\mu, \\sigma \\right) - F\\left( x_i-, \\mu, \\sigma \\right) \\right) \\\\ &amp; = &amp; \\sum\\limits_{x_i \\notin \\{0,M_i\\}} \\log \\left( \\frac{1}{x_i\\sqrt{2\\pi} \\sigma} \\exp\\left( -\\frac{(\\ln(x_i) - \\mu)^2}{\\sigma^2} \\right) \\right) + \\sum\\limits_{x_i = M_i} \\log \\left( 1 - F\\left( M_i-, \\mu, \\sigma \\right) \\right) + \\sum\\limits_{x_i = 0} \\log \\left( F\\left( 0, \\mu, \\sigma \\right) - 0 \\right) \\\\ &amp; = &amp; -\\sum\\limits_{x_i \\notin\\{0,M_i\\}} \\left\\{ \\frac{(\\ln(x_i) - \\mu)^2}{\\sigma^2} +\\log \\left( x_i \\right) +\\log \\left( \\sqrt{2\\pi} \\sigma \\right) \\right\\} + \\sum\\limits_{x_i = M_i} \\log \\left( 1 - \\frac{1}{\\sqrt{2\\pi} \\sigma} \\int\\limits_{0}^{M_i + d_i} \\frac{1}{y} \\exp\\left( -\\frac{(\\ln(y) - \\mu)^2}{\\sigma^2} \\right)\\ dy \\right) \\\\ &amp; &amp; + \\sum\\limits_{x_i = 0} \\log \\left( \\frac{1}{\\sqrt{2\\pi} \\sigma} \\int\\limits_{0}^{d_i} \\frac{1}{y} \\exp\\left( -\\frac{(\\ln(y) - \\mu)^2}{\\sigma^2} \\right)\\ dy \\right) \\\\ \\end{eqnarray*} \\] Preparamos la función de verosimilitud en R, en este caso debemos construirla explícitamente, sin la ayuda de alguna función en un paquete, esto se debe a que el deducible \\(d\\) y el monto máximo de cobertura \\(M\\) varían entre pólizas. Esta construcción debe ser realizada para cada grupo de riesgo y a su vez debemos maximizar cada una de las verosimilitudes logarítmicas, esto lo podemos realizar de forma integrada utilizando un bucle de programación for y el método usual de optimización optim. Code Fd &lt;- plnorm fd &lt;- dlnorm theta0 &lt;- c( 1, 1 ) loglik_max &lt;- list() estim_sev &lt;- NULL for ( g in grpcl$grp ) { datsev &lt;- sev_claims[ grp == g ] # Definimos la función de verosimilitud logarítmica para cada grupo lglk &lt;- function( theta ) { # suma en puntos de continuidad l &lt;- sum( sapply( datsev[ claim &gt; 0 &amp; claim &lt; amount ]$claim, FUN = function( x ) log( fd( x, meanlog = theta[ 1 ], sdlog = theta[ 2 ] ) ) ) ) # suma en las discontinuidades # singularidad en la parte superior, hacia el máximo monto sg &lt;- datsev[ claim == amount, list( x = amount + deductible ) ] sg &lt;- sg$x if ( length( sg ) &gt; 0 ) { l &lt;- l + sum( sapply( sg, FUN = function( x ) log( 1 - Fd( x, meanlog = theta[ 1 ], sdlog = theta[ 2 ] ) ) ) ) } # singularidad en la parte inferior, hacia el deducible sg &lt;- datsev[ claim == 0, list( x = deductible ) ] sg &lt;- sg$x if ( length( sg ) &gt; 0 ) { l &lt;- l + sum( sapply( sg, FUN = function( x ) log( Fd( x, meanlog = theta[ 1 ], sdlog = theta[ 2 ] ) ) ) ) } return( -l ) # con menos ya que el optimizador minimiza } dlglk &lt;- function( x ) nl.grad( x, lglk ) # Maximización de la verosimilitud loglik_max[[ g ]] &lt;- nloptr( x0 = theta0, eval_f = lglk, eval_grad_f = dlglk, lb = c( 0, 0 ), ub = c( Inf, Inf ), opts = list( maxeval = 1e4, ftol_abs = 1e-15, xtol_abs = c( 1e-12, 1e-12 ), algorithm = &#39;NLOPT_LD_LBFGS&#39; ) ) estim_sev &lt;- rbind( estim_sev, data.table( grp = g, n = nrow( datsev ), meanlog = loglik_max[[ g ]]$solution[ 1 ], sdlog = loglik_max[[ g ]]$solution[ 2 ], loglik = -loglik_max[[ g ]]$objective ) ) } estim_sev[ , EX := exp( meanlog + 0.5 * sdlog^2 ) ] estim_sev[ , SDX := sqrt( ( exp( sdlog^2 ) - 1 ) * exp( 2 * meanlog + sdlog^2 ) ) ] estim_sev[ , aic := 2 * 2 - 2 * loglik ] estim_sev[ , bic := 2 * log( n ) - 2 * loglik ] En este caso tenemos un problema donde existe convergencia para cada una de las optimizaciones por verosimilitud sin embargo, en la práctica un bucle de esta naturaleza puede implicar un costo computacional significativo en memoría y tiempo. Dependiendo de la dimensión del problema, se recomienda usar algunas técnicas que utilicen cálculo en paralelo o manejo óptimo de memoria, en algunas otras circunstancias puede ser conveniente utilizar un método de descomposición por batchs de información. Los resultados de la estimación mediante maximización de verosimilitud para la severidad de los reclamos, los presentamos en la tabla a continuación. Code estim_sev %&gt;% kable( label = NA, caption = &#39;Estimación de severidad de los reclamos&#39;, row.names = FALSE, col.names = c( &#39;$g$&#39;, &#39;$n$&#39;, &#39;$\\\\mu$&#39;, &#39;$\\\\sigma$&#39;, &#39;$\\\\ell( \\\\mu, \\\\sigma )$&#39;, &#39;$\\\\E[ X ]$&#39;, &#39;$\\\\sqrt{\\\\V[ X ]}$&#39;, &#39;$AIC$&#39;, &#39;$BIC$&#39; ), align = &#39;lrrrrrrrr&#39;, digits = c( 0, 0, 5, 5, 5, 2, 2, 2, 2 ), format.args = list( big.mark = &#39;,&#39;, decimal.mark = &#39;.&#39;, scientific = FALSE ), escape = FALSE, centering = TRUE ) %&gt;% kable_classic( font_size = 14, full_width = FALSE, html_font = &quot;Cambria&quot;, position = &quot;center&quot; ) %&gt;% scroll_box( width = &quot;100%&quot;, height = &quot;500px&quot; ) Tabla 6.5: Estimación de severidad de los reclamos \\(g\\) \\(n\\) \\(\\mu\\) \\(\\sigma\\) \\(\\ell( \\mu, \\sigma )\\) \\(\\mathbb{E}[ X ]\\) \\(\\sqrt{\\mathbb{V}[ X ]}\\) \\(AIC\\) \\(BIC\\) FEMALE [0,20) 2,127 3.80928 0.59566 -10,018.47 53.88 35.16 20,040.94 20,052.26 FEMALE [20,40) 7,197 3.81895 0.62012 -34,258.09 55.21 37.81 68,520.18 68,533.94 FEMALE [40,60) 12,676 3.85843 0.64676 -61,371.99 58.42 42.10 122,747.97 122,762.87 FEMALE [60,Inf] 10,375 3.91002 0.67717 -51,243.42 62.76 47.87 102,490.83 102,505.33 MALE [0,20) 2,343 3.81387 0.61320 -11,114.59 54.70 36.96 22,233.19 22,244.70 MALE [20,40) 2,468 3.84725 0.66988 -12,008.13 58.65 44.14 24,020.27 24,031.89 MALE [40,60) 6,614 3.89478 0.70528 -32,835.54 63.02 50.59 65,675.08 65,688.67 MALE [60,Inf] 8,372 3.92278 0.66965 -41,363.77 63.24 47.57 82,731.54 82,745.60 Sumarizando, hemos determinado para cada grupo de riesgo \\(g\\) una distribución para la variable aleatoria correspondiente al número de reclamos \\(N_g \\rightsquigarrow NBinom( \\alpha_g, p_g )\\), de igual forma hemos estimado una distribución para la severidad de los reclamos \\(X \\rightsquigarrow LN( \\mu_g, \\sigma_g )\\). Es de notar que la estimación de la variable \\(N_g\\) del número de siniestro se lo realizó por individuo y por cada periodo de observación di a de, esto nos permite estimar una frecuencia anualizada, debido a los anchos de los intervalos de observación. Pero si se considera pólizas con periodos de cobertura diferentes, hay que realizar el respectivo ajuste por la exposición al riesgo. El modelo de colectivo para este caso en particular debe tomar en cuenta el número de individuos asegurados \\(n_g\\) en el total de pólizas por cada grupo de riesgo \\(g\\). Esto bajo el supuesto que todas las pólizas de las \\(n_g\\) tiene la misma exposición al riesgo de un año, si no es el caso habrá que realizar ajustes en la variable \\(N_g\\) que cuenta el número de reclamos. \\[ S_g = \\sum\\limits_{i=1}^{n_g} \\sum\\limits_{j=1}^{N_g} D_{g,i}\\left( X_{g,i,j} \\right) \\] La perdida total que sumariza cada grupo de riesgo \\(g\\), es la dada por la expresión: \\[ S = \\sum\\limits_{g \\in G} S_g = \\sum\\limits_{g \\in G} \\sum\\limits_{i=1}^{n_g} \\sum\\limits_{j=1}^{N_g} D_{g,i}\\left( X_{g,i,j} \\right) \\] Para realizar el cálculo de los valores deducidos se puede examinar la expresión del deducible, con ello llegamos al siguiente resultado. \\[ \\begin{eqnarray*} \\mathbb{E}\\left[D(X)\\right] &amp; = &amp; \\int\\limits_0^{+\\infty} D( x ) dF( x ) \\\\ &amp; = &amp; \\int\\limits_0^{+\\infty} \\min\\left( \\max( x - d, 0 ), M \\right) dF( x ) \\\\ &amp; = &amp; \\int\\limits_d^{M+d} ( x - d ) dF( x ) + \\int\\limits_{M+d}^{+\\infty} M dF( x ) \\\\ &amp; = &amp; \\int\\limits_d^{M+d} x dF( x ) - d P\\left( d \\leq X \\leq M + d \\right) + M P\\left( X &gt; M + d \\right) \\\\ &amp; = &amp; \\int\\limits_d^{M+d} x dF( x ) - d \\left( F( M + d ) - F( d ) \\right) + M \\left( 1 - F( M + d ) \\right) \\\\ &amp; = &amp; \\int\\limits_d^{M+d} x dF( x ) + M + d\\ F( d ) - ( M + d ) F( M + d ) \\end{eqnarray*} \\] La integral a la izquierda pude ser calculada con el uso de una aproximación numérica a la integral. Por su parte, los términos asociados a la probabilidad pueden ser calculados utilizando la función de distribución acumulada de la variable aleatoria de los reclamos \\(X\\). Code estim &lt;- merge.data.table( estim_frec[ , list( grp, EN, SDN ) ], estim_sev[ , list( grp, EX, SDX, meanlog, sdlog ) ], by = &#39;grp&#39; ) Ahora configuramos un posible portafolio, el cual ya en la práctica debe considerar los objetivos comerciales para la venta de diferentes productos de seguro. Para cada grupo de riesgo \\(g\\) se puede considerar un número de póliza de un determinado producto, caracterizados por su deducible \\(d\\) y monto máximo asegurado \\(M\\). Así, para grupo de riesgo \\(g\\) y producto \\(r\\) \\[ S_{g,r} = \\sum\\limits_{i=1}^{n_{g,r}} \\sum\\limits_{j=1}^{N_g} D\\left( X_{i,j} \\right) \\] El valor esperado y varianza de cada uno de estos reclamos totales por grupo de riesgo \\(g\\) y producto \\(r\\), están dados por: \\[ \\mathbb{E}\\left[ S_{g,r} \\right] = n_{g,r} \\mathbb{E}\\left[ N_g \\right] \\mathbb{E}\\left[ D( X_g ) \\right], \\qquad \\mathbb{V}\\left[ S_{g,r} \\right] = n_{g,r} \\left( \\mathbb{E}\\left[ N_g \\right] \\mathbb{V}\\left[ D( X_g ) \\right] + \\mathbb{V}\\left[ N_g \\right] \\mathbb{E}\\left[ D( X_g ) \\right]^2 \\right), \\] El reclamo total por grupo de riesgo \\(g\\), tan solo resulta de la suma de los reclamos totales por cada producto. \\[ S_g = \\sum\\limits_{r=1}^{R} S_{g,r} \\] de igual forma su valor esperado y varianza están dados por: \\[ \\mathbb{E}\\left[ S_g \\right] = \\sum\\limits_{r=1}^R \\mathbb{E}\\left[ S_{g,r} \\right] = \\sum\\limits_{r=1}^R n_{g,r} \\mathbb{E}\\left[ N_g \\right] \\mathbb{E}\\left[ D( X_g ) \\right], \\qquad \\mathbb{V}\\left[ S_{g} \\right] = \\sum\\limits_{r=1}^R \\mathbb{V}\\left[ S_{g,r} \\right] = \\sum\\limits_{r=1}^R n_{g,r} \\left( \\mathbb{E}\\left[ N_g \\right] \\mathbb{V}\\left[ D( X_g ) \\right] + \\mathbb{V}\\left[ N_g \\right] \\mathbb{E}\\left[ D( X_g ) \\right]^2 \\right), \\] Code prods &lt;- data.table( ngr = c( 1000, 800, 600, 400, 200 ), d = c( 20, 20, 20, 20, 20 ), M = c( 2e4, 2e4, 2.5e4, 3e4, 4e4 ) ) prods[ , id := 1 ] grpcl[ , id := 1 ] prods &lt;- merge.data.table( prods, grpcl, by = &#39;id&#39;, allow.cartesian = TRUE ) grpcl[ , id := NULL ] prods[ , id := NULL ] prods &lt;- merge.data.table( prods, estim, by = &#39;grp&#39;, allow.cartesian = TRUE ) setorder( prods, sex, xg, -d ) prods[ , r := 1 ] prods[ , r := cumsum( r ), by = list( sex, xg ) ] intf &lt;- function( meanlog, sdlog, d, M, k ) integrate( function( x ) ( x - d )^k * fd( x, meanlog = meanlog, sdlog = sdlog ), lower = d, upper = M, abs.tol = 1e-15 )$value prods[ , EDX := mapply( FUN = intf, meanlog, sdlog, d, M, 1 ) + M * ( 1 - Fd( M + d ) )] prods[ , EDX2 := mapply( FUN = intf, meanlog, sdlog, d, M, 2 ) + M^2 * ( 1 - Fd( M + d ) ) ] prods[ , SDDX := sqrt( EDX2 - EDX^2 ) ] prods[ , ES := ngr * EN * EDX ] prods[ , SDS := sqrt( ngr * ( EN * SDDX^2 + SDN^2 * EDX^2 ) ) ] Code prods[ , list( sex, xg, r, ngr, d, M, EN, SDN, EX, SDX, EDX, SDDX, ES, SDS ) ] %&gt;% kable( label = NA, caption = &#39;Estimación de los reclamos totales&#39;, row.names = FALSE, col.names = c( &#39;sex&#39;, &#39;$x_g$&#39;, &#39;$r$&#39;, &#39;$n_{g,r}$&#39;, &#39;$d$&#39;, &#39;$M$&#39;, &#39;$\\\\E[ N ]$&#39;, &#39;$\\\\sqrt{\\\\V[ N ]}$&#39;, &#39;$\\\\E[ X ]$&#39;, &#39;$\\\\sqrt{\\\\V[ X ]}$&#39;, &#39;$\\\\E[ D(X) ]$&#39;, &#39;$\\\\sqrt{\\\\V[ D(X) ]}$&#39;, &#39;$\\\\E[ S_{g,r} ]$&#39;, &#39;$\\\\sqrt{\\\\V[ S_{g,r} ]}$&#39; ), align = &#39;llrrrrrrrrrrr&#39;, digits = c( 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2 ), format.args = list( big.mark = &#39;,&#39;, decimal.mark = &#39;.&#39;, scientific = FALSE ), escape = FALSE, centering = TRUE ) %&gt;% kable_classic( font_size = 14, full_width = FALSE, html_font = &quot;Cambria&quot;, position = &quot;center&quot; ) %&gt;% scroll_box( width = &quot;100%&quot;, height = &quot;500px&quot; ) Tabla 6.6: Estimación de los reclamos totales sex \\(x_g\\) \\(r\\) \\(n_{g,r}\\) \\(d\\) \\(M\\) \\(\\mathbb{E}[ N ]\\) \\(\\sqrt{\\mathbb{V}[ N ]}\\) \\(\\mathbb{E}[ X ]\\) \\(\\sqrt{\\mathbb{V}[ X ]}\\) \\(\\mathbb{E}[ D(X) ]\\) \\(\\sqrt{\\mathbb{V}[ D(X) ]}\\) \\(\\mathbb{E}[ S_{g,r} ]\\) \\(\\sqrt{\\mathbb{V}[ S_{g,r} ]}\\) FEMALE [0,20) 1 1,000 20 20,000 2.36 8.99 53.88 35.16 34.25 34.76 80,954.12 9,886.63 FEMALE [0,20) 2 800 20 20,000 2.36 8.99 53.88 35.16 34.25 34.76 64,763.30 8,842.87 FEMALE [0,20) 3 600 20 25,000 2.36 8.99 53.88 35.16 34.25 34.76 48,572.47 7,658.15 FEMALE [0,20) 4 400 20 30,000 2.36 8.99 53.88 35.16 34.25 34.76 32,381.65 6,252.86 FEMALE [0,20) 5 200 20 40,000 2.36 8.99 53.88 35.16 34.25 34.76 16,190.82 4,421.44 FEMALE [20,40) 1 1,000 20 20,000 4.35 16.94 55.21 37.81 35.64 37.37 155,007.68 19,254.60 FEMALE [20,40) 2 800 20 20,000 4.35 16.94 55.21 37.81 35.64 37.37 124,006.14 17,221.83 FEMALE [20,40) 3 600 20 25,000 4.35 16.94 55.21 37.81 35.64 37.37 93,004.61 14,914.55 FEMALE [20,40) 4 400 20 30,000 4.35 16.94 55.21 37.81 35.64 37.37 62,003.07 12,177.68 FEMALE [20,40) 5 200 20 40,000 4.35 16.94 55.21 37.81 35.64 37.37 31,001.54 8,610.92 FEMALE [40,60) 1 1,000 20 20,000 9.89 27.12 58.42 42.10 38.85 41.66 384,035.64 33,568.72 FEMALE [40,60) 2 800 20 20,000 9.89 27.12 58.42 42.10 38.85 41.66 307,228.51 30,024.78 FEMALE [40,60) 3 600 20 25,000 9.89 27.12 58.42 42.10 38.85 41.66 230,421.39 26,002.22 FEMALE [40,60) 4 400 20 30,000 9.89 27.12 58.42 42.10 38.85 41.66 153,614.26 21,230.72 FEMALE [40,60) 5 200 20 40,000 9.89 27.12 58.42 42.10 38.85 41.66 76,807.13 15,012.39 FEMALE [60,Inf] 1 1,000 20 20,000 16.01 39.95 62.76 47.87 43.19 47.45 691,528.26 54,891.01 FEMALE [60,Inf] 2 800 20 20,000 16.01 39.95 62.76 47.87 43.19 47.45 553,222.61 49,096.01 FEMALE [60,Inf] 3 600 20 25,000 16.01 39.95 62.76 47.87 43.19 47.45 414,916.96 42,518.40 FEMALE [60,Inf] 4 400 20 30,000 16.01 39.95 62.76 47.87 43.19 47.45 276,611.30 34,716.12 FEMALE [60,Inf] 5 200 20 40,000 16.01 39.95 62.76 47.87 43.19 47.45 138,305.65 24,548.01 MALE [0,20) 1 1,000 20 20,000 2.21 9.10 54.70 36.96 35.11 36.53 77,713.10 10,250.89 MALE [0,20) 2 800 20 20,000 2.21 9.10 54.70 36.96 35.11 36.53 62,170.48 9,168.68 MALE [0,20) 3 600 20 25,000 2.21 9.10 54.70 36.96 35.11 36.53 46,627.86 7,940.31 MALE [0,20) 4 400 20 30,000 2.21 9.10 54.70 36.96 35.11 36.53 31,085.24 6,483.23 MALE [0,20) 5 200 20 40,000 2.21 9.10 54.70 36.96 35.11 36.53 15,542.62 4,584.34 MALE [20,40) 1 1,000 20 20,000 1.97 8.86 58.65 44.14 39.16 43.65 77,089.70 11,140.40 MALE [20,40) 2 800 20 20,000 1.97 8.86 58.65 44.14 39.16 43.65 61,671.76 9,964.28 MALE [20,40) 3 600 20 25,000 1.97 8.86 58.65 44.14 39.16 43.65 46,253.82 8,629.32 MALE [20,40) 4 400 20 30,000 1.97 8.86 58.65 44.14 39.16 43.65 30,835.88 7,045.81 MALE [20,40) 5 200 20 40,000 1.97 8.86 58.65 44.14 39.16 43.65 15,417.94 4,982.14 MALE [40,60) 1 1,000 20 20,000 6.00 18.64 63.02 50.59 43.54 50.11 261,139.22 25,962.48 MALE [40,60) 2 800 20 20,000 6.00 18.64 63.02 50.59 43.54 50.11 208,911.37 23,221.55 MALE [40,60) 3 600 20 25,000 6.00 18.64 63.02 50.59 43.54 50.11 156,683.53 20,110.45 MALE [40,60) 4 400 20 30,000 6.00 18.64 63.02 50.59 43.54 50.11 104,455.69 16,420.12 MALE [40,60) 5 200 20 40,000 6.00 18.64 63.02 50.59 43.54 50.11 52,227.84 11,610.77 MALE [60,Inf] 1 1,000 20 20,000 16.26 38.61 63.24 47.57 43.64 47.18 709,672.56 53,625.70 MALE [60,Inf] 2 800 20 20,000 16.26 38.61 63.24 47.57 43.64 47.18 567,738.05 47,964.28 MALE [60,Inf] 3 600 20 25,000 16.26 38.61 63.24 47.57 43.64 47.18 425,803.54 41,538.29 MALE [60,Inf] 4 400 20 30,000 16.26 38.61 63.24 47.57 43.64 47.18 283,869.02 33,915.87 MALE [60,Inf] 5 200 20 40,000 16.26 38.61 63.24 47.57 43.64 47.18 141,934.51 23,982.14 6.10 Proceso estocástico de reclamos totales Hasta el momento no hemos considerado que los reclamos se producen en el tiempo, que cada reclamo está bien vinculado al tiempo; es más podemos identificar algunos instantes en el tiempo que le corresponde, tenemos así el tiempo cuando se suscita el siniestro o tiempo de ocurrencia, el tiempo de aviso cuando se comunica al asegurador el siniestro y un tiempo de pago. Los dos últimos no son directos asociados al evento del siniestro sino están asociados a otras variables que pueden afectar la demora para comunicar un siniestro por parte del asegurado y la demora para cancelarlo por parte del asegurador. Así por tanto si tenemos una secuencia de siniestros \\(\\{X_n\\}_{n\\in\\mathbb{N}^*}\\), estos los podemos considerar ordenados en el tiempo conforme han venido presentándose en instantes \\(0= T_0 \\leq T_1 \\leq \\cdots \\leq T_n \\leq \\cdots\\), es decir se le asocia a los reclamos \\(\\{X_n\\}\\) la secuencia de los tiempos de arribo \\(\\{T_n\\}_{n\\in\\mathbb{N}}\\), donde \\(T_{n+1} \\geq T_n\\), para cualquier \\(n \\in \\mathbb{N}\\). Ciertamente, es de esperar que los tiempos de arribo sean variables aleatorias y están asociados a la frecuencia \\(N\\) en un periodo dado, ya que \\(N\\) cuenta los tiempos de arribo hasta un instante dado \\(t \\geq 0\\), bajo esta perspectiva transformamos a \\(N\\) en una variable aleatoria dependiente del tiempo, en lo que se conoce como un proceso estocástico. \\[ N( t ) = \\#\\left\\{ n \\in \\mathbb{N}\\ \\middle|\\ T_n \\leq t \\right\\} = \\sum\\limits_{n=0}^{+\\infty} \\mathbf{1}_{(-\\infty,t]}\\left( T_n \\right) \\] Inmediatamente de este razonamiento, resulta que los reclamos totales también se transforman en proceso estocástico, conforme se van considerando los arribos de los reclamos. \\[ S( t ) = \\sum\\limits_{i=1}^{N( t )} X_i \\] donde claramente, como hemos venido haciéndolo, si \\(N(t) = 0\\), entonces la suma total de reclamos es cero, \\(S(t) = 0\\). Además, junto con lo anterior, se pueden identificar las variables aleatorias de tiempos entre arribos, dadas por las diferencias entre tiempos de arribo contiguos \\[ W_n = T_n - T_{n-1},\\quad \\forall n \\in \\mathbb{N}^* \\] Un hipótesis bien común en el modelamiento de un proceso de pérdida agregada utilizando esta aproximación es asumir que los tiempos entre arribo \\(\\{W_n\\}\\) son independientes entre si, es decir, el momento que se producen cada uno de los siniestros es de forma independiente. También se suele suponer independencia entre los tiempos entre arribo \\(\\{W_n\\}\\) y las variables que representan la magnitud de cada uno de los reclamos \\(\\{X_n\\}\\). Los resultados para el cálculo de la esperanza y la varianza se pueden obtener de forma similar a lo que realizamos en la sección @ref(modelo_individual). \\[ \\begin{eqnarray*} \\mathbb{E}[S(t)] &amp; = &amp; \\mathbb{E}\\left[ \\sum\\limits_{i=1}^{N(t)} X_i \\right] \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} \\mathbb{E}\\left[ \\sum\\limits_{i=1}^n X_i\\ \\middle|\\ N(t) = n \\right]P( N(t) = n ) \\quad \\text{utilizando la esperanza condicional} \\\\ &amp; = &amp; 0 P( N(t) = 0 ) + \\sum\\limits_{n=1}^{+\\infty} \\mathbb{E}\\left[ \\sum\\limits_{i=1}^n X_i\\ \\middle|\\ N(t) = n \\right]P( N(t) = n ) \\\\ &amp; = &amp; \\sum\\limits_{n=1}^{+\\infty} \\sum\\limits_{i=1}^n \\mathbb{E}\\left[ X_i \\mid N(t) = n \\right]P( N(t) = n ) \\quad \\text{linealidad de la esperanza} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} n \\mathbb{E}\\left[ X \\mid N(t) = n \\right]P( N(t) = n ) \\quad \\text{si $\\{X_i\\}$ son idénticamente distribuidas} \\\\ &amp; = &amp; \\mathbb{E}\\left[ X \\right] \\sum\\limits_{n=0}^{+\\infty} n P( N(t) = n ) \\quad \\text{si $X$ y $N(t)$ son independientes} \\\\ &amp; = &amp; \\mathbb{E}[ N(t) ] \\mathbb{E}[ X ] \\end{eqnarray*} \\] el segundo momento de \\(S(t)\\) se calcula de forma similar \\[ \\begin{eqnarray*} \\mathbb{E}[S(t)^2] &amp; = &amp; \\mathbb{E}\\left[ \\left( \\sum\\limits_{i=1}^{N(t)} X_i \\right)^2 \\right] \\\\ &amp; = &amp; \\sum\\limits_{n=0}^\\infty \\mathbb{E}\\left[ \\sum\\limits_{i, j=1}^n X_i X_j \\middle| N(t) = n \\right] P( N = n ) \\quad \\text{propiedades de la esperanza condicional} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^\\infty \\sum\\limits_{i, j=1}^n \\mathbb{E}\\left[ X_i X_j \\right] P( N(t) = n ) \\quad \\text{si $\\{X_i\\}$ y $N(t)$ son independientes} \\\\ &amp; = &amp; \\sum\\limits_{n=0}^\\infty \\left( \\sum\\limits_{i=1}^n \\mathbb{E}\\left[ X_i^2 \\right] + \\sum\\limits_{i,j=1,i\\neq j}^n \\mathbb{E}\\left[ X_i X_j \\right] \\right) P( N(t) = n ) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^\\infty \\left( n \\mathbb{E}\\left[ X^2 \\right] + n(n-1) \\mathbb{E}\\left[ X \\right]^2 \\right) P( N(t) = n ) \\quad \\text{si $\\{X_i\\}$ son i.i.d} \\\\ &amp; = &amp; \\mathbb{E}\\left[N(t)\\right] \\mathbb{E}\\left[X^2\\right] + \\mathbb{E}\\left[N(t)^2\\right] \\mathbb{E}\\left[X\\right]^2 - \\mathbb{E}\\left[N(t)\\right] \\mathbb{E}\\left[X\\right]^2 \\\\ &amp; = &amp; \\mathbb{E}\\left[N(t)\\right] \\mathbb{V}\\left[X\\right] + \\mathbb{E}\\left[N(t)^2\\right] \\mathbb{E}\\left[X\\right]^2 \\end{eqnarray*} \\] y finalmente la varianza de \\(S(t)\\) \\[ \\begin{eqnarray*} \\mathbb{V}\\left[S(t)\\right] &amp; = &amp; \\mathbb{E}\\left[S(t)^2\\right] - \\mathbb{E}\\left[S(t)\\right]^2 \\\\ &amp; = &amp; \\mathbb{E}\\left[N(t)\\right] \\mathbb{V}\\left[X\\right] + \\mathbb{E}\\left[N(t)^2\\right] \\mathbb{E}\\left[X\\right]^2 - \\mathbb{E}\\left[N(t)\\right]^2 \\mathbb{E}\\left[X\\right]^2 \\\\ &amp; = &amp; \\mathbb{E}\\left[N(t)\\right] \\mathbb{V}\\left[X\\right] + \\mathbb{V}\\left[N(t)\\right] \\mathbb{E}\\left[X\\right]^2 \\end{eqnarray*} \\] Si trabajamos bajo la hipótesis que los tiempos entre arribos \\(\\{W_n\\}\\) son i.i.d, con distribución de probabilidad común \\(F_W\\). Podemos comprender y estudiar de una forma un poco más sencilla el proceso estocástico atado a la frecuencia de los siniestros \\(N\\). Notemos primeramente que se tienen la siguiente igualdad entre los eventos \\[ \\{N(t) = n\\} = \\{T_n \\leq \\land T_{n+1} &gt; t\\} = \\{T_n \\leq t \\} \\cap \\{ T_{n+1} \\leq t\\}^c = \\{T_n \\leq t \\} \\setminus \\{ T_{n+1} \\leq t\\} \\] además es de observar que \\(\\{ T_{n+1} \\leq t\\} \\subset \\{ T_{n} \\leq t\\}\\). Con todo esto en consideración para cualquier \\(n &gt; 0\\). \\[ \\begin{eqnarray*} P( N(t) = n ) &amp; = &amp; P( T_n \\leq t \\land T_{n+1} &gt; t ) \\\\ &amp; = &amp; P( \\{T_n \\leq t \\} \\setminus \\{ T_{n+1} \\leq t\\} ) \\\\ &amp; = &amp; P( T_n \\leq t ) - P( T_{n+1} \\leq t ) \\\\ &amp; = &amp; F_W^{\\star n}( t ) - F_W^{\\star n + 1}( t ) \\end{eqnarray*} \\] el caso \\(n = 0\\) también es sencillo \\[ \\begin{eqnarray*} P( N(t) = 0 ) &amp; = &amp; P( T_0 \\leq t \\land T_1 &gt; t ) \\\\ &amp; = &amp; P( \\{T_0 \\leq t \\} \\setminus \\{ T_1 \\leq t\\} ) \\\\ &amp; = &amp; P( T_0 \\leq t ) - P( T_1 \\leq t ) \\\\ &amp; = &amp; 1 - F_W^{\\star 1}( t ) \\\\ &amp; = &amp; F_W^{\\star 0}( t ) - F_W^{\\star 1}( t ) \\end{eqnarray*} \\] De lo anterior resulta que la esperanza de \\(N(t)\\), está dada por la siguiente serie. \\[ \\begin{eqnarray*} \\mathbb{E}[ N( t ) ] &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} n P( N(t) = n ) \\\\ &amp; = &amp; \\sum\\limits_{n=0}^{+\\infty} n \\left( F_W^{\\star n}( t ) - F_W^{\\star n + 1}( t ) \\right) \\\\ &amp; = &amp; 0\\left( F_W^{\\star 0}( t ) - F_W^{\\star 1}( t ) \\right) + 1\\left( F_W^{\\star 1}( t ) - F_W^{\\star 2}( t ) \\right) + 2\\left( F_W^{\\star 2}( t ) - F_W^{\\star 3}( t ) \\right) + \\cdots \\\\ &amp; = &amp; \\sum\\limits_{n=1}^{+\\infty} F_W^{\\star n}( t ) \\end{eqnarray*} \\] 6.10.1 Algoritmo de simulación Se selecciona el número adecuado de simulaciones \\(m \\in \\mathbb{N}^*\\), Se selecciona el número de simulaciones de tiempos de arribo \\(M \\in \\mathbb{N}^*\\), Dada la distribución de los tiempos entre arribos \\(F_W\\) para cada simulación \\(i \\in \\{1, \\ldots, m\\}\\) se genera una muestra \\(W_{i,1}, \\ldots, W_{i,M}\\) de tamaño de \\(M\\), Para cada simulación \\(i \\in \\{1, \\ldots, m\\}\\) y cada \\(n \\in \\{0, \\ldots, M\\}\\) calculamos los tiempos de arribo \\(T_{i,0},\\ldots, T_{i,M}\\) \\[ T_{i,0} = 0,\\qquad T_{i,n} = \\sum\\limits_{k=1}^n W_{i,k} \\] Se toma una malla de discretización en el tiempo \\(0 = t_0 &lt; t_1 &lt; \\cdots &lt; t_p = T\\) y calculamos para cada simulación \\(i \\in \\{1,\\ldots,m\\}\\) y tiempo \\(t_l\\), con \\(l \\in \\{0,\\ldots,p\\}\\). \\[ N_{i,l} = \\#\\left\\{ n \\in \\mathbb{N}\\ \\middle|\\ T_{i,n} \\leq t_l \\right\\} = \\sum\\limits_{n=0}^{M} \\mathbf{1}_{(-\\infty,t_l]}\\left( T_n \\right) \\] precisamente para cada simulación \\(i\\), el término \\(N_{i,l}\\) es una aproximación al proceso \\(N( t_l )\\) evaluado en el tiempo \\(t_l\\). Así se puede tener la aproximación de la media \\[ \\mathbb{E}\\left[ N( t_l ) \\right] \\approx \\frac{1}{m} \\sum\\limits_{i=1}^m N_{i,l} \\] Con la simulación el proceso estocástico \\(N\\) podemos ahora proceder a simular los reclamos totales. Para cada simulación \\(i \\in \\{1,\\ldots,m\\}\\), tomamos una muestra de forma independiente e igualmente distribuida de los reclamos individuales \\(X_{i,1}, \\ldots, X_{i,N_{i,p}}\\), la cual tiene tamaño \\(N_{i,p}\\), y son tomados de la distribución de probabilidad \\(F_X\\) Para cada simulación \\(i \\in \\{1,\\ldots, m\\}\\) y cada tiempo \\(t_l\\) con \\(l \\in \\{0,\\ldots,p\\}\\), calculamos la suma \\[ S_{i,l} = \\sum\\limits_{j=1}^{N_{i,l}} X_{i,j} \\] cada \\(S_{i,l}\\) es una aproximación al proceso del total de reclamos \\(S(t_l)\\) precisamente en el tiempo \\(t_l\\). Así resulta la aproximación \\[ \\mathbb{E}\\left[ S( t_l ) \\right] \\approx \\frac{1}{m} \\sum\\limits_{i=1}^m S_{i,l} \\] Además, para cada instante \\(t_l\\), se puede aproximar la función de distribución acumulada \\(F_{S(t_l)}\\) de la variable aleatoria \\(S( t_l )\\) utilizando la distribución acumulada empírica generada con la muestra \\(S_{1,l},\\ldots,S_{m,l}\\). Para cualquier \\(s \\in \\mathbb{R}\\), tenemos la aproximación \\[ F_{S(t_l)}( s ) \\approx F_{m,l}( s ) = \\frac{1}{m} \\sum\\limits_{i=1}^m \\mathbf{1}_{(-\\infty,s]}\\left( S_{i,l} \\right) \\] El algoritmo de simulación anterior tiene una falencia, no se sabe a priori que valor \\(M\\) se debe escoger para simular de forma correcta los procesos \\(N\\) y \\(S\\) hasta un tiempo máximo \\(T\\) dado. Esto implica que si \\(M\\) no es del tamaño adecuado, las estimaciones que se realice utilizando la simulación va a degradarse conforme avanza el tiempo. Ejemplo 6.8 El siguiente ejemplo es de especial atención ya que es utilizado en muchas aplicaciones, podemos considerar el caso donde el tiempo entre arribos \\(\\{W_n\\}\\) es i.i.d y con distribución de probabilidad común \\(F_W\\) dada por una ley exponencial \\(Exp( \\lambda )\\). Un resultado clásico muestra que la suma de \\(n\\) exponenciales sigue una ley gamma \\(Gamma(n,\\lambda)\\), esto implica que \\(T_n = W_1 + \\cdots + W_n \\rightsquigarrow Gamma( n, \\lambda )\\) lo que quiere decir que la convolución \\(F_W^{\\star n}\\) es una \\(Gamma( n, \\lambda )\\). Así por tanto, el proceso estocástico de conteo \\(N(t) = \\#\\left\\{ n \\in \\mathbb{N}\\ \\middle|\\ T_n \\leq t \\right\\}\\) tiene las siguientes probabilidades \\[ \\begin{eqnarray*} P( N( t ) = n ) &amp; = &amp; F_W^{\\star n}( t ) - F_W^{\\star n + 1}( t ) \\\\ &amp; = &amp; \\exp( -\\lambda t ) \\sum\\limits_{k=n}^{+\\infty} \\frac{(\\lambda t)^k}{k!} - \\exp( -\\lambda t ) \\sum\\limits_{k={n+1}}^{+\\infty} \\frac{(\\lambda t)^k}{k!} \\\\ &amp; = &amp; \\exp( -\\lambda t ) \\frac{(\\lambda t)^n}{n!} \\end{eqnarray*} \\] En conclusión \\(N(t)\\) tiene como distribución una ley de Poisson \\(Pois( \\lambda t )\\), en particular se conoce a \\(N\\) como un proceso de Poisson. Code m &lt;- 1000 lambda &lt;- 10 M &lt;- 30 p &lt;- 365 u &lt;- 4 s &lt;- 2 set.seed( 432147 ) W &lt;- lapply( 1:m, FUN = function( n ) rexp( M, rate = lambda ) ) Tn &lt;- lapply( W, FUN = cumsum ) Tnmax &lt;- max( sapply( Tn, FUN = max ) ) t &lt;- seq( 0, Tnmax, length = p ) N &lt;- lapply( Tn, FUN = function( Tk ) sapply( t, FUN = function( t ) sum( Tk &lt;= t ) ) ) Nmax &lt;- max( sapply( N, FUN = function( Ni ) last( Ni ) ) ) set.seed( 7324312 ) X &lt;- lapply( N, FUN = function( Ni ) rlnorm( last( Ni ), meanlog = u, sdlog = s ) ) S &lt;- lapply( 1:m, FUN = function( i ) { Si &lt;- cumsum( X[[ i ]] ) return( sapply( N[[ i ]], FUN = function( Nj ) ifelse( Nj == 0, 0, Si[ Nj ] ) ) ) } ) Smax &lt;- max( sapply( S, FUN = function( Si ) last( Si ) ) ) EN &lt;- lambda * t EeN &lt;- sapply( 1:p, FUN = function( l ) mean( sapply( 1:m, function( i ) N[[ i ]][ l ] ) ) ) ES &lt;- EN * exp( u + 0.5 * s^2 ) EeS &lt;- sapply( 1:p, FUN = function( l ) mean( sapply( 1:m, function( i ) S[[ i ]][ l ] ) ) ) En el gráfico a continuación presentamos todos los procesos de conteo \\(N_{i}\\) simulados, como es de esperarse son funciones de escalera, siempre crecientes, que toman solo valores positivos. Code Sord &lt;- order( sapply( 1:m, FUN = function( j ) last( S[[j]] ) ) ) Ndat &lt;- NULL for ( j in 1:m ) { Ndat &lt;- rbindlist( list( Ndat, data.table( t = t, m = as.factor( Sord[ j ] ), N = N[[ j ]], S = S[[ j ]] ) ) ) } cols &lt;- wes_palette( m, name = &quot;FantasticFox1&quot;, type = &quot;continuous&quot;) time &lt;- t plt &lt;- ggplot( ) + geom_step( data = Ndat, aes( x = t, y = N, group = m, colour = m ), linewidth = 0.2 ) + geom_line( aes( x = time, y = EN, colour = &#39;a&#39; ), linewidth = 1.5 ) + geom_line( aes( x = time, y = EeN, colour = &#39;b&#39; ), linewidth = 1 ) + scale_color_manual( breaks = c( as.factor( 1:m ), &#39;a&#39;, &#39;b&#39; ), values = c( cols, &#39;dodgerblue3&#39;, &#39;olivedrab3&#39; ) ) + scale_x_continuous( breaks = seq( 0, Tnmax, length = 11 ), labels = formatC( seq( 0, Tnmax, length = 11 ), digits = 2, format = &#39;f&#39; ), limits = c( 0, Tnmax ), expand = c( 0, 0 ) ) + scale_y_continuous( breaks = seq( 0, Nmax, length = 11 ), labels = formatC( seq( 0, Nmax, length = 11 ), digits = 2, format = &#39;f&#39; ), limits = c( 0, Nmax ), expand = c( 0, 0 ) ) + xlab( TeX( &quot;$t$&quot; ) ) + ylab( TeX( &quot;$N(t)$&quot; ) ) + theme_bw() + theme( legend.position = &quot;none&quot; ) plot( plt ) El gráfico a continuación presenta la simulación de los procesos correspondientes al total de reclamos, conforme avanza el tiempo. De igual manera los procesos \\(S_i\\) son funciones de escalera, siempre crecientes, con saltos correspondientes a los reclamos individuales. Code Sqmax &lt;- quantile( sapply( S, FUN = function( Si ) last( Si ) ), probs = 0.99 ) plt &lt;- ggplot( ) + geom_step( data = Ndat, aes( x = t, y = S, group = m, colour = m ), linewidth = 0.2 ) + geom_line( aes( x = time, y = ES, colour = &#39;a&#39; ), linewidth = 1.5 ) + geom_line( aes( x = time, y = EeS, colour = &#39;b&#39; ), linewidth = 1 ) + scale_color_manual( breaks = c( as.factor( 1:m ), &#39;a&#39;, &#39;b&#39; ), values = c( cols, &#39;dodgerblue3&#39;, &#39;olivedrab3&#39; ) ) + scale_x_continuous( breaks = seq( 0, Tnmax, length = 11 ), labels = formatC( seq( 0, Tnmax, length = 11 ), digits = 2, format = &#39;f&#39; ), limits = c( 0, Tnmax ), expand = c( 0, 0 ) ) + scale_y_continuous( breaks = seq( 0, Sqmax, length = 11 ), labels = formatC( seq( 0, Sqmax, length = 11 ), digits = 2, format = &#39;f&#39; ), limits = c( 0, Sqmax ), expand = c( 0, 0 ) ) + xlab( TeX( &quot;$t$&quot; ) ) + ylab( TeX( &quot;$S(t)$&quot; ) ) + theme_bw() + theme( legend.position = &quot;none&quot; ) plot( plt ) Como se describe en el paso 8 del algoritmo de simulación, para cada tiempo \\(t_l\\) se puede estimar la distribución de probabilidad de la variable aleatoria \\(S(t_l)\\). Code FeS &lt;- lapply( 1:p, FUN = function( l ) ecdf( sapply( S, FUN = function( Si ) Si[ l ] ) ) ) ns &lt;- 1e3 s &lt;- seq( 0, Smax, length = ns ) Fes &lt;- lapply( FeS, FUN = function( FeSl ) sapply( s, FUN = FeSl ) ) La figura a continuación muestra cada una de las distribuciones de probabilidad empíricas estimadas \\(F_{m,l}\\). Se puede observar que conforme avanza el tiempo, aumenta la probabilidad de observar valores mayores del proceso \\(S\\) correspondiente al total de reclamos. Code FeSdat &lt;- NULL for ( j in 1:p ) { FeSdat &lt;- rbindlist( list( FeSdat, data.table( s = s, m = as.factor( j ), Fes = Fes[[ j ]] ) ) ) } cols &lt;- wes_palette( p, name = &quot;FantasticFox1&quot;, type = &quot;continuous&quot;) plt &lt;- ggplot( ) + geom_step( data = FeSdat, aes( x = s, y = Fes, group = m, colour = m ), linewidth = 0.1 ) + scale_color_manual( values = c( cols ) ) + scale_x_continuous( breaks = seq( 0, Smax, length = 5 ), labels = formatC( seq( 0, Smax, length = 5 ), digits = 2, format = &#39;f&#39; ), limits = c( 0, Smax ), expand = c( 0, 0 ) ) + scale_y_continuous( breaks = seq( 0, 1, length = 11 ), labels = formatC( seq( 0, 1, length = 11 ), digits = 2, format = &#39;f&#39; ), limits = c( 0, 1 ), expand = c( 0.005, 0.005 ) ) + xlab( TeX( &quot;$S$&quot; ) ) + ylab( TeX( &quot;$F_{m,l}$&quot; ) ) + theme_bw() + theme( legend.position = &quot;none&quot; ) plot( plt ) "],["tarificacion.html", "Capítulo 7 Tarificación 7.1 Medidas de riesgo 7.2 Tarificación en grandes términos 7.3 Prima 7.4 Segmentación", " Capítulo 7 Tarificación Para realizar la tarificación de un producto de seguro, además de estudiar y estimar el comportamiento futuro de los reclamos totales \\(S\\), es necesario también tomar en cuenta el capital \\(K\\) destinado para hacer frente al riesgo subscrito y los costos generales \\(G\\) 7.1 Medidas de riesgo Definición 4.7 (Medida de riesgo coherente) Una medida de riesgo coeherente es una función \\(\\rho: \\mathbb{R}\\longrightarrow \\mathbb{R}\\), que satisface la siguientes propiedades: Homogenidad positiva, para cualquier \\(a &gt; 0\\) \\[ \\rho( a X ) = a \\rho( X ) \\] Invarianza ante las traslaciones, para cualquier \\(a &gt; 0\\) \\[ \\rho( \\alpha X + a ) = \\rho( \\alpha X ) + a \\] Monotonicidad, Si \\(X \\leq Y\\) \\[ \\rho( X ) \\leq \\rho( Y ) \\] Sub-aditividad \\[ \\rho( X + Y ) \\leq \\rho( X ) + \\rho( Y ) \\] En lo que continúa citamos algunas de las medidas de riesgo usualmente utilizadas. Definición 7.1 (Valor en riesgo) Dada una variable aleatoria a valores reales \\(X\\), el valor en riesgo (value at risk) de \\(X\\) al nivel de probabilidad \\(\\alpha \\in (0,1)\\) está dado por \\[ \\operatorname{VaR}_{\\alpha}( X ) = \\inf\\left\\{ x \\in \\mathbb{R}\\middle| F_X( x ) &gt; \\alpha \\right\\} \\] Proposición 7.1 Si la función de distribución acumulada \\(F_X\\) es continua, entonces \\(\\operatorname{VaR}_{\\alpha}( X ) = F_X^{-1}( \\alpha )\\). Por otra parte, \\(\\operatorname{VaR}_{\\alpha}\\) para cualquier \\(\\alpha\\) no es una medida de riesgo sub-aditiva. Definición 7.2 (Valor en riesgo en la cola) Dada una variable aleatoria a valores reales \\(X\\), el valor en riesgo en la colas (tail value at risk) de \\(X\\) al nivel de probabilidad \\(\\alpha \\in (0,1)\\) está dado por \\[ \\operatorname{TVaR}_{\\alpha}( X ) = \\frac{1}{1-\\alpha} \\int\\limits_{\\alpha}^1 \\operatorname{VaR}_u( X )\\ du \\] Proposición 7.2 (Coherencia de la medida TVaR) La medida de riesgo \\(\\operatorname{TVaR}_{\\alpha}\\) es una medida de riesgo coherente si la variable aleatoria sobre la cual se mide es una variable aleatoria continua. Definición 7.3 (Esperanza condicional en la cola) Dada una variable aleatoria a valores reales \\(X\\), la esperanza condicional en la cola (conditional tail expectation) de \\(X\\) al nivel de probabilidad \\(\\alpha \\in (0,1)\\) está dado por \\[ \\operatorname{CTE}_{\\alpha}( X ) = \\mathbb{E}\\left[ X \\middle| X &gt; \\operatorname{VaR}_{\\alpha}( X ) \\right] \\] Proposición 7.3 Si la función de distribución acumulada \\(F_X\\) de la variable aleatoria \\(X\\) es continua, entonces se tiene la siguiente igualdad \\[ \\operatorname{CTE}_{\\alpha}( X ) = \\operatorname{TVaR}_{\\alpha}( X ) \\] Definición 7.4 (Valor en riesgo condicionado) Dada una variable aleatoria a valores reales \\(X\\), el valor en riesgo condicionado (conditional value at risk) de \\(X\\) al nivel de probabilidad \\(\\alpha \\in (0,1)\\) está dado por \\[ \\operatorname{CVaR}_{\\alpha}( X ) = \\mathbb{E}\\left[ X - \\operatorname{VaR}_{\\alpha}( X ) \\middle| X &gt; \\operatorname{VaR}_{\\alpha}( X ) \\right] = \\operatorname{CTE}_{\\alpha}( X ) - \\operatorname{VaR}_{\\alpha}( X ) \\] Definición 7.5 (Déficit esperado) Dada una variable aleatoria a valores reales \\(X\\), el déficit esperado (expected shortfall) de \\(X\\) al nivel de probabilidad \\(\\alpha \\in (0,1)\\) está dado por \\[ \\operatorname{ES}_{\\alpha}( X ) = \\mathbb{E}\\left[ \\max\\left( X - \\operatorname{VaR}_{\\alpha}( X ), 0 \\right) \\right] \\] Definición 7.6 (Valor en riesgo entrópico) Dada una variable aleatoria a valores reales \\(X\\), el valor en riesgo entrópico (entropic value at risk) de \\(X\\) al nivel de probabilidad \\(\\alpha \\in (0,1)\\) está dado por \\[ \\operatorname{EVaR}_{\\alpha}( X ) = \\inf\\left\\{ \\frac{1}{t} \\ln\\left( \\frac{M_X( t )}{1 - \\alpha} \\right) \\middle| t &gt; 0 \\right\\} \\] Proposición 7.4 (Coherencia de la medida EVaR) La medida de riesgo \\(\\operatorname{EVaR}_{\\alpha}\\) es una medida de riesgo coherente. Ejemplo 7.1 Podemos considerar el caso particular donde todos los reclamos se suponen independientes e idénticamente distribuidos (i.i.d), en este caso con distribución \\(X_i \\rightsquigarrow LN(\\mu,\\sigma)\\) Code set.seed(94312) u &lt;- 4 s &lt;- 0.5 n &lt;- 1e4 X &lt;- rlnorm( n, meanlog = u, sdlog = s ) alpha &lt;- seq( 0, 1, 0.01 ) VaRX &lt;- quantile( X, probs = alpha, names = FALSE ) TVaRX &lt;- sapply( 1:length( VaRX ), FUN = function( i ) ifelse( alpha[ i ] &lt; 1, ( 1 / ( 1 - alpha[ i ] ) ) * mean( X * ( X &gt; VaRX[ i ] ) ), max( X ) ) ) Code plt &lt;- ggplot() + geom_point( aes( x = alpha, y = VaRX ), colour = &#39;darkred&#39; ) + geom_point( aes( x = alpha, y = TVaRX ), colour = &#39;orange&#39; ) + xlab( TeX( &quot;$\\\\alpha$&quot; ) ) + ylab( TeX( &quot;$VaR,TVaR$&quot; ) ) + theme_bw() plot( plt ) 7.2 Tarificación en grandes términos La tarificación que conlleva a la selección de la prima \\(\\Pi\\) debe tomar en cuenta como se manejan y equilibran los activos y pasivos en el negocio asegurador. Pasivos Capitales propios Reservas técnicas Reservas para otros riesgos Deudas o depósitos en dinero recibidos por cesiones Otras deudas por pagar Activos Capital suscrito no desembolsado Activos no materiales Inversiones Parte de reaseguros en reservas técnicas Deudas por cobrar Otros activos En el proceso de tarificación no es pertinente incluir todos los activos de la empresa, ya que muchos de estos no tienen la liquidez necesaria como para ser considerados un tipo de activo viable para la tarificación. Tampoco se toma en cuenta el dinero recibido por la cesión de primas en un ramo en particular, ya que esto constituye un nivel más arriba propio del negocio reasegurador. En términos generales se busca equilibrar el resultado operativo del ramo de negocio \\(R\\) a lo largo de la vida del ramo. El resultado \\(R\\) a su vez está dado por la siguiente relación: \\[ R = \\Pi + I - S - G - K \\] donde las variables a considerarse en principio son: \\(\\Pi\\) Ingreso por primas \\(I\\) Ingreso por inversiones \\(S\\) Pago de siniestros \\(G\\) Gastos agregados, incluyendo gastos de emisión, operativos, gastos por reclamos \\(K\\) Coste de capital, esencialmente es el retorno que se espera sobre el capital invertido por los inversores para mantener el nivel de solvencia del ramo. En varias ocasiones el ciclo del negocio puede ser corto plazo y no permite considerar un ingreso por inversiones \\(I = 0\\). \\[ R = \\Pi - S - G - K \\] Sería ideal que a lo largo de la vida del ramo el resultado mantenga \\(R &gt; 0\\), pero al tratarse de un negocio que depende de la aleatoriedad de los reclamos, es bastante complicado encontrar un costo de capital \\(K\\) y una prima \\(\\Pi\\) que siempre asegure ante todo escenario que se mantenga la positividad. Ante este riesgo continuo se busca minimizar la probabilidad de ruina, es decir, acotar la probabilidad del evento \\(R &lt; 0\\) a un nivel de confianza \\(\\alpha &gt; 0\\) adecuado \\[ P( R &lt; 0 ) &lt; \\alpha \\] Muchas de las veces se parte del principio de equilibrio financiero 4.6.4, donde se busca la igualdad \\(\\mathbb{E}[R] = 0\\), la misma implica la siguiente relación: \\[ \\begin{eqnarray*} 0 &amp; = &amp; \\mathbb{E}[R] \\\\ 0 &amp; = &amp; \\mathbb{E}[R\\mid R \\geq 0]P( R \\geq 0 ) + \\mathbb{E}[R\\mid R &lt; 0]P( R &lt; 0 ) \\\\ \\mathbb{E}[R\\mid R \\geq 0]P( R \\geq 0 ) &amp; = &amp; -\\mathbb{E}[R\\mid R &lt; 0]P( R &lt; 0 ) \\\\ \\frac{P( R &lt; 0 )}{P( R \\geq 0 ) } &amp; = &amp; -\\frac{\\mathbb{E}[R\\mid R \\geq 0]}{\\mathbb{E}[R\\mid R &lt; 0]} \\end{eqnarray*} \\] en el equilibrio financiero, la proporción de la probabilidad de ruina respecto de la probabilidad de no estar en ruina es igual a la proporción entre la esperanza condicional del resultado cuando no se produce la ruina respecto de la esperanza condicional cuando si se produce la ruina. Un modelo puede estar equilibrado financieramente \\(\\mathbb{E}[R] = 0\\), pero se desconoce la probabilidad de ruina \\(P( R &lt; 0)\\), esta podría ser muy grande. La razón anterior permite estimar la relevancia de la probabilidad de ruina en un modelo equilibrado, con el uso de las esperanzas condicionales. Es usual asumir que la única parte aleatoria de \\(R\\) viene dada por el valor de los reclamos totales, en razón de esto se tiene: \\[ \\mathbb{E}[ R ] = \\mathbb{E}[ \\Pi - S - G - K ] = \\Pi - \\mathbb{E}[S] - G - K \\] El coste de capital \\(K\\) como ya lo mencionamos es el retorno mínimo esperado por los inversores sobre el capital invertido. Usualmente este capital puede ser visto como un porcentaje \\(r &gt; 0\\) que se toma sobre el capital colocado para mantener un nivel de solvencia adecuado sobre el valor esperado \\(\\mathbb{E}[S]\\) del total de reclamos \\(S\\). Para ello se suele utilizar precisamente una medida de medida de riesgo \\(\\rho\\) que permita mantener el nivel de solvencia. \\[ K = r\\left( \\rho( S ) - \\mathbb{E}[S] \\right) \\] con esta perspectiva \\[ \\mathbb{E}[ R ] = \\mathbb{E}\\left[ \\Pi - S - G - r\\left( \\rho( S ) - \\mathbb{E}[S] \\right) \\right] = \\Pi - \\mathbb{E}[S] - G - r \\left( \\rho(S) - \\mathbb{E}[S] \\right) \\] Lo que se busca es evitar la ruina y por tanto se busca cubrirse ante el evento \\(R &lt; 0\\), desde una perspectiva probabilista esto se puede realizar seleccionando un nivel de cobertura \\(\\alpha &gt; 0\\), que acote la probabilidad del evento de ruina. \\[ P( R &lt; 0 ) = P( \\Pi - S - G - K &lt; 0 ) = P\\left( \\Pi - S - G - r\\left( \\rho(S) - \\mathbb{E}[S] \\right) &lt; 0 \\right) &lt; \\alpha. \\] De la relación anterior se observa que una vez seleccionado el nivel de cobertura \\(\\alpha\\) y la medida de riesgo \\(\\rho\\), las variables correspondientes a la prima \\(\\Pi\\) y a los gastos \\(G\\) quedan libres, de ahí resulta un margen que permite seleccionar la prima más óptima para un producto de seguro, así como también optimizar los gastos \\(G\\). Este proceso de selección es precisamente lo que llamamos en este contexto como tarificación (pricing). Razonando un poco más al respecto, si asumimos que se dispone de la distribución acumulada \\(F_S\\) de \\(S\\), se puede obtener las siguientes expresiones: \\[ \\begin{eqnarray*} P\\left( \\Pi - S - G - K &lt; 0 \\right) &amp; &lt; &amp; \\alpha \\\\ P\\left( S &gt; \\Pi - G - K \\right) &amp; &lt; &amp; \\alpha \\\\ 1 - P\\left( S \\leq \\Pi - G - K \\right) &amp; &lt; &amp; \\alpha \\\\ P\\left( S \\leq \\Pi - G - K \\right) &amp; &gt; &amp; 1 - \\alpha \\\\ F_S\\left( \\Pi - G - K \\right) &amp; &gt; &amp; 1 - \\alpha \\\\ F_S\\left( \\Pi - G - K \\right) &amp; \\in &amp; \\left( 1 - \\alpha, +\\infty \\right), \\qquad \\text{la desigualdad anterior es equivalente a la inclusión}\\\\ \\Pi - G - K &amp; \\in &amp; F_S^{-1}\\left( \\left( 1 - \\alpha, +\\infty \\right) \\right),\\qquad \\text{por propiedades de la inversión de funciones}\\\\ \\Pi &amp; \\geq &amp; G + K + F_S^{-1}\\left( 1 - \\alpha \\right), \\qquad \\text{com $F_S$ es creciente, mínimo se debe satisfacer la desigualdad} \\end{eqnarray*} \\] En especial cuando \\(K = r\\left( \\rho(S) - \\mathbb{E}[S] \\right)\\), la última desigualdad toma la forma \\[ \\Pi \\geq G + r\\left( \\rho(S) - \\mathbb{E}[S] \\right) + F_S^{-1}\\left( 1 - \\alpha \\right) \\] Así, en el caso anterior si se utiliza como medida de riesgo al mismo nivel de confianza \\(1 - \\alpha\\), esto es \\(\\rho( S ) = \\operatorname{VaR}_{1-\\alpha}( S ) = F_S^{-1}( 1 - \\alpha )\\), la última igualdad se cumple si \\(S\\) es una variable aleatoria continua. \\[ \\Pi \\geq G + (1 + r) F_S^{-1}\\left( 1 - \\alpha \\right) - r \\mathbb{E}[S] \\] Si en caso los gastos \\(G\\) son proporcionales a la prima \\(G = \\gamma \\Pi\\), para una constante \\(\\gamma &gt; 0\\), y seguramente \\(\\gamma &lt; 1\\) ya que es de esperar gastos no mayores a la misma prima, sino esto estaría en una situación insostenible donde los gastos son mayores a la cobertura del riesgo. Las desigualdades anteriores toman la forma: \\[ \\begin{eqnarray*} \\Pi &amp; \\geq &amp; \\frac{r}{1 - \\gamma} K + \\frac{1}{1 - \\gamma} F_S^{-1}\\left( 1 - \\alpha \\right) \\\\ \\Pi &amp; \\geq &amp; \\frac{r}{1 - \\gamma} \\left( \\rho(S) - \\mathbb{E}[S] \\right) + \\frac{1}{1 - \\gamma} F_S^{-1}\\left( 1 - \\alpha \\right) \\\\ \\Pi &amp; \\geq &amp; \\frac{1 + r}{1 - \\gamma} F_S^{-1}\\left( 1 - \\alpha \\right) - \\frac{r}{1 - \\gamma} \\mathbb{E}[S] \\end{eqnarray*} \\] De lo anterior se observa, que un buen inicio para estimar la prima de riesgo es ciertamente usar la medida \\(\\operatorname{VaR}_{1-\\alpha}\\) al nivel adecuado de confianza \\(\\alpha\\). 7.3 Prima La prima es la cantidad de dinero que un individuo o entidad pagan por una póliza de seguro, la cual está diseñada para cubrir ciertos riesgos personales o comerciales. La determinación de las primas por parte del asegurador hace uso de la mutualización del riesgo y diversificación, para así poder asumir la transferencia del riesgo por parte de sus asegurados. Así por tanto, es deseable que cualquier método que se utilice para la estimación de primas, se satisfaga, algunas propiedades importantes. Sin consideramos dos riesgos a cubrir \\(S_1\\) y \\(S_2\\), entonces la función que estima \\(\\rho\\) las primas sería aconsejable satisfaga las siguientes propiedades. Si se decide cubrir por completo dos riesgos \\(S_1\\) y \\(S_2\\) en un mismo producto, el valor de la prima deberá ser menor o igual al valor que se resultaría de cubrir cada uno de los riesgos con productos separados. \\[ \\rho( S_1 + S_2 ) \\leq \\rho( S_1 ) + \\rho( S_2 ) \\] El asumir mayor riesgo debe tener como consecuencia el aumento de la prima \\[ \\rho( S_1 ) \\leq \\rho( S_1 + S_2 ) \\] Esta propiedad implica que al configurar un producto de seguro con mejor cobertura, se espera una prima de mayor costo. Si el riesgo a cubrir está limitado, es decir \\(P( S \\leq M ) = 1\\), para un valor \\(M &gt; 0\\), entonces jamás la prima será superior a \\(M\\) \\[ \\rho( S ) \\leq M \\] Esto se traduce a que ningún asegurado estará interesado en adquirir una póliza para cubrir un riesgo por encima del valor total asegurado. Es así que hay algunos principios para la estimación de primas, aquí citamos algunos de los más conocidos: Prima neta, o prima pura de riesgo \\[ \\Pi = \\rho( S ) = \\mathbb{E}[S] \\approx \\overline{S} \\] Prima de riesgo con recargo sobre la esperanza matemática \\[ \\Pi = \\rho( S ) = (1 + \\rho) \\mathbb{E}[S] \\approx (1 + \\rho) \\overline{S} \\] Prima de riesgo con recargo sobre la varianza \\[ \\Pi = \\rho( S ) = \\mathbb{E}[S] + \\rho \\mathbb{V}[S] \\approx \\overline{S} + \\rho \\sigma_S^2 \\] Prima de riesgo con recargo sobre la desviación \\[ \\Pi = \\rho( S ) = \\mathbb{E}[S] + \\rho \\sqrt{\\mathbb{V}[S]} \\approx \\overline{S} + \\rho \\sigma_S \\] Prima de riesgo con principio exponencial para \\(t &gt; 0\\) \\[ \\Pi = \\rho( S ) = \\frac{1}{2} \\mathbb{E}\\left[\\exp(tS)\\right] = \\frac{1}{2} M_N\\big( \\ln M_X( t ) \\big) \\approx \\frac{1}{m} \\sum\\limits_{i=1}^m \\exp\\left(t S_i\\right) \\] Prima de percentiles para un valor de confianza \\(\\alpha \\in [0,1]\\) o prima de valor en riesgo \\(VaR_\\alpha\\) \\[ \\Pi = \\rho( S ) = \\operatorname{VaR}_\\alpha( S ) = F_S^{-1}( \\alpha ) \\] Prima de valor en riesgo en la cola (Tail Value at Risk) \\(TVaR_\\alpha\\). Es el promedio uniforme de todos los valores en riesgo \\(VaR_u\\), con \\(u \\geq \\alpha\\). \\[ \\Pi = \\rho( S ) = \\operatorname{TVaR}_\\alpha( S ) = \\frac{1}{1-\\alpha} \\int\\limits_{\\alpha}^1 \\operatorname{VaR}_u( S )\\ du \\] Ejemplo 7.1 Consideremos el caso donde todos los siniestros son igualmente distribuidos e independientes (i.i.d) \\(X_i \\rightsquigarrow Gamma( \\alpha_i, \\theta )\\), para \\(i \\in \\{1,\\ldots,n\\}\\), el número de unidades aseguradas está dado por \\(n \\in \\mathbb{N}\\). Utilizaremos el modelo individual para la agregación de los reclamos y obtener el reclamo total \\(S = \\sum\\limits_{i=1}^n X_i\\). Como todas las variables \\(X_i\\) siguen una ley \\(Gamma( \\alpha_i, \\theta )\\), sabemos que la familia \\(Gamma\\) es cerrada por adición, es decir, a suma de variables aleatorias con ley \\(Gamma\\) también sigue una ley \\(Gamma\\). En este caso en particular para el reclamo total tenemos que \\(S \\rightsquigarrow Gamma\\left( \\sum\\limits_{i=1}^n \\alpha_i, \\theta \\right)\\). Es de notar que para cada \\(i\\in \\{1,\\ldots,n\\}\\), la variable aleatoria \\(X_i\\) correspondiente al \\(i\\)-ésimo reclamo tiene como parámetro un diferente factor \\(\\alpha_i\\), pero el mismo factor \\(\\theta\\). Ya que cada \\(X_i \\rightsquigarrow Gamma( \\alpha_i, \\theta )\\), podemos calcular de forma determinista las esperanzas de \\(\\mathbb{E}[X_i]\\), para cada \\(i \\in \\{1,\\ldots,n\\}\\) y de igual forma podemos calcular la esperanza del reclamo total \\(\\mathbb{E}[S] = \\sum\\limits_{i=1}^n \\mathbb{E}[X_i]\\). Además como asumimos independencia entre los \\(X_i\\), la varianza de \\(S\\) también puede ser calculada fácilmente como \\(\\mathbb{V}[S] = \\sum\\limits_{i=1}^n \\mathbb{V}[X_i]\\). También estamos en la capacidad de simular la variable \\(S\\) utilizando un algoritmo de aleatorio, para así aproximar los cálculos de sus momentos y otros estadísticos. Primeramente definamos los parámetros. Code # número de unidades aseguradas n &lt;- 1000 # parámetros para cada X_i a &lt;- runif( n, 5, 10 ) # parámetro theta, común a todas las X_i theta &lt;- 4 # parámetro para S A &lt;- sum( a ) Code EX &lt;- a * theta VX &lt;- a * theta^2 ES &lt;- sum( EX ) VS &lt;- sum( VX ) SDS &lt;- sqrt( VS ) La variable aleatoria del reclamo total \\(S\\) la podemos simular tomando una muestra i.i.d de tamaño \\(m\\), i.e. \\(S_1,\\ldots,S_m\\) de la distribución \\(Gamma\\left( \\sum\\limits_{i=1}^n \\alpha_i, \\theta \\right)\\). Code m &lt;- 1e5 S &lt;- rgamma( m, shape = A, scale = theta ) Prima pura: Code P &lt;- ES P &lt;- mean( S ) alpha &lt;- 0.95 P_avg &lt;- ( 1 + alpha ) * ES P_avg &lt;- ( 1 + alpha ) * mean( S ) P_var &lt;- ES + alpha * VS P_var &lt;- mean( S ) + alpha * var( S ) P_sde &lt;- ES + alpha * SDS P_sde &lt;- mean( S ) + alpha * sd( S ) VaRS &lt;- qgamma( alpha, shape = A, scale = theta ) P_VaR &lt;- VaRS P_VaR &lt;- quantile( S, probs = alpha ) P_TVaR &lt;- ( 1 / ( 1 - alpha ) ) * ( A * theta ) * ( 1 - pgamma( VaRS, shape = A + 1, scale = theta ) ) P_TVaR &lt;- ( 1 / ( 1 - alpha ) ) * integrate( f = function( u ) qgamma( u, shape = A, scale = theta ), alpha, 1 )$value P_TVaR &lt;- mean( sapply( runif( m, alpha, 1 ), FUN = function( k ) qgamma( k, shape = A, scale = theta ) ) ) I &lt;- as.numeric( S &gt; VaRS ) P_TVaR &lt;- mean( S * I ) / mean( I ) 7.4 Segmentación En muchas ocasiones es necesario tener en cuenta algunas características asociadas al riesgo de asegurado, de tal forma que la prima sea lo más eficiente y adecuado según el riesgo cubierto y las características del mismo. La idea de segmentar la población es obtener grupos homogéneos con riesgos similares. "],["reserva_tecnicas.html", "Capítulo 8 Reservas técnicas 8.1 Reservas para primas no adquiridas 8.2 Reservas de riesgos en curso 8.3 Reservas de siniestros a pagar", " Capítulo 8 Reservas técnicas 8.1 Reservas para primas no adquiridas 8.2 Reservas de riesgos en curso Esta reserva corresponde a la cantidad restante prima que debería ser prorrateada en el tiempo para cubrir de forma uniforme los reclamos de cada póliza hasta su fecha término. En otras palabras, si tenemos una cantidad de pólizas vendidas \\(n\\), a cada póliza \\(i \\in \\{1, \\ldots, n \\}\\), le corresponde una duración \\(D_i = \\left[ T^1_i, T^2_i \\right]\\), donde \\(T^1_i &gt; 0\\) el tiempo inicial de la vigencia de la póliza, \\(T^2_i &gt; T^1_i\\) el tiempo final de vigencia de la póliza \\(i\\)-ésima y una prima pagada por la cobertura adquirida \\(\\Pi_i\\) por la venta de la \\(i\\)-ésima póliza. Así, la forma más sencilla de calcular la reserva de riesgos en curso \\(RRC\\) en el tiempo \\(t\\), está dada por: \\[ RRC( t ) = \\sum\\limits_{i=1}^n \\mathbf{1}_{D_i}( t ) \\frac{T^2_i - t}{T^2_i - T^1_i} \\Pi_i \\] Esta metodología es la más sencilla, pero no toma en cuenta que no siempre sucede que los reclamos son proporcionales a la cantidad de prima restante en el tiempo. Incluso en el caso que el valor de los reclamos sea proporcional al tiempo restante, no necesariamente será uniformemente proporcional al tiempo restante de cobertura. Esto puede llevar a manera niveles de reservas de primas no óptimos acorde a las operaciones del asegurador. La cantidad de prima que va quedando a favor del asegurador y de la cual en teoría este puede disponer está dada por la prima devengada \\(PDG\\): \\[ PDG( t ) = \\sum\\limits_{i=1}^n \\mathbf{1}_{\\left[T^1_i, +\\infty\\right)}( t ) \\frac{\\min\\left( t, T^2_i \\right) - T^1_i}{T^2_i - T^1_i} \\Pi_i \\] En algunas situaciones se suele considerar tener reserva de primas por el mismo valor constante a los largo de la duración de la póliza. Usualmente esto se lo suele hacer para los productos de corto plazo con duraciones menores de un año. Así se suele dividir el conjunto de pólizas \\(\\{1,\\ldots,n\\} = I \\cup J\\) en dos conjuntos disjuntos, donde \\(I\\) contiene a las pólizas para las cuales se reserva proporcionalmente al tiempo y la prima y \\(J\\) contiene aquellas pólizas para las cuales se mantiene la reserva constante por toda la duración de la póliza. \\[ RRC( t ) = \\sum\\limits_{i \\in I} \\mathbf{1}_{D_i}( t ) \\frac{T^2_i - t}{T^2_i - T^1_i} \\Pi_i + \\sum\\limits_{i \\in J} \\mathbf{1}_{D_i}( t ) \\Pi_i \\] de igual manera la prima devengada \\(PDG\\) está dada por: \\[ PDG( t ) = \\sum\\limits_{i \\in I} \\mathbf{1}_{\\left[T^1_i, +\\infty\\right)}( t ) \\frac{\\min\\left( t, T^2_i \\right) - T^1_i}{T^2_i - T^1_i} \\Pi_i + \\sum\\limits_{i \\in J} \\mathbf{1}_{\\left(T^2_i,+\\infty\\right)}( t ) \\Pi_i \\] Para dar mayor realidad al cálculo de la reserva de riesgos en curso \\(RRC\\), podemos incluir los costos de adquisición \\(A_i\\) por cada una de las pólizas vendidas \\(i \\in \\{1, \\ldots, n \\}\\). Usualmente, este valor ya se incluye en el valor de la prima, pero es directamente utilizado para solventar los costos de adquisición. De ahí que resulta razonable quitar estos costos de la prima, para así ajustar la \\(RRC\\). \\[ RRC( t ) = \\sum\\limits_{i \\in I} \\mathbf{1}_{D_i}( t ) \\frac{T^2_i - t}{T^2_i - T^1_i} \\left( \\Pi_i - A_i \\right) + \\sum\\limits_{i \\in J} \\mathbf{1}_{D_i}( t ) \\left( \\Pi_i - A_i \\right) \\] y de igual forma la prima devengada \\[ PDG( t ) = \\sum\\limits_{i \\in I} \\mathbf{1}_{\\left[T^1_i, +\\infty\\right)}( t ) \\frac{\\min\\left( t, T^2_i \\right) - T^1_i}{T^2_i - T^1_i} \\left( \\Pi_i - A_i \\right) + \\sum\\limits_{i \\in J} \\mathbf{1}_{\\left(T^2_i,+\\infty\\right)}( t ) \\left( \\Pi_i - A_i \\right) \\] 8.3 Reservas de siniestros a pagar \\(T\\) 8.3.1 Siniestros sucedidos, reportados, resueltos, no pagados 8.3.2 Siniestros sucedidos, reportados, no resueltos, no pagados 8.3.3 Siniestros sucedidos, no reportados, no resueltos, no pagados La siguiente lista, aunque no exhaustiva, citamos algunos de los métodos que se utiliza para estimar reserva \\(IBNR\\), para más detalle se puede consultar [19] o [16]. Chain-Ladder Chain-Ladder con mínimos cuadrados Benktander-Hovinen Cape-Cod Mack Modelos Bayesianos Markov chain Monte Carlo Bühlmann-Straub Modelos basados en distribuciones GLM \\[ IBNR \\] "],["modelos_glm.html", "Capítulo 9 Modelos lineales generalizados (GLM) 9.1 Familia exponencial 9.2 Modelo lineal generalizado (GLM)", " Capítulo 9 Modelos lineales generalizados (GLM) 9.1 Familia exponencial De forma amplia, un modelo lineal generalizado aprovecha algunas propiedades de la distribución de probabilidad \\(f_X\\) de la variable (vector) aleatoria \\(X : \\Omega \\longrightarrow \\mathbb{R}^n\\) en estudio. Se parte de asumir que \\(X\\) tiene una distribución dentro de la familia exponencial, es decir, existen: Un conjunto admisible de parámetros \\(\\Theta \\subset \\mathbb{R}^m\\), así cada parámetro \\(\\theta = ( \\theta_1, \\ldots, \\theta_m )^T \\in \\Theta\\), Una función \\(T: \\mathbb{R}^n \\longrightarrow \\mathbb{R}^p\\) Una función \\(A: \\mathbb{R}^m \\longrightarrow \\mathbb{R}\\) Una función \\(\\eta: \\mathbb{R}^m \\longrightarrow \\mathbb{R}^p\\) de tal forma que: \\[ f_X( x \\mid \\theta ) = h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right) \\] Al tener varias observaciones independientes de la misma variable aleatoria \\(x_1, \\ldots, x_N\\), su distribución conjunta se puede expresar como: \\[ f_{X_1,\\ldots,X_N}( x_1, \\ldots, x_N \\mid \\theta ) = \\prod\\limits_{i=1}^N f_{X_i}( x_i \\mid \\theta ) \\] La función de verosimilitud logarítmica, “log-likelihood”, toma una forma específica, la cual puede ser trabajada con comodidad para la maximización de verosimilitud. \\[ \\begin{eqnarray*} \\ell( \\theta ) &amp; = &amp; \\log f_{X_1,\\ldots,X_N}( x_1, \\ldots, x_N \\mid \\theta ) \\\\ &amp; = &amp; \\sum\\limits_{i=1}^N \\log f_{X_i}( x_i \\mid \\theta ) \\\\ &amp; = &amp; \\sum\\limits_{i=1}^N \\left( \\log h( x_i ) + \\eta( \\theta ) \\cdot T( x_i ) - A( \\theta ) \\right) \\end{eqnarray*} \\] lo que podemos observar es que existe una casi linealidad respecto de la variable \\(\\theta\\). Esta propiedad permite obtener un problema de maximización de verosimilitud que puede ser atacado con varios paquetes de optimización numérica de una forma eficiente. \\[ \\underset{\\theta \\in \\Theta}{\\sup} \\ell( \\theta ) = \\underset{\\theta \\in \\Theta}{\\sup} \\sum\\limits_{i=1}^N \\left( \\eta( \\theta ) \\cdot T( x_i ) - A( \\theta ) \\right) \\] Usualmente, este problema se suele atacar mediante la anulación del gradiente de la función objetivo, esto lo realiza la mayor parte de paquetes de software. El sistema a resolver es el siguiente sistema, usualmente no lineal, de dimensión \\(m\\): \\[ \\frac{\\partial\\ell}{\\partial\\theta_i}( \\theta ) = \\sum\\limits_{i=1}^N \\left( \\frac{\\partial\\eta}{\\partial\\theta_i}( \\theta ) \\cdot T( x_i ) - \\frac{\\partial A}{\\partial\\theta_i}( \\theta ) \\right) = 0,\\qquad \\forall i \\in \\{1,\\ldots, m\\} \\] En la familia exponential tenemos las siguientes distribuciones: normal, exponencial, log-normal, gamma, chi-cuadrado, beta, Dirichlet, Bernoulli, Poisson, binomial, geométrica, binomial negativa, von Mises-Fisher, Pareto con valor mínimo conocido, Gaussiana inversa, gamma inversa, multinomial con número \\(n\\) conocido, Wishart, categórica. Por la condición de normalización de la densidad de probabilidad \\(f_X\\), se satisface la igualdad: \\[ \\begin{eqnarray*} 1 &amp; = &amp; \\int\\limits f_X( x \\mid \\theta )\\ dx \\\\ 1 &amp; = &amp; \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right)\\ dx \\\\ 1 &amp; = &amp; \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) \\right) \\exp\\left( - A( \\theta ) \\right)\\ dx \\\\ 1 &amp; = &amp; \\exp\\left( - A( \\theta ) \\right) \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) \\right)\\ dx \\\\ \\exp\\left( A( \\theta ) \\right) &amp; = &amp; \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) \\right)\\ dx \\\\ A( \\theta ) &amp; = &amp; \\log\\left( \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) \\right)\\ dx \\right) \\end{eqnarray*} \\] de donde se determina precisamente la forma que tiene la función \\(A\\) y su el papel como factor de normalización para la distribución de la variable aleatoria \\(X\\). Así mismo, podemos establecer una cierta relación para la espera de los valores observados de \\(T(X)\\) en función de \\(A\\) \\[ \\begin{eqnarray*} 0 &amp; = &amp; \\frac{\\partial}{\\partial\\theta_i} 1 \\\\ 0 &amp; = &amp; \\frac{\\partial}{\\partial\\theta_i} \\int\\limits f_X( x \\mid \\theta )\\ dx \\\\ 0 &amp; = &amp; \\int\\limits h( x ) \\frac{\\partial}{\\partial\\theta_i} \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right)\\ dx \\\\ 0 &amp; = &amp; \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right) \\left( \\frac{\\partial\\eta}{\\partial\\theta_i}( \\theta ) \\cdot T( x ) - \\frac{\\partial A}{\\partial\\theta_i}( \\theta ) \\right)\\ dx \\\\ 0 &amp; = &amp; \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right) \\frac{\\partial\\eta}{\\partial\\theta_i}( \\theta ) \\cdot T( x )\\ dx \\\\ &amp; &amp; - \\frac{\\partial A}{\\partial\\theta_i} ( \\theta ) \\int\\limits h( x ) \\exp\\left( \\eta( \\theta ) \\cdot T( x ) - A( \\theta ) \\right)\\ dx \\\\ 0 &amp; = &amp; \\int \\limits \\frac{\\partial\\eta}{\\partial\\theta_i}( \\theta ) \\cdot T( x ) f_X( x \\mid \\theta )\\ dx - \\frac{\\partial A}{\\partial\\theta_i}( \\theta ) \\int \\limits f_X( x \\mid \\theta )\\ dx \\end{eqnarray*} \\] estamos en la capacidad de concluir que: \\[ \\mathbb{E}\\left[ \\frac{\\partial\\eta}{\\partial\\theta_i}( \\theta ) \\cdot T( X ) \\right] = \\frac{\\partial A}{\\partial\\theta_i}( \\theta ) \\] Cuando se da el caso que \\(\\eta\\) y \\(T\\) son las funciones identidad, la relación anterior se reduce a la siguiente igualdad: \\[ \\mathbb{E}\\left[ X_i \\right] = \\frac{\\partial A}{\\partial\\theta_i}( \\theta ) \\] 9.2 Modelo lineal generalizado (GLM) Precisamente, un modelo lineal generalizado (GLM por sus siglas en inglés) busca explotar las propiedades de las variables aleatorias que poseen una densidad de probabilidad dada por alguna de la funciones de la familia exponencial. Para más detalles se puede consultar [5]. La idea general es poder describir el comportamiento de una variable aleatoria \\(Y\\) que se presume puede ser descrita por alguna función de la familia exponencial, a partir de otras variables aleatorias \\(X : \\Omega \\longrightarrow \\mathbb{R}^n\\) mediante una función de vínculo \\(g: \\mathbb{R}^q \\longrightarrow \\mathbb{R}^m\\) entre \\(\\theta\\) y \\(X\\), a través del paso por una composición con una función lineal \\(\\beta : \\mathbb{R}^n \\longrightarrow \\mathbb{R}^q\\), de tal forma que: \\[ \\theta = g( \\beta( X ) ) = g( \\beta X ) \\] Así, un GLM prescribe una distribución de probabilidad para \\(Y\\) que tendrá la siguiente forma y será dependiente de los parámetros \\(\\beta\\) y las variables explicativas \\(X\\) \\[ f_Y( y \\mid \\theta ) = f_Y( y \\mid g( \\beta x ) ) = h( y ) \\exp\\left( \\eta( g( \\beta x ) ) \\cdot T( y ) - A( g( \\beta x ) ) \\right) \\] En la aplicación, el ajuste de un modelo GLM a \\(N \\in \\mathbb{N}\\) observaciones \\(y_1, \\ldots, y_N\\) de la variable aleatoria \\(Y\\) y sus respectivas variables explicativas \\(x_1, \\ldots, x_N\\). Se asume independencias entre las observaciones y se busca maximizar la verosimilitud de los valores observados, pero en función del nuevo parámetro \\(\\beta\\), de ahí la parte lineal del modelo. \\[ \\ell( \\beta ) = \\sum\\limits_{i=1}^N \\left( \\log h( y_i ) + \\eta( g( \\beta x_i ) ) \\cdot T( y_i ) - A( g( \\beta x_i ) \\right) \\] De ello resulta el problema de maximización de verosimilitud que se busca resolver para ajustar un modelo GLM. \\[ \\underset{\\beta \\in \\mathbb{R}^{q \\times n}}{\\sup} \\ell( \\beta ) = \\underset{\\beta \\in \\mathbb{R}^{q \\times n}}{\\sup} \\sum\\limits_{i=1}^N \\left( \\log h( y_i ) + \\eta( g( \\beta x_i ) ) \\cdot T( y_i ) - A( g( \\beta x_i ) \\right) \\] es de notar que el término \\(\\sum\\limits_{i=1}^N \\log h( y_i )\\) no depende de \\(\\beta\\) y por tal razón puede ser omitido al momento de maximizar la verosimilitud. En varias ocasiones no todos los parámetros \\(\\theta\\) de la densidad de probabilidad son considerados, sino tan solo una parte de los mismos, los otros parámetros se consideran como un valor constante ya dado o también como un parámetro a determinar. Así, se divide \\(\\theta = ( \\theta_1, \\theta_2 ), \\theta_1 \\in \\mathbb{R}^{m_1}, \\theta_2 \\in \\mathbb{R}^{m_2}, m = m_1 + m_2\\), donde solo se establece una función de vínculo para la primera parte \\(\\theta_1 = g( \\beta X )\\). Esta consideración en muchos casos ayuda a simplificar la formulación del modelo y el costo computacional de estimación. En este contexto la función de verosimilitud tomaría la forma: \\[ \\ell( \\beta, \\theta_2 ) = \\sum\\limits_{i=1}^N \\left( \\log h( y_i ) + \\eta( g( \\beta x_i ), \\theta_2 ) \\cdot T( y_i ) - A( g( \\beta x_i ), \\theta_2 ) \\right) \\] Ejemplo 9.1 (Regresión de Poisson) En este caso presentamos el modelo bastante utilizado conocido como regresión de Poisson. En donde suponemos que \\(N \\rightsquigarrow Pois( \\lambda( x ) ER( x ) ) = Pois( g( \\beta x ) ER( x ) )\\) donde \\(\\lambda\\) es el parámetro a estimar en función de las variables explicativas \\(x\\). \\[ \\mathbb{E}[ N ] = \\lambda( x ) ER( x ) = g( \\beta x ) ER( x ) \\] \\[ P( N = n ) = \\exp(-g( \\beta x ) ER( x )) \\frac{g( \\beta x )^n ER( x )^n}{n!} \\] Code # la librería CASdatasets fue previamente cargada data( beMTPL97 ) beMTPL97 &lt;- as.data.table( beMTPL97 ) # Impresión de las primeras filas de la tabla beMTPL97[ 1:100 ] %&gt;% kable( label = NA, caption = &quot;Pólizas y reclamos de automóviles en Bélgica&quot;, row.names = FALSE, col.names = names( beMTPL97 ), align = paste0( rep( &quot;r&quot;, ncol( beMTPL97 ) ), collapse = &quot;&quot; ), digits = c( 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4 ), format.args = list( big.mark = &#39;,&#39;, decimal.mark = &#39;.&#39;, scientific = FALSE ), escape = FALSE, centering = TRUE ) %&gt;% kable_classic( font_size = 14, full_width = FALSE, html_font = &quot;Cambria&quot;, position = &quot;center&quot; ) %&gt;% scroll_box( width = &quot;100%&quot;, height = &quot;500px&quot; ) Tabla 9.1: Pólizas y reclamos de automóviles en Bélgica id expo claim nclaims amount average coverage ageph sex bm power agec fuel use fleet postcode long lat 1 1.00 1 1 1,618.00 1,618.00 TPL 50 male 5 77 12 gasoline private 0 1,000 4.3552 50.8454 2 1.00 0 0 0.00 NaN TPL+ 64 female 5 66 3 gasoline private 0 1,000 4.3552 50.8454 3 1.00 0 0 0.00 NaN TPL 60 male 0 70 10 diesel private 0 1,000 4.3552 50.8454 4 1.00 0 0 0.00 NaN TPL 77 male 0 57 15 gasoline private 0 1,000 4.3552 50.8454 5 0.05 1 1 155.97 155.97 TPL 28 female 9 70 7 gasoline private 0 1,000 4.3552 50.8454 6 1.00 0 0 0.00 NaN TPL 26 male 11 70 12 gasoline private 0 1,000 4.3552 50.8454 7 1.00 1 1 155.97 155.97 TPL++ 26 male 11 55 8 gasoline private 0 1,000 4.3552 50.8454 8 0.40 0 0 0.00 NaN TPL 58 female 11 47 14 gasoline private 0 1,000 4.3552 50.8454 9 1.00 0 0 0.00 NaN TPL++ 59 male 0 98 3 gasoline private 0 1,000 4.3552 50.8454 10 1.00 0 0 0.00 NaN TPL+ 34 male 7 74 6 gasoline private 0 1,000 4.3552 50.8454 11 1.00 1 1 544.87 544.87 TPL++ 39 male 1 85 2 diesel private 0 1,000 4.3552 50.8454 12 0.98 0 0 0.00 NaN TPL 55 male 11 87 6 diesel private 0 1,000 4.3552 50.8454 13 1.00 0 0 0.00 NaN TPL+ 77 male 9 104 6 gasoline private 0 1,000 4.3552 50.8454 14 0.97 0 0 0.00 NaN TPL 49 male 8 71 19 gasoline private 0 1,000 4.3552 50.8454 15 0.58 0 0 0.00 NaN TPL 63 male 0 104 7 gasoline private 0 1,000 4.3552 50.8454 16 1.00 0 0 0.00 NaN TPL++ 43 male 1 85 2 diesel private 1 1,000 4.3552 50.8454 17 1.00 0 0 0.00 NaN TPL+ 51 male 0 113 7 gasoline private 1 1,000 4.3552 50.8454 18 0.21 0 0 0.00 NaN TPL 67 male 10 130 6 gasoline private 0 1,000 4.3552 50.8454 19 0.18 0 0 0.00 NaN TPL 52 male 0 125 16 gasoline private 0 1,000 4.3552 50.8454 20 0.89 0 0 0.00 NaN TPL++ 40 male 0 66 1 diesel private 0 1,000 4.3552 50.8454 21 1.00 0 0 0.00 NaN TPL+ 45 male 2 128 6 gasoline private 0 1,000 4.3552 50.8454 22 1.00 1 1 252.03 252.03 TPL 34 male 6 119 9 gasoline private 0 1,000 4.3552 50.8454 23 0.85 0 0 0.00 NaN TPL+ 47 male 0 85 4 gasoline private 0 1,000 4.3552 50.8454 24 1.00 0 0 0.00 NaN TPL+ 51 male 1 98 8 gasoline private 0 1,000 4.3552 50.8454 25 1.00 0 0 0.00 NaN TPL 61 male 3 98 8 gasoline private 0 1,000 4.3552 50.8454 26 0.90 0 0 0.00 NaN TPL 65 male 7 51 11 diesel private 0 1,000 4.3552 50.8454 27 1.00 0 0 0.00 NaN TPL 57 male 0 98 7 gasoline private 0 1,000 4.3552 50.8454 28 1.00 0 0 0.00 NaN TPL 38 male 11 74 15 gasoline private 0 1,000 4.3552 50.8454 29 1.00 0 0 0.00 NaN TPL+ 59 male 1 85 4 gasoline private 1 1,000 4.3552 50.8454 30 1.00 0 0 0.00 NaN TPL 31 male 9 98 7 gasoline private 0 1,000 4.3552 50.8454 31 1.00 1 2 232.60 116.30 TPL 33 male 4 101 9 gasoline private 0 1,000 4.3552 50.8454 32 1.00 0 0 0.00 NaN TPL 53 male 10 55 6 diesel private 0 1,000 4.3552 50.8454 33 1.00 0 0 0.00 NaN TPL+ 47 male 1 55 7 diesel work 0 1,000 4.3552 50.8454 34 1.00 0 0 0.00 NaN TPL+ 65 male 0 110 5 gasoline private 0 1,000 4.3552 50.8454 35 1.00 0 0 0.00 NaN TPL+ 62 female 1 55 11 gasoline private 0 1,000 4.3552 50.8454 36 1.00 0 0 0.00 NaN TPL++ 39 male 4 66 5 diesel work 0 1,000 4.3552 50.8454 37 0.68 0 0 0.00 NaN TPL++ 64 male 0 66 5 diesel private 0 1,000 4.3552 50.8454 38 0.84 0 0 0.00 NaN TPL+ 28 male 5 59 8 diesel private 0 1,000 4.3552 50.8454 39 0.98 0 0 0.00 NaN TPL 56 male 1 98 6 gasoline private 0 1,000 4.3552 50.8454 40 1.00 1 1 62.42 62.42 TPL 41 female 11 66 10 gasoline private 0 1,000 4.3552 50.8454 41 1.00 0 0 0.00 NaN TPL++ 28 male 0 85 4 gasoline private 0 1,000 4.3552 50.8454 42 0.17 0 0 0.00 NaN TPL+ 58 male 10 50 7 diesel private 0 1,000 4.3552 50.8454 43 0.48 0 0 0.00 NaN TPL 31 male 11 50 8 diesel private 0 1,000 4.3552 50.8454 44 0.20 0 0 0.00 NaN TPL 40 male 0 66 14 gasoline private 0 1,000 4.3552 50.8454 45 1.00 0 0 0.00 NaN TPL+ 70 female 0 55 4 diesel private 0 1,000 4.3552 50.8454 46 1.00 0 0 0.00 NaN TPL+ 51 male 3 55 10 gasoline private 0 1,000 4.3552 50.8454 47 1.00 0 0 0.00 NaN TPL++ 57 male 3 110 2 gasoline work 1 1,000 4.3552 50.8454 48 1.00 1 1 164.65 164.65 TPL 47 male 11 55 16 gasoline private 0 1,000 4.3552 50.8454 49 1.00 0 0 0.00 NaN TPL+ 46 male 0 44 16 gasoline private 0 1,000 4.3552 50.8454 50 1.00 0 0 0.00 NaN TPL++ 31 male 10 110 3 gasoline private 0 1,000 4.3552 50.8454 51 0.59 0 0 0.00 NaN TPL+ 66 male 0 50 9 diesel private 0 1,000 4.3552 50.8454 52 1.00 1 1 562.72 562.72 TPL++ 36 male 0 98 4 gasoline private 0 1,000 4.3552 50.8454 53 1.00 1 1 461.75 461.75 TPL++ 37 male 5 94 7 gasoline private 0 1,000 4.3552 50.8454 54 1.00 0 0 0.00 NaN TPL+ 36 male 0 55 2 gasoline private 0 1,000 4.3552 50.8454 55 1.00 0 0 0.00 NaN TPL 78 male 1 87 8 gasoline private 0 1,000 4.3552 50.8454 56 1.00 0 0 0.00 NaN TPL 58 male 0 151 23 gasoline private 0 1,000 4.3552 50.8454 57 1.00 0 0 0.00 NaN TPL+ 31 male 12 66 2 gasoline work 0 1,000 4.3552 50.8454 58 1.00 1 2 2,852.76 1,426.38 TPL++ 24 male 11 70 2 gasoline private 0 1,000 4.3552 50.8454 59 1.00 0 0 0.00 NaN TPL 74 female 5 29 14 gasoline private 0 1,000 4.3552 50.8454 60 1.00 0 0 0.00 NaN TPL 26 female 11 29 5 gasoline private 0 1,000 4.3552 50.8454 61 1.00 0 0 0.00 NaN TPL++ 46 male 0 75 2 gasoline work 0 1,000 4.3552 50.8454 62 0.13 0 0 0.00 NaN TPL 34 male 4 100 16 gasoline private 0 1,000 4.3552 50.8454 63 0.29 0 0 0.00 NaN TPL 51 male 0 85 5 gasoline private 0 1,000 4.3552 50.8454 64 1.00 1 1 16.86 16.86 TPL++ 54 male 0 103 3 gasoline work 0 1,000 4.3552 50.8454 65 1.00 0 0 0.00 NaN TPL++ 43 male 0 85 7 diesel private 0 1,000 4.3552 50.8454 66 1.00 0 0 0.00 NaN TPL+ 35 male 1 105 5 diesel private 0 1,000 4.3552 50.8454 67 1.00 0 0 0.00 NaN TPL 37 male 10 95 8 gasoline work 0 1,000 4.3552 50.8454 68 1.00 1 2 99.23 49.62 TPL+ 56 male 13 103 3 gasoline work 0 1,000 4.3552 50.8454 69 1.00 0 0 0.00 NaN TPL+ 39 male 0 75 4 gasoline work 0 1,000 4.3552 50.8454 70 1.00 0 0 0.00 NaN TPL 62 female 0 65 12 gasoline private 0 1,000 4.3552 50.8454 71 1.00 0 0 0.00 NaN TPL++ 33 male 5 110 6 gasoline private 0 1,000 4.3552 50.8454 72 0.13 0 0 0.00 NaN TPL 24 male 9 83 10 gasoline private 0 1,000 4.3552 50.8454 73 1.00 0 0 0.00 NaN TPL++ 39 male 4 110 4 gasoline private 0 1,000 4.3552 50.8454 74 1.00 0 0 0.00 NaN TPL 36 male 11 72 8 gasoline private 0 1,000 4.3552 50.8454 75 1.00 0 0 0.00 NaN TPL 37 male 11 77 16 gasoline private 0 1,000 4.3552 50.8454 76 0.45 0 0 0.00 NaN TPL 52 male 6 63 12 diesel private 0 1,000 4.3552 50.8454 77 0.47 0 0 0.00 NaN TPL 27 male 11 92 14 gasoline private 0 1,000 4.3552 50.8454 78 0.64 0 0 0.00 NaN TPL++ 33 male 12 75 3 gasoline work 0 1,000 4.3552 50.8454 79 0.34 0 0 0.00 NaN TPL++ 43 male 0 85 1 diesel private 0 1,000 4.3552 50.8454 80 1.00 0 0 0.00 NaN TPL++ 68 male 0 110 7 gasoline work 1 1,000 4.3552 50.8454 81 1.00 0 0 0.00 NaN TPL+ 55 female 0 92 14 gasoline private 0 1,000 4.3552 50.8454 82 0.38 0 0 0.00 NaN TPL+ 41 male 5 124 8 gasoline work 0 1,000 4.3552 50.8454 83 0.55 0 0 0.00 NaN TPL 55 male 1 90 16 gasoline private 0 1,000 4.3552 50.8454 84 1.00 0 0 0.00 NaN TPL 43 female 0 85 3 gasoline private 0 1,000 4.3552 50.8454 85 1.00 1 1 1,837.16 1,837.16 TPL+ 35 male 8 85 5 diesel private 0 1,000 4.3552 50.8454 86 1.00 0 0 0.00 NaN TPL++ 29 male 14 66 2 diesel work 0 1,000 4.3552 50.8454 87 1.00 1 1 158.38 158.38 TPL 45 female 11 83 9 gasoline private 0 1,000 4.3552 50.8454 88 0.46 0 0 0.00 NaN TPL++ 51 male 0 83 5 gasoline private 0 1,000 4.3552 50.8454 89 1.00 0 0 0.00 NaN TPL++ 51 male 0 110 1 gasoline private 1 1,000 4.3552 50.8454 90 1.00 1 1 1,306.10 1,306.10 TPL 23 male 8 90 6 gasoline private 0 1,000 4.3552 50.8454 91 1.00 0 0 0.00 NaN TPL++ 36 female 0 74 8 gasoline private 0 1,000 4.3552 50.8454 92 1.00 1 1 1,363.41 1,363.41 TPL 27 male 11 66 3 diesel private 0 1,000 4.3552 50.8454 93 0.07 0 0 0.00 NaN TPL 29 male 13 75 4 gasoline work 0 1,000 4.3552 50.8454 94 1.00 1 1 70.80 70.80 TPL++ 54 male 4 110 4 gasoline private 0 1,000 4.3552 50.8454 95 1.00 0 0 0.00 NaN TPL++ 68 male 0 85 4 diesel private 0 1,000 4.3552 50.8454 96 1.00 0 0 0.00 NaN TPL+ 58 female 4 110 10 gasoline work 0 1,000 4.3552 50.8454 97 1.00 0 0 0.00 NaN TPL+ 69 male 1 85 11 diesel work 1 1,000 4.3552 50.8454 98 1.00 0 0 0.00 NaN TPL+ 52 female 0 68 2 diesel private 0 1,000 4.3552 50.8454 99 1.00 0 0 0.00 NaN TPL 34 male 3 19 8 gasoline private 0 1,000 4.3552 50.8454 100 1.00 0 0 0.00 NaN TPL++ 34 male 12 51 1 diesel private 0 1,000 4.3552 50.8454 Code model_N &lt;- glm( formula = nclaims ~ ageph + sex + power + fuel + offset( log( expo ) ) + 0, family = poisson( link = &#39;log&#39; ), data = beMTPL97 ) Code dat &lt;- tidy( model_N ) dat %&gt;% kable( label = NA, caption = &quot;Resultados del modelo GLM&quot;, row.names = FALSE, col.names = names( dat ), align = &#39;lrrrr&#39;, digits = c( 0, 6, 6, 6, 6 ), format.args = list( big.mark = &#39;,&#39;, decimal.mark = &#39;.&#39;, scientific = FALSE ), escape = FALSE, centering = TRUE ) %&gt;% kable_classic( font_size = 14, full_width = FALSE, html_font = &quot;Cambria&quot;, position = &quot;center&quot; ) %&gt;% scroll_box( width = &quot;100%&quot;, height = &quot;300px&quot; ) Tabla 9.2: Resultados del modelo GLM term estimate std.error statistic p.value ageph -0.015627 0.000508 -30.790409 0 sexfemale -1.409836 0.032166 -43.830099 0 sexmale -1.458010 0.034274 -42.539517 0 power 0.002499 0.000372 6.714624 0 fueldiesel 0.140048 0.015098 9.275900 0 Code dat &lt;- glance( model_N ) dat %&gt;% kable( label = NA, caption = &quot;Resultados del modelo GLM&quot;, row.names = FALSE, col.names = names( dat ), align = paste0( rep( &quot;r&quot;, ncol( dat ) ), collapse = &quot;&quot; ), digits = c( 4, 0, 2, 2, 2, 2, 0, 0 ), format.args = list( big.mark = &#39;,&#39;, decimal.mark = &#39;.&#39;, scientific = FALSE ), escape = FALSE, centering = TRUE ) %&gt;% kable_classic( font_size = 14, full_width = FALSE, html_font = &quot;Cambria&quot;, position = &quot;center&quot; ) %&gt;% scroll_box( width = &quot;100%&quot;, height = &quot;200px&quot; ) Tabla 9.3: Resultados del modelo GLM null.deviance df.null logLik AIC BIC deviance df.residual nobs 260,163.9 163,212 -63,171.99 126,354 126,404 88,651.89 163,207 163,212 Code pob &lt;- expand.grid( ageph = seq( 18, 90, 1 ), sex = c( &#39;male&#39;, &#39;female&#39; ), power = seq( 10, 250 ), fuel = c( &#39;gasoline&#39;, &#39;diesel&#39; ), expo = 1 ) pob &lt;- as.data.table( pob ) pob[ , EN := predict( model_N, newdata = pob, type = &#39;response&#39; ) ] "],["estimacion_valores_extremos.html", "Capítulo 10 Estimación de valores extremos 10.1 Estimación con valores extremos 10.2 Simulación con valores extremos", " Capítulo 10 Estimación de valores extremos Definición 10.1 (Distribución con cola pesada) Una variable aleatoria a valores reales \\(X\\) se dice que tiene su distribución \\(F\\) es de cola pesada hacia la derecha si el siguiente límite no es finito. \\[ \\underset{x \\rightarrow +\\infty}{\\lim} \\exp( t x ) P( X &gt; x ) = \\underset{x \\rightarrow +\\infty}{\\lim} \\exp( t x ) ( 1 - F( x ) ) = + \\infty, \\qquad \\forall t &gt; 0 \\] de forma muy similar diremos que la distribución tiene cola pesada hacia la izquierda si \\[ \\underset{x \\rightarrow -\\infty}{\\lim} \\exp( -t x ) P( X \\leq x ) = \\underset{x \\rightarrow -\\infty}{\\lim} \\exp( -t x ) F( x ) = + \\infty, \\qquad \\forall t &gt; 0 \\] Como consecuencia de la definición anterior, las variables aleatoria a valores reales que tiene cola pesada no poseen función generadora de momentos ya que la integral a continuación diverge para cualquier valor \\(t &gt; 0\\) \\[ \\int\\limits_{\\mathbb{R}} \\exp( t x ) dF( x ) = + \\infty \\] Teorema 10.1 (Fisher-Tippett-Gnedenko) Si consideramos una secuencia de variables aleatorias \\(\\{X_i\\}_{i\\in \\mathbb{N}}\\) las mismas son i.i.d, con distribución acumulada \\(F\\). Entonces, si existen dos sucesiones de valores reales \\(\\{a_n\\}_{n \\in \\mathbb{N}}\\) y \\(\\{b_n\\}_{n \\in \\mathbb{N}}\\), con \\(a_n &gt; 0\\) para cualquier \\(n \\in \\mathbb{N}\\) y una distribución acumulada no degenerada \\(G\\), de tal forma que para la variable aleatoria del máximo \\(M_n = \\max\\{ X_1, \\ldots, X_n \\}\\) se satisfaga el siguiente límite \\[ \\underset{n \\rightarrow +\\infty}{\\lim} P\\left( \\frac{M_n - b_n}{a_n} &lt; x\\right) = \\underset{n \\rightarrow +\\infty}{\\lim} ( F\\left( a_n x + b_n \\right) )^n = G( x ), \\forall x \\in \\mathbb{R} \\] decimos por tanto que la distribución \\(F\\) pertenece al máximo dominio de atracción de \\(G\\) y lo representamos por \\(F \\in MDA( G )\\). Además, las distribuciones \\(G\\) vienen caracterizadas por ser alguna de las distribuciones valores extremos generalizadas \\(GEV( \\mu, \\sigma, \\xi )\\). Las cuales engloban tres tipos relevantes: Tipo I, una distribución de Gumbel \\(G(x) = \\exp\\left( -\\exp\\left( -\\frac{x-\\mu}{\\sigma} \\right) \\right)\\), para \\(x \\in \\mathbb{R}, \\xi = 0\\) Tipo II, una distribución de Fréchet \\(G( x ) = \\exp\\left( -\\left(1 + \\xi\\frac{x-\\mu}{\\sigma}\\right)^{-\\frac{1}{\\xi}} \\right)\\), para \\(x &gt; \\mu - \\frac{\\sigma}{\\xi}\\) y \\(\\frac{1}{\\xi} &gt; 0\\), Tipo III, una distribución de Weibull inversa \\(G( x ) = \\exp\\left( -\\left(1 - |\\xi|\\frac{x-\\mu}{\\sigma}\\right)^{\\frac{1}{\\xi}} \\right)\\), para \\(x &lt; \\mu + \\frac{\\sigma}{|\\xi|}\\) y \\(\\frac{1}{\\xi} &lt; 0\\), Teorema 10.2 (Pickands-Balkema-De Haan) Sea \\(F_u\\) la distribución de exceso asociada a la variable aleatoria \\(X\\) y con umbral de condicionamiento \\(u &gt; 0\\). Entonces, para cualquier \\(\\varepsilon \\in \\mathbb{R}\\) tenemos que \\(F \\in MDA( H )\\) para alguna distribución \\(H = GEV( \\mu, \\sigma, \\varepsilon )\\) si y solamente si existe una distribución \\(G = GPD( \\nu, \\beta, \\varepsilon )\\), de tal forma que el siguiente límite se satisface por la distribución de exceso \\(F_u\\). \\[ \\underset{u \\longrightarrow x_F}{\\lim} \\underset{0 &lt; x &lt; x_F - u}{\\sup} \\left| F_u( x ) - G( x ) \\right| = 0 \\] donde \\(x_F = \\sup\\{ x\\in \\mathbb{R}\\mid F(x) &lt; 1 \\}\\) y \\(\\nu, \\beta\\) dependen de los parámetros \\(\\mu\\), \\(\\sigma\\) y \\(u\\). El teorema anterior 10.2 en cierta forma sugiere que si en el límite la distribución de exceso a partir de un valor de condicionamiento \\(u\\) cada vez se comporta más como una distribución de generalizada de Pareto. Entonces, la distribución de los máximos que se observen de una muestra de la variable aleatoria \\(X\\) tienen un comportamiento que puede ser descrito por una distribución de valores extremos generalizada. Un forma de estimar si hay la posibilidad de presentar valores extremos es tomando un corte a un nivel \\(u\\) de los valores observados de reclamos \\(X_1, \\ldots, X_n\\), es decir tomar de la muestra todos los valores \\(\\{ X_i \\mid X_i \\geq u \\}\\), a estos valores realizarles un test de ajuste a una distribución de Pareto generalizada \\(GPD( \\nu, \\beta, \\varepsilon )\\), si el test es aceptable y no se rechaza la hipótesis nula, entonces tenemos el resultado de aproximación anterior 10.2. Luego se puede simular los reclamos de forma condicional. Es importante observar antes de continuar que para estudiar los valores extremos de reclamos estos no deben haber pasado por alguna deducción, después de aplicar alguna función deducible \\(D\\), sino posiblemente estaremos en el caso inútil de tener valores truncados, con una cola limitada, para los cuales es imposible estimar de forma adecuada alguna distribución de valores extremos. 10.1 Estimación con valores extremos Para generar un modelo utilizando valores extremos se puede tomar la siguiente aproximación haciendo uso 10.2 Seleccionar un valor de corte \\(u &gt; 0\\). A partir de la muestra de valores de reclamos observados, tomar aquellos valores observados tales que \\(X_i \\geq u\\). Al conjunto \\(\\{ X_i \\mid X_i \\geq u \\}\\) aplicarle un test de ajuste a una distribución de Pareto generalizada \\(GPD( u, \\beta, \\varepsilon )\\), donde \\(u\\) está fijo como parámetro. Si el test es satisfactorio, buscar un nuevo \\(u\\), realizar nuevamente los pasos 2 y 3. Comparar el resultado de ajuste con el anterior y decidir cuál \\(u\\) mantener según algún criterio de selección estadística. Usualmente un criterio de información o la significancia de los valores \\(p\\) Si llegamos a obtener un resultado satisfactorio para algún \\(u &gt; 0\\), podemos concluir con cierto nivel de certeza, que los valores extremos de los reclamos si pueden ser descritos con una distribución de valores extremos generalizada \\(GEV( \\mu, \\sigma, \\varepsilon )\\) o de forma equivalente que los reclamos en la cola \\(X \\geq u\\) pueden ser descritos con una distribución de Pareto generalizada \\(GPD( u, \\beta, \\varepsilon )\\). Se ajusta una distribución de severidad \\(F\\) a todos los reclamos en la muestra \\(X\\). La distribución que se ajusta, debe estar precisamente dentro de la familia de funciones que están el dominio máximo de atracción de la familia de distribuciones de valores extremos generalizadas, i.e. \\(F \\in MDA( GEV( \\mu, \\sigma, \\varepsilon ) )\\). Si la prueba anterior fue satisfactoria para algún \\(u &gt; 0\\). Se determina a que percentil \\(p_u\\) pertenece, esto se lo puede realizar a partir de la muestra mismo \\(F_n( X \\leq u ) = p_u\\) o con la distribución ajustada para los reclamos \\(F( X \\leq u ) = p_u\\). 10.2 Simulación con valores extremos Si en caso se desea simular los reclamos, se toma con probabilidad \\(p_u\\) un muestra con la distribución truncada \\(X \\rightsquigarrow F_{(u)}( x ) = F( x \\mid X \\leq u ) = \\frac{F(\\min(u,x))}{F(u)}\\) y con probabilidad \\(1 - p_u\\) una muestra con la distribución de Pareto generalizada estimada \\(X \\rightsquigarrow G = GPD( u, \\beta, \\varepsilon )\\). Así, en particular al esperanza de \\(X\\) tiene al forma \\[ \\mathbb{E}[ X ] = \\mathbb{E}[ X \\mid X \\leq u ] P( X \\leq u ) + \\mathbb{E}[ X \\mid X &gt; u ] P( X &gt; u ) = p_u \\mathbb{E}_{F_{(u)}}[ X ] + \\left( 1 - p_u \\right) \\mathbb{E}_{G}[ X ] \\] Si la muestra inicial es lo suficientemente representable y por tanto tiene un buen tamaño, el valor \\(p_u\\) puede ser realmente cercano a \\(1\\), por tal razón si se decide realizar una simulación de valores extremos de tamaño \\(m\\), se tiene que tomar en cuenta que en promedio \\(m ( 1 - p_u )\\) de esos valores serán valores extremos, si \\(m\\) no es lo suficientemente grande puede que los valores extremos simulados sean cero en cantidad y habrá sido inútil el haber realizado una estimación más compleja con valores extremos, ya que no se la está utilizando en las simulaciones. En tales circunstancias es mucho mejor utilizar algún algoritmo determinista que supere este problema. "],["bibliografia.html", "Capítulo 11 Bibliografía", " Capítulo 11 Bibliografía "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
