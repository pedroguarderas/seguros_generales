<!------------------------------------------------------------------------------------------------->
# Tarificación {#tarificacion}

```{r}
#| echo: false
#| warning: false
source("_common.R")
```

Una vez estimado los reclamos totales se trata de establecer una forma optima para estimar el 
valor que deberá pagar el asegurado, la **prima**, para que la compañia de seguros se haga cargo de
riesgo. En esto debe incluirse algunas consideraciones adicionales, además de la estimación 
de la frecuencia y severidad de los reclamos, es también relevante tener en consideración otros 
valores asociados a diferentes costo, el retorno esperado por el inversionista y finalmente el
rendimiento de inversiones. Todo lo anterior debe ser conjugado para obtener una adecuada 
estimación de la prima.

Adicionalmente, se debe tener en cuenta que el riesgo cubierto está sujeto a variaciones propias
de la aleatoriedad del fenómeno y que puede presentar variaciones significativas respecto de la 
media, es decir, que la volatilidad del riesgo cubierto puede influenciar significativamente el
pago total de los reclamos. Ante ello surge un concepto de vital importancia, el cual lo 
desarrollamos a continuación y se lo conoce como medidas de riesgo.

<!------------------------------------------------------------------------------------------------->
## Medidas de riesgo {#medidas_riesgo}

Para medir el riesgo suelen ser de utilidad para determinar el capital regulatorio que debería 
mantener alguien que está dispuesto a correr un riesgo. 

Así un medida de riesgo es una función que se espera tenga algunas propiedades como.

::: {.Definition #dmedriskprop title="Medida de riesgo propiedad"}
Una **medida de riesgo** es una función $\rho: \R \longrightarrow \R$, 
que satisface la siguientes propiedades:

1. **Normalización**, el riesgo de nada es nada
$$
\rho( 0 ) = 0
$$

2. **Homogeneidad positiva**, el riesgo crece con la escala, así para cualquier $a > 0$
$$
\rho( a X ) = a \rho( X )
$$

3. **Invarianza ante las traslaciones**, para cualquier $a > 0$
$$
\rho( \alpha X + a ) = \rho( \alpha X ) + a
$$

4. **Monotonicidad**, Si $X \leq Y$
$$
\rho( X ) \leq \rho( Y )
$$

5. **Sub-aditividad**, el diversificar el riesgo es menor a la suma de los riesgos independientes
$$
\rho( X + Y ) \leq \rho( X ) + \rho( Y )
$$
6. **Convexidad**, igual está relacionado con la diversificación, así para cualquier 
$\lambda \in (0,1)$
$$
\rho( \lambda X + ( 1 - \lambda ) Y ) \leq \lambda \rho( X ) + ( 1 - \lambda ) \rho( Y )
$$

Una medida de riesgo se dice **coherente** si satisface la condición de normalización, homogeneidad
positiva, monotonía y sub-aditivadad. 

Por otra parte las nociones de sub-aditividad y homogenidad positiva son equivalentes a la noción
de convexidad.
:::

A las propiedades anteriores se suma una propiedad adicional que se conoce como **objetividad**

::: {.Definition #drskobj title="Objetividad"}
Una medida de riesgo se dice que es **objetiva** si y solo si la misma depende de la distribución
acumulada $F_X$ de la variable aleatoria $X$ sobre la que se calcula y no de la variable en si 
mismo.
$$
\rho( X ) = \rho( F_X )
$$
:::

Sin embargo, es de notar que la coherencia de una medida de riesgo puede estar en contraposición con
la propiedad de objetividad.

La siguiente proposición es de ayuda para establecer un requerimiento necesario y suficiente para 
tener una medida coherente dado que esta es positivamente homogénea.

::: {.Proposition}
Una medida de riesgo que tiene homogeneidad positiva es coherente si y solamente si esta es convexa.
:::

Existe el siguiente resultado de potencia inusual, caracteriza las medidas de riesgo convexas y
tiene un efecto también sobre la caracterización de medidas de riesgo coherentes. El mismo está 
por fuera del alcance de estas notas sin embargo, vale la pena citarlo, ya que su conclusión 
provee de un resultado que es de utilidad para construir medidas de riesgo coherentes bajo un 
princípio de optimalidad.

::: {.Theorem}
Una medida de riesgo $\rho$ es convexa si y solamente si esta puede ser representada como el 
infimo de esperanzas sobre medidas que son absolutamente continuas a la medida de probabilidad
inicial $P$. Más precisamente
$$
\rho( X ) = -\underset{Q \in AC( P )}{\inf} \left( \E_Q\left[ X \right] + \alpha( Q ) \right)
$$
donde, $\alpha : AC( P ) \longrightarrow \R$ es un mapeo tal que 
$\underset{Q \in AC( P )}{\inf} \alpha( Q ) = 0$ y $AC(P)$ es el conjunto de medidas absolutamente
continuas respecto a $P$.
:::

Como consecuencia del teorema anterior tenemos el siguiente corolario.

::: {.Corollary}
Una medida de riesgo $\rho$ es coherente si y solamente si esta puede ser representada de la 
siguiente forma:
$$
\rho( X ) = -\underset{Q \in AC( P )}{\inf} E_Q\left[ X \right]
$$
:::

En lo que continúa citamos algunas de las medidas de riesgo usualmente utilizadas.

<!------------------------------------------------------------------------------------------------->
## Valor en riesgo $\VaR_{\alpha}$

::: {.Definition #dVaR title="Valor en riesgo"}
Dada una variable aleatoria a valores reales $X$, el **valor en riesgo** (value at risk) de $X$ al 
nivel de probabilidad $\alpha \in (0,1)$ está dado por
$$
\VaR_{\alpha}( X ) = \inf\left\{ x \in \R \middle| F_X( x ) > \alpha \right\}
$$
:::

::: {.Proposition #varinv}
Si la función de distribución acumulada $F_X$ es continua, entonces 
$\VaR_{\alpha}( X ) = F_X^{-1}( \alpha )$.
:::

La medida de riesgo $\VaR_{\alpha}$ tiene las siguientes propiedades que se satisfacen para cualquier
nivel $\alpha$ de seguridad.

1. Es una medida de riesgo normalizada

2. Es una medida de riesgo con homogeneidad positiva

3. Es una medida de riesgo invariante ante las traslaciones

4. Es una medida de riesgo monótona

5. Es una medida de riesgo que no es necesariamente sub-aditiva y en consecuencia no es una medida
de riesgo que privilegia la diversificación.

El método directo para el calcular el $\VaR_\alpha$ es directamente atacando el problema de 
encontrar el ínfimo, esto es un problema de optimización que puede tener sus complicaciones, ya
que muchas de las veces la distribución acumulada $F$ no es conocida o fácilmente computable. 
Incluso en el caso cuando la función de distribución $F$ es continua, resta el problema de poder
invertir esta función.

Otra forma es acudir a los métodos de simulación estocástica, partiendo de una muestra 
$X_1, \ldots, X_n$ y calculando de forma aproximada
$$
\VaR_{\alpha}( X ) \approx F_n^{-1}( \alpha )
$$
En principio no sabemos si esta aproximación será consistente conforme se aumenta el tamaño de la 
muestra, sin embargo para ello tenemos la siguiente proposición, la cual nos da una certeza al 
respecto.

::: {.Proposition #appoxvar}
Si consideramos una familia de variables aleatorias $\{X_n\}_{n\in \N}$ i.i.d con distribución común
$F$ no necesariamente continua, entonces el percentil empírico de orden $\alpha$, 
$\xi_{n,\alpha} = F_n^{-1}( \alpha )$, que se puede extraer a partir de las $n$ primeras variables 
en la muestra converge en probabilidad al valor $\xi_{\alpha} = \VaR_{\alpha}( X )$, correspondiente
al valor en riesgo.
:::

:::{.proof}
Utilizando la versión unilateral de la desigualdad \ref{ddkw}, podemos establecer las 
siguientes acotaciones
$$
\begin{split}
P\left( \xi_{n,\alpha}- \xi_{\alpha} > \varepsilon \right)
& = P\left( \xi_{n,\alpha} >  \xi_{\alpha} + \varepsilon \right) \\
& = P\left( F_n( \xi_{n,\alpha} ) >  F_n( \xi_{\alpha} + \varepsilon ) \right) \\
& = P\left( F( \xi_{\alpha} + \varepsilon ) + \alpha > F( \xi_{\alpha} + \varepsilon ) + F_n( \xi_{\alpha} + \varepsilon ) \right) \\
& = P\left( F( \xi_{\alpha} + \varepsilon ) - F_n( \xi_{\alpha} + \varepsilon ) > F( \xi_{\alpha} + \varepsilon ) - \alpha \right) \\
& \leq P\left( \underset{x \in \R}{\sup} \left( F - F_n \right) > F( \xi_{\alpha} + \varepsilon ) - \alpha \right) \\
& \leq Ce^{-2n \left( F( \xi_{\alpha} + \varepsilon ) - \alpha \right) ^2 }
\end{split}
$$

$$
\begin{split}
P\left( \xi_{n,\alpha} - \xi_{\alpha} < -\varepsilon \right)
& = P\left( \xi_{n,\alpha} <  \xi_{\alpha} - \varepsilon \right) \\
& = P\left( F_n( \xi_{n,\alpha} ) <  F_n( \xi_{\alpha} - \varepsilon ) \right) \\
& = P\left( F( \xi_{\alpha} - \varepsilon ) + \alpha < F( \xi_{\alpha} - \varepsilon ) + F_n( \xi_{\alpha} - \varepsilon ) \right) \\
& = P\left( F_n( \xi_{\alpha} - \varepsilon ) - F( \xi_{\alpha} - \varepsilon ) > \alpha - F( \xi_{\alpha} - \varepsilon ) \right) \\
& \leq P\left( \underset{x \in \R}{\sup} \left( F - F_n \right) > \alpha - F( \xi_{\alpha} - \varepsilon ) \right) \\
& \leq Ce^{-2n \left( \alpha - F( \xi_{\alpha} - \varepsilon ) \right) ^2 }
\end{split}
$$
Uniendo ambos resultados concluimos
$$
P\left( \left| \xi_{n,\alpha}- \xi_{\alpha} \right| > \varepsilon \right)
\leq 2 C e^{-2n \min\left( F( \xi_{\alpha} + \varepsilon ) - \alpha, \alpha - F( \xi_{\alpha} - \varepsilon ) \right)^2 }
$$
Podemos concluir con toda confianza que el percentil $\xi_{n,\alpha}$ que se obtiene de la 
distribución empírica se aproxima en probabilidad al percentil $\xi_{\alpha} = \VaR_{\alpha}( X )$ 
:::

<!------------------------------------------------------------------------------------------------->
### Algoritmo de simulación

Con lo anterior se puede crear un algoritmo de simulación estocástico que precisamente contemple
el respectivo nivel de convergencia, de ahí que la demostración de la proposición anterior no es 
inútil, ya que de la misma resulta un criterio para determinar el número de simulaciones que se
desea calcular.

Fijamos un valor $\delta > 0$ el cual acota la probabilidad del evento que mide el error de 
aproximación, i.e. $P\left( \left| \xi_{n,\alpha} - \xi_{\alpha} \right| > \varepsilon \right) \leq \delta$ 
y tomando en cuenta la desigualdad en \ref{appoxvar}.
$$
\begin{split}
2 C e^{-2n \min\left( F( \xi_{\alpha} + \varepsilon ) - \alpha, \alpha - F( \xi_{\alpha} - \varepsilon ) \right)^2 } & \leq \delta \\
-2n \min\left( F( \xi_{\alpha} + \varepsilon ) - \alpha, \alpha - F( \xi_{\alpha} - \varepsilon ) \right)^2 
& \leq \log( \delta )-\log(2) - \log( C ) \\
n & \geq -\frac{\log( \delta )-\log(2)-\log( C )}{2 \min\left( F( \xi_{\alpha} + \varepsilon ) - \alpha, \alpha - F( \xi_{\alpha} - \varepsilon ) \right)^2}
\end{split}
$$
Como se evidencia $n$ crece en orden cuadrático proporcional a la aproximación dada por 
$\min\left( F( \xi_{\alpha} + \varepsilon ) - \alpha, \alpha - F( \xi_{\alpha} - \varepsilon ) \right)$
alrededor del percentile $\alpha$. Lo cual no es un resultado muy alentador.

Si se establece un valor $\widetilde{\varepsilon} > 0$ para el término 
$\widetilde{\varepsilon} \leq \min\left( F( \xi_{\alpha} + \varepsilon ) - \alpha, \alpha - F( \xi_{\alpha} - \varepsilon ) \right)$, la expresión anterior se modifica a la siguiente
$$
n \geq -\frac{\log( \delta )-\log(2)-\log(C)}{2 \widetilde{\varepsilon}^2}
$$
Claramente la cantidad de simulaciones que se debe realizar para lograr una aproximación de orden
$\varepsilon$, se requiere un orden de simulaciones cuadrático inverso a este valor.
El ejemplo numérico a continuación es aleccionador al respecto de la dificultad numérica de 
aproximar un cálculo de $VaR_\alpha$.

Entonces los pasos del pseudo-algoritmo de simulación estarán dados por:

1. Fijar el nivel de confianza al que se desea calcular $0 < \alpha < 1$

2. Fijar el nivel probabilidad para los errores de aproximación $\delta > 0$

3. Fijar el nivel erro $\widetilde{\varepsilon} > 0$

4. Estimar el posible error de estimación $\varepsilon > 0$

5. Buscar el número de simulaciones adecuadas $n \in \N$ que aseguren con una probabilidad menor a 
$\delta$ que se presente errores de aproximación superiores a $\varepsilon$.

6. Generar una muestra de tamaño $n$ de la variable aleatoria, i.e. $X_1, \ldots, X_n$

7. Calcular el percentil de la $\alpha$ de la muestra $\xi_{n,\alpha} = F_n^{-1}( \alpha )$

Esta simulación solo genera una sola estimación del $\VaR_{\alpha}(X)$, se puede repetir algunas
veces esta algoritmo para tener más valores y sacar la media de estos como estimador.
```{r l7c1}
u <- 7
s <- 4
Fd <- function( x ) plnorm( x, meanlog = u, sdlog = s )
Fdi <- function( x ) qlnorm( x, meanlog = u, sdlog = s )
Rd <- function( x ) rlnorm( n = n, meanlog = u, sdlog = s )
alpha <- 0.98
delta <- 1e-2
hepsilon <- 0.2e-4

q <- Fdi( alpha )
epsilon <- max( Fdi( hepsilon + alpha ) - q, q - Fdi( alpha - hepsilon ) )
C <- 5.001e-3 # seleccionado acorde a cada problema
n <- round( -( log( delta ) - log( 2 ) - log( C ) ) / ( 2 * hepsilon^2 ), 0 )

m <- 1e3
qn <- sapply( 1:m, FUN = function( i ) as.numeric( quantile( Rd( n ), probs = alpha ) ) )

P <- mean( abs( qn - q ) > epsilon ) 
```
$$
P\left( \left| \xi_{n,\alpha}- \xi_{\alpha} \right| > \varepsilon \right) = 
`r formatC( P, digits = 8, format = 'f' )`
$$
Como se observa se tendrá que realizar muchas simulaciones más para llegar a tener en probabilidad
un error de aproximación adecuado.


<!------------------------------------------------------------------------------------------------->
## Valor en riesgo en la cola $\TVaR_{\alpha}$

::: {.Definition #dTVaR title="Valor en riesgo en la cola"}
Dada una variable aleatoria a valores reales $X$, el **valor en riesgo en la cola** 
(tail value at risk) de $X$ al nivel de probabilidad $\alpha \in (0,1)$ está dado por
$$
\TVaR_{\alpha}( X ) = \frac{1}{1-\alpha} \int\limits_{\alpha}^1 \VaR_u( X )\ du
$$
:::

La medida de riesgo $\TVaR_{\alpha}$ tiene las siguientes propiedades que se satisfacen para cualquier
nivel $\alpha$ de seguridad.

1. Es una medida de riesgo normalizada

2. Es una medida de riesgo con homogeneidad positiva

3. Es una medida de riesgo invariante ante las traslaciones

4. Es una medida de riesgo monótona

5. Es una medida de riesgo sub-aditiva

En conclusión $\TVaR_{\alpha}$ es una medida de riesgo coherente.

<!------------------------------------------------------------------------------------------------->
### Algoritmo de simulación

Es de notar que si se toma una variable aleatoria uniforme $U \rightsquigarrow U(\alpha,1)$, tenemos 
que el valor en riesgo en la cola, puede ser expresado como la esperanza.
$$
\TVaR_{\alpha}( X ) = \E\left[ \VaR_U( X ) \right]
$$
De ahí que se una forma de calcular el valor en riesgo en la cola es utilizando una simulación
estocástica que aproveche el \ref{twln}. Así se puede generar una muestra $U_1, \ldots, U_m$ de 
la distribución uniforme $U(\alpha,1)$ y para cada uno de estos valores se calcula por simulación el 
$\xi_{n,U_1} \approx \VaR_{U_1}( X ), \ldots, \xi_{n,U_n} \approx  \VaR_{U_n}( X )$, luego aproximar
utilizando la media empírica
$$
\TVaR_{\alpha}( X ) \approx \frac{1}{m} \sum\limits_{i=1}^m \xi_{n,U_i}
$$
Pero como ya se mencionó, esta aproximación puede ser realmente costosa en términos 
computacionales; por tal razón, se requiere utilizar métodos numéricos más eficientes.


<!------------------------------------------------------------------------------------------------->
## Esperanza condicional en la cola $\CTE_{\alpha}$

::: {.Definition #dCTE title="Esperanza condicional en la cola"} 
Dada una variable aleatoria a valores reales $X$, la **esperanza condicional en la cola** 
(conditional tail expectation) de $X$ al nivel de probabilidad $\alpha \in (0,1)$ está dado por
$$
\CTE_{\alpha}( X ) = \E\left[ X \middle| X > \VaR_{\alpha}( X ) \right]
$$
:::

::: {.Proposition #eqtvarcte}
Si la función de distribución acumulada $F_X$ de la variable aleatoria $X$ es continua, entonces
se tiene la siguiente igualdad
$$
\CTE_{\alpha}( X ) = \TVaR_{\alpha}( X )
$$
:::

::: {.Proposition #CTEcohe title="Coherencia de la medida de esperanza condicional en la cola"}
La medida de riesgo $\CTE_{\alpha}$ es una medida de riesgo coherente si la variable aleatoria
sobre la cual se mide es una variable aleatoria continua.
:::

<!------------------------------------------------------------------------------------------------->
## Valor en riesgo condicionado $\CVaR_{\alpha}$

::: {.Definition #dCVaR title="Valor en riesgo condicionado"}
Dada una variable aleatoria a valores reales $X$, el **valor en riesgo condicionado** 
(conditional value at risk) de $X$ al nivel de probabilidad $\alpha \in (0,1)$ está dado por
$$
\CVaR_{\alpha}( X ) = \E\left[ X - \VaR_{\alpha}( X ) \middle| X > \VaR_{\alpha}( X ) \right]
= \CTE_{\alpha}( X ) - \VaR_{\alpha}( X )
$$
:::


<!------------------------------------------------------------------------------------------------->
## Déficit esperado

::: {.Definition #dES title="Déficit esperado"}
Dada una variable aleatoria a valores reales $X$, el **déficit esperado** (expected shortfall) de 
$X$ al nivel de probabilidad $\alpha \in (0,1)$ está dado por
$$
\ES_{\alpha}( X ) = \E\left[ \max\left( X - \VaR_{\alpha}( X ), 0 \right) \right]
$$
:::


<!------------------------------------------------------------------------------------------------->
## Valor en riesgo entrópico $\EVaR_{\alpha}$

::: {.Definition #dEVaR title="Valor en riesgo entrópico"}
Dada una variable aleatoria a valores reales $X$, el **valor en riesgo entrópico** 
(entropic value at risk) de $X$ al nivel de probabilidad $\alpha \in (0,1)$ está dado por
$$
\EVaR_{\alpha}( X ) = \inf\left\{ \frac{1}{t} \ln\left( \frac{M_X( t )}{1 - \alpha} \right) \middle| t > 0 \right\}
$$
:::

::: {.Proposition #EVaRcohe title="Coherencia de la medida EVaR"}
La medida de riesgo $\EVaR_{\alpha}$ es una medida de riesgo coherente.
:::


::: {.example #l7ex2}
Podemos considerar el caso particular donde todos los reclamos se suponen independientes e 
idénticamente distribuidos (i.i.d), en este caso con distribución $X_i \rightsquigarrow LN(\mu,\sigma)$
```{r l7c2}
set.seed(94312)
u <- 4
s <- 0.5
n <- 1e4
X <- rlnorm( n, meanlog = u, sdlog = s )
alpha <- seq( 0, 1, 0.01 ) 
VaRX <- quantile( X, probs = alpha, names = FALSE )
TVaRX <- sapply( 
  1:length( VaRX ), 
  FUN = function( i ) ifelse( alpha[ i ] < 1, ( 1 / ( 1 - alpha[ i ] ) ) * mean( X * ( X > VaRX[ i ] ) ), max( X ) ) )
```

```{r l7g1}
#| warning: false
#| out-width: '70%'
#| fig-align: center
#| code-fold: true
plt <- ggplot() +
  geom_point( aes( x = alpha, y = VaRX ), colour = 'darkred' ) + 
  geom_point( aes( x = alpha, y = TVaRX ), colour = 'orange' ) + 
  xlab( TeX( "$\\alpha$" ) ) + 
  ylab( TeX( "$VaR,TVaR$" ) ) + 
  theme_bw()
plot( plt )
```
:::

<!------------------------------------------------------------------------------------------------->
## Medidas de riesgo de Wang

Hay otra forma de construir medidas de riesgo, estas son las medidas de riesgo de Wang, las mismas
dependen de lo que conocemos como **función de distorsión** $g : [0,1] \longrightarrow [0,1]$,
tal que $g(0) = 0$ y $g(1) = 1$.

::: {.Definition #drskwang title="Medida de riesgod de Wang"}
La **medida de riesgo de Wang** asociada a la función de distorsión $g$ y representada por $\rho_g$
está dada por la siguiente expresión:
$$
\rho_g( X ) = \int\limits_{0}^{+\infty} g\left( S_X( u ) \right)\, du
$$
:::

Por lo regular se enfoca a utilizar medidas de distorsión $g$ superlineales es decir, $g(x) \geq x$,
para así construir medidas de riesgo de Wang de tal forma que $\rho_g( X ) \geq \E[ X ]$.

Si tomamos $H( \alpha ) = \VaR_{1-\alpha}( X )$, entonces sabemos que 
$d\left( g( \alpha ) H( \alpha ) \right) = g( \alpha ) dH( \alpha ) + H( \alpha ) dg( \alpha )$ y 
además se tiene que:
$$
\int\limits_0^1 d\left( g( \alpha ) H( \alpha ) \right) = g( 1 ) H( 1 ) - g( 0 ) H( 0 ) = 0
$$

también se tiene que que $H$ no es más que la inversa de $S_X$, i.e $S_X( H( \alpha ) ) = \alpha$, 
en pocas si realizamos el cambio de variable $u = H( \alpha )$, en la integral que define la medida 
de riesgo de Wang. Primeramente tomando un valor finito $x \in \R$ trabajamos la integral definida, 
así tenemos:
$$
\begin{split}
\int\limits_0^{x} g( S_X( u ) )\, du
& = \int\limits_0^{x} g( S_X( H( \alpha ) ) )\, dH( \alpha ),  \qquad \text{integral de Riemann-Stieltjes} \\
& = \int\limits_{H^{-1}(0)}^{H^{-1}(x)} g( \alpha )\, dH( \alpha ) \\
& = \int\limits_{S_X(0)}^{S_X(x)} g( \alpha )\, dH( \alpha ) \\
& = \int\limits_{1}^{S_X(x)} g( \alpha )\, dH( \alpha ) \\
& = -\int\limits_{1}^{S_X(x)} H( \alpha )\, dg( \alpha ),  \qquad \text{por la igualdad que hemos citado}  \\
& = \int\limits_{S_X(x)}^1 H( \alpha )\, dg( \alpha ) \\
& = \int\limits_{S_X(x)}^1 \VaR_{1 - \alpha}( X )\, dg( \alpha )
\end{split}
$$

tomando límite $x \rightarrow +\infty$, se tiene
$$
\begin{split}
\rho_g( X ) 
& = \underset{x \rightarrow +\infty}{\lim} \int\limits_0^x g( S_X( u ) )\, du \\
& = \underset{x \rightarrow +\infty}{\lim} \int\limits_{S_X(x)}^1 \VaR_{1 - \alpha}( X )\, dg( \alpha ) \\
& = \int\limits_0^1 \VaR_{1 - \alpha}( X )\, dg( \alpha )
\end{split}
$$

Esto quiere decir que una medida de riesgo de Wang, no es más que una suma ponderada por $g$ de los 
valores $\VaR$.

Como casos particulares de interés tenemos:

1. Si $g = \mathbf{1}_{(1-\alpha,+\infty)}$, entonces $\rho_g( X ) = \VaR_{\alpha}( X )$

2. Si $g = \min\left( \frac{x}{1-\alpha}, 1 \right)$, entonces $\rho_g( X ) = \TVaR_{\alpha}( X )$

Además, para las medidas de riesgo de Wang se tiene las siguientes propiedades:

1. Es una medida de riesgo con homogeneidad positiva

3. Es una medida de riesgo invariante ante las traslaciones

4. Es una medida de riesgo monótona

Si la función de distorsión $g$ que define la medida de riesgo de Wang es una función cóncava y 
si para una variable aleatoria $X$, la función compuesta $g \circ S_X$ es continua por derecha, 
entonces $1 - g \circ S_X$ es efectivamente la distribución de probabilidad de alguna variable 
aleatoria $Y$, quiere decir que:
$$
P( Y \leq y ) = 1 - g( F_X( y ) ),\quad \forall y \geq 0
$$
y por tanto
$$
\rho_g( X ) = \E[ Y ]
$$

En general lo que le falta a una medida de riesgo de Wang para ser coherente es que sea sub-aditiva, 
esto puede ser determinado con las propiedades de la función de distorsión.

::: {.Proposition}
La medida de riesgo de Wang es coherente si la función de distorsión es cóncava
:::

<!------------------------------------------------------------------------------------------------->
## Tarificación en grandes términos {#tarificacion_grandes_terminos}

La tarificación que conlleva a la selección de la prima $\Pi$ debe tomar en cuenta como se manejan y 
equilibran los activos y pasivos en el negocio asegurador.

**Pasivos**

1. Capitales propios

2. Reservas técnicas

3. Reservas para otros riesgos

4. Deudas o depósitos en dinero recibidos por cesiones

5. Otras deudas por pagar


**Activos**

1. Capital suscrito no desembolsado

2. Activos no materiales

3. Inversiones

4. Parte de reaseguros en reservas técnicas

5. Deudas por cobrar

6. Otros activos

En el proceso de tarificación no es pertinente incluir todos los activos de la empresa, ya que 
muchos de estos no tienen la liquidez necesaria como para ser considerados un tipo de activo 
viable para la tarificación. Tampoco se toma en cuenta el dinero recibido por la cesión de primas
en un ramo en particular, ya que esto constituye un nivel más arriba propio del negocio 
reasegurador.


::: {.Definition #dpruin title="Probabilidad de ruina"}
En términos generales se busca equilibrar el resultado operativo del ramo de negocio $R$ a lo largo 
de la vida del ramo. El resultado $R$ a su vez está dado por la siguiente relación:
$$
R = \Pi + I - S - G - K
$$
donde las variables a considerarse en principio son:

1. $\Pi$ Ingreso por primas

2. $I$ Ingreso por inversiones

3. $S$ Pago de siniestros

4. $G$ Gastos agregados, incluyendo gastos de emisión, operativos, gastos por reclamos

5. $K$ Coste de capital, esencialmente es el retorno que se espera sobre el capital invertido por 
los inversores para mantener el nivel de solvencia del ramo.

En varias ocasiones el ciclo del negocio puede ser corto plazo y no permite considerar un ingreso 
por inversiones $I = 0$.
$$
R = \Pi - S - G - K
$$

Sería ideal que a lo largo de la vida del ramo el resultado mantenga $R > 0$, pero al tratarse de 
un negocio que depende de la aleatoriedad de los reclamos, es bastante complicado encontrar un 
costo de capital $K$ y una prima $\Pi$ que siempre asegure ante todo escenario que se mantenga 
la positividad. Ante este riesgo continuo se busca minimizar la **probabilidad de ruina**, es decir,
acotar la probabilidad del evento $R < 0$ a un nivel de confianza $\alpha > 0$ adecuado
$$
P( R < 0 ) < \alpha
$$
:::


Muchas de las veces se parte del principio de equilibrio financiero @sec-equifin, donde 
se busca la igualdad $\E[R] = 0$, la misma implica la siguiente relación:
$$
\begin{split}
0 & = \E[R] \\
0 & = \E[R\mid R \geq 0]P( R \geq 0 ) + \E[R\mid R < 0]P( R < 0 ) \\
\E[R\mid R \geq 0]P( R \geq 0 ) & = -\E[R\mid R < 0]P( R < 0 ) \\
\frac{P( R < 0 )}{P( R \geq 0 ) } & = -\frac{\E[R\mid R \geq 0]}{\E[R\mid R < 0]}
\end{split}
$$
en el equilibrio financiero, la proporción de la probabilidad de ruina respecto de la probabilidad
de no estar en ruina es igual a la proporción entre la esperanza condicional del resultado cuando 
no se produce la ruina respecto de la esperanza condicional cuando si se produce la ruina. 

Un modelo puede estar equilibrado financieramente $\E[R] = 0$, pero se desconoce la 
probabilidad de ruina $P( R < 0)$, esta podría ser muy grande. La razón anterior permite estimar
la relevancia de la probabilidad de ruina en un modelo equilibrado, con el uso de las esperanzas
condicionales.

Es usual asumir que la única parte aleatoria de $R$ viene dada por el valor de los reclamos totales,
en razón de esto se tiene:
$$
\E[ R ] 
= \E[ \Pi - S - G - K ] 
= \Pi - \E[S] - G - K
$$

El **coste de capital** $K$ como ya lo mencionamos es el retorno mínimo esperado por los inversores 
sobre el capital invertido. Usualmente este capital puede ser visto como un porcentaje 
$r > 0$ que se toma sobre el capital colocado para mantener un nivel de solvencia adecuado 
sobre el valor esperado  $\E[S]$ del total de reclamos $S$. Para ello se suele utilizar precisamente
una medida de **medida de riesgo** $\rho$ que permita mantener el nivel de solvencia.
$$
K = r\left( \rho( S ) - \E[S] \right)
$$
con esta perspectiva
$$
\E[ R ] 
= \E\left[ \Pi - S - G - r\left( \rho( S ) - \E[S] \right) \right] 
= \Pi - \E[S] - G - r \left( \rho(S) - \E[S] \right)
$$


::: {.Definition #dpricing title="Tarificación (Pricing)"}
Lo que se busca es evitar la ruina y por tanto se busca cubrirse ante el evento $R < 0$, desde una 
perspectiva probabilista esto se puede realizar seleccionando un nivel de cobertura $\alpha > 0$, 
que acote la probabilidad del evento de ruina.
$$
P( R < 0 ) 
= P( \Pi - S - G - K < 0 )
= P\left( \Pi - S - G - r\left( \rho(S) - \E[S] \right) < 0 \right) < \alpha.
$$

De la relación anterior se observa que una vez seleccionado el nivel de cobertura $\alpha$ y la 
medida de riesgo $\rho$, las variables correspondientes a la prima $\Pi$ y a los gastos $G$ quedan 
libres, de ahí resulta un margen que permite seleccionar la prima más óptima para un producto de 
seguro, así como también optimizar los gastos $G$. Este proceso de selección es precisamente lo que 
llamamos en este contexto como **tarificación** (pricing).
:::


Razonando un poco más al respecto, si asumimos que se dispone de la distribución acumulada $F_S$
de $S$, se puede obtener las siguientes expresiones:
$$
\begin{split}
P\left( \Pi - S - G - K < 0 \right) & < \alpha \\
P\left( S > \Pi - G - K \right) & < \alpha  \\
1 - P\left( S \leq \Pi - G - K \right) & < \alpha \\
P\left( S \leq \Pi - G - K \right) & > 1 - \alpha \\
F_S\left( \Pi - G - K \right) & > 1 - \alpha \\
F_S\left( \Pi - G - K \right) & \in \left( 1 - \alpha, +\infty \right), \qquad
\text{la desigualdad anterior es equivalente a la inclusión}\\
\Pi - G - K & \in F_S^{-1}\left( \left( 1 - \alpha, +\infty \right) \right),\qquad
\text{por propiedades de la inversión de funciones}\\
\Pi & \geq G + K + \VaR_{1 - \alpha}(S), \qquad 
\text{como $F_S$ es creciente, mínimo se debe satisfacer la desigualdad}
\end{split}
$$

En especial cuando $K = r\left( \rho(S) - \E[S] \right)$, la última desigualdad toma la forma
$$
\Pi \geq G + r\left( \rho(S) - \E[S] \right) + \VaR_{1 - \alpha}(S)
$$

Así, en el caso anterior si se utiliza como medida de riesgo al mismo nivel de confianza $1 - \alpha$, 
esto es $\rho( S ) = \VaR_{1-\alpha}( S )$, la última igualdad se cumple si $S$
es una variable aleatoria continua.
$$
\Pi \geq G + (1 + r) \VaR_{1 - \alpha}(S)- r \E[S] 
$$

Si en caso los gastos $G$ son proporcionales a la prima $G = \gamma \Pi$, para una constante 
$\gamma > 0$, y seguramente $\gamma < 1$ ya que es de esperar gastos no mayores a la misma prima, 
sino esto estaría en una situación insostenible donde los gastos son mayores a la cobertura del 
riesgo. Las desigualdades anteriores toman la forma:
$$
\begin{split}
\Pi & \geq \frac{r}{1 - \gamma} K + \frac{1}{1 - \gamma} \VaR_{1 - \alpha}(S) \\
\Pi & \geq \frac{r}{1 - \gamma} \left( \rho(S) - \E[S] \right) + \frac{1}{1 - \gamma} \VaR_{1 - \alpha}(S) \\
\Pi & \geq \frac{1 + r}{1 - \gamma} \VaR_{1 - \alpha}(S) -  \frac{r}{1 - \gamma} \E[S]
\end{split}
$$

De lo anterior se observa que un buen inicio para estimar la prima de riesgo es ciertamente 
usar la medida de riesgo dada por $\VaR_{1-\alpha}$ con el nivel adecuado de confianza $\alpha$. 
Por otra parte, esta versión más moderna de tarificación contempla parte de la utilidad debe 
estar reflejada en la experticia que tenga el asegurador  comprender y administrar el riesgo, 
esto se lo incluye en el término $\frac{r}{1 - \gamma} \E[S]$.


<!------------------------------------------------------------------------------------------------->
## Prima {#prima}
La prima es la cantidad de dinero que un individuo o entidad pagan por una póliza de seguro, la cual
está diseñada para cubrir ciertos riesgos personales o comerciales.

La determinación de las primas por parte del asegurador hace uso de la mutualización del riesgo y
diversificación, para así poder asumir la transferencia del riesgo por parte de sus asegurados. Así
por tanto, es deseable que cualquier método que se utilice para la estimación de primas, se 
satisfaga, algunas propiedades importantes.

Sin consideramos dos riesgos a cubrir $S_1$ y $S_2$, entonces la función que estima $\rho$ las primas 
sería aconsejable satisfaga las siguientes propiedades.

1. Si se decide cubrir por completo dos riesgos $S_1$ y $S_2$ en un mismo producto, el valor de la 
prima deberá ser menor o igual al valor que se resultaría de cubrir cada uno de los riesgos con 
productos separados.
$$
\rho( S_1 + S_2 ) \leq \rho( S_1 ) + \rho( S_2 )
$$

2. El asumir mayor riesgo debe tener como consecuencia el aumento de la prima
$$
\rho( S_1 ) \leq \rho( S_1 + S_2 )
$$
Esta propiedad implica que al configurar un producto de seguro con mejor cobertura, se espera 
una prima de mayor costo.

3. Si el riesgo a cubrir está limitado, es decir $P( S \leq M ) = 1$, para un valor $M > 0$, 
entonces jamás la prima será superior a $M$
$$
\rho( S ) \leq M
$$
Esto se traduce a que ningún asegurado estará interesado en adquirir una póliza para cubrir un 
riesgo por encima del valor total asegurado.


<!------------------------------------------------------------------------------------------------->
## Métodos clásicos para calular la prima {#sec-clasprima}

Para la estimación de primas existe algunos métodos que podemos llamar clásicos, que en un principio
no consideraban la cobertura ante el riesgo y el uso de una medida de riesgo. Son métodos bien 
establecidos, comunes en la práctica y pueden ser ajustados para contemplar una cobertura ante 
el riesgo, aquí citamos algunos de los más conocidos:

1. Prima neta, o prima pura de riesgo
$$
  \Pi = \rho( S ) = \E[S] \approx \overline{S}
$$

2. Prima de riesgo con recargo sobre la esperanza matemática
$$
  \Pi = \rho( S ) = (1 + \rho) \E[S] \approx (1 + \rho) \overline{S}
$$

3. Prima de riesgo con recargo sobre la varianza
$$
  \Pi = \rho( S ) = \E[S] + \rho \V[S] 
  \approx \overline{S} + \rho \sigma_S^2
$$

4. Prima de riesgo con recargo sobre la desviación
$$
  \Pi = \rho( S ) = \E[S] + \rho \sqrt{\V[S]}
  \approx \overline{S} + \rho \sigma_S
$$ 

5. Prima de riesgo con principio exponencial para $t > 0$
$$
  \Pi = \rho( S )
  = \frac{1}{2} \E\left[\exp(tS)\right]
  = \frac{1}{2} M_N\big( \ln M_X( t ) \big)
  \approx \frac{1}{m} \sum\limits_{i=1}^m \exp\left(t S_i\right)
$$

6. Prima de percentiles para un valor de confianza $\alpha \in [0,1]$ o prima de valor en riesgo 
$\VaR_\alpha$
$$
\begin{split}
\Pi 
& = \rho( S ) \\
& = \VaR_\alpha( S ) \\
& =  F_S^{-1}( \alpha ), \quad \text{cuando $F_S$ es continua}
\end{split}
$$

7. Prima de valor en riesgo en la cola (Tail Value at Risk) $TVaR_\alpha$. Es el promedio uniforme
de todos los valores en riesgo $VaR_u$, con $u \geq \alpha$.
$$
  \Pi = \rho( S ) = \TVaR_\alpha( S )
$$

::: {.example #l7ex1}
Consideremos el caso donde todos los siniestros son igualmente distribuidos e independientes (i.i.d) 
$X_i \rightsquigarrow Gamma( \alpha_i, \theta )$, para $i \in \{1,\ldots,n\}$, el número de 
unidades aseguradas está dado por $n \in \N$. Utilizaremos el modelo individual para
la agregación de los reclamos y obtener el reclamo total $S = \sum\limits_{i=1}^n X_i$.

Como todas las variables $X_i$ siguen una ley $Gamma( \alpha_i, \theta )$, sabemos que la 
familia $Gamma$ es cerrada por adición, es decir, a suma de variables aleatorias con ley $Gamma$
también sigue una ley $Gamma$. En este caso en particular para el reclamo total tenemos que 
$S \rightsquigarrow Gamma\left( \sum\limits_{i=1}^n \alpha_i, \theta \right)$.

Es de notar que para cada $i\in \{1,\ldots,n\}$, la variable aleatoria $X_i$ correspondiente al
$i$-ésimo reclamo tiene como parámetro un diferente factor $\alpha_i$, pero el mismo factor 
$\theta$. 

Ya que cada $X_i \rightsquigarrow Gamma( \alpha_i, \theta )$, podemos calcular de forma determinista
las esperanzas de $\E[X_i]$, para cada $i \in \{1,\ldots,n\}$ y de igual forma podemos 
calcular la esperanza del reclamo total $\E[S] = \sum\limits_{i=1}^n \E[X_i]$. 
Además como asumimos independencia entre los $X_i$, la varianza de $S$ también puede ser calculada
fácilmente como $\V[S] = \sum\limits_{i=1}^n \V[X_i]$.

También estamos en la capacidad de simular la variable $S$ utilizando un algoritmo de aleatorio, 
para así aproximar los cálculos de sus momentos y otros estadísticos. Primeramente definamos los 
parámetros.
```{r l7c3}
# número de unidades aseguradas
n <- 1000

# parámetros para cada X_i
a <- runif( n, 5, 10 )

# parámetro theta, común a todas las X_i
theta <- 4

# parámetro para S
A <- sum( a )
```

```{r l7c4}
EX <- a * theta
VX <- a * theta^2
ES <- sum( EX )
VS <- sum( VX )
SDS <- sqrt( VS )
```

La variable aleatoria del reclamo total $S$ la podemos simular tomando una muestra i.i.d de tamaño $m$, 
i.e. $S_1,\ldots,S_m$ de la distribución $Gamma\left( \sum\limits_{i=1}^n \alpha_i, \theta \right)$.
```{r l7c5}
m <- 1e5
S <- rgamma( m, shape = A, scale = theta )
``` 

Prima pura:
```{r l7c6}
P <- ES
P <- mean( S )

alpha <- 0.95
P_avg <- ( 1 + alpha ) * ES
P_avg <- ( 1 + alpha ) * mean( S )

P_var <- ES + alpha * VS
P_var <- mean( S ) + alpha * var( S )

P_sde <- ES + alpha * SDS
P_sde <- mean( S ) + alpha * sd( S )

VaRS <- qgamma( alpha, shape = A, scale = theta )
P_VaR <- VaRS
P_VaR <- quantile( S, probs = alpha )

P_TVaR <- ( 1 / ( 1 - alpha ) ) * ( A * theta ) * ( 1 - pgamma( VaRS, shape = A + 1, scale = theta ) )
P_TVaR <- ( 1 / ( 1 - alpha ) ) * integrate( f = function( u ) qgamma( u, shape = A, scale = theta ), alpha, 1 )$value
P_TVaR <- mean( sapply( runif( m, alpha, 1 ), FUN = function( k ) qgamma( k, shape = A, scale = theta ) ) )
I <- as.numeric( S > VaRS )
P_TVaR <- mean( S * I ) / mean( I )
```
:::

<!------------------------------------------------------------------------------------------------->
## Segmentación

En muchas ocasiones es necesario tener en cuenta algunas características asociadas al riesgo 
asegurado, de tal forma que la prima sea lo más eficiente y adecuada según el riesgo cubierto y
las características del mismo. La idea de segmentar la población es obtener grupos homogéneos 
con riesgos similares.

Sin segmentación de la población, este el caso más sencillo para la tarificación, el asegurado

```{r l7t1}
#| echo: true
#| out-width: '60%'
#| code-fold: true
dat <- data.table( nom = c( 'Pago', 'Pago esperado', 'Varianza' ),
                   cl = c( "\\( \\E[S] \\)", "\\(\\E[S]\\)", "\\(0\\)" ), 
                   as = c( "\\(S - \\E[S]\\)", "\\(0\\)", "\\(\\V[S]\\)" ) )
dat %>%
  kable(
    label = NA,
    caption = 'Transferencia de riesgo sin segmentación',
    row.names = FALSE,
    col.names = c( '', 'Asegurado', 'Asegurador' ),
    align = 'lrr',
    digits = c( 0, 0, 0 ),
    format.args = list( big.mark = ',', decimal.mark = '.', scientific = FALSE ),
    escape = FALSE,
    centering = TRUE, 
    booktabs = TRUE ) %>%
  kable_classic( full_width = FALSE, html_font = "Cambria", position = "center" )
```

Para el caso cuando se puede caracterizar la severidad total a partir de otra variable explicativa 
$Y$, condicionando así cada una de las estimaciones según los valores que va tomando la variable 
explicativa. Esto permite estables primas de forma más adecuada según las diferentes características
del riesgo cubierto.

```{r l7t2}
#| echo: true
#| out-width: '60%'
#| code-fold: true
dat <- data.table( nom = c( 'Pago', 'Pago esperado', 'Varianza' ),
                   cl = c( "\\(\\E[S \\mid Y]\\)", "\\(\\E[S]\\)", "\\(\\V[\\E[S \\mid Y]]\\)" ), 
                   as = c( "\\(S - \\E[S \\mid Y]\\)", "\\(0\\)", "\\(\\V[S-\\E[S \\mid Y]]\\)" ) )
dat %>%
  kable(
    label = NA,
    caption = 'Transferencia de riesgo con segmentación',
    row.names = FALSE,
    col.names = c( '', 'Asegurado', 'Asegurador' ),
    align = 'lrr',
    digits = c( 0, 0, 0 ),
    format.args = list( big.mark = ',', decimal.mark = '.', scientific = FALSE ),
    escape = FALSE,
    centering = TRUE,
    booktabs = TRUE ) %>%
  kable_classic( full_width = FALSE, html_font = "Cambria", position = "center" )
```

La varianza $\V[\E[S \mid Y]]$ es atribuible a la heterogeneidad del portafolio de asegurados, 
y la misma se asigna a cada asegurado, más no es absorbida por el asegurador.

```{r l7end, echo = FALSE}
rm( list = ls()[ ls() != 'def.chunk.hook' ] )
```
