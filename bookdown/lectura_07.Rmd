<!------------------------------------------------------------------------------------------------->
# Tarificación {#tarificacion}

Para realizar la tarificación de un producto de seguro, además de estudiar y estimar el 
comportamiento futuro de los reclamos totales $S$, es necesario también tomar en cuenta el capital 
$K$ destinado para hacer frente al riesgo subscrito y los costos generales $G$

<!------------------------------------------------------------------------------------------------->
## Medidas de riesgo {#medidas_riesgo}

::: {.definition #spv name="Medida de riesgo coherente"}
Una **medida de riesgo coeherente** es una función $\rho: \R \longrightarrow \R$, 
que satisface la siguientes propiedades:

1. **Homogenidad positiva**, para cualquier $a > 0$
$$
\rho( a X ) = a \rho( X )
$$

2. **Invarianza ante las traslaciones**, para cualquier $a > 0$
$$
\rho( \alpha X + a ) = \rho( \alpha X ) + a
$$

3. **Monotonicidad**, Si $X \leq Y$
$$
\rho( X ) \leq \rho( Y )
$$

4. **Sub-aditividad**
$$
\rho( X + Y ) \leq \rho( X ) + \rho( Y )
$$
:::

En lo que continúa citamos algunas de las medidas de riesgo usualmente utilizadas.

::: {.definition #dVaR name="Valor en riesgo"}
Dada una variable aleatoria a valores reales $X$, el **valor en riesgo** (value at risk) de $X$ al 
nivel de probabilidad $\alpha \in (0,1)$ está dado por
$$
\VaR_{\alpha}( X ) = \inf\left\{ x \in \R \middle| F_X( x ) > \alpha \right\}
$$
:::

::: {.proposition #varinv}
Si la función de distribución acumulada $F_X$ es continua, entonces 
$\VaR_{\alpha}( X ) = F_X^{-1}( \alpha )$.
:::

Por otra parte, $\VaR_{\alpha}$ para cualquier $\alpha$ no es una medida de riesgo sub-aditiva.

El método directo para el calcular el $\VaR_\alpha$ es directamente atacando el problema de 
encontrar el ínfimo, esto es un problema de optimizaión que puede tener sus complicaciones, ya
que muchas de las veces la distribución acumulada no es conocida $F$ o fácilmente computable. 
Incluso en el caso cuando la función de distribución $F$ es continua, resta el problema de poder
invertir esta función. 

Otra forma es acudir a los métodos de simulación estocástica, partiendo de una muestra 
$X_1, \ldots, X_n$ y calculando de forma aproximada
$$
\VaR_{\alpha}( X ) \approx F_n^{-1}( \alpha )
$$
En principio no sabemos si esta aproximación será consistente conforme se aumenta el tamaño de la 
muestra, sin embargo para ello tenemos la siguiente proposición, la cual nos da una certeza al 
respecto.

::: {.proposition #appoxvar}
Si consideramos una familia de variables aleatorias $\{X_n\}_{n\in \N}$ i.i.d con distribución común
$F$ no necesariamente continua, entonces el percentil empírico de orden $\alpha$, 
$\xi_{n,\alpha} = F_n^{-1}( \alpha )$, que se puede extraer a partir de las $n$ primeras variables 
en la muestra converge en probabilidad al valor $\xi_{\alpha} = \VaR_{\alpha}( X )$, correspondiente
al valor en riesgo.
:::

:::{.proof}
Utilizando la versión unilateral de la desigualdad \@ref(thm:ddkw), podemos establecer las 
siguientes acotaciones
$$
\begin{eqnarray*}
P\left( \xi_{n,\alpha}- \xi_{\alpha} > \varepsilon \right)
& = & P\left( \xi_{n,\alpha} >  \xi_{\alpha} + \varepsilon \right) \\
& = & P\left( F_n( \xi_{n,\alpha} ) >  F_n( \xi_{\alpha} + \varepsilon ) \right) \\
& = & P\left( F( \xi_{\alpha} + \varepsilon ) + \alpha > F( \xi_{\alpha} + \varepsilon ) + F_n( \xi_{\alpha} + \varepsilon ) \right) \\
& = & P\left( F( \xi_{\alpha} + \varepsilon ) - F_n( \xi_{\alpha} + \varepsilon ) > F( \xi_{\alpha} + \varepsilon ) - \alpha \right) \\
& \leq & P\left( \underset{x \in \R}{\sup} \left( F - F_n \right) > F( \xi_{\alpha} + \varepsilon ) - \alpha \right) \\
& \leq & Ce^{-2n \left( F( \xi_{\alpha} + \varepsilon ) - \alpha \right) ^2 }
\end{eqnarray*}
$$

$$
\begin{eqnarray*}
P\left( \xi_{n,\alpha} - \xi_{\alpha} < -\varepsilon \right)
& = & P\left( \xi_{n,\alpha} <  \xi_{\alpha} - \varepsilon \right) \\
& = & P\left( F_n( \xi_{n,\alpha} ) <  F_n( \xi_{\alpha} - \varepsilon ) \right) \\
& = & P\left( F( \xi_{\alpha} - \varepsilon ) + \alpha < F( \xi_{\alpha} - \varepsilon ) + F_n( \xi_{\alpha} - \varepsilon ) \right) \\
& = & P\left( F_n( \xi_{\alpha} - \varepsilon ) - F( \xi_{\alpha} - \varepsilon ) > \alpha - F( \xi_{\alpha} - \varepsilon ) \right) \\
& \leq & P\left( \underset{x \in \R}{\sup} \left( F - F_n \right) > \alpha - F( \xi_{\alpha} - \varepsilon ) \right) \\
& \leq & Ce^{-2n \left( \alpha - F( \xi_{\alpha} - \varepsilon ) \right) ^2 }
\end{eqnarray*}
$$
Uniendo ambos resultados concluimos
$$
P\left( \left| \xi_{n,\alpha}- \xi_{\alpha} \right| > \varepsilon \right)
\leq 2 C e^{-2n \min\left( F( \xi_{\alpha} + \varepsilon ) - \alpha, \alpha - F( \xi_{\alpha} - \varepsilon ) \right)^2 }
$$
Podemos concluir con toda confianza que el percentil $\xi_{n,\alpha}$ que se obtiene de la 
distribución empírica se aproxima en probabilidad al percentil $\xi_{\alpha} = \VaR_{\alpha}( X )$ 
:::

<!------------------------------------------------------------------------------------------------->
### Algoritmo de simulación

Con lo anterior se puede crear un algoritmo de simulación estocástico que precisamente contemple
el respectivo nivel de convergencia, de ahí que la demostración de la proposición anterior no es 
inútil, ya que de la misma resulta un criterio para determinar el número de simulaciones que se
desea calcular.

Fijamos un valor $\delta > 0$ el cual acota la probabilidad del evento que mide el error de 
aproximación, i.e. $P\left( \left| \xi_{n,\alpha} - \xi_{\alpha} \right| > \varepsilon \right) \leq \delta$ 
y tomando en cuenta la desigualdad en \@ref(prp:appoxvar).
$$
\begin{eqnarray*}
2 C e^{-2n \min\left( F( \xi_{\alpha} + \varepsilon ) - \alpha, \alpha - F( \xi_{\alpha} - \varepsilon ) \right)^2 } & \leq & \delta \\
-2n \min\left( F( \xi_{\alpha} + \varepsilon ) - \alpha, \alpha - F( \xi_{\alpha} - \varepsilon ) \right)^2 
& \leq & \log( \delta )-\log(2) - \log( C ) \\
n 
& \geq & -\frac{\log( \delta )-\log(2)-\log( C )}{2 
\min\left( F( \xi_{\alpha} + \varepsilon ) - \alpha, \alpha - F( \xi_{\alpha} - \varepsilon ) \right)^2}
\end{eqnarray*}
$$
Como se evidencia $n$ crece en orden cuadrático proporcional a la aproximación dada por 
$\min\left( F( \xi_{\alpha} + \varepsilon ) - \alpha, \alpha - F( \xi_{\alpha} - \varepsilon ) \right)$
alrededor del percentile $\alpha$. Lo cual no es un resultado muy alentador.

Si se establece un valor $\widetilde{\varepsilon} > 0$ para el término 
$\widetilde{\varepsilon} \leq \min\left( F( \xi_{\alpha} + \varepsilon ) - \alpha, \alpha - F( \xi_{\alpha} - \varepsilon ) \right)$, la expresión anterior se modifica a la siguiente
$$
n \geq -\frac{\log( \delta )-\log(2)-\log(C)}{2 \widetilde{\varepsilon}^2}
$$
Claramente la cantidad de simulaciones que se debe realizar para lograr una aproximación de orden
$\varepsilon$, se requiere un orden de simulaciones cuadrático inverso a este valor.
El ejemplo numérico a continuación es aleccionador al respecto de la dificultad numérica de 
aproximar un cálculo de $VaR_\alpha$.
```{r l7c1}
u <- 7
s <- 4
Fd <- function( x ) plnorm( x, meanlog = u, sdlog = s )
Fdi <- function( x ) qlnorm( x, meanlog = u, sdlog = s )
Rd <- function( x ) rlnorm( n = n, meanlog = u, sdlog = s )
alpha <- 0.98
delta <- 1e-2
hepsilon <- 0.2e-4

q <- Fdi( alpha )
epsilon <- max( Fdi( hepsilon + alpha ) - q, q - Fdi( alpha - hepsilon ) )
C <- 5.001e-3 # seleccionado acorde a cada problema
n <- round( -( log( delta ) - log( 2 ) - log( C ) ) / ( 2 * hepsilon^2 ), 0 )

m <- 1e3
qn <- sapply( 1:m, FUN = function( i ) as.numeric( quantile( Rd( n ), probs = alpha ) ) )

P <- mean( abs( qn - q ) > epsilon ) 
```
$$
P\left( \left| \xi_{n,\alpha}- \xi_{\alpha} \right| > \varepsilon \right) = 
`r formatC( P, digits = 8, format = 'f' )`
$$
Como se observa se tendrá que realizar muchas simulaciones más para llegar a tener en probabilidad
un error de aproximación adecuado.

Entonces los pasos del pseudo-algoritmo de simulación estarán dados por:

1. Fijar el nivel de confianza al que se desea calcular $0 < \alpha < 1$

2. Fijar el nivel probabilidad para los errores de aproximación $\delta > 0$

3. Fijar el nivel erro $\widetilde{\varepsilon} > 0$

4. Estimar el posible error de estimación $\varepsilon > 0$

5. Buscar el número de simulaciones adecuadas $n \in \N$ que aseguren con una probabilidad menor a 
$\delta$ que se presente errores de aproximación superiores a $\varepsilon$.

6. Generar una muestra de tamaño $n$ de la variable aleatoria, i.e. $X_1, \ldots, X_n$

7. Calcular el percentil de la $\alpha$ de la muestra $\xi_{n,\alpha} = F_n^{-1}( \alpha )$

Esta simulación solo genera una sola estimación del $\VaR_{\alpha}(X)$, se puede repetir algunas
veces esta algoritmo para tener más valores y sacar la media de estos como estimador.

::: {.definition #dTVaR name="Valor en riesgo en la cola"}
Dada una variable aleatoria a valores reales $X$, el **valor en riesgo en la colas** 
(tail value at risk) de $X$ al nivel de probabilidad $\alpha \in (0,1)$ está dado por
$$
\TVaR_{\alpha}( X ) = \frac{1}{1-\alpha} \int\limits_{\alpha}^1 \VaR_u( X )\ du
$$
:::

::: {.proposition #TVaRcohe name="Coherencia de la medida TVaR"}
La medida de riesgo $\TVaR_{\alpha}$ es una medida de riesgo coherente si la variable aleatoria
sobre la cual se mide es una variable aleatoria continua.
:::

::: {.definition #dCTE name="Esperanza condicional en la cola"} 
Dada una variable aleatoria a valores reales $X$, la **esperanza condicional en la cola** 
(conditional tail expectation) de $X$ al nivel de probabilidad $\alpha \in (0,1)$ está dado por
$$
\CTE_{\alpha}( X ) = \E\left[ X \middle| X > \VaR_{\alpha}( X ) \right]
$$
:::

::: {.proposition #eqtvarcte}
Si la función de distribución acumulada $F_X$ de la variable aleatoria $X$ es continua, entonces
se tiene la siguiente igualdad
$$
\CTE_{\alpha}( X ) = \TVaR_{\alpha}( X )
$$
:::

::: {.definition #dCVaR name="Valor en riesgo condicionado"}
Dada una variable aleatoria a valores reales $X$, el **valor en riesgo condicionado** 
(conditional value at risk) de $X$ al nivel de probabilidad $\alpha \in (0,1)$ está dado por
$$
\CVaR_{\alpha}( X ) = \E\left[ X - \VaR_{\alpha}( X ) \middle| X > \VaR_{\alpha}( X ) \right]
= \CTE_{\alpha}( X ) - \VaR_{\alpha}( X )
$$
:::

::: {.definition #dES name="Déficit esperado"}
Dada una variable aleatoria a valores reales $X$, el **déficit esperado** (expected shortfall) de 
$X$ al nivel de probabilidad $\alpha \in (0,1)$ está dado por
$$
\ES_{\alpha}( X ) = \E\left[ \max\left( X - \VaR_{\alpha}( X ), 0 \right) \right]
$$
:::

::: {.definition #dEVaR name="Valor en riesgo entrópico"}
Dada una variable aleatoria a valores reales $X$, el **valor en riesgo entrópico** 
(entropic value at risk) de $X$ al nivel de probabilidad $\alpha \in (0,1)$ está dado por
$$
\EVaR_{\alpha}( X ) = \inf\left\{ \frac{1}{t} \ln\left( \frac{M_X( t )}{1 - \alpha} \right) \middle| t > 0 \right\}
$$
:::

::: {.proposition #EVaRcohe name="Coherencia de la medida EVaR"}
La medida de riesgo $\EVaR_{\alpha}$ es una medida de riesgo coherente.
:::

::: {.example #l6ex2}
Podemos considerar el caso particular donde todos los reclamos se suponen independientes e 
idénticamente distribuidos (i.i.d), en este caso con distribución $X_i \rightsquigarrow LN(\mu,\sigma)$
```{r l7c2}
set.seed(94312)
u <- 4
s <- 0.5
n <- 1e4
X <- rlnorm( n, meanlog = u, sdlog = s )
alpha <- seq( 0, 1, 0.01 ) 
VaRX <- quantile( X, probs = alpha, names = FALSE )
TVaRX <- sapply( 
  1:length( VaRX ), 
  FUN = function( i ) ifelse( alpha[ i ] < 1, ( 1 / ( 1 - alpha[ i ] ) ) * mean( X * ( X > VaRX[ i ] ) ), max( X ) ) )
```

```{r l7g1, out.width='80%', out.height='450px', fig.align='center', class.source = 'fold-hide'}
plt <- ggplot() +
  geom_point( aes( x = alpha, y = VaRX ), colour = 'darkred' ) + 
  geom_point( aes( x = alpha, y = TVaRX ), colour = 'orange' ) + 
  xlab( TeX( "$\\alpha$" ) ) + 
  ylab( TeX( "$VaR,TVaR$" ) ) + 
  theme_bw()
plot( plt )
```
:::

<!------------------------------------------------------------------------------------------------->
## Tarificación en grandes términos {#tarificacion_grandes_terminos}

La tarificación que conlleva a la selección de la prima $\Pi$ debe tomar en cuenta como se manejan y 
equilibran los activos y pasivos en el negocio asegurador.

**Pasivos**

1. Capitales propios

2. Reservas técnicas

3. Reservas para otros riesgos

4. Deudas o depósitos en dinero recibidos por cesiones

5. Otras deudas por pagar


**Activos**

1. Capital suscrito no desembolsado

2. Activos no materiales

3. Inversiones

4. Parte de reaseguros en reservas técnicas

5. Deudas por cobrar

6. Otros activos

En el proceso de tarificación no es pertinente incluir todos los activos de la empresa, ya que 
muchos de estos no tienen la liquidez necesaria como para ser considerados un tipo de activo 
viable para la tarificación. Tampoco se toma en cuenta el dinero recibido por la cesión de primas
en un ramo en particular, ya que esto constituye un nivel más arriba propio del negocio 
reasegurador.

En términos generales se busca equilibrar el resultado operativo del ramo de negocio $R$ a lo largo 
de la vida del ramo. El resultado $R$ a su vez está dado por la siguiente relación:
$$
R = \Pi + I - S - G - K
$$
donde las variables a considerarse en principio son:

1. $\Pi$ Ingreso por primas

2. $I$ Ingreso por inversiones

3. $S$ Pago de siniestros

4. $G$ Gastos agregados, incluyendo gastos de emisión, operativos, gastos por reclamos

5. $K$ Coste de capital, esencialmente es el retorno que se espera sobre el capital invertido por 
los inversores para mantener el nivel de solvencia del ramo.

En varias ocasiones el ciclo del negocio puede ser corto plazo y no permite considerar un ingreso 
por inversiones $I = 0$.
$$
R = \Pi - S - G - K
$$

Sería ideal que a lo largo de la vida del ramo el resultado mantenga $R > 0$, pero al tratarse de 
un negocio que depende de la aleatoriedad de los reclamos, es bastante complicado encontrar un 
costo de capital $K$ y una prima $\Pi$ que siempre asegure ante todo escenario que se mantenga 
la positividad. Ante este riesgo continuo se busca minimizar la **probabilidad de ruina**, es decir,
acotar la probabilidad del evento $R < 0$ a un nivel de confianza $\alpha > 0$ adecuado
$$
P( R < 0 ) < \alpha
$$

Muchas de las veces se parte del principio de equilibrio financiero \@ref(sec:equifin), donde 
se busca la igualdad $\E[R] = 0$, la misma implica la siguiente relación:
$$
\begin{eqnarray*}
0 & = & \E[R] \\
0 & = & \E[R\mid R \geq 0]P( R \geq 0 ) + \E[R\mid R < 0]P( R < 0 ) \\
\E[R\mid R \geq 0]P( R \geq 0 ) & = & -\E[R\mid R < 0]P( R < 0 ) \\
\frac{P( R < 0 )}{P( R \geq 0 ) } & = & -\frac{\E[R\mid R \geq 0]}{\E[R\mid R < 0]}
\end{eqnarray*}
$$
en el equilibrio financiero, la proporción de la probabilidad de ruina respecto de la probabilidad
de no estar en ruina es igual a la proporción entre la esperanza condicional del resultado cuando 
no se produce la ruina respecto de la esperanza condicional cuando si se produce la ruina. 

Un modelo puede estar equilibrado financieramente $\E[R] = 0$, pero se desconoce la 
probabilidad de ruina $P( R < 0)$, esta podría ser muy grande. La razón anterior permite estimar
la relevancia de la probabilidad de ruina en un modelo equilibrado, con el uso de las esperanzas
condicionales.

Es usual asumir que la única parte aleatoria de $R$ viene dada por el valor de los reclamos totales,
en razón de esto se tiene:
$$
\E[ R ] 
= \E[ \Pi - S - G - K ] 
= \Pi - \E[S] - G - K
$$

El **coste de capital** $K$ como ya lo mencionamos es el retorno mínimo esperado por los inversores 
sobre el capital invertido. Usualmente este capital puede ser visto como un porcentaje 
$r > 0$ que se toma sobre el capital colocado para mantener un nivel de solvencia adecuado 
sobre el valor esperado  $\E[S]$ del total de reclamos $S$. Para ello se suele utilizar precisamente
una medida de **medida de riesgo** $\rho$ que permita mantener el nivel de solvencia.
$$
K = r\left( \rho( S ) - \E[S] \right)
$$
con esta perspectiva
$$
\E[ R ] 
= \E\left[ \Pi - S - G - r\left( \rho( S ) - \E[S] \right) \right] 
= \Pi - \E[S] - G - r \left( \rho(S) - \E[S] \right)
$$
Lo que se busca es evitar la ruina y por tanto se busca cubrirse ante el evento $R < 0$, desde una 
perspectiva probabilista esto se puede realizar seleccionando un nivel de cobertura $\alpha > 0$, 
que acote la probabilidad del evento de ruina.
$$
P( R < 0 ) 
= P( \Pi - S - G - K < 0 )
= P\left( \Pi - S - G - r\left( \rho(S) - \E[S] \right) < 0 \right) < \alpha.
$$

De la relación anterior se observa que una vez seleccionado el nivel de cobertura $\alpha$ y la 
medida de riesgo $\rho$, las variables correspondientes a la prima $\Pi$ y a los gastos $G$ quedan 
libres, de ahí resulta un margen que permite seleccionar la prima más óptima para un producto de 
seguro, así como también optimizar los gastos $G$. Este proceso de selección es precisamente lo que 
llamamos en este contexto como **tarificación** (pricing).

Razonando un poco más al respecto, si asumimos que se dispone de la distribución acumulada $F_S$
de $S$, se puede obtener las siguientes expresiones:
$$
\begin{eqnarray*}
P\left( \Pi - S - G - K < 0 \right) & < & \alpha \\
P\left( S > \Pi - G - K \right) & < & \alpha  \\
1 - P\left( S \leq \Pi - G - K \right) & < & \alpha \\
P\left( S \leq \Pi - G - K \right) & > & 1 - \alpha \\
F_S\left( \Pi - G - K \right) & > & 1 - \alpha \\
F_S\left( \Pi - G - K \right) & \in & \left( 1 - \alpha, +\infty \right), \qquad
\text{la desigualdad anterior es equivalente a la inclusión}\\
\Pi - G - K & \in & F_S^{-1}\left( \left( 1 - \alpha, +\infty \right) \right),\qquad
\text{por propiedades de la inversión de funciones}\\
\Pi & \geq & G + K + F_S^{-1}\left( 1 - \alpha \right), \qquad 
\text{com $F_S$ es creciente, mínimo se debe satisfacer la desigualdad}
\end{eqnarray*}
$$
En especial cuando $K = r\left( \rho(S) - \E[S] \right)$, la última desigualdad toma la forma
$$
\Pi \geq G + r\left( \rho(S) - \E[S] \right) + F_S^{-1}\left( 1 - \alpha \right)
$$

Así, en el caso anterior si se utiliza como medida de riesgo al mismo nivel de confianza $1 - \alpha$, 
esto es $\rho( S ) = \VaR_{1-\alpha}( S ) = F_S^{-1}( 1 - \alpha )$, la última igualdad se cumple si $S$
es una variable aleatoria continua.
$$
\Pi \geq G + (1 + r) F_S^{-1}\left( 1 - \alpha \right) - r \E[S] 
$$

Si en caso los gastos $G$ son proporcionales a la prima $G = \gamma \Pi$, para una constante 
$\gamma > 0$, y seguramente $\gamma < 1$ ya que es de esperar gastos no mayores a la misma prima, 
sino esto estaría en una situación insostenible donde los gastos son mayores a la cobertura del 
riesgo. Las desigualdades anteriores toman la forma:
$$
\begin{eqnarray*}
\Pi & \geq & \frac{r}{1 - \gamma} K + \frac{1}{1 - \gamma} F_S^{-1}\left( 1 - \alpha \right) \\
\Pi & \geq & \frac{r}{1 - \gamma} \left( \rho(S) - \E[S] \right) + \frac{1}{1 - \gamma} F_S^{-1}\left( 1 - \alpha \right) \\
\Pi & \geq &  \frac{1 + r}{1 - \gamma} F_S^{-1}\left( 1 - \alpha \right) -  \frac{r}{1 - \gamma} \E[S]
\end{eqnarray*}
$$

De lo anterior se observa, que un buen inicio para estimar la prima de riesgo es ciertamente 
usar la medida $\VaR_{1-\alpha}$ al nivel adecuado de confianza $\alpha$.

<!------------------------------------------------------------------------------------------------->
## Prima {#prima}
La prima es la cantidad de dinero que un individuo o entidad pagan por una póliza de seguro, la cual
está diseñada para cubrir ciertos riesgos personales o comerciales.

La determinación de las primas por parte del asegurador hace uso de la mutualización del riesgo y
diversificación, para así poder asumir la transferencia del riesgo por parte de sus asegurados. Así
por tanto, es deseable que cualquier método que se utilice para la estimación de primas, se 
satisfaga, algunas propiedades importantes.

Sin consideramos dos riesgos a cubrir $S_1$ y $S_2$, entonces la función que estima $\rho$ las primas 
sería aconsejable satisfaga las siguientes propiedades.

1. Si se decide cubrir por completo dos riesgos $S_1$ y $S_2$ en un mismo producto, el valor de la 
prima deberá ser menor o igual al valor que se resultaría de cubrir cada uno de los riesgos con 
productos separados.
$$
\rho( S_1 + S_2 ) \leq \rho( S_1 ) + \rho( S_2 )
$$

2. El asumir mayor riesgo debe tener como consecuencia el aumento de la prima
$$
\rho( S_1 ) \leq \rho( S_1 + S_2 )
$$
Esta propiedad implica que al configurar un producto de seguro con mejor cobertura, se espera 
una prima de mayor costo.

3. Si el riesgo a cubrir está limitado, es decir $P( S \leq M ) = 1$, para un valor $M > 0$, 
entonces jamás la prima será superior a $M$
$$
\rho( S ) \leq M
$$
Esto se traduce a que ningún asegurado estará interesado en adquirir una póliza para cubrir un 
riesgo por encima del valor total asegurado.

Es así que hay algunos principios para la estimación de primas, aquí citamos algunos de los más 
conocidos:

1. Prima neta, o prima pura de riesgo
$$
  \Pi = \rho( S ) = \E[S] \approx \overline{S}
$$

2. Prima de riesgo con recargo sobre la esperanza matemática
$$
  \Pi = \rho( S ) = (1 + \rho) \E[S] \approx (1 + \rho) \overline{S}
$$

3. Prima de riesgo con recargo sobre la varianza
$$
  \Pi = \rho( S ) = \E[S] + \rho \V[S] 
  \approx \overline{S} + \rho \sigma_S^2
$$

4. Prima de riesgo con recargo sobre la desviación
$$
  \Pi = \rho( S ) = \E[S] + \rho \sqrt{\V[S]}
  \approx \overline{S} + \rho \sigma_S
$$ 

5. Prima de riesgo con principio exponencial para $t > 0$
$$
  \Pi = \rho( S )
  = \frac{1}{2} \E\left[\exp(tS)\right]
  = \frac{1}{2} M_N\big( \ln M_X( t ) \big)
  \approx \frac{1}{m} \sum\limits_{i=1}^m \exp\left(t S_i\right)
$$

6. Prima de percentiles para un valor de confianza $\alpha \in [0,1]$ o prima de valor en riesgo 
$VaR_\alpha$
$$
  \Pi = \rho( S ) = \VaR_\alpha( S ) =  F_S^{-1}( \alpha )
$$

7. Prima de valor en riesgo en la cola (Tail Value at Risk) $TVaR_\alpha$. Es el promedio uniforme
de todos los valores en riesgo $VaR_u$, con $u \geq \alpha$.
$$
  \Pi = \rho( S ) = \TVaR_\alpha( S ) = \frac{1}{1-\alpha} \int\limits_{\alpha}^1 \VaR_u( S )\ du
$$

::: {.example #l6ex2}
Consideremos el caso donde todos los siniestros son igualmente distribuidos e independientes (i.i.d) 
$X_i \rightsquigarrow Gamma( \alpha_i, \theta )$, para $i \in \{1,\ldots,n\}$, el número de 
unidades aseguradas está dado por $n \in \N$. Utilizaremos el modelo individual para
la agregación de los reclamos y obtener el reclamo total $S = \sum\limits_{i=1}^n X_i$.

Como todas las variables $X_i$ siguen una ley $Gamma( \alpha_i, \theta )$, sabemos que la 
familia $Gamma$ es cerrada por adición, es decir, a suma de variables aleatorias con ley $Gamma$
también sigue una ley $Gamma$. En este caso en particular para el reclamo total tenemos que 
$S \rightsquigarrow Gamma\left( \sum\limits_{i=1}^n \alpha_i, \theta \right)$.

Es de notar que para cada $i\in \{1,\ldots,n\}$, la variable aleatoria $X_i$ correspondiente al
$i$-ésimo reclamo tiene como parámetro un diferente factor $\alpha_i$, pero el mismo factor 
$\theta$. 

Ya que cada $X_i \rightsquigarrow Gamma( \alpha_i, \theta )$, podemos calcular de forma determinista
las esperanzas de $\E[X_i]$, para cada $i \in \{1,\ldots,n\}$ y de igual forma podemos 
calcular la esperanza del reclamo total $\E[S] = \sum\limits_{i=1}^n \E[X_i]$. 
Además como asumimos independencia entre los $X_i$, la varianza de $S$ también puede ser calculada
fácilmente como $\V[S] = \sum\limits_{i=1}^n \V[X_i]$.

También estamos en la capacidad de simular la variable $S$ utilizando un algoritmo de aleatorio, 
para así aproximar los cálculos de sus momentos y otros estadísticos. Primeramente definamos los 
parámetros.
```{r l7c3}
# número de unidades aseguradas
n <- 1000

# parámetros para cada X_i
a <- runif( n, 5, 10 )

# parámetro theta, común a todas las X_i
theta <- 4

# parámetro para S
A <- sum( a )
```

```{r l7c4}
EX <- a * theta
VX <- a * theta^2
ES <- sum( EX )
VS <- sum( VX )
SDS <- sqrt( VS )
```

La variable aleatoria del reclamo total $S$ la podemos simular tomando una muestra i.i.d de tamaño $m$, 
i.e. $S_1,\ldots,S_m$ de la distribución $Gamma\left( \sum\limits_{i=1}^n \alpha_i, \theta \right)$.
```{r l7c5}
m <- 1e5
S <- rgamma( m, shape = A, scale = theta )
``` 

Prima pura:
```{r l7c6}
P <- ES
P <- mean( S )

alpha <- 0.95
P_avg <- ( 1 + alpha ) * ES
P_avg <- ( 1 + alpha ) * mean( S )

P_var <- ES + alpha * VS
P_var <- mean( S ) + alpha * var( S )

P_sde <- ES + alpha * SDS
P_sde <- mean( S ) + alpha * sd( S )

VaRS <- qgamma( alpha, shape = A, scale = theta )
P_VaR <- VaRS
P_VaR <- quantile( S, probs = alpha )

P_TVaR <- ( 1 / ( 1 - alpha ) ) * ( A * theta ) * ( 1 - pgamma( VaRS, shape = A + 1, scale = theta ) )
P_TVaR <- ( 1 / ( 1 - alpha ) ) * integrate( f = function( u ) qgamma( u, shape = A, scale = theta ), alpha, 1 )$value
P_TVaR <- mean( sapply( runif( m, alpha, 1 ), FUN = function( k ) qgamma( k, shape = A, scale = theta ) ) )
I <- as.numeric( S > VaRS )
P_TVaR <- mean( S * I ) / mean( I )
```
:::

<!------------------------------------------------------------------------------------------------->
## Segmentación

En muchas ocasiones es necesario tener en cuenta algunas características asociadas al riesgo 
de asegurado, de tal forma que la prima sea lo más eficiente y adecuado según el riesgo cubierto y
las características del mismo. La idea de segmentar la población es obtener grupos homogéneos 
con riesgos similares.


```{r l6end, echo = FALSE}
rm( list = ls()[ ls() != 'def.chunk.hook' ] )
```
